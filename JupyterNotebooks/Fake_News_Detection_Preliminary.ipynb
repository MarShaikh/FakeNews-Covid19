{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from time import time\n",
    "from tensorflow.keras.models import Sequential, load_model, model_from_json\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, LSTM, Embedding, Reshape\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from os import mkdir, makedirs, remove, listdir\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from python_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glove vector data \n",
    "with open('glove.6B/glove.6B.50d.txt','rb') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "glove_weights = np.zeros((len(lines), 50))\n",
    "words = []\n",
    "for i, line in enumerate(lines):\n",
    "    word_weights = line.split()\n",
    "    words.append(word_weights[0])\n",
    "    weight = word_weights[1:]\n",
    "    glove_weights[i] = np.array([float(w) for w in weight])\n",
    "word_vocab = [w.decode(\"utf-8\") for w in words]\n",
    "\n",
    "word2glove = dict(zip(word_vocab, glove_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Layer\n",
    "# import tensorflow.keras.backend as K\n",
    "# from tensorflow.keras import initializers\n",
    "# import numpy as np\n",
    "\n",
    "# class Embedding2(Layer):\n",
    "\n",
    "#     def __init__(self, input_dim, output_dim, fixed_weights, embeddings_initializer='uniform', \n",
    "#                  input_length=None, **kwargs):\n",
    "#         kwargs['dtype'] = 'int32'\n",
    "#         if 'input_shape' not in kwargs:\n",
    "#             if input_length:\n",
    "#                 kwargs['input_shape'] = (input_length,)\n",
    "#             else:\n",
    "#                 kwargs['input_shape'] = (None,)\n",
    "#         super(Embedding2, self).__init__(**kwargs)\n",
    "    \n",
    "#         self.input_dim = input_dim\n",
    "#         self.output_dim = output_dim\n",
    "#         self.embeddings_initializer = embeddings_initializer\n",
    "#         self.fixed_weights = fixed_weights\n",
    "#         self.num_trainable = input_dim - len(fixed_weights)\n",
    "#         self.input_length = input_length\n",
    "        \n",
    "#         w_mean = fixed_weights.mean(axis=0)\n",
    "#         w_std = fixed_weights.std(axis=0)\n",
    "#         self.variable_weights = w_mean + w_std*np.random.randn(self.num_trainable, output_dim)\n",
    "\n",
    "#     def build(self, input_shape, name='embeddings'):        \n",
    "#         fixed_weight = K.variable(self.fixed_weights, name=name+'_fixed')\n",
    "#         variable_weight = K.variable(self.variable_weights, name=name+'_var')\n",
    "        \n",
    "#         self._trainable_weights.append(variable_weight)\n",
    "#         self._non_trainable_weights.append(fixed_weight)\n",
    "        \n",
    "#         self.embeddings = K.concatenate([fixed_weight, variable_weight], axis=0)\n",
    "        \n",
    "#         self.built = True\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         if K.dtype(inputs) != 'int32':\n",
    "#             inputs = K.cast(inputs, 'int32')\n",
    "#         out = K.gather(self.embeddings, inputs)\n",
    "#         return out\n",
    "\n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         if not self.input_length:\n",
    "#             input_length = input_shape[1]\n",
    "#         else:\n",
    "#             input_length = self.input_length\n",
    "#         return (input_shape[0], input_length, self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('liar_dataset/test.tsv', delimiter = '\\t' ,encoding = 'utf-8')\n",
    "df.columns = ['ID', 'label', 'statement','subjects','speaker','speakersJobTitle', 'state_info', 'party_afflin','bt_c', 'f_c', 'ht_c', 'mt_c', 'pof_c', 'context']\n",
    "df.ID = df.ID.str.lower()\n",
    "df.statement = df.statement.str.lower()\n",
    "df.subjects = df.subjects.str.lower()\n",
    "df.speaker = df.speaker.str.lower()\n",
    "df.speakersJobTitle = df.speakersJobTitle.str.lower()\n",
    "df.state_info = df.state_info.str.lower()\n",
    "df.party_afflin = df.party_afflin.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('ID', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subjects</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speakersJobTitle</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_afflin</th>\n",
       "      <th>bt_c</th>\n",
       "      <th>f_c</th>\n",
       "      <th>ht_c</th>\n",
       "      <th>mt_c</th>\n",
       "      <th>pof_c</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false</td>\n",
       "      <td>wisconsin is on pace to double the number of l...</td>\n",
       "      <td>jobs</td>\n",
       "      <td>katrina-shankland</td>\n",
       "      <td>state representative</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a news conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>false</td>\n",
       "      <td>says john mccain has done nothing to help the ...</td>\n",
       "      <td>military,veterans,voting-record</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>president-elect</td>\n",
       "      <td>new york</td>\n",
       "      <td>republican</td>\n",
       "      <td>63</td>\n",
       "      <td>114</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>comments on ABC's This Week.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>half-true</td>\n",
       "      <td>suzanne bonamici supports a plan that will cut...</td>\n",
       "      <td>medicare,message-machine-2012,campaign-adverti...</td>\n",
       "      <td>rob-cornilles</td>\n",
       "      <td>consultant</td>\n",
       "      <td>oregon</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a radio show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pants-fire</td>\n",
       "      <td>when asked by a reporter whether hes at the ce...</td>\n",
       "      <td>campaign-finance,legal-issues,campaign-adverti...</td>\n",
       "      <td>state-democratic-party-wisconsin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>a web video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true</td>\n",
       "      <td>over the past five years the federal governmen...</td>\n",
       "      <td>federal-budget,pensions,retirement</td>\n",
       "      <td>brendan-doherty</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rhode island</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a campaign website</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                          statement  \\\n",
       "0       false  wisconsin is on pace to double the number of l...   \n",
       "1       false  says john mccain has done nothing to help the ...   \n",
       "2   half-true  suzanne bonamici supports a plan that will cut...   \n",
       "3  pants-fire  when asked by a reporter whether hes at the ce...   \n",
       "4        true  over the past five years the federal governmen...   \n",
       "\n",
       "                                            subjects  \\\n",
       "0                                               jobs   \n",
       "1                    military,veterans,voting-record   \n",
       "2  medicare,message-machine-2012,campaign-adverti...   \n",
       "3  campaign-finance,legal-issues,campaign-adverti...   \n",
       "4                 federal-budget,pensions,retirement   \n",
       "\n",
       "                            speaker      speakersJobTitle    state_info  \\\n",
       "0                 katrina-shankland  state representative     wisconsin   \n",
       "1                      donald-trump       president-elect      new york   \n",
       "2                     rob-cornilles            consultant        oregon   \n",
       "3  state-democratic-party-wisconsin                   NaN     wisconsin   \n",
       "4                   brendan-doherty                   NaN  rhode island   \n",
       "\n",
       "  party_afflin  bt_c  f_c  ht_c  mt_c  pof_c                       context  \n",
       "0     democrat     2    1     0     0      0             a news conference  \n",
       "1   republican    63  114    51    37     61  comments on ABC's This Week.  \n",
       "2   republican     1    1     3     1      1                  a radio show  \n",
       "3     democrat     5    7     2     2      7                   a web video  \n",
       "4   republican     1    2     1     1      0            a campaign website  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of unique words in glove vectors:  0.6779039301310044\n",
      "The number of unique words are:  5725\n",
      "The first review looks like this: \n",
      "[112, 8, 10, 1690, 3, 797, 0, 204, 2, 1691, 36, 3883]\n",
      "And once this is converted back to words, it looks like: \n",
      "wisconsin is on pace to double the number of layoffs this year.\n"
     ]
    }
   ],
   "source": [
    "#creating a list where words are converted into ints\n",
    "all_text = ' '.join(df.statement.values)\n",
    "words = all_text.split()\n",
    "u_words = Counter(words).most_common()           #in the form of [('the', 1208), ('<word>', <count>), ...]\n",
    "u_words_counter = u_words\n",
    "u_words_frequent = [word[0] for word in u_words if word[1] > 5]      #in the form of ['the', '<word>', ...]\n",
    "\n",
    "u_words_total = [k for k,v in u_words_counter]                       #in the form of ['the', '<word>', ...]\n",
    "word_vocab = dict(zip(word_vocab, range(len(word_vocab))))           #in the form of {'the':<num>, ...}\n",
    "word_in_glove = np.array([w in word_vocab for w in u_words_total])   \n",
    "\n",
    "words_in_glove = [w for w,is_true in zip(u_words_total,word_in_glove) if is_true]   #[True, False, False ..] array\n",
    "words_not_in_glove = [w for w,is_true in zip(u_words_total,word_in_glove) if not is_true]\n",
    "\n",
    "\n",
    "print('Fraction of unique words in glove vectors: ', sum(word_in_glove)/len(word_in_glove))\n",
    "\n",
    "# # create the dictionary\n",
    "word2num = dict(zip(words_in_glove,range(len(words_in_glove))))\n",
    "len_glove_words = len(word2num)\n",
    "freq_words_not_glove = [w for w in words_not_in_glove if w in u_words_frequent]\n",
    "b = dict(zip(freq_words_not_glove,range(len(word2num), len(word2num)+len(freq_words_not_glove))))\n",
    "word2num = dict(**word2num, **b)\n",
    "word2num['<Other>'] = len(word2num)\n",
    "num2word = dict(zip(word2num.values(), word2num.keys()))\n",
    "\n",
    "int_text = [[word2num[word] if word in word2num else word2num['<Other>'] \n",
    "             for word in content.split()] for content in df.statement.values]\n",
    "\n",
    "print('The number of unique words are: ', len(u_words))\n",
    "print('The first review looks like this: ')\n",
    "print(int_text[0][:20])\n",
    "print('And once this is converted back to words, it looks like: ')\n",
    "print(' '.join([num2word[i] for i in int_text[0][:20]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAC+dJREFUeJzt3X+o3fddx/Hny6Rdt9WxxN6E2BRvB2EahtpyKdXKELOxrStL/ilU6AhSyT86OxXGrQOH/02RMf8QIbSTwOpG6QoJ7VBDtiH+03nTdNqa1XSbdnXX5M4xN/1jW93bP86XeRfuzT33V+697/N8wOWc7/d8T87nvv945pvvuecmVYUkaef7ia1egCRpYxh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklN7L6eL3bLLbfU9PT09XxJSdrxzp8//82qmlrpuOsa9Onpaebm5q7nS0rSjpfk38Y5zksuktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqYmxgp7kd5O8mOSFJJ9KclOSvUnOJrk03O7Z7MVKkpa3YtCT3Ar8DjBTVW8DdgEPALPAuao6BJwbtiVJW2TcSy67gdcn2Q28AfgGcBQ4NTx+Cji28cuTJI1rxaBX1b8Dfwq8AswD/1VVfwvsr6r54Zh5YN9Sz09yIslckrmFhYWNW7kk6ceMc8llD6Oz8duBnwbemOTBcV+gqk5W1UxVzUxNTa19pZKkaxrnkss7gK9V1UJV/QB4Cvhl4HKSAwDD7ZXNW6YkaSXjBP0V4O4kb0gS4AhwETgDHB+OOQ6c3pwlSpLGsXulA6rq2SRPAs8BrwEXgJPAzcATSR5iFP37N3OhkqRrWzHoAFX1EeAjV+3+HqOzdUnSNuAnRSWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWqiTdCnZ5/Z6iVI0pZqE3RJmnQGXZKaMOiS1IRBl6QmWgXdN0YlTbJWQZekSWbQJakJgy5JTRh0SWpixwfdN0IlaWTHB12SNGLQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJloG3f/0QtIkGivoSd6c5MkkX05yMckvJdmb5GySS8Ptns1erCRpeeOeof8Z8NdV9bPALwAXgVngXFUdAs4N25KkLbJi0JO8CXg78BhAVX2/qr4NHAVODYedAo5t1iIlSSsb5wz9LcAC8JdJLiR5NMkbgf1VNQ8w3O5b6slJTiSZSzK3sLCwYQuXJP24cYK+G7gT+IuqugP4H1ZxeaWqTlbVTFXNTE1NrXGZkqSVjBP0V4FXq+rZYftJRoG/nOQAwHB7ZXOWKEkax4pBr6r/AL6e5K3DriPAPwNngOPDvuPA6U1ZoSRpLLvHPO4DwONJbgS+CvwGo78MnkjyEPAKcP/mLFGSNI6xgl5VzwMzSzx0ZGOXI0laq5afFJWkSWTQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktTE2EFPsivJhSRPD9t7k5xNcmm43bN5y5QkrWQ1Z+gPAxcXbc8C56rqEHBu2JYkbZGxgp7kIPBe4NFFu48Cp4b7p4BjG7s0SdJqjHuG/nHgQ8APF+3bX1XzAMPtvqWemOREkrkkcwsLC+tarCRpeSsGPcl9wJWqOr+WF6iqk1U1U1UzU1NTa/kjJElj2D3GMfcA70tyL3AT8KYknwQuJzlQVfNJDgBXNnOhkqRrW/EMvaoeqaqDVTUNPAB8rqoeBM4Ax4fDjgOnN22VkqQVrefn0D8KvDPJJeCdw7YkaYusKuhV9YWqum+4/59VdaSqDg2339qcJW6M6dlntnoJkrSp/KSoJDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYmLuj+RxeSupq4oEtSVwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJamJFYOe5LYkn09yMcmLSR4e9u9NcjbJpeF2z+YvV5K0nHHO0F8Dfr+qfg64G/itJIeBWeBcVR0Czg3bkqQtsmLQq2q+qp4b7n8XuAjcChwFTg2HnQKObdYiJUkrW9U19CTTwB3As8D+qpqHUfSBfRu9OEnS+MYOepKbgc8AH6yq76zieSeSzCWZW1hYWMsaJUljGCvoSW5gFPPHq+qpYfflJAeGxw8AV5Z6blWdrKqZqpqZmpraiDVLkpYwzk+5BHgMuFhVH1v00Bng+HD/OHB645cnSRrX7jGOuQd4P/BPSZ4f9v0B8FHgiSQPAa8A92/OEiVJ41gx6FX190CWefjIxi5HkrRWflJUkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEEHpmefYXr2ma1ehiSti0GXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBv0q/viipJ3KoEtSEwZdkpow6It4uUXSTmbQJamJHRV0z6AlaXnrCnqSdyd5KcnLSWY3alGSpNVbc9CT7AL+HHgPcBj49SSHN2phW81/DUjaKNerJ+s5Q78LeLmqvlpV3wc+DRzdmGVJklZrPUG/Ffj6ou1Xh32SpC2QqlrbE5P7gXdV1W8O2+8H7qqqD1x13AngxLD5VuClNbzcLcA317TQ/pzN8pzN8pzN8rbjbH6mqqZWOmj3Ol7gVeC2RdsHgW9cfVBVnQROruN1SDJXVTPr+TO6cjbLczbLczbL28mzWc8ll38ADiW5PcmNwAPAmY1ZliRptdZ8hl5VryX5beBvgF3AJ6rqxQ1bmSRpVdZzyYWq+izw2Q1ay7Ws65JNc85mec5mec5meTt2Nmt+U1SStL3sqI/+S5KWt62DPum/WiDJJ5JcSfLCon17k5xNcmm43bPosUeGWb2U5F1bs+rrI8ltST6f5GKSF5M8POyf+PkkuSnJF5N8aZjNHw37J342MPqUe5ILSZ4etvvMpaq25RejN1q/ArwFuBH4EnB4q9d1nWfwduBO4IVF+/4EmB3uzwJ/PNw/PMzodcDtw+x2bfX3sImzOQDcOdz/SeBfhhlM/HyAADcP928AngXudjY/ms/vAX8FPD1st5nLdj5Dn/hfLVBVfwd866rdR4FTw/1TwLFF+z9dVd+rqq8BLzOaYUtVNV9Vzw33vwtcZPRJ5YmfT43897B5w/BVOBuSHATeCzy6aHebuWznoPurBZa2v6rmYRQ1YN+wf2LnlWQauIPRmajz4UeXFZ4HrgBnq8rZjHwc+BDww0X72sxlOwc9S+zzR3KWN5HzSnIz8Bngg1X1nWsdusS+tvOpqv+tql9k9Anuu5K87RqHT8RsktwHXKmq8+M+ZYl923ou2znoY/1qgQl0OckBgOH2yrB/4uaV5AZGMX+8qp4adjufRarq28AXgHfjbO4B3pfkXxldwv21JJ+k0Vy2c9D91QJLOwMcH+4fB04v2v9AktcluR04BHxxC9Z3XSQJ8Bhwsao+tuihiZ9Pkqkkbx7uvx54B/BlJnw2VfVIVR2sqmlGPflcVT1Ip7ls9buyK7wbfS+jn174CvDhrV7PFnz/nwLmgR8wOlt4CPgp4Bxwabjdu+j4Dw+zegl4z1avf5Nn8yuM/vn7j8Dzw9e9zqcAfh64MMzmBeAPh/0TP5tF3++v8v8/5dJmLn5SVJKa2M6XXCRJq2DQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCb+D3tqXRXIz/uVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(t) for t in int_text], bins = 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of articles greater than 50 in length is:  211\n",
      "The number of articles less than 10 in length is:  59\n"
     ]
    }
   ],
   "source": [
    "print('The number of articles greater than 50 in length is: ', np.sum(np.array([len(t)>25 for t in int_text])))\n",
    "print('The number of articles less than 10 in length is: ', np.sum(np.array([len(t)<8 for t in int_text])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num2word[len(word2num)] = '<PAD>'\n",
    "word2num['<PAD>'] = len(word2num)\n",
    "\n",
    "for i, t in enumerate(int_text):\n",
    "    if len(t)<25:\n",
    "        int_text[i] = [word2num['<PAD>']]*(25-len(t)) + t\n",
    "    elif len(t)>25:\n",
    "        int_text[i] = t[:25]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "x = np.array(int_text)\n",
    "y = (df.label.values=='true').astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'over the past five years the federal government has paid out $601 million in retirement and disability benefits to deceased former federal employees.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label == 'true'].statement.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when asked by a reporter whether hes at the center of a criminal scheme to violate campaign laws, gov. scott walker nodded yes.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label == 'pants-fire'].statement.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 50)          196150    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 225,655\n",
      "Trainable params: 225,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word2num), 50))\n",
    "model.add(LSTM(64))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir = \"logs/{}\".format(time()))\n",
    "\n",
    "model.compile(loss = 'MSE', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 / 10\n",
      "Train on 1139 samples, validate on 127 samples\n",
      "1139/1139 [==============================] - 37s 33ms/sample - loss: 0.1654 - accuracy: 0.8086 - val_loss: 0.1128 - val_accuracy: 0.8740\n",
      "Epoch  2 / 10\n",
      "Train on 1139 samples, validate on 127 samples\n",
      "1139/1139 [==============================] - 22s 19ms/sample - loss: 0.1399 - accuracy: 0.8323 - val_loss: 0.1103 - val_accuracy: 0.8740\n",
      "Epoch  3 / 10\n",
      "Train on 1139 samples, validate on 127 samples\n",
      "1139/1139 [==============================] - 23s 20ms/sample - loss: 0.1374 - accuracy: 0.8323 - val_loss: 0.1120 - val_accuracy: 0.8740\n",
      "Epoch  4 / 10\n",
      "Train on 1139 samples, validate on 127 samples\n",
      "1139/1139 [==============================] - 22s 19ms/sample - loss: 0.1324 - accuracy: 0.8323 - val_loss: 0.1161 - val_accuracy: 0.8740\n",
      "Epoch  5 / 10\n",
      "Train on 1139 samples, validate on 127 samples\n",
      "1139/1139 [==============================] - 22s 19ms/sample - loss: 0.1106 - accuracy: 0.8341 - val_loss: 0.1261 - val_accuracy: 0.8740\n",
      "Epoch  6 / 10\n",
      "Train on 1139 samples, validate on 127 samples\n",
      "1139/1139 [==============================] - 20s 18ms/sample - loss: 0.0845 - accuracy: 0.8753 - val_loss: 0.1214 - val_accuracy: 0.8740\n",
      "Epoch  7 / 10\n",
      "Train on 1139 samples, validate on 127 samples\n",
      "1139/1139 [==============================] - 20s 18ms/sample - loss: 0.0647 - accuracy: 0.9306 - val_loss: 0.1286 - val_accuracy: 0.8740\n",
      "Epoch  8 / 10\n",
      "Train on 1139 samples, validate on 127 samples\n",
      "1139/1139 [==============================] - 20s 17ms/sample - loss: 0.0820 - accuracy: 0.9201 - val_loss: 0.1257 - val_accuracy: 0.8740\n",
      "Epoch  9 / 10\n",
      "Train on 1139 samples, validate on 127 samples\n",
      "1139/1139 [==============================] - 21s 18ms/sample - loss: 0.1663 - accuracy: 0.8323 - val_loss: 0.1217 - val_accuracy: 0.8740\n",
      "Epoch  10 / 10\n",
      "Train on 1139 samples, validate on 127 samples\n",
      "1139/1139 [==============================] - 22s 20ms/sample - loss: 0.1587 - accuracy: 0.8376 - val_loss: 0.1253 - val_accuracy: 0.8740\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "v = 0\n",
    "for i in range(epochs):\n",
    "    if i % (epochs//10) == 0 or i == epochs - 1:\n",
    "        v = 1\n",
    "        print('Epoch ',i+1,'/',epochs)\n",
    "        \n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=1, validation_data=(X_test, y_test),verbose=v, callbacks=[tensorboard])\n",
    "    v = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0124297]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Says the unemployment rate for college graduates is 4.4 percent and over 10 percent for noncollege-educated.\".lower()\n",
    "sentence_num = [word2num[w] if w in word2num else word2num['<Other>'] for w in sentence.split()]\n",
    "sentence_num = [word2num['<PAD>']]*(25-len(sentence_num)) + sentence_num\n",
    "sentence_num = np.array(sentence_num)\n",
    "model.predict(sentence_num[None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding2 (Embedding2)      (None, None, 50)          196150    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 225,655\n",
      "Trainable params: 31,605\n",
      "Non-trainable params: 194,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding2(len(word2num), 50,\n",
    "#                     fixed_weights=np.array([word2glove[w] for w in words_in_glove])))\n",
    "\n",
    "# model.add(LSTM(64))\n",
    "\n",
    "# model.add(Dense(1, activation = 'sigmoid'))\n",
    "# model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1139 samples, validate on 127 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding2/embeddings_var:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding2/embeddings_var:0'] when minimizing the loss.\n",
      "1139/1139 [==============================] - 23s 20ms/sample - loss: 0.4734 - accuracy: 0.8253 - val_loss: 0.3828 - val_accuracy: 0.8740\n",
      "Epoch 2/10\n",
      "1139/1139 [==============================] - 19s 17ms/sample - loss: 0.4552 - accuracy: 0.8323 - val_loss: 0.3775 - val_accuracy: 0.8740\n",
      "Epoch 3/10\n",
      "1139/1139 [==============================] - 24s 21ms/sample - loss: 0.4516 - accuracy: 0.8323 - val_loss: 0.3745 - val_accuracy: 0.8740\n",
      "Epoch 4/10\n",
      "1139/1139 [==============================] - 20s 17ms/sample - loss: 0.4459 - accuracy: 0.8323 - val_loss: 0.3784 - val_accuracy: 0.8740\n",
      "Epoch 5/10\n",
      "1139/1139 [==============================] - 19s 17ms/sample - loss: 0.4439 - accuracy: 0.8323 - val_loss: 0.3674 - val_accuracy: 0.8740\n",
      "Epoch 6/10\n",
      "1139/1139 [==============================] - 19s 16ms/sample - loss: 0.4389 - accuracy: 0.8323 - val_loss: 0.3940 - val_accuracy: 0.8740\n",
      "Epoch 7/10\n",
      "1139/1139 [==============================] - 19s 16ms/sample - loss: 0.4351 - accuracy: 0.8323 - val_loss: 0.3764 - val_accuracy: 0.8740\n",
      "Epoch 8/10\n",
      "1139/1139 [==============================] - 19s 16ms/sample - loss: 0.4295 - accuracy: 0.8323 - val_loss: 0.3697 - val_accuracy: 0.8740\n",
      "Epoch 9/10\n",
      "1139/1139 [==============================] - 19s 16ms/sample - loss: 0.4317 - accuracy: 0.8323 - val_loss: 0.3713 - val_accuracy: 0.8740\n",
      "Epoch 10/10\n",
      "1139/1139 [==============================] - 19s 17ms/sample - loss: 0.4231 - accuracy: 0.8332 - val_loss: 0.4095 - val_accuracy: 0.8661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a7fa54e50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19414745]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence = \"Says the unemployment rate for college graduates is 4.4 percent and over 10 percent for noncollege-educated.\".lower()\n",
    "# sentence_num = [word2num[w] if w in word2num else word2num['<Other>'] for w in sentence.split()]\n",
    "# sentence_num = [word2num['<PAD>']]*(500-len(sentence_num)) + sentence_num\n",
    "# sentence_num = np.array(sentence_num)\n",
    "# model.predict(sentence_num[None,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FakeNews] *",
   "language": "python",
   "name": "conda-env-FakeNews-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

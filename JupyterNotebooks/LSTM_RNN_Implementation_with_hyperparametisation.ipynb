{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "LSTM_RNN_Implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PmulUWcFHGsm"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3jqXYq_HGq6",
        "colab_type": "text"
      },
      "source": [
        "# Model without spatio temporal features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvou8khGRpI6",
        "colab_type": "code",
        "outputId": "aedf9ea5-9acc-49ab-a8a3-be62d540e0a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1PhkenXi3yG",
        "colab_type": "code",
        "outputId": "67e5d8cd-4a4c-431e-c0d6-129b56db0004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install talos"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: talos in /usr/local/lib/python3.6/dist-packages (0.6.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from talos) (2.23.0)\n",
            "Requirement already satisfied: kerasplotlib in /usr/local/lib/python3.6/dist-packages (from talos) (0.1.6)\n",
            "Requirement already satisfied: chances in /usr/local/lib/python3.6/dist-packages (from talos) (0.1.9)\n",
            "Requirement already satisfied: keras==2.3.0 in /usr/local/lib/python3.6/dist-packages (from talos) (2.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from talos) (1.0.3)\n",
            "Requirement already satisfied: astetik in /usr/local/lib/python3.6/dist-packages (from talos) (1.9.9)\n",
            "Collecting tensorflow==1.14.0\n",
            "  Using cached https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: statsmodels>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from talos) (0.11.1)\n",
            "Requirement already satisfied: wrangle in /usr/local/lib/python3.6/dist-packages (from talos) (0.6.7)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from talos) (0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from talos) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from talos) (1.18.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->talos) (2020.4.5.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from kerasplotlib->talos) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from chances->talos) (1.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0->talos) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0->talos) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0->talos) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0->talos) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0->talos) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->talos) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->talos) (2.8.1)\n",
            "Requirement already satisfied: geonamescache in /usr/local/lib/python3.6/dist-packages (from astetik->talos) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (0.34.2)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (1.29.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->talos) (3.10.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.11.0->talos) (0.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->talos) (0.22.2.post1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (46.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (2.1.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (4.3.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->kerasplotlib->talos) (1.0.18)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->talos) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->talos) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->talos) (0.15.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->kerasplotlib->talos) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->kerasplotlib->talos) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kerasplotlib->talos) (0.1.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->talos) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->talos) (3.1.0)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n1ueeYWh8Rl",
        "colab_type": "code",
        "outputId": "36a20480-3387-432f-abd7-b41e26930f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-beta1\n",
            "  Using cached https://files.pythonhosted.org/packages/2b/53/e18c5e7a2263d3581a979645a185804782e59b8e13f42b9c3c3cfb5bb503/tensorflow_gpu-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.34.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.3.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.29.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.18.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0a20190603)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-beta1) (46.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta1) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.0.0b1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuff-M4gHGq8",
        "colab_type": "code",
        "outputId": "94aff472-7755-46eb-ef88-6271d94044dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%matplotlib inline\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import talos\n",
        "\n",
        "from time import time\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, LSTM, Embedding, Input, Concatenate\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import os, sys\n",
        "import string\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from python_utils import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xx0I86zHGrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading the dataset\n",
        "df = pd.read_csv(\"/content/drive/My Drive/26_5_Final-Merged-File.csv\", encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wm9lbdtHGrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataframe without spatial and temporal information\n",
        "df_nc = df[['title ', 'text', 'URL', 'label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uet0bR6yHGrN",
        "colab_type": "code",
        "outputId": "4e0986ca-6a3a-41ad-b3bb-9a33483b2e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "df_nc.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>URL</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A video shows a fortune teller predicting the...</td>\n",
              "      <td>Circulating on social networks a video that sh...</td>\n",
              "      <td>https://observador.pt/factchecks/fact-check-um...</td>\n",
              "      <td>FALSE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              title   ...  label\n",
              "0   A video shows a fortune teller predicting the...  ...  FALSE\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mff8wSBsHGrQ",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dwj47ZiHGrR",
        "colab_type": "code",
        "outputId": "b2c9fa7b-f6ae-44b4-a713-db5e429bb0df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "df_nc.columns\n",
        "#needed are title, text, label, URL"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['title ', 'text', 'URL', 'label'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQGECBKEHGrW",
        "colab_type": "code",
        "outputId": "fe87e3f7-35b1-4e76-c0a3-eba784f8e791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df_nc.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title     2901\n",
              "text      2894\n",
              "URL       2901\n",
              "label     2901\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XijHb0ONHGrd",
        "colab_type": "code",
        "outputId": "18bf4b38-6111-4dbc-bb31-7868caa720ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "df_nc.label.unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['FALSE', 'Pants on Fire!', 'misleading', 'Explanatory',\n",
              "       'Partly false', 'Mostly False', 'PARTLY FALSE', 'MISLEADING',\n",
              "       'Misleading', 'No Evidence', 'Mainly false', 'Mostly false',\n",
              "       'No evidence', 'Partially false', 'Misleading/False',\n",
              "       'MOSTLY TRUE', 'Partly true', 'false and misleading', 'HALF TRUE',\n",
              "       'Mostly True', \"(Org. doesn't apply rating)\", 'Fake', 'Correct',\n",
              "       'Unlikely', 'Conspiracy theory', 'Partially true', 'Not true',\n",
              "       'Half True', 'MOSTLY FALSE', 'PARTLY TRUE', 'TRUE', nan],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8srQHjHuHGrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting our problem into a binary classification problem\n",
        "df_nc['label'] = df_nc['label'].replace({\n",
        "                                        'FALSE' : 'False',\n",
        "                                        'Pants on Fire!' : 'False', \n",
        "                                        'misleading': 'False',\n",
        "                                        'Partly false' : 'False',\n",
        "                                        'Mostly False' : 'False',\n",
        "                                        'PARTLY FALSE' : 'False',\n",
        "                                        'MISLEADING' : 'False',\n",
        "                                        'Misleading' : 'False',\n",
        "                                        'Mainly false' : 'False',\n",
        "                                        'Mostly false' : 'False',\n",
        "                                        'Partially false' : 'False',\n",
        "                                        'Misleading/False' : 'False',\n",
        "                                        'false and misleading' : 'False',\n",
        "                                        'Fake' : 'False',\n",
        "                                        'Unlikely' : 'False',\n",
        "                                        'Not true' : 'False',\n",
        "                                        'MOSTLY FALSE' : 'False',\n",
        "                                        'Conspiracy theory' : 'False',\n",
        "                                        'MOSTLY TRUE' : 'True',\n",
        "                                        'Partly true' : 'True',\n",
        "                                        'Mostly True' : 'True',\n",
        "                                        'Correct' : 'True',\n",
        "                                        'Half True' : 'True',\n",
        "                                        'HALF TRUE' : 'True',\n",
        "                                        'Partially true' : 'True',\n",
        "                                        'PARTLY TRUE' : 'True',\n",
        "                                        'TRUE' : 'True',\n",
        "                                  })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dztrupa2HGrm",
        "colab_type": "code",
        "outputId": "ae5c5384-c937-4d77-cba4-c6e673eeab37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "df_nc.label.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False                          1635\n",
              "True                           1236\n",
              "Explanatory                    13  \n",
              "No evidence                    11  \n",
              "(Org. doesn't apply rating)    5   \n",
              "No Evidence                    1   \n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpWlO9apHGrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing anything except 'True' or 'False'\n",
        "df_nc = df_nc[df_nc['label'].isin(['False', 'True'])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDtSvXBAHGrs",
        "colab_type": "code",
        "outputId": "e3705e60-eb59-477c-9891-0bf8e9ec9c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df_nc.label.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    1635\n",
              "True     1236\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMMnyG1PHGrv",
        "colab_type": "code",
        "outputId": "2e8104a7-a124-4b78-8608-1c64f005590d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df_nc.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title     object\n",
              "text      object\n",
              "URL       object\n",
              "label     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc_uOzOsHGry",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning text data here so as to remove any records that have an excessive amount of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmJNTb20HGrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting to a text array first\n",
        "all_text = []\n",
        "\n",
        "all_text.extend(list(df_nc.text.values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3kCIGalHGr2",
        "colab_type": "code",
        "outputId": "a19b5d88-9a50-4eb4-fe3a-50405ad0b71d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "all_text[:1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Circulating on social networks a video that shows an excerpt from a Spanish television show, supposedly issued December 24, 2019, in which it appears a woman (who claims to be psychic) ??to make \"predictions\". In this video, the woman describes a set of events that have been interpreted as a detailed forecast of Covid-19 pandemic that has hit the world. It is, however, a fake video, at least as regards the date of issue. The video has been being disseminated on the Internet with a date and not tampered with the real.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5abgmOwHGr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(txt):\n",
        "    \n",
        "    #removing numbers and punctuations\n",
        "    text = re.sub(r\"[^a-zA-Z]\", ' ', txt)\n",
        "    \n",
        "    #removing multiple spaces\n",
        "    text = re.sub(r\"\\s+\", ' ', text)\n",
        "    \n",
        "    #single character removal\n",
        "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
        "    \n",
        "    #converting to lower case\n",
        "    text = text.lower()\n",
        "    \n",
        "    return text\n",
        "\n",
        "corpus = [clean_text(str(x)) for x in all_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzTKPlx6HGr6",
        "colab_type": "code",
        "outputId": "a0fbf996-3c95-493e-ce2d-312c3472096e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#testing whether the cleaning process took place successfully or not.\n",
        "#this corpus variable has all the text data in its clean form\n",
        "corpus[:1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['circulating on social networks video that shows an excerpt from spanish television show supposedly issued december in which it appears woman who claims to be psychic to make predictions in this video the woman describes set of events that have been interpreted as detailed forecast of covid pandemic that has hit the world it is however fake video at least as regards the date of issue the video has been being disseminated on the internet with date and not tampered with the real ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvDBcEtBHGr8",
        "colab_type": "code",
        "outputId": "1ddb1b72-5a04-4e63-8e16-dd528084126d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df_nc.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title     object\n",
              "text      object\n",
              "URL       object\n",
              "label     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKXzLfZHHGr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#counting average length of words found in the corpus\n",
        "\n",
        "def avg_wl(txt):\n",
        "    words = txt.split()\n",
        "    mean = sum(len(word) for word in words)/len(words)\n",
        "    \n",
        "    return mean\n",
        "\n",
        "avg_word_len = [avg_wl(sentence) for sentence in corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E8KDucsHGsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_nc['avg_word_len'] = avg_word_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anOC8AvBHGsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#finding number of words present in each sentence within the corpus\n",
        "\n",
        "len_sentences = [len(s.split()) for s in corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwTuq795HGsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_nc['len_sentences'] = len_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s3r0JiQHGsG",
        "colab_type": "code",
        "outputId": "cc0a5e9f-9c2d-4fea-f231-2e42bdad2ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "df_nc.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>URL</th>\n",
              "      <th>label</th>\n",
              "      <th>avg_word_len</th>\n",
              "      <th>len_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A video shows a fortune teller predicting the coronavirus pandemic in December on Spanish TV.</td>\n",
              "      <td>Circulating on social networks a video that shows an excerpt from a Spanish television show, supposedly issued December 24, 2019, in which it appears a woman (who claims to be psychic) ??to make \"predictions\". In this video, the woman describes a set of events that have been interpreted as a detailed forecast of Covid-19 pandemic that has hit the world. It is, however, a fake video, at least as regards the date of issue. The video has been being disseminated on the Internet with a date and not tampered with the real.</td>\n",
              "      <td>https://observador.pt/factchecks/fact-check-uma-vidente-previu-a-pandemia-da-covid-19-na-televisao-espanhola-em-dezembro/</td>\n",
              "      <td>False</td>\n",
              "      <td>4.795181</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                           title   ... len_sentences\n",
              "0   A video shows a fortune teller predicting the coronavirus pandemic in December on Spanish TV.  ...  83          \n",
              "\n",
              "[1 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViGs45zgHGsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cleaning the URL feature to only have relevanant domain names in the data available for training\n",
        "##getting the URL into an array first\n",
        "\n",
        "all_url = []\n",
        "all_url.extend(list(df_nc.URL.values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-BZEYk3HGsJ",
        "colab_type": "code",
        "outputId": "191b093e-87a1-49fe-abd9-ae2f5487720d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_url[:1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://observador.pt/factchecks/fact-check-uma-vidente-previu-a-pandemia-da-covid-19-na-televisao-espanhola-em-dezembro/']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-os8BwgNHGsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_url(url_long):    \n",
        "    domain_name = []\n",
        "    regexp = re.compile(r\"(https?:\\/\\/)?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b\")\n",
        "    url = regexp.search(url_long) \n",
        "    return url.group()\n",
        "\n",
        "domain_name_list = [clean_url(u) for u in all_url]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KbvTwytHGsM",
        "colab_type": "code",
        "outputId": "93158276-d589-4f96-871f-263d8f14e8ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#contains the domain names that are present in the list of urls\n",
        "domain_name_list[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://observador.pt',\n",
              " 'https://www.newschecker.in',\n",
              " 'https://factcheck.afp.com',\n",
              " 'https://pesacheck.org',\n",
              " 'https://www.animalpolitico.com']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHdxSX_lHGsO",
        "colab_type": "code",
        "outputId": "3a66a56e-8081-475b-e38e-0410cbfbb22e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#this shows where the data is coming from and domains that contibute to fake news or not.\n",
        "\n",
        "print(Counter(domain_name_list).keys())\n",
        "print(Counter(domain_name_list).values())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['https://observador.pt', 'https://www.newschecker.in', 'https://factcheck.afp.com', 'https://pesacheck.org', 'https://www.animalpolitico.com', 'https://dubawa.org', 'https://www.politifact.com', 'https://www.newtral.es', 'https://aosfatos.org', 'https://lasillavacia.com', 'https://piaui.folha.uol.com.br', 'https://correctiv.org', 'https://teyit.org', 'https://africacheck.org', 'https://leadstories.com', 'https://factuel.afp.com', 'https://maldita.es', 'https://politica.estadao.com.br', 'https://srilanka.factcrescendo.com', 'https://www.rappler.com', 'https://faktograf.hr', 'https://ici.radio-canada.ca', 'https://efectococuyo.com', 'https://www.factcheck.org', 'https://english.factcrescendo.com', 'https://ghana.dubawa.org', 'https://www.francetvinfo.fr', 'https://vistinomer.mk', 'https://analysis.leadstories.com', 'http://u.afp.com', 'https://www.15min.lt', 'https://observers.france24.com', 'http://factuel.afp.com', 'https://s.id', 'https://www.lemonde.fr', 'https://factly.in', 'https://hoax-alert.leadstories.com', 'https://www.boomlive.in', 'https://www.buzzfeed.com', 'https://pagellapolitica.it', 'https://colombiacheck.com', 'http://www.aaj.tv', 'https://www.afghanistannews.net', 'https://www.adelaidenow.com.au', 'http://www.adelaidenow.com.au', 'https://www.snopes.com'])\n",
            "dict_values([25, 60, 204, 34, 27, 24, 178, 107, 35, 24, 55, 32, 79, 19, 59, 36, 132, 47, 20, 27, 31, 28, 22, 22, 32, 13, 30, 18, 1, 26, 25, 22, 2, 28, 2, 65, 31, 19, 9, 4, 1, 118, 365, 554, 2, 177])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug67lPAdHGsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_nc['source'] = domain_name_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNA5XSjBHGsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_nc.drop('URL', axis=1, inplace=True)\n",
        "df_nc.drop('text', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO4BUVi0HGsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_nc['text'] = corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMuYFPZjHGsU",
        "colab_type": "code",
        "outputId": "7651a71b-4ac8-4f05-97d0-19739106782c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "import seaborn as sns\n",
        "l = ['avg_word_len', 'len_sentences']\n",
        "number_of_columns = 2\n",
        "number_of_rows = len(l)-1/number_of_columns\n",
        "plt.figure(figsize=(2*number_of_columns,6*number_of_rows))\n",
        "for i in range(0,len(l)):\n",
        "    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n",
        "    sns.set_style('whitegrid')\n",
        "    sns.boxplot(df_nc[l[i]],color='green',orient='v')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUa9cXAxHGsW",
        "colab_type": "code",
        "outputId": "e8af795a-d717-4b34-ceb6-a0e4ba1b639b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum = 0\n",
        "for x in range(1500, 4000, 1000 ):\n",
        "    results = df_nc[df_nc['len_sentences'] > x]\n",
        "    sum = sum + results['title '].size\n",
        "    \n",
        "amt = (sum/df_nc['title '].size)*100\n",
        "print('Percentage of articles that have a word count of more than 1500 is {percent:.2f}%'.format(percent = amt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of articles that have a word count of more than 1500 is 1.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXLRLXIbHGsX",
        "colab_type": "code",
        "outputId": "a9e9f158-7e60-481c-be28-7e8cffedee4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#articles of word count more than 1900 are thus being dropped\n",
        "result_df = df_nc[df_nc['len_sentences']>=1500]\n",
        "\n",
        "df_nc.drop(df_nc[df_nc['len_sentences'] >= 1500].index, inplace = True) \n",
        "sns.boxplot(df_nc['len_sentences'],color='green',orient='v')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f74c1d0f630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIUC6jSpHGsZ",
        "colab_type": "code",
        "outputId": "ef8b99f6-7218-431a-a15e-55271ae2d996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "df_nc.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title            2822\n",
              "label            2822\n",
              "avg_word_len     2822\n",
              "len_sentences    2822\n",
              "source           2822\n",
              "text             2822\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAxfLEVJHGsa",
        "colab_type": "code",
        "outputId": "2b065f05-7358-4f7f-ebea-59a783e334f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "df_nc.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title            0\n",
              "label            0\n",
              "avg_word_len     0\n",
              "len_sentences    0\n",
              "source           0\n",
              "text             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scZ3RHmWHGsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dropping all those features where text is null\n",
        "df_nc = df_nc.dropna(how='any',axis=0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrGmNFtiHGsd",
        "colab_type": "code",
        "outputId": "63c5dea8-243c-4730-c020-e1f14c72d54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "df_nc.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title            2822\n",
              "label            2822\n",
              "avg_word_len     2822\n",
              "len_sentences    2822\n",
              "source           2822\n",
              "text             2822\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KImvEMeHGsf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Splitting the training and testing data to make the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqj2GWyTHGsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df_nc.drop('label', axis=1)\n",
        "y = df_nc['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "qYrDBmM6HGsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqSU2tBHHGsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnnR9X1kHGsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5fbYvXpHGsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1_train = list(X_train['text'])\n",
        "X1_val = list(X_val['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmulUWcFHGsm",
        "colab_type": "text"
      },
      "source": [
        "### Tokenisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyp-yPtsHGsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X1_train)\n",
        "\n",
        "X1_train = tokenizer.texts_to_sequences(X1_train)\n",
        "X1_val = tokenizer.texts_to_sequences(X1_val)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 1500\n",
        "\n",
        "X1_train = pad_sequences(X1_train, padding='post', maxlen=maxlen)\n",
        "X1_val = pad_sequences(X1_val, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WiwByU0HGsn",
        "colab_type": "text"
      },
      "source": [
        "### Generating Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AilRp4-HGsn",
        "colab_type": "code",
        "outputId": "a3d34f00-892e-441d-a55c-80700546cffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#prepare embeddings by GloVe\n",
        "embedding_index = {}\n",
        "f = open(os.path.join('/content/drive/My Drive/','glove.6B.300d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embedding_index[word] = coefs\n",
        "\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embedding_index))\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        #words not found in embedding index will be all-zero\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400001 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbcNNWP2HGsp",
        "colab_type": "text"
      },
      "source": [
        "### Preparing variables for second and third input to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvvzNmyUHGsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X2_train = X_train[['avg_word_len', 'len_sentences']]\n",
        "X2_val = X_val[['avg_word_len', 'len_sentences']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5GqG-GbHGsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#adding this following line because X2_train was not a numpy array and wasn't training properly\n",
        "\n",
        "X2_train = np.asarray(X2_train)\n",
        "X2_val = np.asarray(X2_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8eHaJLtHGss",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsbgbFmcHGss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lstm_model(x_train, y_train, x_val, y_val, params):\n",
        "  \n",
        "  #for input one\n",
        "  input_1 = Input(shape=(maxlen,))\n",
        "  embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], trainable=False)(input_1)\n",
        "\n",
        "  LSTM_Layer_1 = LSTM(params['neurons'])(embedding_layer)\n",
        "\n",
        "  #for input two\n",
        "  input_2 = Input(shape=(2,))\n",
        "  dense_layer_1 = Dense(params['dense'], activation=params['activation'])(input_2)\n",
        "  dense_layer_2 = Dense(params['dense'], activation=params['activation'])(dense_layer_1)\n",
        "\n",
        "  #concatanation\n",
        "  concat_layer = Concatenate()([LSTM_Layer_1, dense_layer_2])\n",
        "  \n",
        "  dense_layer_3 = Dense(params['dense'], activation=params['activation'])(concat_layer)\n",
        "\n",
        "  #adding a dropout layer to reduce overfitting\n",
        "  dense_layer_4 = Dropout(params['dropout'])(dense_layer_3)\n",
        "  \n",
        "  #output layer\n",
        "  output = Dense(2, activation='softmax')(dense_layer_4)\n",
        "  \n",
        "  model = Model(inputs=[input_1, input_2], outputs=output)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', talos.utils.metrics.f1score])\n",
        "  model.summary()\n",
        "\n",
        "\n",
        "  #creating checkpoints to save the state of the model\n",
        "  filepath=\"/content/drive/My Drive/LSTM_Model/model.{epoch:02d}-{val_loss:.2f}.h5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "  out = model.fit(x=x_train,\n",
        "                      y=y_train, \n",
        "                      validation_data=[x_val, y_val],\n",
        "                      callbacks=[checkpoint],\n",
        "                      batch_size=params['batch_size'],\n",
        "                      epochs=params['epochs'],\n",
        "                      verbose=1)\n",
        "  \n",
        "  return out, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wgbfJFkPIXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = { 'neurons' : [64, 128],\n",
        "      'dense' : [10, 20],\n",
        "     'activation':['relu', 'elu'],\n",
        "     'dropout' : [0.1, 0.3],\n",
        "     'batch_size' : [64, 128],\n",
        "     'epochs' : [10, 30, 50]\n",
        "     }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXA39RFFQA50",
        "colab_type": "code",
        "outputId": "088235e5-0409-446f-f897-3f06c50450fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "scan_object = talos.Scan(x=[X1_train, X2_train],\n",
        "                         y=y_train,\n",
        "                         x_val=[X1_val, X2_val],\n",
        "                         y_val=y_val,\n",
        "                         params=p,\n",
        "                         model=lstm_model,\n",
        "                         experiment_name=\"LSTM Model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5350 - acc: 0.7834 - f1score: 0.7834\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5306 - acc: 0.7862 - f1score: 0.7887 - val_loss: 0.5019 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5306 - acc: 0.7862 - f1score: 0.7887 - val_loss: 0.5019 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4723 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4697 - acc: 0.8180 - f1score: 0.8190 - val_loss: 0.4966 - val_acc: 0.7854 - val_f1score: 0.7884\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4697 - acc: 0.8180 - f1score: 0.8190 - val_loss: 0.4966 - val_acc: 0.7854 - val_f1score: 0.7884\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4630 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4621 - acc: 0.8138 - f1score: 0.8157 - val_loss: 0.4898 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4621 - acc: 0.8138 - f1score: 0.8157 - val_loss: 0.4898 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4549 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4573 - acc: 0.8169 - f1score: 0.8157 - val_loss: 0.4871 - val_acc: 0.7800 - val_f1score: 0.7808\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4573 - acc: 0.8169 - f1score: 0.8157 - val_loss: 0.4871 - val_acc: 0.7800 - val_f1score: 0.7808\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4645 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4637 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4978 - val_acc: 0.7865 - val_f1score: 0.7870\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4637 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4978 - val_acc: 0.7865 - val_f1score: 0.7870\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4581 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4605 - acc: 0.8138 - f1score: 0.8125 - val_loss: 0.4918 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4605 - acc: 0.8138 - f1score: 0.8125 - val_loss: 0.4918 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4498 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4479 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4931 - val_acc: 0.7833 - val_f1score: 0.7815\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4479 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4931 - val_acc: 0.7833 - val_f1score: 0.7815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  1%|          | 1/96 [01:20<2:08:11, 80.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 4.0930 - acc: 0.5544 - f1score: 0.5544\n",
            "Epoch 00001: val_acc improved from -inf to 0.71245, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.15.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 4.0531 - acc: 0.5566 - f1score: 0.5585 - val_loss: 1.1490 - val_acc: 0.7124 - val_f1score: 0.7144\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.71245, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.15.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 4.0531 - acc: 0.5566 - f1score: 0.5585 - val_loss: 1.1490 - val_acc: 0.7124 - val_f1score: 0.7144\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.8238 - acc: 0.7080 - f1score: 0.7080\n",
            "Epoch 00002: val_acc improved from 0.71245 to 0.75536, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.56.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.8236 - acc: 0.7085 - f1score: 0.7089 - val_loss: 0.5552 - val_acc: 0.7554 - val_f1score: 0.7536\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.71245 to 0.75536, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.56.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.8236 - acc: 0.7085 - f1score: 0.7089 - val_loss: 0.5552 - val_acc: 0.7554 - val_f1score: 0.7536\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.5106 - acc: 0.7559 - f1score: 0.7559\n",
            "Epoch 00003: val_acc did not improve from 0.75536\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.4994 - acc: 0.7561 - f1score: 0.7562 - val_loss: 0.5596 - val_acc: 0.7425 - val_f1score: 0.7403\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.75536\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.4994 - acc: 0.7561 - f1score: 0.7562 - val_loss: 0.5596 - val_acc: 0.7425 - val_f1score: 0.7403\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.3766 - acc: 0.7548 - f1score: 0.7548\n",
            "Epoch 00004: val_acc improved from 0.75536 to 0.75751, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.55.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.3596 - acc: 0.7561 - f1score: 0.7571 - val_loss: 0.5463 - val_acc: 0.7575 - val_f1score: 0.7573\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.75536 to 0.75751, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.55.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.3596 - acc: 0.7561 - f1score: 0.7571 - val_loss: 0.5463 - val_acc: 0.7575 - val_f1score: 0.7573\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.5825 - acc: 0.7392 - f1score: 0.7392\n",
            "Epoch 00005: val_acc improved from 0.75751 to 0.78755, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.52.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.5850 - acc: 0.7402 - f1score: 0.7411 - val_loss: 0.5247 - val_acc: 0.7876 - val_f1score: 0.7848\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.75751 to 0.78755, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.52.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.5850 - acc: 0.7402 - f1score: 0.7411 - val_loss: 0.5247 - val_acc: 0.7876 - val_f1score: 0.7848\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.4614 - acc: 0.7667 - f1score: 0.7667\n",
            "Epoch 00006: val_acc did not improve from 0.78755\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.4756 - acc: 0.7646 - f1score: 0.7627 - val_loss: 0.5368 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.78755\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.4756 - acc: 0.7646 - f1score: 0.7627 - val_loss: 0.5368 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.0621 - acc: 0.7759 - f1score: 0.7759\n",
            "Epoch 00007: val_acc improved from 0.78755 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.07-0.51.h5\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.78755 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.07-0.51.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.0597 - acc: 0.7767 - f1score: 0.7775 - val_loss: 0.5073 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.0597 - acc: 0.7767 - f1score: 0.7775 - val_loss: 0.5073 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.7565 - acc: 0.7786 - f1score: 0.7786\n",
            "Epoch 00008: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.48.h5\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.48.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.7509 - acc: 0.7788 - f1score: 0.7791 - val_loss: 0.4770 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.7509 - acc: 0.7788 - f1score: 0.7791 - val_loss: 0.4770 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4721 - acc: 0.7893 - f1score: 0.7893\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4711 - acc: 0.7905 - f1score: 0.7915 - val_loss: 0.4782 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4711 - acc: 0.7905 - f1score: 0.7915 - val_loss: 0.4782 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4658 - acc: 0.7710 - f1score: 0.7710\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4640 - acc: 0.7725 - f1score: 0.7737 - val_loss: 0.4858 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4640 - acc: 0.7725 - f1score: 0.7737 - val_loss: 0.4858 - val_acc: 0.8004 - val_f1score: 0.8006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  2%|▏         | 2/96 [03:05<2:17:59, 88.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.8353 - acc: 0.6261 - f1score: 0.6261\n",
            "Epoch 00001: val_acc improved from -inf to 0.79936, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.51.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.8288 - acc: 0.6291 - f1score: 0.6317 - val_loss: 0.5132 - val_acc: 0.7994 - val_f1score: 0.8003\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.79936, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.51.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.8288 - acc: 0.6291 - f1score: 0.6317 - val_loss: 0.5132 - val_acc: 0.7994 - val_f1score: 0.8003\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5279 - acc: 0.7893 - f1score: 0.7893\n",
            "Epoch 00002: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5276 - acc: 0.7905 - f1score: 0.7915 - val_loss: 0.4895 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5276 - acc: 0.7905 - f1score: 0.7915 - val_loss: 0.4895 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4780 - acc: 0.8050 - f1score: 0.8050\n",
            "Epoch 00003: val_acc improved from 0.79936 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4769 - acc: 0.8053 - f1score: 0.8056 - val_loss: 0.4806 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.79936 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4769 - acc: 0.8053 - f1score: 0.8056 - val_loss: 0.4806 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4641 - acc: 0.8044 - f1score: 0.8044\n",
            "Epoch 00004: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4635 - acc: 0.8048 - f1score: 0.8051 - val_loss: 0.4809 - val_acc: 0.8015 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4635 - acc: 0.8048 - f1score: 0.8051 - val_loss: 0.4809 - val_acc: 0.8015 - val_f1score: 0.7984\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4744 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00005: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4727 - acc: 0.8079 - f1score: 0.8086 - val_loss: 0.4806 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4727 - acc: 0.8079 - f1score: 0.8086 - val_loss: 0.4806 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4774 - acc: 0.8028 - f1score: 0.8028\n",
            "Epoch 00006: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4780 - acc: 0.8026 - f1score: 0.8025 - val_loss: 0.5039 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4780 - acc: 0.8026 - f1score: 0.8025 - val_loss: 0.5039 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4804 - acc: 0.8028 - f1score: 0.8028\n",
            "Epoch 00007: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4803 - acc: 0.8026 - f1score: 0.8025 - val_loss: 0.4939 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4803 - acc: 0.8026 - f1score: 0.8025 - val_loss: 0.4939 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4797 - acc: 0.7861 - f1score: 0.7861\n",
            "Epoch 00008: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4798 - acc: 0.7868 - f1score: 0.7873 - val_loss: 0.4906 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4798 - acc: 0.7868 - f1score: 0.7873 - val_loss: 0.4906 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4689 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00009: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4693 - acc: 0.7958 - f1score: 0.7948 - val_loss: 0.4885 - val_acc: 0.7972 - val_f1score: 0.7942\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4693 - acc: 0.7958 - f1score: 0.7948 - val_loss: 0.4885 - val_acc: 0.7972 - val_f1score: 0.7942\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4718 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00010: val_acc improved from 0.80150 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.10-0.49.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4748 - acc: 0.7931 - f1score: 0.7922 - val_loss: 0.4946 - val_acc: 0.8036 - val_f1score: 0.8021\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.80150 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.10-0.49.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4748 - acc: 0.7931 - f1score: 0.7922 - val_loss: 0.4946 - val_acc: 0.8036 - val_f1score: 0.8021\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4692 - acc: 0.7936 - f1score: 0.7936\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4666 - acc: 0.7952 - f1score: 0.7966 - val_loss: 0.4925 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4666 - acc: 0.7952 - f1score: 0.7966 - val_loss: 0.4925 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4664 - acc: 0.7936 - f1score: 0.7936\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4655 - acc: 0.7942 - f1score: 0.7946 - val_loss: 0.4956 - val_acc: 0.7961 - val_f1score: 0.7980\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4655 - acc: 0.7942 - f1score: 0.7946 - val_loss: 0.4956 - val_acc: 0.7961 - val_f1score: 0.7980\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4687 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4676 - acc: 0.7963 - f1score: 0.7972 - val_loss: 0.4876 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4676 - acc: 0.7963 - f1score: 0.7972 - val_loss: 0.4876 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4722 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4695 - acc: 0.7974 - f1score: 0.7991 - val_loss: 0.4883 - val_acc: 0.7929 - val_f1score: 0.7949\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4695 - acc: 0.7974 - f1score: 0.7991 - val_loss: 0.4883 - val_acc: 0.7929 - val_f1score: 0.7949\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4763 - acc: 0.7947 - f1score: 0.7947\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4768 - acc: 0.7931 - f1score: 0.7918 - val_loss: 0.4903 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4768 - acc: 0.7931 - f1score: 0.7918 - val_loss: 0.4903 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4745 - acc: 0.7888 - f1score: 0.7888\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4740 - acc: 0.7889 - f1score: 0.7890 - val_loss: 0.4933 - val_acc: 0.7929 - val_f1score: 0.7957\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4740 - acc: 0.7889 - f1score: 0.7890 - val_loss: 0.4933 - val_acc: 0.7929 - val_f1score: 0.7957\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4687 - acc: 0.7936 - f1score: 0.7936\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4671 - acc: 0.7947 - f1score: 0.7956 - val_loss: 0.4923 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4671 - acc: 0.7947 - f1score: 0.7956 - val_loss: 0.4923 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4723 - acc: 0.7872 - f1score: 0.7872\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4707 - acc: 0.7884 - f1score: 0.7894 - val_loss: 0.4911 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4707 - acc: 0.7884 - f1score: 0.7894 - val_loss: 0.4911 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4602 - acc: 0.7990 - f1score: 0.7990\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4628 - acc: 0.7974 - f1score: 0.7959 - val_loss: 0.4915 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4628 - acc: 0.7974 - f1score: 0.7959 - val_loss: 0.4915 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4692 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4715 - acc: 0.7931 - f1score: 0.7922 - val_loss: 0.4919 - val_acc: 0.7865 - val_f1score: 0.7838\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4715 - acc: 0.7931 - f1score: 0.7922 - val_loss: 0.4919 - val_acc: 0.7865 - val_f1score: 0.7838\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4656 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4644 - acc: 0.7979 - f1score: 0.7983 - val_loss: 0.4933 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4644 - acc: 0.7979 - f1score: 0.7983 - val_loss: 0.4933 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4657 - acc: 0.8017 - f1score: 0.8017\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4671 - acc: 0.7995 - f1score: 0.7975 - val_loss: 0.4912 - val_acc: 0.7843 - val_f1score: 0.7817\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4671 - acc: 0.7995 - f1score: 0.7975 - val_loss: 0.4912 - val_acc: 0.7843 - val_f1score: 0.7817\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4614 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4610 - acc: 0.7958 - f1score: 0.7962 - val_loss: 0.4916 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4610 - acc: 0.7958 - f1score: 0.7962 - val_loss: 0.4916 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4618 - acc: 0.7996 - f1score: 0.7996\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4622 - acc: 0.7984 - f1score: 0.7974 - val_loss: 0.4907 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4622 - acc: 0.7984 - f1score: 0.7974 - val_loss: 0.4907 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4694 - acc: 0.7904 - f1score: 0.7904\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4694 - acc: 0.7894 - f1score: 0.7886 - val_loss: 0.4923 - val_acc: 0.7822 - val_f1score: 0.7812\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4694 - acc: 0.7894 - f1score: 0.7886 - val_loss: 0.4923 - val_acc: 0.7822 - val_f1score: 0.7812\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4618 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4617 - acc: 0.7984 - f1score: 0.7988 - val_loss: 0.4913 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4617 - acc: 0.7984 - f1score: 0.7988 - val_loss: 0.4913 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4679 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4658 - acc: 0.7974 - f1score: 0.7982 - val_loss: 0.4928 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4658 - acc: 0.7974 - f1score: 0.7982 - val_loss: 0.4928 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4688 - acc: 0.7926 - f1score: 0.7926\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4705 - acc: 0.7915 - f1score: 0.7907 - val_loss: 0.4900 - val_acc: 0.7843 - val_f1score: 0.7874\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4705 - acc: 0.7915 - f1score: 0.7907 - val_loss: 0.4900 - val_acc: 0.7843 - val_f1score: 0.7874\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4592 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4598 - acc: 0.7979 - f1score: 0.7974 - val_loss: 0.4892 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4598 - acc: 0.7979 - f1score: 0.7974 - val_loss: 0.4892 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4582 - acc: 0.8001 - f1score: 0.8001\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4622 - acc: 0.7979 - f1score: 0.7960 - val_loss: 0.4895 - val_acc: 0.7843 - val_f1score: 0.7882\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4622 - acc: 0.7979 - f1score: 0.7960 - val_loss: 0.4895 - val_acc: 0.7843 - val_f1score: 0.7882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 3/96 [06:56<3:22:58, 130.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.4143 - acc: 0.5334 - f1score: 0.5334\n",
            "Epoch 00001: val_acc improved from -inf to 0.77575, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.75.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 1.4002 - acc: 0.5381 - f1score: 0.5421 - val_loss: 0.7477 - val_acc: 0.7758 - val_f1score: 0.7791\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77575, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.75.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 1.4002 - acc: 0.5381 - f1score: 0.5421 - val_loss: 0.7477 - val_acc: 0.7758 - val_f1score: 0.7791\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.7214 - acc: 0.7446 - f1score: 0.7446\n",
            "Epoch 00002: val_acc improved from 0.77575 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.56.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.7174 - acc: 0.7460 - f1score: 0.7472 - val_loss: 0.5605 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.77575 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.56.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.7174 - acc: 0.7460 - f1score: 0.7472 - val_loss: 0.5605 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5292 - acc: 0.7834 - f1score: 0.7834\n",
            "Epoch 00003: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.50.h5\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.50.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5271 - acc: 0.7847 - f1score: 0.7857 - val_loss: 0.4988 - val_acc: 0.8036 - val_f1score: 0.8061\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5271 - acc: 0.7847 - f1score: 0.7857 - val_loss: 0.4988 - val_acc: 0.8036 - val_f1score: 0.8061\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4728 - acc: 0.7866 - f1score: 0.7866\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4752 - acc: 0.7847 - f1score: 0.7830 - val_loss: 0.4942 - val_acc: 0.8026 - val_f1score: 0.8051\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4752 - acc: 0.7847 - f1score: 0.7830 - val_loss: 0.4942 - val_acc: 0.8026 - val_f1score: 0.8051\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4761 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4744 - acc: 0.7984 - f1score: 0.7983 - val_loss: 0.4895 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4744 - acc: 0.7984 - f1score: 0.7983 - val_loss: 0.4895 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4739 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4742 - acc: 0.8148 - f1score: 0.8140 - val_loss: 0.4984 - val_acc: 0.8015 - val_f1score: 0.7992\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4742 - acc: 0.8148 - f1score: 0.8140 - val_loss: 0.4984 - val_acc: 0.8015 - val_f1score: 0.7992\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4755 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4756 - acc: 0.8111 - f1score: 0.8104 - val_loss: 0.4875 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4756 - acc: 0.8111 - f1score: 0.8104 - val_loss: 0.4875 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4612 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4632 - acc: 0.8106 - f1score: 0.8108 - val_loss: 0.4838 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4632 - acc: 0.8106 - f1score: 0.8108 - val_loss: 0.4838 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4622 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4607 - acc: 0.8159 - f1score: 0.8165 - val_loss: 0.4829 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4607 - acc: 0.8159 - f1score: 0.8165 - val_loss: 0.4829 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4536 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4542 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4811 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4542 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4811 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4636 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4608 - acc: 0.8132 - f1score: 0.8148 - val_loss: 0.4801 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4608 - acc: 0.8132 - f1score: 0.8148 - val_loss: 0.4801 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4546 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4593 - acc: 0.8132 - f1score: 0.8125 - val_loss: 0.4878 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4593 - acc: 0.8132 - f1score: 0.8125 - val_loss: 0.4878 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4619 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4599 - acc: 0.8185 - f1score: 0.8195 - val_loss: 0.4776 - val_acc: 0.7929 - val_f1score: 0.7957\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4599 - acc: 0.8185 - f1score: 0.8195 - val_loss: 0.4776 - val_acc: 0.7929 - val_f1score: 0.7957\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4588 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4594 - acc: 0.8169 - f1score: 0.8161 - val_loss: 0.4851 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4594 - acc: 0.8169 - f1score: 0.8161 - val_loss: 0.4851 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4637 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4631 - acc: 0.8175 - f1score: 0.8180 - val_loss: 0.4838 - val_acc: 0.7972 - val_f1score: 0.7983\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4631 - acc: 0.8175 - f1score: 0.8180 - val_loss: 0.4838 - val_acc: 0.7972 - val_f1score: 0.7983\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4586 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4586 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4790 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4586 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4790 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4575 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4567 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4769 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4567 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4769 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4555 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4576 - acc: 0.8148 - f1score: 0.8140 - val_loss: 0.4785 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4576 - acc: 0.8148 - f1score: 0.8140 - val_loss: 0.4785 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4559 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4545 - acc: 0.8201 - f1score: 0.8211 - val_loss: 0.4778 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4545 - acc: 0.8201 - f1score: 0.8211 - val_loss: 0.4778 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4571 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4572 - acc: 0.8138 - f1score: 0.8139 - val_loss: 0.4753 - val_acc: 0.7908 - val_f1score: 0.7847\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4572 - acc: 0.8138 - f1score: 0.8139 - val_loss: 0.4753 - val_acc: 0.7908 - val_f1score: 0.7847\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4546 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4518 - acc: 0.8111 - f1score: 0.8122 - val_loss: 0.4784 - val_acc: 0.7929 - val_f1score: 0.7957\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4518 - acc: 0.8111 - f1score: 0.8122 - val_loss: 0.4784 - val_acc: 0.7929 - val_f1score: 0.7957\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4522 - acc: 0.8185 - f1score: 0.8177 - val_loss: 0.4855 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4522 - acc: 0.8185 - f1score: 0.8177 - val_loss: 0.4855 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4608 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4611 - acc: 0.8180 - f1score: 0.8176 - val_loss: 0.4826 - val_acc: 0.8026 - val_f1score: 0.8002\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4611 - acc: 0.8180 - f1score: 0.8176 - val_loss: 0.4826 - val_acc: 0.8026 - val_f1score: 0.8002\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4579 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4582 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4748 - val_acc: 0.8015 - val_f1score: 0.8016\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4582 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4748 - val_acc: 0.8015 - val_f1score: 0.8016\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4528 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4528 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4845 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4528 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4845 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4650 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4638 - acc: 0.8153 - f1score: 0.8155 - val_loss: 0.4857 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4638 - acc: 0.8153 - f1score: 0.8155 - val_loss: 0.4857 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4503 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4502 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4774 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4502 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4774 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4489 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4525 - acc: 0.8164 - f1score: 0.8142 - val_loss: 0.4749 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4525 - acc: 0.8164 - f1score: 0.8142 - val_loss: 0.4749 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4562 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4545 - acc: 0.8185 - f1score: 0.8200 - val_loss: 0.4782 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4545 - acc: 0.8185 - f1score: 0.8200 - val_loss: 0.4782 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4540 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4526 - acc: 0.8127 - f1score: 0.8133 - val_loss: 0.4755 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4526 - acc: 0.8127 - f1score: 0.8133 - val_loss: 0.4755 - val_acc: 0.8015 - val_f1score: 0.8032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  4%|▍         | 4/96 [12:02<4:41:12, 183.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.7751 - acc: 0.6740 - f1score: 0.6740\n",
            "Epoch 00001: val_acc improved from -inf to 0.78755, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.04.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.7587 - acc: 0.6751 - f1score: 0.6761 - val_loss: 1.0431 - val_acc: 0.7876 - val_f1score: 0.7889\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78755, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.04.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.7587 - acc: 0.6751 - f1score: 0.6761 - val_loss: 1.0431 - val_acc: 0.7876 - val_f1score: 0.7889\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.2888 - acc: 0.7214 - f1score: 0.7214\n",
            "Epoch 00002: val_acc did not improve from 0.78755\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.2934 - acc: 0.7201 - f1score: 0.7190 - val_loss: 0.6817 - val_acc: 0.7693 - val_f1score: 0.7679\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.78755\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.2934 - acc: 0.7201 - f1score: 0.7190 - val_loss: 0.6817 - val_acc: 0.7693 - val_f1score: 0.7679\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.8533 - acc: 0.7344 - f1score: 0.7344\n",
            "Epoch 00003: val_acc improved from 0.78755 to 0.78970, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.60.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.8536 - acc: 0.7360 - f1score: 0.7373 - val_loss: 0.6011 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.78755 to 0.78970, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.60.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.8536 - acc: 0.7360 - f1score: 0.7373 - val_loss: 0.6011 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6374 - acc: 0.7602 - f1score: 0.7602\n",
            "Epoch 00004: val_acc improved from 0.78970 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.50.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6366 - acc: 0.7593 - f1score: 0.7584 - val_loss: 0.5041 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.78970 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.50.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6366 - acc: 0.7593 - f1score: 0.7584 - val_loss: 0.5041 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5502 - acc: 0.7786 - f1score: 0.7786\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5509 - acc: 0.7778 - f1score: 0.7771 - val_loss: 0.5015 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5509 - acc: 0.7778 - f1score: 0.7771 - val_loss: 0.5015 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5235 - acc: 0.7899 - f1score: 0.7899\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5232 - acc: 0.7899 - f1score: 0.7900 - val_loss: 0.4907 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5232 - acc: 0.7899 - f1score: 0.7900 - val_loss: 0.4907 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4669 - acc: 0.8132 - f1score: 0.8129 - val_loss: 0.4818 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4669 - acc: 0.8132 - f1score: 0.8129 - val_loss: 0.4818 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4715 - acc: 0.8055 - f1score: 0.8055\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4697 - acc: 0.8069 - f1score: 0.8081 - val_loss: 0.4898 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4697 - acc: 0.8069 - f1score: 0.8081 - val_loss: 0.4898 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4691 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4687 - acc: 0.8127 - f1score: 0.8138 - val_loss: 0.4762 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4687 - acc: 0.8127 - f1score: 0.8138 - val_loss: 0.4762 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4567 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4540 - acc: 0.8090 - f1score: 0.8106 - val_loss: 0.4748 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4540 - acc: 0.8090 - f1score: 0.8106 - val_loss: 0.4748 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4637 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4614 - acc: 0.8153 - f1score: 0.8169 - val_loss: 0.4730 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4614 - acc: 0.8153 - f1score: 0.8169 - val_loss: 0.4730 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4574 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4556 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4730 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4556 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4730 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4570 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4573 - acc: 0.8101 - f1score: 0.8098 - val_loss: 0.4737 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4573 - acc: 0.8101 - f1score: 0.8098 - val_loss: 0.4737 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4525 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4514 - acc: 0.8122 - f1score: 0.8128 - val_loss: 0.4746 - val_acc: 0.7961 - val_f1score: 0.7988\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4514 - acc: 0.8122 - f1score: 0.8128 - val_loss: 0.4746 - val_acc: 0.7961 - val_f1score: 0.7988\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4522 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4493 - acc: 0.8132 - f1score: 0.8152 - val_loss: 0.4686 - val_acc: 0.8015 - val_f1score: 0.8016\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4493 - acc: 0.8132 - f1score: 0.8152 - val_loss: 0.4686 - val_acc: 0.8015 - val_f1score: 0.8016\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4455 - acc: 0.8180 - f1score: 0.8185 - val_loss: 0.4690 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4455 - acc: 0.8180 - f1score: 0.8185 - val_loss: 0.4690 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4461 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4423 - acc: 0.8169 - f1score: 0.8189 - val_loss: 0.4683 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4423 - acc: 0.8169 - f1score: 0.8189 - val_loss: 0.4683 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4427 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4433 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4721 - val_acc: 0.8036 - val_f1score: 0.7997\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4433 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4721 - val_acc: 0.8036 - val_f1score: 0.7997\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4447 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4461 - acc: 0.8127 - f1score: 0.8115 - val_loss: 0.4751 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4461 - acc: 0.8127 - f1score: 0.8115 - val_loss: 0.4751 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4601 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4578 - acc: 0.8085 - f1score: 0.8096 - val_loss: 0.4706 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4578 - acc: 0.8085 - f1score: 0.8096 - val_loss: 0.4706 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4414 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4430 - acc: 0.8132 - f1score: 0.8120 - val_loss: 0.4716 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4430 - acc: 0.8132 - f1score: 0.8120 - val_loss: 0.4716 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4496 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4484 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4749 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4484 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4749 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4371 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4373 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4698 - val_acc: 0.7843 - val_f1score: 0.7874\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4373 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4698 - val_acc: 0.7843 - val_f1score: 0.7874\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4510 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4523 - acc: 0.8132 - f1score: 0.8120 - val_loss: 0.4780 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4523 - acc: 0.8132 - f1score: 0.8120 - val_loss: 0.4780 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4502 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4492 - acc: 0.8159 - f1score: 0.8169 - val_loss: 0.4674 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4492 - acc: 0.8159 - f1score: 0.8169 - val_loss: 0.4674 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4417 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4392 - acc: 0.8143 - f1score: 0.8158 - val_loss: 0.4701 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4392 - acc: 0.8143 - f1score: 0.8158 - val_loss: 0.4701 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4442 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4432 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4712 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4432 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4712 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4489 - acc: 0.8136 - f1score: 0.81361856/1890 [============================>.] - ETA: 0s - loss: 0.4489 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4486 - acc: 0.8138 - f1score: 0.8139 - val_loss: 0.4711 - val_acc: 0.7822 - val_f1score: 0.7821\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4486 - acc: 0.8138 - f1score: 0.8139 - val_loss: 0.4711 - val_acc: 0.7822 - val_f1score: 0.7821\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4438 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4453 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4700 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4453 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4700 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4339 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4342 - acc: 0.8148 - f1score: 0.8150 - val_loss: 0.4695 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4342 - acc: 0.8148 - f1score: 0.8150 - val_loss: 0.4695 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4436 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00031: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4424 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4682 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4424 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4682 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4445 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00032: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4424 - acc: 0.8169 - f1score: 0.8184 - val_loss: 0.4683 - val_acc: 0.7865 - val_f1score: 0.7887\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4424 - acc: 0.8169 - f1score: 0.8184 - val_loss: 0.4683 - val_acc: 0.7865 - val_f1score: 0.7887\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4417 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4419 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4695 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4419 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4695 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4329 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4355 - acc: 0.8201 - f1score: 0.8179 - val_loss: 0.4680 - val_acc: 0.7886 - val_f1score: 0.7899\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4355 - acc: 0.8201 - f1score: 0.8179 - val_loss: 0.4680 - val_acc: 0.7886 - val_f1score: 0.7899\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4442 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4426 - acc: 0.8153 - f1score: 0.8164 - val_loss: 0.4703 - val_acc: 0.7876 - val_f1score: 0.7840\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4426 - acc: 0.8153 - f1score: 0.8164 - val_loss: 0.4703 - val_acc: 0.7876 - val_f1score: 0.7840\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4384 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4376 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4693 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4376 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4693 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4449 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4737 - val_acc: 0.7833 - val_f1score: 0.7847\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4449 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4737 - val_acc: 0.7833 - val_f1score: 0.7847\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4337 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4389 - acc: 0.8153 - f1score: 0.8132 - val_loss: 0.4693 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4389 - acc: 0.8153 - f1score: 0.8132 - val_loss: 0.4693 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4372 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4373 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4658 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4373 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4658 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4403 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4402 - acc: 0.8153 - f1score: 0.8155 - val_loss: 0.4666 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4402 - acc: 0.8153 - f1score: 0.8155 - val_loss: 0.4666 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4363 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4386 - acc: 0.8116 - f1score: 0.8109 - val_loss: 0.4669 - val_acc: 0.8026 - val_f1score: 0.8043\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4386 - acc: 0.8116 - f1score: 0.8109 - val_loss: 0.4669 - val_acc: 0.8026 - val_f1score: 0.8043\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4330 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4364 - acc: 0.8180 - f1score: 0.8167 - val_loss: 0.4691 - val_acc: 0.7843 - val_f1score: 0.7793\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4364 - acc: 0.8180 - f1score: 0.8167 - val_loss: 0.4691 - val_acc: 0.7843 - val_f1score: 0.7793\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4344 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4385 - acc: 0.8190 - f1score: 0.8177 - val_loss: 0.4674 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4385 - acc: 0.8190 - f1score: 0.8177 - val_loss: 0.4674 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4423 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4395 - acc: 0.8159 - f1score: 0.8178 - val_loss: 0.4685 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4395 - acc: 0.8159 - f1score: 0.8178 - val_loss: 0.4685 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4391 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4376 - acc: 0.8228 - f1score: 0.8232 - val_loss: 0.4730 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4376 - acc: 0.8228 - f1score: 0.8232 - val_loss: 0.4730 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4416 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4466 - acc: 0.8111 - f1score: 0.8095 - val_loss: 0.4671 - val_acc: 0.7940 - val_f1score: 0.7911\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4466 - acc: 0.8111 - f1score: 0.8095 - val_loss: 0.4671 - val_acc: 0.7940 - val_f1score: 0.7911\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4384 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00047: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4396 - acc: 0.8122 - f1score: 0.8123 - val_loss: 0.4665 - val_acc: 0.7897 - val_f1score: 0.7869\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4396 - acc: 0.8122 - f1score: 0.8123 - val_loss: 0.4665 - val_acc: 0.7897 - val_f1score: 0.7869\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4361 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00048: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4346 - acc: 0.8228 - f1score: 0.8237 - val_loss: 0.4668 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4346 - acc: 0.8228 - f1score: 0.8237 - val_loss: 0.4668 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4381 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00049: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4375 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4693 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4375 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4693 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4387 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00050: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4407 - acc: 0.8148 - f1score: 0.8140 - val_loss: 0.4674 - val_acc: 0.7854 - val_f1score: 0.7836\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4407 - acc: 0.8148 - f1score: 0.8140 - val_loss: 0.4674 - val_acc: 0.7854 - val_f1score: 0.7836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  5%|▌         | 5/96 [18:25<6:09:02, 243.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.0831 - acc: 0.7403 - f1score: 0.7403\n",
            "Epoch 00001: val_acc improved from -inf to 0.78755, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.69.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 2.0632 - acc: 0.7413 - f1score: 0.7421 - val_loss: 1.6915 - val_acc: 0.7876 - val_f1score: 0.7856\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78755, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.69.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 2.0632 - acc: 0.7413 - f1score: 0.7421 - val_loss: 1.6915 - val_acc: 0.7876 - val_f1score: 0.7856\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.6801 - acc: 0.7608 - f1score: 0.7608\n",
            "Epoch 00002: val_acc did not improve from 0.78755\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.6776 - acc: 0.7593 - f1score: 0.7580 - val_loss: 1.5400 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.78755\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.6776 - acc: 0.7593 - f1score: 0.7580 - val_loss: 1.5400 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.1642 - acc: 0.7473 - f1score: 0.7473\n",
            "Epoch 00003: val_acc did not improve from 0.78755\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.1814 - acc: 0.7460 - f1score: 0.7449 - val_loss: 0.8735 - val_acc: 0.7479 - val_f1score: 0.7479\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.78755\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.1814 - acc: 0.7460 - f1score: 0.7449 - val_loss: 0.8735 - val_acc: 0.7479 - val_f1score: 0.7479\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.9601 - acc: 0.7392 - f1score: 0.7392\n",
            "Epoch 00004: val_acc did not improve from 0.78755\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9539 - acc: 0.7376 - f1score: 0.7362 - val_loss: 0.5865 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.78755\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9539 - acc: 0.7376 - f1score: 0.7362 - val_loss: 0.5865 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6813 - acc: 0.7543 - f1score: 0.7543\n",
            "Epoch 00005: val_acc improved from 0.78755 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.52.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.6773 - acc: 0.7550 - f1score: 0.7556 - val_loss: 0.5173 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.78755 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.52.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.6773 - acc: 0.7550 - f1score: 0.7556 - val_loss: 0.5173 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5082 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5086 - acc: 0.7963 - f1score: 0.7958 - val_loss: 0.4879 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5086 - acc: 0.7963 - f1score: 0.7958 - val_loss: 0.4879 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4614 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4605 - acc: 0.8101 - f1score: 0.8098 - val_loss: 0.4912 - val_acc: 0.8026 - val_f1score: 0.8002\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4605 - acc: 0.8101 - f1score: 0.8098 - val_loss: 0.4912 - val_acc: 0.8026 - val_f1score: 0.8002\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4592 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4581 - acc: 0.8148 - f1score: 0.8163 - val_loss: 0.4821 - val_acc: 0.7800 - val_f1score: 0.7816\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4581 - acc: 0.8148 - f1score: 0.8163 - val_loss: 0.4821 - val_acc: 0.7800 - val_f1score: 0.7816\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4615 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00009: val_acc improved from 0.80258 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.09-0.48.h5\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.80258 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.09-0.48.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4600 - acc: 0.8127 - f1score: 0.8133 - val_loss: 0.4825 - val_acc: 0.8047 - val_f1score: 0.8072\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4600 - acc: 0.8127 - f1score: 0.8133 - val_loss: 0.4825 - val_acc: 0.8047 - val_f1score: 0.8072\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4739 - acc: 0.8082 - f1score: 0.8082\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4766 - acc: 0.8079 - f1score: 0.8077 - val_loss: 0.5236 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4766 - acc: 0.8079 - f1score: 0.8077 - val_loss: 0.5236 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4639 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00011: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4598 - acc: 0.8159 - f1score: 0.8178 - val_loss: 0.5072 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4598 - acc: 0.8159 - f1score: 0.8178 - val_loss: 0.5072 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4677 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00012: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4675 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4917 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4675 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4917 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4598 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00013: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4594 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4843 - val_acc: 0.7940 - val_f1score: 0.7911\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4594 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4843 - val_acc: 0.7940 - val_f1score: 0.7911\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4569 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00014: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4568 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4847 - val_acc: 0.7843 - val_f1score: 0.7785\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4568 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4847 - val_acc: 0.7843 - val_f1score: 0.7785\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4550 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00015: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4558 - acc: 0.8185 - f1score: 0.8191 - val_loss: 0.4966 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4558 - acc: 0.8185 - f1score: 0.8191 - val_loss: 0.4966 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4621 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00016: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4607 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4874 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4607 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4874 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00017: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4590 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4932 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4590 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4932 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4595 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00018: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4601 - acc: 0.8148 - f1score: 0.8145 - val_loss: 0.4980 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4601 - acc: 0.8148 - f1score: 0.8145 - val_loss: 0.4980 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4606 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00019: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4626 - acc: 0.8175 - f1score: 0.8148 - val_loss: 0.5037 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4626 - acc: 0.8175 - f1score: 0.8148 - val_loss: 0.5037 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4670 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00020: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4669 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4842 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4669 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4842 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4528 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00021: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4538 - acc: 0.8206 - f1score: 0.8202 - val_loss: 0.4864 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4538 - acc: 0.8206 - f1score: 0.8202 - val_loss: 0.4864 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4578 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4567 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4828 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4567 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4828 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4553 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4553 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4830 - val_acc: 0.7843 - val_f1score: 0.7874\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4553 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4830 - val_acc: 0.7843 - val_f1score: 0.7874\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4494 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4511 - acc: 0.8143 - f1score: 0.8131 - val_loss: 0.4842 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4511 - acc: 0.8143 - f1score: 0.8131 - val_loss: 0.4842 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4537 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4548 - acc: 0.8143 - f1score: 0.8135 - val_loss: 0.4828 - val_acc: 0.7833 - val_f1score: 0.7815\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4548 - acc: 0.8143 - f1score: 0.8135 - val_loss: 0.4828 - val_acc: 0.7833 - val_f1score: 0.7815\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4541 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4545 - acc: 0.8201 - f1score: 0.8188 - val_loss: 0.4794 - val_acc: 0.8026 - val_f1score: 0.8027\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4545 - acc: 0.8201 - f1score: 0.8188 - val_loss: 0.4794 - val_acc: 0.8026 - val_f1score: 0.8027\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4549 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4552 - acc: 0.8143 - f1score: 0.8131 - val_loss: 0.4810 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4552 - acc: 0.8143 - f1score: 0.8131 - val_loss: 0.4810 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4562 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4551 - acc: 0.8153 - f1score: 0.8159 - val_loss: 0.4774 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4551 - acc: 0.8153 - f1score: 0.8159 - val_loss: 0.4774 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4525 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4538 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4807 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4538 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4807 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4576 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4561 - acc: 0.8175 - f1score: 0.8185 - val_loss: 0.4793 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4561 - acc: 0.8175 - f1score: 0.8185 - val_loss: 0.4793 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4589 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00031: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4616 - acc: 0.8132 - f1score: 0.8120 - val_loss: 0.4776 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4616 - acc: 0.8132 - f1score: 0.8120 - val_loss: 0.4776 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4524 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00032: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4534 - acc: 0.8159 - f1score: 0.8151 - val_loss: 0.4785 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4534 - acc: 0.8159 - f1score: 0.8151 - val_loss: 0.4785 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4502 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00033: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4492 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4774 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4492 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4774 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4473 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00034: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4463 - acc: 0.8180 - f1score: 0.8185 - val_loss: 0.4760 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4463 - acc: 0.8180 - f1score: 0.8185 - val_loss: 0.4760 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4528 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00035: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4539 - acc: 0.8148 - f1score: 0.8136 - val_loss: 0.4819 - val_acc: 0.7972 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4539 - acc: 0.8148 - f1score: 0.8136 - val_loss: 0.4819 - val_acc: 0.7972 - val_f1score: 0.7975\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4515 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00036: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4533 - acc: 0.8138 - f1score: 0.8121 - val_loss: 0.4779 - val_acc: 0.7972 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4533 - acc: 0.8138 - f1score: 0.8121 - val_loss: 0.4779 - val_acc: 0.7972 - val_f1score: 0.7975\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4497 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00037: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4522 - acc: 0.8180 - f1score: 0.8172 - val_loss: 0.4762 - val_acc: 0.7961 - val_f1score: 0.7956\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4522 - acc: 0.8180 - f1score: 0.8172 - val_loss: 0.4762 - val_acc: 0.7961 - val_f1score: 0.7956\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00038: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4467 - acc: 0.8180 - f1score: 0.8176 - val_loss: 0.4781 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4467 - acc: 0.8180 - f1score: 0.8176 - val_loss: 0.4781 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4568 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00039: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4559 - acc: 0.8148 - f1score: 0.8154 - val_loss: 0.4764 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4559 - acc: 0.8148 - f1score: 0.8154 - val_loss: 0.4764 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4523 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00040: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4555 - acc: 0.8175 - f1score: 0.8157 - val_loss: 0.4747 - val_acc: 0.7929 - val_f1score: 0.7965\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4555 - acc: 0.8175 - f1score: 0.8157 - val_loss: 0.4747 - val_acc: 0.7929 - val_f1score: 0.7965\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00041: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4518 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4781 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4518 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4781 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4444 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00042: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4450 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4783 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4450 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4783 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00043: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4485 - acc: 0.8175 - f1score: 0.8166 - val_loss: 0.4759 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4485 - acc: 0.8175 - f1score: 0.8166 - val_loss: 0.4759 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4559 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00044: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4544 - acc: 0.8153 - f1score: 0.8159 - val_loss: 0.4791 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4544 - acc: 0.8153 - f1score: 0.8159 - val_loss: 0.4791 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00045: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4497 - acc: 0.8212 - f1score: 0.8217 - val_loss: 0.4768 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4497 - acc: 0.8212 - f1score: 0.8217 - val_loss: 0.4768 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4482 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00046: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4502 - acc: 0.8138 - f1score: 0.8125 - val_loss: 0.4761 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4502 - acc: 0.8138 - f1score: 0.8125 - val_loss: 0.4761 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4536 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00047: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4527 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4762 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4527 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4762 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4497 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00048: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4507 - acc: 0.8153 - f1score: 0.8141 - val_loss: 0.4765 - val_acc: 0.7843 - val_f1score: 0.7874\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4507 - acc: 0.8153 - f1score: 0.8141 - val_loss: 0.4765 - val_acc: 0.7843 - val_f1score: 0.7874\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4477 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00049: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4476 - acc: 0.8175 - f1score: 0.8180 - val_loss: 0.4750 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4476 - acc: 0.8175 - f1score: 0.8180 - val_loss: 0.4750 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4424 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00050: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4435 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4759 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4435 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4759 - val_acc: 0.7908 - val_f1score: 0.7904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  6%|▋         | 6/96 [26:50<8:02:31, 321.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.0910 - acc: 0.5506 - f1score: 0.5484\n",
            "Epoch 00001: val_acc improved from -inf to 0.43133, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.70.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.0839 - acc: 0.5487 - f1score: 0.5448 - val_loss: 0.6959 - val_acc: 0.4313 - val_f1score: 0.4333\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.43133, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.70.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.0839 - acc: 0.5487 - f1score: 0.5448 - val_loss: 0.6959 - val_acc: 0.4313 - val_f1score: 0.4333\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6949 - acc: 0.4386 - f1score: 0.4386\n",
            "Epoch 00002: val_acc did not improve from 0.43133\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6949 - acc: 0.4386 - f1score: 0.4387 - val_loss: 0.6937 - val_acc: 0.4313 - val_f1score: 0.4301\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.43133\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6949 - acc: 0.4386 - f1score: 0.4387 - val_loss: 0.6937 - val_acc: 0.4313 - val_f1score: 0.4301\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6928 - acc: 0.5237 - f1score: 0.5237\n",
            "Epoch 00003: val_acc improved from 0.43133 to 0.56867, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.69.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6928 - acc: 0.5233 - f1score: 0.5229 - val_loss: 0.6916 - val_acc: 0.5687 - val_f1score: 0.5699\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.43133 to 0.56867, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.69.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6928 - acc: 0.5233 - f1score: 0.5229 - val_loss: 0.6916 - val_acc: 0.5687 - val_f1score: 0.5699\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6910 - acc: 0.5609 - f1score: 0.5609\n",
            "Epoch 00004: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6910 - acc: 0.5614 - f1score: 0.5618 - val_loss: 0.6898 - val_acc: 0.5687 - val_f1score: 0.5707\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6910 - acc: 0.5614 - f1score: 0.5618 - val_loss: 0.6898 - val_acc: 0.5687 - val_f1score: 0.5707\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6894 - acc: 0.5630 - f1score: 0.5630\n",
            "Epoch 00005: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6895 - acc: 0.5614 - f1score: 0.5600 - val_loss: 0.6884 - val_acc: 0.5687 - val_f1score: 0.5715\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6895 - acc: 0.5614 - f1score: 0.5600 - val_loss: 0.6884 - val_acc: 0.5687 - val_f1score: 0.5715\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6888 - acc: 0.5587 - f1score: 0.5587\n",
            "Epoch 00006: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6885 - acc: 0.5614 - f1score: 0.5636 - val_loss: 0.6872 - val_acc: 0.5687 - val_f1score: 0.5691\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6885 - acc: 0.5614 - f1score: 0.5636 - val_loss: 0.6872 - val_acc: 0.5687 - val_f1score: 0.5691\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6875 - acc: 0.5625 - f1score: 0.5625\n",
            "Epoch 00007: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6876 - acc: 0.5614 - f1score: 0.5604 - val_loss: 0.6862 - val_acc: 0.5687 - val_f1score: 0.5707\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6876 - acc: 0.5614 - f1score: 0.5604 - val_loss: 0.6862 - val_acc: 0.5687 - val_f1score: 0.5707\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6868 - acc: 0.5630 - f1score: 0.5630\n",
            "Epoch 00008: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6870 - acc: 0.5614 - f1score: 0.5600 - val_loss: 0.6856 - val_acc: 0.5687 - val_f1score: 0.5723\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6870 - acc: 0.5614 - f1score: 0.5600 - val_loss: 0.6856 - val_acc: 0.5687 - val_f1score: 0.5723\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6869 - acc: 0.5598 - f1score: 0.5598\n",
            "Epoch 00009: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6866 - acc: 0.5614 - f1score: 0.5627 - val_loss: 0.6852 - val_acc: 0.5687 - val_f1score: 0.5723\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6866 - acc: 0.5614 - f1score: 0.5627 - val_loss: 0.6852 - val_acc: 0.5687 - val_f1score: 0.5723\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6864 - acc: 0.5603 - f1score: 0.5603\n",
            "Epoch 00010: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6863 - acc: 0.5614 - f1score: 0.5623 - val_loss: 0.6849 - val_acc: 0.5687 - val_f1score: 0.5691\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.56867\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6863 - acc: 0.5614 - f1score: 0.5623 - val_loss: 0.6849 - val_acc: 0.5687 - val_f1score: 0.5691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  7%|▋         | 7/96 [28:09<6:09:31, 249.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.1247 - acc: 0.5442 - f1score: 0.5442\n",
            "Epoch 00001: val_acc improved from -inf to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.58.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 2.0973 - acc: 0.5466 - f1score: 0.5486 - val_loss: 0.5813 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.58.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 2.0973 - acc: 0.5466 - f1score: 0.5486 - val_loss: 0.5813 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6886 - acc: 0.7010 - f1score: 0.7010\n",
            "Epoch 00002: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6856 - acc: 0.7026 - f1score: 0.7041 - val_loss: 0.5121 - val_acc: 0.7800 - val_f1score: 0.7800\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6856 - acc: 0.7026 - f1score: 0.7041 - val_loss: 0.5121 - val_acc: 0.7800 - val_f1score: 0.7800\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5780 - acc: 0.7419 - f1score: 0.7419\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5745 - acc: 0.7434 - f1score: 0.7446 - val_loss: 0.5164 - val_acc: 0.7994 - val_f1score: 0.7979\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5745 - acc: 0.7434 - f1score: 0.7446 - val_loss: 0.5164 - val_acc: 0.7994 - val_f1score: 0.7979\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5453 - acc: 0.7775 - f1score: 0.7775\n",
            "Epoch 00004: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.53.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5422 - acc: 0.7794 - f1score: 0.7810 - val_loss: 0.5260 - val_acc: 0.8015 - val_f1score: 0.7992\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.53.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5422 - acc: 0.7794 - f1score: 0.7810 - val_loss: 0.5260 - val_acc: 0.8015 - val_f1score: 0.7992\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5236 - acc: 0.7877 - f1score: 0.7877\n",
            "Epoch 00005: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.50.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5245 - acc: 0.7884 - f1score: 0.7889 - val_loss: 0.5030 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.50.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5245 - acc: 0.7884 - f1score: 0.7889 - val_loss: 0.5030 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5203 - acc: 0.7807 - f1score: 0.7807\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5186 - acc: 0.7810 - f1score: 0.7812 - val_loss: 0.5027 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5186 - acc: 0.7810 - f1score: 0.7812 - val_loss: 0.5027 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5092 - acc: 0.7877 - f1score: 0.7877\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5071 - acc: 0.7884 - f1score: 0.7889 - val_loss: 0.5036 - val_acc: 0.8004 - val_f1score: 0.8046\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5071 - acc: 0.7884 - f1score: 0.7889 - val_loss: 0.5036 - val_acc: 0.8004 - val_f1score: 0.8046\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5059 - acc: 0.7839 - f1score: 0.7839\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5069 - acc: 0.7831 - f1score: 0.7823 - val_loss: 0.4975 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5069 - acc: 0.7831 - f1score: 0.7823 - val_loss: 0.4975 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5124 - acc: 0.7839 - f1score: 0.7839\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5135 - acc: 0.7841 - f1score: 0.7843 - val_loss: 0.5005 - val_acc: 0.7994 - val_f1score: 0.8020\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5135 - acc: 0.7841 - f1score: 0.7843 - val_loss: 0.5005 - val_acc: 0.7994 - val_f1score: 0.8020\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4952 - acc: 0.7904 - f1score: 0.7904\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4959 - acc: 0.7905 - f1score: 0.7905 - val_loss: 0.4959 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4959 - acc: 0.7905 - f1score: 0.7905 - val_loss: 0.4959 - val_acc: 0.7811 - val_f1score: 0.7818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  8%|▊         | 8/96 [29:53<5:01:20, 205.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 6.3406 - acc: 0.4316 - f1score: 0.4312\n",
            "Epoch 00001: val_acc improved from -inf to 0.43133, saving model to /content/drive/My Drive/LSTM_Model/model.01-4.63.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 6.3034 - acc: 0.4307 - f1score: 0.4295 - val_loss: 4.6284 - val_acc: 0.4313 - val_f1score: 0.4301\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.43133, saving model to /content/drive/My Drive/LSTM_Model/model.01-4.63.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 6.3034 - acc: 0.4307 - f1score: 0.4295 - val_loss: 4.6284 - val_acc: 0.4313 - val_f1score: 0.4301\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.8625 - acc: 0.4079 - f1score: 0.4079\n",
            "Epoch 00002: val_acc improved from 0.43133 to 0.43670, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.37.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.8420 - acc: 0.4095 - f1score: 0.4109 - val_loss: 1.3714 - val_acc: 0.4367 - val_f1score: 0.4337\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.43133 to 0.43670, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.37.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.8420 - acc: 0.4095 - f1score: 0.4109 - val_loss: 1.3714 - val_acc: 0.4367 - val_f1score: 0.4337\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.9803 - acc: 0.4758 - f1score: 0.4758\n",
            "Epoch 00003: val_acc improved from 0.43670 to 0.49678, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.69.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.9753 - acc: 0.4767 - f1score: 0.4775 - val_loss: 0.6897 - val_acc: 0.4968 - val_f1score: 0.4969\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.43670 to 0.49678, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.69.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.9753 - acc: 0.4767 - f1score: 0.4775 - val_loss: 0.6897 - val_acc: 0.4968 - val_f1score: 0.4969\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6476 - acc: 0.5555 - f1score: 0.5555\n",
            "Epoch 00004: val_acc improved from 0.49678 to 0.73712, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.59.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6460 - acc: 0.5577 - f1score: 0.5595 - val_loss: 0.5867 - val_acc: 0.7371 - val_f1score: 0.7343\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.49678 to 0.73712, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.59.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6460 - acc: 0.5577 - f1score: 0.5595 - val_loss: 0.5867 - val_acc: 0.7371 - val_f1score: 0.7343\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5798 - acc: 0.6956 - f1score: 0.6956\n",
            "Epoch 00005: val_acc improved from 0.73712 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.54.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5804 - acc: 0.6963 - f1score: 0.6969 - val_loss: 0.5390 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.73712 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.54.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5804 - acc: 0.6963 - f1score: 0.6969 - val_loss: 0.5390 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5413 - acc: 0.7651 - f1score: 0.7651\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5419 - acc: 0.7646 - f1score: 0.7641 - val_loss: 0.5128 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5419 - acc: 0.7646 - f1score: 0.7641 - val_loss: 0.5128 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5010 - acc: 0.7958 - f1score: 0.7958\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5009 - acc: 0.7942 - f1score: 0.7928 - val_loss: 0.4975 - val_acc: 0.8004 - val_f1score: 0.7965\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5009 - acc: 0.7942 - f1score: 0.7928 - val_loss: 0.4975 - val_acc: 0.8004 - val_f1score: 0.7965\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4889 - acc: 0.7996 - f1score: 0.7996\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4874 - acc: 0.8005 - f1score: 0.8013 - val_loss: 0.4936 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4874 - acc: 0.8005 - f1score: 0.8013 - val_loss: 0.4936 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4803 - acc: 0.8082 - f1score: 0.8082\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4829 - acc: 0.8063 - f1score: 0.8048 - val_loss: 0.4905 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4829 - acc: 0.8063 - f1score: 0.8048 - val_loss: 0.4905 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4736 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4781 - acc: 0.7931 - f1score: 0.7899 - val_loss: 0.4906 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4781 - acc: 0.7931 - f1score: 0.7899 - val_loss: 0.4906 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4910 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4941 - acc: 0.7958 - f1score: 0.7944 - val_loss: 0.4905 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4941 - acc: 0.7958 - f1score: 0.7944 - val_loss: 0.4905 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4880 - acc: 0.7888 - f1score: 0.7888\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4844 - acc: 0.7910 - f1score: 0.7929 - val_loss: 0.4913 - val_acc: 0.7822 - val_f1score: 0.7788\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4844 - acc: 0.7910 - f1score: 0.7929 - val_loss: 0.4913 - val_acc: 0.7822 - val_f1score: 0.7788\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4802 - acc: 0.7996 - f1score: 0.7996\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4796 - acc: 0.8000 - f1score: 0.8004 - val_loss: 0.4904 - val_acc: 0.7833 - val_f1score: 0.7807\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4796 - acc: 0.8000 - f1score: 0.8004 - val_loss: 0.4904 - val_acc: 0.7833 - val_f1score: 0.7807\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4925 - acc: 0.7909 - f1score: 0.7909\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4916 - acc: 0.7905 - f1score: 0.7901 - val_loss: 0.4899 - val_acc: 0.7800 - val_f1score: 0.7832\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4916 - acc: 0.7905 - f1score: 0.7901 - val_loss: 0.4899 - val_acc: 0.7800 - val_f1score: 0.7832\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4842 - acc: 0.7915 - f1score: 0.7915\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4843 - acc: 0.7899 - f1score: 0.7886 - val_loss: 0.4903 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4843 - acc: 0.7899 - f1score: 0.7886 - val_loss: 0.4903 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4843 - acc: 0.7931 - f1score: 0.7931\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4837 - acc: 0.7937 - f1score: 0.7941 - val_loss: 0.4918 - val_acc: 0.7833 - val_f1score: 0.7807\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4837 - acc: 0.7937 - f1score: 0.7941 - val_loss: 0.4918 - val_acc: 0.7833 - val_f1score: 0.7807\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4855 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4845 - acc: 0.7963 - f1score: 0.7963 - val_loss: 0.4905 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4845 - acc: 0.7963 - f1score: 0.7963 - val_loss: 0.4905 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4822 - acc: 0.7899 - f1score: 0.7899\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4804 - acc: 0.7910 - f1score: 0.7920 - val_loss: 0.4896 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4804 - acc: 0.7910 - f1score: 0.7920 - val_loss: 0.4896 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4830 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00019: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4844 - acc: 0.7952 - f1score: 0.7938 - val_loss: 0.4886 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4844 - acc: 0.7952 - f1score: 0.7938 - val_loss: 0.4886 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4832 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00020: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4842 - acc: 0.7947 - f1score: 0.7929 - val_loss: 0.4898 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4842 - acc: 0.7947 - f1score: 0.7929 - val_loss: 0.4898 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4721 - acc: 0.8039 - f1score: 0.8039\n",
            "Epoch 00021: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4738 - acc: 0.8005 - f1score: 0.7977 - val_loss: 0.4887 - val_acc: 0.7822 - val_f1score: 0.7796\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4738 - acc: 0.8005 - f1score: 0.7977 - val_loss: 0.4887 - val_acc: 0.7822 - val_f1score: 0.7796\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4812 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00022: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4810 - acc: 0.7989 - f1score: 0.7998 - val_loss: 0.4896 - val_acc: 0.7811 - val_f1score: 0.7794\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4810 - acc: 0.7989 - f1score: 0.7998 - val_loss: 0.4896 - val_acc: 0.7811 - val_f1score: 0.7794\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4854 - acc: 0.7926 - f1score: 0.7926\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4827 - acc: 0.7952 - f1score: 0.7975 - val_loss: 0.4893 - val_acc: 0.7800 - val_f1score: 0.7792\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4827 - acc: 0.7952 - f1score: 0.7975 - val_loss: 0.4893 - val_acc: 0.7800 - val_f1score: 0.7792\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4768 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00024: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4776 - acc: 0.7984 - f1score: 0.7988 - val_loss: 0.4890 - val_acc: 0.7800 - val_f1score: 0.7840\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4776 - acc: 0.7984 - f1score: 0.7988 - val_loss: 0.4890 - val_acc: 0.7800 - val_f1score: 0.7840\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4849 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00025: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4833 - acc: 0.7963 - f1score: 0.7972 - val_loss: 0.4919 - val_acc: 0.7822 - val_f1score: 0.7812\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4833 - acc: 0.7963 - f1score: 0.7972 - val_loss: 0.4919 - val_acc: 0.7822 - val_f1score: 0.7812\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4751 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00026: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4757 - acc: 0.7937 - f1score: 0.7932 - val_loss: 0.4883 - val_acc: 0.7811 - val_f1score: 0.7810\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4757 - acc: 0.7937 - f1score: 0.7932 - val_loss: 0.4883 - val_acc: 0.7811 - val_f1score: 0.7810\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4804 - acc: 0.7915 - f1score: 0.7915\n",
            "Epoch 00027: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4789 - acc: 0.7926 - f1score: 0.7935 - val_loss: 0.4901 - val_acc: 0.7800 - val_f1score: 0.7824\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4789 - acc: 0.7926 - f1score: 0.7935 - val_loss: 0.4901 - val_acc: 0.7800 - val_f1score: 0.7824\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4847 - acc: 0.7926 - f1score: 0.7926\n",
            "Epoch 00028: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4833 - acc: 0.7942 - f1score: 0.7956 - val_loss: 0.4891 - val_acc: 0.7811 - val_f1score: 0.7794\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4833 - acc: 0.7942 - f1score: 0.7956 - val_loss: 0.4891 - val_acc: 0.7811 - val_f1score: 0.7794\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4789 - acc: 0.7872 - f1score: 0.7872\n",
            "Epoch 00029: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4769 - acc: 0.7889 - f1score: 0.7903 - val_loss: 0.4884 - val_acc: 0.7800 - val_f1score: 0.7784\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4769 - acc: 0.7889 - f1score: 0.7903 - val_loss: 0.4884 - val_acc: 0.7800 - val_f1score: 0.7784\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4721 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00030: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4739 - acc: 0.7952 - f1score: 0.7943 - val_loss: 0.4894 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4739 - acc: 0.7952 - f1score: 0.7943 - val_loss: 0.4894 - val_acc: 0.7822 - val_f1score: 0.7804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  9%|▉         | 9/96 [33:50<5:11:44, 215.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 7.6722 - acc: 0.4558 - f1score: 0.4558\n",
            "Epoch 00001: val_acc improved from -inf to 0.43133, saving model to /content/drive/My Drive/LSTM_Model/model.01-8.54.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 7.6601 - acc: 0.4556 - f1score: 0.4553 - val_loss: 8.5439 - val_acc: 0.4313 - val_f1score: 0.4285\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.43133, saving model to /content/drive/My Drive/LSTM_Model/model.01-8.54.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 7.6601 - acc: 0.4556 - f1score: 0.4553 - val_loss: 8.5439 - val_acc: 0.4313 - val_f1score: 0.4285\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 6.1778 - acc: 0.4758 - f1score: 0.4758\n",
            "Epoch 00002: val_acc improved from 0.43133 to 0.56867, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.32.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 6.1567 - acc: 0.4751 - f1score: 0.4746 - val_loss: 1.3177 - val_acc: 0.5687 - val_f1score: 0.5659\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.43133 to 0.56867, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.32.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 6.1567 - acc: 0.4751 - f1score: 0.4746 - val_loss: 1.3177 - val_acc: 0.5687 - val_f1score: 0.5659\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.7006 - acc: 0.6848 - f1score: 0.6848\n",
            "Epoch 00003: val_acc improved from 0.56867 to 0.77253, saving model to /content/drive/My Drive/LSTM_Model/model.03-1.78.h5\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.56867 to 0.77253, saving model to /content/drive/My Drive/LSTM_Model/model.03-1.78.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.6885 - acc: 0.6852 - f1score: 0.6855 - val_loss: 1.7793 - val_acc: 0.7725 - val_f1score: 0.7719\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.6885 - acc: 0.6852 - f1score: 0.6855 - val_loss: 1.7793 - val_acc: 0.7725 - val_f1score: 0.7719\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.9330 - acc: 0.6880 - f1score: 0.6880\n",
            "Epoch 00004: val_acc did not improve from 0.77253\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9278 - acc: 0.6873 - f1score: 0.6867 - val_loss: 0.6653 - val_acc: 0.6116 - val_f1score: 0.6132\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.77253\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9278 - acc: 0.6873 - f1score: 0.6867 - val_loss: 0.6653 - val_acc: 0.6116 - val_f1score: 0.6132\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6211 - acc: 0.6589 - f1score: 0.6589\n",
            "Epoch 00005: val_acc did not improve from 0.77253\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6202 - acc: 0.6577 - f1score: 0.6566 - val_loss: 0.5226 - val_acc: 0.7715 - val_f1score: 0.7716\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.77253\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6202 - acc: 0.6577 - f1score: 0.6566 - val_loss: 0.5226 - val_acc: 0.7715 - val_f1score: 0.7716\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5538 - acc: 0.6864 - f1score: 0.6864\n",
            "Epoch 00006: val_acc improved from 0.77253 to 0.78541, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.52.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5505 - acc: 0.6889 - f1score: 0.6910 - val_loss: 0.5160 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.77253 to 0.78541, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.52.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5505 - acc: 0.6889 - f1score: 0.6910 - val_loss: 0.5160 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5424 - acc: 0.6983 - f1score: 0.6983\n",
            "Epoch 00007: val_acc improved from 0.78541 to 0.78755, saving model to /content/drive/My Drive/LSTM_Model/model.07-0.52.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5437 - acc: 0.6984 - f1score: 0.6985 - val_loss: 0.5160 - val_acc: 0.7876 - val_f1score: 0.7905\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.78541 to 0.78755, saving model to /content/drive/My Drive/LSTM_Model/model.07-0.52.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5437 - acc: 0.6984 - f1score: 0.6985 - val_loss: 0.5160 - val_acc: 0.7876 - val_f1score: 0.7905\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5372 - acc: 0.7020 - f1score: 0.7020\n",
            "Epoch 00008: val_acc improved from 0.78755 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.50.h5\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.78755 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.50.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5393 - acc: 0.7011 - f1score: 0.7002 - val_loss: 0.5032 - val_acc: 0.8026 - val_f1score: 0.8027\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5393 - acc: 0.7011 - f1score: 0.7002 - val_loss: 0.5032 - val_acc: 0.8026 - val_f1score: 0.8027\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5375 - acc: 0.6967 - f1score: 0.6967\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5362 - acc: 0.6974 - f1score: 0.6979 - val_loss: 0.5017 - val_acc: 0.7736 - val_f1score: 0.7737\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5362 - acc: 0.6974 - f1score: 0.6979 - val_loss: 0.5017 - val_acc: 0.7736 - val_f1score: 0.7737\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5371 - acc: 0.6907 - f1score: 0.6907\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5369 - acc: 0.6889 - f1score: 0.6873 - val_loss: 0.4993 - val_acc: 0.7768 - val_f1score: 0.7752\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5369 - acc: 0.6889 - f1score: 0.6873 - val_loss: 0.4993 - val_acc: 0.7768 - val_f1score: 0.7752\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5391 - acc: 0.6950 - f1score: 0.6950\n",
            "Epoch 00011: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5393 - acc: 0.6963 - f1score: 0.6974 - val_loss: 0.5135 - val_acc: 0.7758 - val_f1score: 0.7750\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5393 - acc: 0.6963 - f1score: 0.6974 - val_loss: 0.5135 - val_acc: 0.7758 - val_f1score: 0.7750\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5150 - acc: 0.7328 - f1score: 0.7328\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5185 - acc: 0.7328 - f1score: 0.7328 - val_loss: 0.4993 - val_acc: 0.7725 - val_f1score: 0.7727\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5185 - acc: 0.7328 - f1score: 0.7328 - val_loss: 0.4993 - val_acc: 0.7725 - val_f1score: 0.7727\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5339 - acc: 0.7220 - f1score: 0.7220\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5349 - acc: 0.7212 - f1score: 0.7205 - val_loss: 0.4959 - val_acc: 0.7736 - val_f1score: 0.7721\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5349 - acc: 0.7212 - f1score: 0.7205 - val_loss: 0.4959 - val_acc: 0.7736 - val_f1score: 0.7721\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5204 - acc: 0.7333 - f1score: 0.7333\n",
            "Epoch 00014: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5184 - acc: 0.7344 - f1score: 0.7353 - val_loss: 0.4982 - val_acc: 0.7747 - val_f1score: 0.7740\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5184 - acc: 0.7344 - f1score: 0.7353 - val_loss: 0.4982 - val_acc: 0.7747 - val_f1score: 0.7740\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5344 - acc: 0.7241 - f1score: 0.7241\n",
            "Epoch 00015: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5331 - acc: 0.7265 - f1score: 0.7284 - val_loss: 0.4988 - val_acc: 0.7768 - val_f1score: 0.7809\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5331 - acc: 0.7265 - f1score: 0.7284 - val_loss: 0.4988 - val_acc: 0.7768 - val_f1score: 0.7809\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5295 - acc: 0.7284 - f1score: 0.7284\n",
            "Epoch 00016: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5280 - acc: 0.7286 - f1score: 0.7287 - val_loss: 0.4953 - val_acc: 0.7758 - val_f1score: 0.7791\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5280 - acc: 0.7286 - f1score: 0.7287 - val_loss: 0.4953 - val_acc: 0.7758 - val_f1score: 0.7791\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5320 - acc: 0.7231 - f1score: 0.7231\n",
            "Epoch 00017: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5342 - acc: 0.7228 - f1score: 0.7225 - val_loss: 0.4985 - val_acc: 0.7779 - val_f1score: 0.7771\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5342 - acc: 0.7228 - f1score: 0.7225 - val_loss: 0.4985 - val_acc: 0.7779 - val_f1score: 0.7771\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5276 - acc: 0.7317 - f1score: 0.7317\n",
            "Epoch 00018: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5261 - acc: 0.7328 - f1score: 0.7338 - val_loss: 0.4998 - val_acc: 0.7768 - val_f1score: 0.7744\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5261 - acc: 0.7328 - f1score: 0.7338 - val_loss: 0.4998 - val_acc: 0.7768 - val_f1score: 0.7744\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5226 - acc: 0.7311 - f1score: 0.7311\n",
            "Epoch 00019: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5244 - acc: 0.7307 - f1score: 0.7303 - val_loss: 0.4940 - val_acc: 0.7758 - val_f1score: 0.7766\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5244 - acc: 0.7307 - f1score: 0.7303 - val_loss: 0.4940 - val_acc: 0.7758 - val_f1score: 0.7766\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5203 - acc: 0.7274 - f1score: 0.7274\n",
            "Epoch 00020: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5199 - acc: 0.7286 - f1score: 0.7296 - val_loss: 0.4958 - val_acc: 0.7768 - val_f1score: 0.7777\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5199 - acc: 0.7286 - f1score: 0.7296 - val_loss: 0.4958 - val_acc: 0.7768 - val_f1score: 0.7777\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5310 - acc: 0.7311 - f1score: 0.7311\n",
            "Epoch 00021: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5296 - acc: 0.7328 - f1score: 0.7342 - val_loss: 0.4962 - val_acc: 0.7768 - val_f1score: 0.7744\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5296 - acc: 0.7328 - f1score: 0.7342 - val_loss: 0.4962 - val_acc: 0.7768 - val_f1score: 0.7744\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5181 - acc: 0.7360 - f1score: 0.7360\n",
            "Epoch 00022: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5173 - acc: 0.7381 - f1score: 0.7399 - val_loss: 0.4931 - val_acc: 0.7758 - val_f1score: 0.7774\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5173 - acc: 0.7381 - f1score: 0.7399 - val_loss: 0.4931 - val_acc: 0.7758 - val_f1score: 0.7774\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5196 - acc: 0.7349 - f1score: 0.7349\n",
            "Epoch 00023: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5185 - acc: 0.7349 - f1score: 0.7349 - val_loss: 0.4985 - val_acc: 0.7779 - val_f1score: 0.7779\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5185 - acc: 0.7349 - f1score: 0.7349 - val_loss: 0.4985 - val_acc: 0.7779 - val_f1score: 0.7779\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5163 - acc: 0.7398 - f1score: 0.7398\n",
            "Epoch 00024: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5142 - acc: 0.7392 - f1score: 0.7386 - val_loss: 0.4931 - val_acc: 0.7768 - val_f1score: 0.7777\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5142 - acc: 0.7392 - f1score: 0.7386 - val_loss: 0.4931 - val_acc: 0.7768 - val_f1score: 0.7777\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5158 - acc: 0.7317 - f1score: 0.7317\n",
            "Epoch 00025: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5185 - acc: 0.7302 - f1score: 0.7289 - val_loss: 0.4938 - val_acc: 0.7758 - val_f1score: 0.7693\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5185 - acc: 0.7302 - f1score: 0.7289 - val_loss: 0.4938 - val_acc: 0.7758 - val_f1score: 0.7693\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5209 - acc: 0.7290 - f1score: 0.7290\n",
            "Epoch 00026: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5201 - acc: 0.7280 - f1score: 0.7272 - val_loss: 0.4949 - val_acc: 0.7768 - val_f1score: 0.7777\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5201 - acc: 0.7280 - f1score: 0.7272 - val_loss: 0.4949 - val_acc: 0.7768 - val_f1score: 0.7777\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5320 - acc: 0.7236 - f1score: 0.7236\n",
            "Epoch 00027: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5350 - acc: 0.7222 - f1score: 0.7210 - val_loss: 0.4960 - val_acc: 0.7779 - val_f1score: 0.7811\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5350 - acc: 0.7222 - f1score: 0.7210 - val_loss: 0.4960 - val_acc: 0.7779 - val_f1score: 0.7811\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5200 - acc: 0.7290 - f1score: 0.7290\n",
            "Epoch 00028: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5228 - acc: 0.7307 - f1score: 0.7321 - val_loss: 0.4947 - val_acc: 0.7736 - val_f1score: 0.7737\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5228 - acc: 0.7307 - f1score: 0.7321 - val_loss: 0.4947 - val_acc: 0.7736 - val_f1score: 0.7737\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5214 - acc: 0.7290 - f1score: 0.7290\n",
            "Epoch 00029: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5195 - acc: 0.7312 - f1score: 0.7331 - val_loss: 0.4924 - val_acc: 0.7758 - val_f1score: 0.7726\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5195 - acc: 0.7312 - f1score: 0.7331 - val_loss: 0.4924 - val_acc: 0.7758 - val_f1score: 0.7726\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5216 - acc: 0.7349 - f1score: 0.7349\n",
            "Epoch 00030: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5210 - acc: 0.7328 - f1score: 0.7310 - val_loss: 0.4950 - val_acc: 0.7768 - val_f1score: 0.7777\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5210 - acc: 0.7328 - f1score: 0.7310 - val_loss: 0.4950 - val_acc: 0.7768 - val_f1score: 0.7777\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 10%|█         | 10/96 [38:58<5:47:51, 242.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.7201 - acc: 0.6552 - f1score: 0.6552\n",
            "Epoch 00001: val_acc improved from -inf to 0.76931, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.95.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.7020 - acc: 0.6577 - f1score: 0.6598 - val_loss: 0.9533 - val_acc: 0.7693 - val_f1score: 0.7696\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.76931, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.95.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.7020 - acc: 0.6577 - f1score: 0.6598 - val_loss: 0.9533 - val_acc: 0.7693 - val_f1score: 0.7696\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.7485 - acc: 0.7150 - f1score: 0.7150\n",
            "Epoch 00002: val_acc did not improve from 0.76931\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7452 - acc: 0.7153 - f1score: 0.7157 - val_loss: 0.6140 - val_acc: 0.7543 - val_f1score: 0.7542\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.76931\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7452 - acc: 0.7153 - f1score: 0.7157 - val_loss: 0.6140 - val_acc: 0.7543 - val_f1score: 0.7542\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5752 - acc: 0.6843 - f1score: 0.6843\n",
            "Epoch 00003: val_acc improved from 0.76931 to 0.78970, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.53.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5734 - acc: 0.6852 - f1score: 0.6860 - val_loss: 0.5268 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.76931 to 0.78970, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.53.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5734 - acc: 0.6852 - f1score: 0.6860 - val_loss: 0.5268 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5572 - acc: 0.6762 - f1score: 0.6762\n",
            "Epoch 00004: val_acc improved from 0.78970 to 0.79936, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.52.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5567 - acc: 0.6762 - f1score: 0.6762 - val_loss: 0.5232 - val_acc: 0.7994 - val_f1score: 0.8020\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.78970 to 0.79936, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.52.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5567 - acc: 0.6762 - f1score: 0.6762 - val_loss: 0.5232 - val_acc: 0.7994 - val_f1score: 0.8020\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5569 - acc: 0.6972 - f1score: 0.6972\n",
            "Epoch 00005: val_acc improved from 0.79936 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.53.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5561 - acc: 0.7000 - f1score: 0.7024 - val_loss: 0.5258 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.79936 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.53.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5561 - acc: 0.7000 - f1score: 0.7024 - val_loss: 0.5258 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5311 - acc: 0.7419 - f1score: 0.7419\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5332 - acc: 0.7418 - f1score: 0.7417 - val_loss: 0.5109 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5332 - acc: 0.7418 - f1score: 0.7417 - val_loss: 0.5109 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5233 - acc: 0.7592 - f1score: 0.7592\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5240 - acc: 0.7593 - f1score: 0.7593 - val_loss: 0.5090 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5240 - acc: 0.7593 - f1score: 0.7593 - val_loss: 0.5090 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5289 - acc: 0.7575 - f1score: 0.7575\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5261 - acc: 0.7577 - f1score: 0.7578 - val_loss: 0.5059 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5261 - acc: 0.7577 - f1score: 0.7578 - val_loss: 0.5059 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5156 - acc: 0.7543 - f1score: 0.7543\n",
            "Epoch 00009: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.09-0.51.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5219 - acc: 0.7524 - f1score: 0.7507 - val_loss: 0.5111 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.09-0.51.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5219 - acc: 0.7524 - f1score: 0.7507 - val_loss: 0.5111 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5234 - acc: 0.7462 - f1score: 0.7462\n",
            "Epoch 00010: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5224 - acc: 0.7466 - f1score: 0.7468 - val_loss: 0.5108 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5224 - acc: 0.7466 - f1score: 0.7468 - val_loss: 0.5108 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5221 - acc: 0.7414 - f1score: 0.7414\n",
            "Epoch 00011: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.11-0.51.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5203 - acc: 0.7439 - f1score: 0.7461 - val_loss: 0.5051 - val_acc: 0.8026 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.11-0.51.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5203 - acc: 0.7439 - f1score: 0.7461 - val_loss: 0.5051 - val_acc: 0.8026 - val_f1score: 0.8059\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5198 - acc: 0.7500 - f1score: 0.7500\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5199 - acc: 0.7503 - f1score: 0.7505 - val_loss: 0.5067 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5199 - acc: 0.7503 - f1score: 0.7505 - val_loss: 0.5067 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5447 - acc: 0.7349 - f1score: 0.7349\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5442 - acc: 0.7339 - f1score: 0.7330 - val_loss: 0.5161 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5442 - acc: 0.7339 - f1score: 0.7330 - val_loss: 0.5161 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5433 - acc: 0.7284 - f1score: 0.7284\n",
            "Epoch 00014: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.14-0.51.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5398 - acc: 0.7307 - f1score: 0.7326 - val_loss: 0.5100 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.14-0.51.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5398 - acc: 0.7307 - f1score: 0.7326 - val_loss: 0.5100 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5312 - acc: 0.7408 - f1score: 0.7408\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5307 - acc: 0.7418 - f1score: 0.7426 - val_loss: 0.5081 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5307 - acc: 0.7418 - f1score: 0.7426 - val_loss: 0.5081 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5298 - acc: 0.7430 - f1score: 0.7430\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5293 - acc: 0.7413 - f1score: 0.7398 - val_loss: 0.5074 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5293 - acc: 0.7413 - f1score: 0.7398 - val_loss: 0.5074 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5282 - acc: 0.7387 - f1score: 0.7387\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5273 - acc: 0.7397 - f1score: 0.7405 - val_loss: 0.5026 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5273 - acc: 0.7397 - f1score: 0.7405 - val_loss: 0.5026 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5233 - acc: 0.7408 - f1score: 0.7408\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5230 - acc: 0.7407 - f1score: 0.7407 - val_loss: 0.5057 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5230 - acc: 0.7407 - f1score: 0.7407 - val_loss: 0.5057 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5238 - acc: 0.7333 - f1score: 0.7333\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5219 - acc: 0.7354 - f1score: 0.7373 - val_loss: 0.4978 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5219 - acc: 0.7354 - f1score: 0.7373 - val_loss: 0.4978 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5155 - acc: 0.7403 - f1score: 0.7403\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5149 - acc: 0.7402 - f1score: 0.7401 - val_loss: 0.4996 - val_acc: 0.7940 - val_f1score: 0.7878\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5149 - acc: 0.7402 - f1score: 0.7401 - val_loss: 0.4996 - val_acc: 0.7940 - val_f1score: 0.7878\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5151 - acc: 0.7516 - f1score: 0.7516\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5163 - acc: 0.7534 - f1score: 0.7550 - val_loss: 0.4955 - val_acc: 0.7908 - val_f1score: 0.7872\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5163 - acc: 0.7534 - f1score: 0.7550 - val_loss: 0.4955 - val_acc: 0.7908 - val_f1score: 0.7872\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5044 - acc: 0.7478 - f1score: 0.7478\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5034 - acc: 0.7497 - f1score: 0.7513 - val_loss: 0.4931 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5034 - acc: 0.7497 - f1score: 0.7513 - val_loss: 0.4931 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5253 - acc: 0.7301 - f1score: 0.7301\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5283 - acc: 0.7270 - f1score: 0.7244 - val_loss: 0.4982 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5283 - acc: 0.7270 - f1score: 0.7244 - val_loss: 0.4982 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5312 - acc: 0.7365 - f1score: 0.7365\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5301 - acc: 0.7365 - f1score: 0.7365 - val_loss: 0.4934 - val_acc: 0.7854 - val_f1score: 0.7884\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5301 - acc: 0.7365 - f1score: 0.7365 - val_loss: 0.4934 - val_acc: 0.7854 - val_f1score: 0.7884\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5193 - acc: 0.7290 - f1score: 0.7290\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5170 - acc: 0.7302 - f1score: 0.7312 - val_loss: 0.4948 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5170 - acc: 0.7302 - f1score: 0.7312 - val_loss: 0.4948 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5082 - acc: 0.7419 - f1score: 0.7419\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5068 - acc: 0.7434 - f1score: 0.7446 - val_loss: 0.4975 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5068 - acc: 0.7434 - f1score: 0.7446 - val_loss: 0.4975 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4982 - acc: 0.7495 - f1score: 0.7495\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5024 - acc: 0.7471 - f1score: 0.7451 - val_loss: 0.4911 - val_acc: 0.7843 - val_f1score: 0.7858\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5024 - acc: 0.7471 - f1score: 0.7451 - val_loss: 0.4911 - val_acc: 0.7843 - val_f1score: 0.7858\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5125 - acc: 0.7489 - f1score: 0.7489\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5113 - acc: 0.7487 - f1score: 0.7485 - val_loss: 0.4930 - val_acc: 0.7800 - val_f1score: 0.7792\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5113 - acc: 0.7487 - f1score: 0.7485 - val_loss: 0.4930 - val_acc: 0.7800 - val_f1score: 0.7792\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5223 - acc: 0.7392 - f1score: 0.7392\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5185 - acc: 0.7413 - f1score: 0.7430 - val_loss: 0.4941 - val_acc: 0.7800 - val_f1score: 0.7775\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5185 - acc: 0.7413 - f1score: 0.7430 - val_loss: 0.4941 - val_acc: 0.7800 - val_f1score: 0.7775\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5044 - acc: 0.7468 - f1score: 0.7468\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5063 - acc: 0.7444 - f1score: 0.7425 - val_loss: 0.4910 - val_acc: 0.7822 - val_f1score: 0.7796\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5063 - acc: 0.7444 - f1score: 0.7425 - val_loss: 0.4910 - val_acc: 0.7822 - val_f1score: 0.7796\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5108 - acc: 0.7365 - f1score: 0.7365\n",
            "Epoch 00031: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5113 - acc: 0.7349 - f1score: 0.7335 - val_loss: 0.4978 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5113 - acc: 0.7349 - f1score: 0.7335 - val_loss: 0.4978 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5149 - acc: 0.7338 - f1score: 0.7338\n",
            "Epoch 00032: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5156 - acc: 0.7339 - f1score: 0.7339 - val_loss: 0.4911 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5156 - acc: 0.7339 - f1score: 0.7339 - val_loss: 0.4911 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5102 - acc: 0.7371 - f1score: 0.7371\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5117 - acc: 0.7360 - f1score: 0.7350 - val_loss: 0.4944 - val_acc: 0.7843 - val_f1score: 0.7874\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5117 - acc: 0.7360 - f1score: 0.7350 - val_loss: 0.4944 - val_acc: 0.7843 - val_f1score: 0.7874\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5097 - acc: 0.7408 - f1score: 0.7408\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5087 - acc: 0.7413 - f1score: 0.7416 - val_loss: 0.4930 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5087 - acc: 0.7413 - f1score: 0.7416 - val_loss: 0.4930 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4991 - acc: 0.7495 - f1score: 0.7495\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5013 - acc: 0.7455 - f1score: 0.7421 - val_loss: 0.4907 - val_acc: 0.7811 - val_f1score: 0.7778\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5013 - acc: 0.7455 - f1score: 0.7421 - val_loss: 0.4907 - val_acc: 0.7811 - val_f1score: 0.7778\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5053 - acc: 0.7495 - f1score: 0.7495\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5078 - acc: 0.7492 - f1score: 0.7490 - val_loss: 0.4889 - val_acc: 0.7854 - val_f1score: 0.7868\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5078 - acc: 0.7492 - f1score: 0.7490 - val_loss: 0.4889 - val_acc: 0.7854 - val_f1score: 0.7868\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5158 - acc: 0.7452 - f1score: 0.7452\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5172 - acc: 0.7429 - f1score: 0.7409 - val_loss: 0.4923 - val_acc: 0.7822 - val_f1score: 0.7861\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5172 - acc: 0.7429 - f1score: 0.7409 - val_loss: 0.4923 - val_acc: 0.7822 - val_f1score: 0.7861\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5009 - acc: 0.7457 - f1score: 0.7457\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5025 - acc: 0.7434 - f1score: 0.7414 - val_loss: 0.4984 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5025 - acc: 0.7434 - f1score: 0.7414 - val_loss: 0.4984 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5067 - acc: 0.7381 - f1score: 0.7381\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5047 - acc: 0.7413 - f1score: 0.7439 - val_loss: 0.4888 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5047 - acc: 0.7413 - f1score: 0.7439 - val_loss: 0.4888 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5032 - acc: 0.7419 - f1score: 0.7419\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5012 - acc: 0.7423 - f1score: 0.7427 - val_loss: 0.4919 - val_acc: 0.7854 - val_f1score: 0.7828\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5012 - acc: 0.7423 - f1score: 0.7427 - val_loss: 0.4919 - val_acc: 0.7854 - val_f1score: 0.7828\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5110 - acc: 0.7414 - f1score: 0.7414\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5121 - acc: 0.7402 - f1score: 0.7392 - val_loss: 0.5082 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5121 - acc: 0.7402 - f1score: 0.7392 - val_loss: 0.5082 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5078 - acc: 0.7419 - f1score: 0.7419\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5055 - acc: 0.7444 - f1score: 0.7466 - val_loss: 0.5009 - val_acc: 0.7822 - val_f1score: 0.7853\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5055 - acc: 0.7444 - f1score: 0.7466 - val_loss: 0.5009 - val_acc: 0.7822 - val_f1score: 0.7853\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5055 - acc: 0.7495 - f1score: 0.7495\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5061 - acc: 0.7503 - f1score: 0.7509 - val_loss: 0.4869 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5061 - acc: 0.7503 - f1score: 0.7509 - val_loss: 0.4869 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5029 - acc: 0.7446 - f1score: 0.7446\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5038 - acc: 0.7434 - f1score: 0.7423 - val_loss: 0.4855 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5038 - acc: 0.7434 - f1score: 0.7423 - val_loss: 0.4855 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5031 - acc: 0.7398 - f1score: 0.7398\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5025 - acc: 0.7407 - f1score: 0.7416 - val_loss: 0.4887 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5025 - acc: 0.7407 - f1score: 0.7416 - val_loss: 0.4887 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5043 - acc: 0.7430 - f1score: 0.7430\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5063 - acc: 0.7413 - f1score: 0.7398 - val_loss: 0.4914 - val_acc: 0.7790 - val_f1score: 0.7781\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5063 - acc: 0.7413 - f1score: 0.7398 - val_loss: 0.4914 - val_acc: 0.7790 - val_f1score: 0.7781\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4988 - acc: 0.7473 - f1score: 0.7473\n",
            "Epoch 00047: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4996 - acc: 0.7466 - f1score: 0.7459 - val_loss: 0.4903 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4996 - acc: 0.7466 - f1score: 0.7459 - val_loss: 0.4903 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5044 - acc: 0.7495 - f1score: 0.7495\n",
            "Epoch 00048: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5029 - acc: 0.7492 - f1score: 0.7490 - val_loss: 0.4882 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5029 - acc: 0.7492 - f1score: 0.7490 - val_loss: 0.4882 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5090 - acc: 0.7365 - f1score: 0.7365\n",
            "Epoch 00049: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5086 - acc: 0.7365 - f1score: 0.7365 - val_loss: 0.4878 - val_acc: 0.7833 - val_f1score: 0.7807\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5086 - acc: 0.7365 - f1score: 0.7365 - val_loss: 0.4878 - val_acc: 0.7833 - val_f1score: 0.7807\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5042 - acc: 0.7387 - f1score: 0.7387\n",
            "Epoch 00050: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5070 - acc: 0.7360 - f1score: 0.7337 - val_loss: 0.4854 - val_acc: 0.7854 - val_f1score: 0.7836\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5070 - acc: 0.7360 - f1score: 0.7337 - val_loss: 0.4854 - val_acc: 0.7854 - val_f1score: 0.7836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 11%|█▏        | 11/96 [45:29<6:46:59, 287.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.7226 - acc: 0.6816 - f1score: 0.6817\n",
            "Epoch 00001: val_acc improved from -inf to 0.78648, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.22.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 1.7465 - acc: 0.6804 - f1score: 0.6796 - val_loss: 1.2158 - val_acc: 0.7865 - val_f1score: 0.7854\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78648, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.22.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 1.7465 - acc: 0.6804 - f1score: 0.6796 - val_loss: 1.2158 - val_acc: 0.7865 - val_f1score: 0.7854\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.2210 - acc: 0.7150 - f1score: 0.7150\n",
            "Epoch 00002: val_acc did not improve from 0.78648\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.2145 - acc: 0.7164 - f1score: 0.7176 - val_loss: 0.9234 - val_acc: 0.7543 - val_f1score: 0.7534\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.78648\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.2145 - acc: 0.7164 - f1score: 0.7176 - val_loss: 0.9234 - val_acc: 0.7543 - val_f1score: 0.7534\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.9151 - acc: 0.7150 - f1score: 0.7150\n",
            "Epoch 00003: val_acc did not improve from 0.78648\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9155 - acc: 0.7153 - f1score: 0.7157 - val_loss: 0.7152 - val_acc: 0.7500 - val_f1score: 0.7516\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.78648\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9155 - acc: 0.7153 - f1score: 0.7157 - val_loss: 0.7152 - val_acc: 0.7500 - val_f1score: 0.7516\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.7469 - acc: 0.7274 - f1score: 0.7274\n",
            "Epoch 00004: val_acc improved from 0.78648 to 0.79936, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.61.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.7437 - acc: 0.7265 - f1score: 0.7257 - val_loss: 0.6050 - val_acc: 0.7994 - val_f1score: 0.7971\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.78648 to 0.79936, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.61.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.7437 - acc: 0.7265 - f1score: 0.7257 - val_loss: 0.6050 - val_acc: 0.7994 - val_f1score: 0.7971\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6130 - acc: 0.7489 - f1score: 0.7489\n",
            "Epoch 00005: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6130 - acc: 0.7481 - f1score: 0.7475 - val_loss: 0.5587 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6130 - acc: 0.7481 - f1score: 0.7475 - val_loss: 0.5587 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5866 - acc: 0.7581 - f1score: 0.7581\n",
            "Epoch 00006: val_acc improved from 0.79936 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.54.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5863 - acc: 0.7614 - f1score: 0.7642 - val_loss: 0.5389 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.79936 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.54.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5863 - acc: 0.7614 - f1score: 0.7642 - val_loss: 0.5389 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5621 - acc: 0.7522 - f1score: 0.7522\n",
            "Epoch 00007: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5633 - acc: 0.7540 - f1score: 0.7555 - val_loss: 0.5164 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5633 - acc: 0.7540 - f1score: 0.7555 - val_loss: 0.5164 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5272 - acc: 0.7586 - f1score: 0.7586\n",
            "Epoch 00008: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5288 - acc: 0.7587 - f1score: 0.7588 - val_loss: 0.5021 - val_acc: 0.7994 - val_f1score: 0.8003\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5288 - acc: 0.7587 - f1score: 0.7588 - val_loss: 0.5021 - val_acc: 0.7994 - val_f1score: 0.8003\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5241 - acc: 0.7468 - f1score: 0.7468\n",
            "Epoch 00009: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5220 - acc: 0.7481 - f1score: 0.7493 - val_loss: 0.4942 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5220 - acc: 0.7481 - f1score: 0.7493 - val_loss: 0.4942 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5056 - acc: 0.7322 - f1score: 0.7322\n",
            "Epoch 00010: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5087 - acc: 0.7291 - f1score: 0.7264 - val_loss: 0.4956 - val_acc: 0.7854 - val_f1score: 0.7811\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5087 - acc: 0.7291 - f1score: 0.7264 - val_loss: 0.4956 - val_acc: 0.7854 - val_f1score: 0.7811\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5126 - acc: 0.7365 - f1score: 0.7365\n",
            "Epoch 00011: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5140 - acc: 0.7349 - f1score: 0.7335 - val_loss: 0.4871 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5140 - acc: 0.7349 - f1score: 0.7335 - val_loss: 0.4871 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5087 - acc: 0.7247 - f1score: 0.7247\n",
            "Epoch 00012: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5088 - acc: 0.7249 - f1score: 0.7250 - val_loss: 0.4897 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5088 - acc: 0.7249 - f1score: 0.7250 - val_loss: 0.4897 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5147 - acc: 0.7198 - f1score: 0.7198\n",
            "Epoch 00013: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5151 - acc: 0.7201 - f1score: 0.7203 - val_loss: 0.4908 - val_acc: 0.7800 - val_f1score: 0.7808\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5151 - acc: 0.7201 - f1score: 0.7203 - val_loss: 0.4908 - val_acc: 0.7800 - val_f1score: 0.7808\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5286 - acc: 0.7182 - f1score: 0.7182\n",
            "Epoch 00014: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5277 - acc: 0.7185 - f1score: 0.7188 - val_loss: 0.4905 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5277 - acc: 0.7185 - f1score: 0.7188 - val_loss: 0.4905 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4982 - acc: 0.7435 - f1score: 0.7435\n",
            "Epoch 00015: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5021 - acc: 0.7413 - f1score: 0.7393 - val_loss: 0.4849 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5021 - acc: 0.7413 - f1score: 0.7393 - val_loss: 0.4849 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5077 - acc: 0.7290 - f1score: 0.7290\n",
            "Epoch 00016: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5072 - acc: 0.7302 - f1score: 0.7312 - val_loss: 0.4866 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5072 - acc: 0.7302 - f1score: 0.7312 - val_loss: 0.4866 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5069 - acc: 0.7435 - f1score: 0.7435\n",
            "Epoch 00017: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5093 - acc: 0.7418 - f1score: 0.7403 - val_loss: 0.4857 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5093 - acc: 0.7418 - f1score: 0.7403 - val_loss: 0.4857 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5089 - acc: 0.7247 - f1score: 0.7247\n",
            "Epoch 00018: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5077 - acc: 0.7275 - f1score: 0.7299 - val_loss: 0.4900 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5077 - acc: 0.7275 - f1score: 0.7299 - val_loss: 0.4900 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5014 - acc: 0.7435 - f1score: 0.7435\n",
            "Epoch 00019: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5021 - acc: 0.7434 - f1score: 0.7433 - val_loss: 0.4823 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5021 - acc: 0.7434 - f1score: 0.7433 - val_loss: 0.4823 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5090 - acc: 0.7301 - f1score: 0.7301\n",
            "Epoch 00020: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5078 - acc: 0.7312 - f1score: 0.7322 - val_loss: 0.4868 - val_acc: 0.7822 - val_f1score: 0.7821\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5078 - acc: 0.7312 - f1score: 0.7322 - val_loss: 0.4868 - val_acc: 0.7822 - val_f1score: 0.7821\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5003 - acc: 0.7376 - f1score: 0.7376\n",
            "Epoch 00021: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5008 - acc: 0.7360 - f1score: 0.7346 - val_loss: 0.4805 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5008 - acc: 0.7360 - f1score: 0.7346 - val_loss: 0.4805 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5064 - acc: 0.7425 - f1score: 0.7425\n",
            "Epoch 00022: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5068 - acc: 0.7418 - f1score: 0.7412 - val_loss: 0.4845 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5068 - acc: 0.7418 - f1score: 0.7412 - val_loss: 0.4845 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4952 - acc: 0.7446 - f1score: 0.7446\n",
            "Epoch 00023: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4942 - acc: 0.7460 - f1score: 0.7472 - val_loss: 0.4815 - val_acc: 0.7822 - val_f1score: 0.7821\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4942 - acc: 0.7460 - f1score: 0.7472 - val_loss: 0.4815 - val_acc: 0.7822 - val_f1score: 0.7821\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5018 - acc: 0.7355 - f1score: 0.7355\n",
            "Epoch 00024: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5038 - acc: 0.7344 - f1score: 0.7335 - val_loss: 0.4854 - val_acc: 0.7822 - val_f1score: 0.7821\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5038 - acc: 0.7344 - f1score: 0.7335 - val_loss: 0.4854 - val_acc: 0.7822 - val_f1score: 0.7821\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4963 - acc: 0.7468 - f1score: 0.7468\n",
            "Epoch 00025: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4981 - acc: 0.7444 - f1score: 0.7425 - val_loss: 0.4848 - val_acc: 0.7843 - val_f1score: 0.7825\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4981 - acc: 0.7444 - f1score: 0.7425 - val_loss: 0.4848 - val_acc: 0.7843 - val_f1score: 0.7825\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5059 - acc: 0.7220 - f1score: 0.7220\n",
            "Epoch 00026: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5057 - acc: 0.7217 - f1score: 0.7214 - val_loss: 0.4807 - val_acc: 0.7854 - val_f1score: 0.7828\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5057 - acc: 0.7217 - f1score: 0.7214 - val_loss: 0.4807 - val_acc: 0.7854 - val_f1score: 0.7828\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4911 - acc: 0.7392 - f1score: 0.7392\n",
            "Epoch 00027: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4922 - acc: 0.7386 - f1score: 0.7381 - val_loss: 0.4821 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4922 - acc: 0.7386 - f1score: 0.7381 - val_loss: 0.4821 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5256 - acc: 0.7284 - f1score: 0.7284\n",
            "Epoch 00028: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5269 - acc: 0.7270 - f1score: 0.7257 - val_loss: 0.4941 - val_acc: 0.7747 - val_f1score: 0.7756\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5269 - acc: 0.7270 - f1score: 0.7257 - val_loss: 0.4941 - val_acc: 0.7747 - val_f1score: 0.7756\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5053 - acc: 0.7839 - f1score: 0.7839\n",
            "Epoch 00029: val_acc improved from 0.80150 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.29-0.48.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5047 - acc: 0.7847 - f1score: 0.7853 - val_loss: 0.4807 - val_acc: 0.8058 - val_f1score: 0.8050\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.80150 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.29-0.48.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5047 - acc: 0.7847 - f1score: 0.7853 - val_loss: 0.4807 - val_acc: 0.8058 - val_f1score: 0.8050\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4823 - acc: 0.8012 - f1score: 0.8012\n",
            "Epoch 00030: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4810 - acc: 0.8016 - f1score: 0.8019 - val_loss: 0.4757 - val_acc: 0.7983 - val_f1score: 0.7944\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4810 - acc: 0.8016 - f1score: 0.8019 - val_loss: 0.4757 - val_acc: 0.7983 - val_f1score: 0.7944\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4556 - acc: 0.8077 - f1score: 0.8077\n",
            "Epoch 00031: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4570 - acc: 0.8069 - f1score: 0.8062 - val_loss: 0.4773 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4570 - acc: 0.8069 - f1score: 0.8062 - val_loss: 0.4773 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4686 - acc: 0.7883 - f1score: 0.7883\n",
            "Epoch 00032: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4662 - acc: 0.7899 - f1score: 0.7914 - val_loss: 0.4743 - val_acc: 0.7961 - val_f1score: 0.7964\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4662 - acc: 0.7899 - f1score: 0.7914 - val_loss: 0.4743 - val_acc: 0.7961 - val_f1score: 0.7964\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4800 - acc: 0.7888 - f1score: 0.7888\n",
            "Epoch 00033: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4795 - acc: 0.7899 - f1score: 0.7909 - val_loss: 0.4737 - val_acc: 0.7983 - val_f1score: 0.7969\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4795 - acc: 0.7899 - f1score: 0.7909 - val_loss: 0.4737 - val_acc: 0.7983 - val_f1score: 0.7969\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4669 - acc: 0.7926 - f1score: 0.7926\n",
            "Epoch 00034: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4647 - acc: 0.7942 - f1score: 0.7956 - val_loss: 0.4748 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4647 - acc: 0.7942 - f1score: 0.7956 - val_loss: 0.4748 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4575 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00035: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4555 - acc: 0.7979 - f1score: 0.7987 - val_loss: 0.4763 - val_acc: 0.7951 - val_f1score: 0.7946\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4555 - acc: 0.7979 - f1score: 0.7987 - val_loss: 0.4763 - val_acc: 0.7951 - val_f1score: 0.7946\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4720 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00036: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4691 - acc: 0.7984 - f1score: 0.8002 - val_loss: 0.4756 - val_acc: 0.7865 - val_f1score: 0.7838\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4691 - acc: 0.7984 - f1score: 0.8002 - val_loss: 0.4756 - val_acc: 0.7865 - val_f1score: 0.7838\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4720 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00037: val_acc improved from 0.80579 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.37-0.47.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4717 - acc: 0.7952 - f1score: 0.7943 - val_loss: 0.4729 - val_acc: 0.8069 - val_f1score: 0.8068\n",
            "\n",
            "Epoch 00037: val_acc improved from 0.80579 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.37-0.47.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4717 - acc: 0.7952 - f1score: 0.7943 - val_loss: 0.4729 - val_acc: 0.8069 - val_f1score: 0.8068\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4808 - acc: 0.7909 - f1score: 0.7909\n",
            "Epoch 00038: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4788 - acc: 0.7926 - f1score: 0.7940 - val_loss: 0.4734 - val_acc: 0.7918 - val_f1score: 0.7914\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4788 - acc: 0.7926 - f1score: 0.7940 - val_loss: 0.4734 - val_acc: 0.7918 - val_f1score: 0.7914\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4717 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00039: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4717 - acc: 0.7942 - f1score: 0.7942 - val_loss: 0.4748 - val_acc: 0.7886 - val_f1score: 0.7891\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4717 - acc: 0.7942 - f1score: 0.7942 - val_loss: 0.4748 - val_acc: 0.7886 - val_f1score: 0.7891\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4631 - acc: 0.7996 - f1score: 0.7996\n",
            "Epoch 00040: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4624 - acc: 0.8005 - f1score: 0.8013 - val_loss: 0.4735 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4624 - acc: 0.8005 - f1score: 0.8013 - val_loss: 0.4735 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4665 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00041: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4692 - acc: 0.7952 - f1score: 0.7938 - val_loss: 0.4765 - val_acc: 0.7886 - val_f1score: 0.7891\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4692 - acc: 0.7952 - f1score: 0.7938 - val_loss: 0.4765 - val_acc: 0.7886 - val_f1score: 0.7891\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00042: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4679 - acc: 0.7979 - f1score: 0.7978 - val_loss: 0.4770 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4679 - acc: 0.7979 - f1score: 0.7978 - val_loss: 0.4770 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4758 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00043: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4738 - acc: 0.7968 - f1score: 0.7982 - val_loss: 0.4742 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4738 - acc: 0.7968 - f1score: 0.7982 - val_loss: 0.4742 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4696 - acc: 0.7996 - f1score: 0.7996\n",
            "Epoch 00044: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4689 - acc: 0.8011 - f1score: 0.8023 - val_loss: 0.4718 - val_acc: 0.8026 - val_f1score: 0.8002\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4689 - acc: 0.8011 - f1score: 0.8023 - val_loss: 0.4718 - val_acc: 0.8026 - val_f1score: 0.8002\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4554 - acc: 0.8066 - f1score: 0.8066\n",
            "Epoch 00045: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4550 - acc: 0.8069 - f1score: 0.8071 - val_loss: 0.4744 - val_acc: 0.7886 - val_f1score: 0.7875\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4550 - acc: 0.8069 - f1score: 0.8071 - val_loss: 0.4744 - val_acc: 0.7886 - val_f1score: 0.7875\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4557 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00046: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4548 - acc: 0.7942 - f1score: 0.7942 - val_loss: 0.4738 - val_acc: 0.7886 - val_f1score: 0.7875\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4548 - acc: 0.7942 - f1score: 0.7942 - val_loss: 0.4738 - val_acc: 0.7886 - val_f1score: 0.7875\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4676 - acc: 0.7936 - f1score: 0.7936\n",
            "Epoch 00047: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4648 - acc: 0.7958 - f1score: 0.7976 - val_loss: 0.4733 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4648 - acc: 0.7958 - f1score: 0.7976 - val_loss: 0.4733 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4793 - acc: 0.7899 - f1score: 0.7899\n",
            "Epoch 00048: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4796 - acc: 0.7921 - f1score: 0.7939 - val_loss: 0.4763 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4796 - acc: 0.7921 - f1score: 0.7939 - val_loss: 0.4763 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4642 - acc: 0.7931 - f1score: 0.7931\n",
            "Epoch 00049: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4641 - acc: 0.7937 - f1score: 0.7941 - val_loss: 0.4739 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4641 - acc: 0.7937 - f1score: 0.7941 - val_loss: 0.4739 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4576 - acc: 0.8012 - f1score: 0.8012\n",
            "Epoch 00050: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4606 - acc: 0.7989 - f1score: 0.7970 - val_loss: 0.4765 - val_acc: 0.7876 - val_f1score: 0.7881\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4606 - acc: 0.7989 - f1score: 0.7970 - val_loss: 0.4765 - val_acc: 0.7876 - val_f1score: 0.7881\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 12%|█▎        | 12/96 [53:55<8:14:18, 353.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.3454 - acc: 0.7333 - f1score: 0.7333\n",
            "Epoch 00001: val_acc improved from -inf to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.18.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.3422 - acc: 0.7354 - f1score: 0.7373 - val_loss: 2.1822 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.18.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.3422 - acc: 0.7354 - f1score: 0.7373 - val_loss: 2.1822 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.9451 - acc: 0.7866 - f1score: 0.7866\n",
            "Epoch 00002: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.9207 - acc: 0.7889 - f1score: 0.7908 - val_loss: 2.0020 - val_acc: 0.7961 - val_f1score: 0.7940\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.9207 - acc: 0.7889 - f1score: 0.7908 - val_loss: 2.0020 - val_acc: 0.7961 - val_f1score: 0.7940\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.8457 - acc: 0.7807 - f1score: 0.7807\n",
            "Epoch 00003: val_acc improved from 0.80043 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.03-1.78.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.8543 - acc: 0.7788 - f1score: 0.7772 - val_loss: 1.7770 - val_acc: 0.8047 - val_f1score: 0.8023\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.80043 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.03-1.78.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.8543 - acc: 0.7788 - f1score: 0.7772 - val_loss: 1.7770 - val_acc: 0.8047 - val_f1score: 0.8023\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.6874 - acc: 0.7635 - f1score: 0.7635\n",
            "Epoch 00004: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.6730 - acc: 0.7640 - f1score: 0.7645 - val_loss: 1.4106 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.6730 - acc: 0.7640 - f1score: 0.7645 - val_loss: 1.4106 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.4186 - acc: 0.7505 - f1score: 0.7505\n",
            "Epoch 00005: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.4186 - acc: 0.7471 - f1score: 0.7441 - val_loss: 0.9084 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.4186 - acc: 0.7471 - f1score: 0.7441 - val_loss: 0.9084 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.0787 - acc: 0.7333 - f1score: 0.7333\n",
            "Epoch 00006: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0814 - acc: 0.7354 - f1score: 0.7373 - val_loss: 0.7130 - val_acc: 0.7876 - val_f1score: 0.7889\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0814 - acc: 0.7354 - f1score: 0.7373 - val_loss: 0.7130 - val_acc: 0.7876 - val_f1score: 0.7889\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.9522 - acc: 0.7247 - f1score: 0.7247\n",
            "Epoch 00007: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.9611 - acc: 0.7238 - f1score: 0.7231 - val_loss: 0.6529 - val_acc: 0.8047 - val_f1score: 0.8023\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.9611 - acc: 0.7238 - f1score: 0.7231 - val_loss: 0.6529 - val_acc: 0.8047 - val_f1score: 0.8023\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.7129 - acc: 0.7489 - f1score: 0.7489\n",
            "Epoch 00008: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7165 - acc: 0.7487 - f1score: 0.7485 - val_loss: 0.6040 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7165 - acc: 0.7487 - f1score: 0.7485 - val_loss: 0.6040 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6122 - acc: 0.7742 - f1score: 0.7742\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6096 - acc: 0.7757 - f1score: 0.7769 - val_loss: 0.5454 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6096 - acc: 0.7757 - f1score: 0.7769 - val_loss: 0.5454 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4967 - acc: 0.8006 - f1score: 0.8006\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4955 - acc: 0.7995 - f1score: 0.7985 - val_loss: 0.4747 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4955 - acc: 0.7995 - f1score: 0.7985 - val_loss: 0.4747 - val_acc: 0.7929 - val_f1score: 0.7925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 14%|█▎        | 13/96 [55:17<6:15:54, 271.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.5212 - acc: 0.6907 - f1score: 0.6907\n",
            "Epoch 00001: val_acc improved from -inf to 0.74678, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.74.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 1.5027 - acc: 0.6931 - f1score: 0.6952 - val_loss: 0.7383 - val_acc: 0.7468 - val_f1score: 0.7469\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.74678, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.74.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 1.5027 - acc: 0.6931 - f1score: 0.6952 - val_loss: 0.7383 - val_acc: 0.7468 - val_f1score: 0.7469\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5615 - acc: 0.7613 - f1score: 0.7613\n",
            "Epoch 00002: val_acc improved from 0.74678 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.49.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.74678 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.49.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5580 - acc: 0.7635 - f1score: 0.7653 - val_loss: 0.4924 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5580 - acc: 0.7635 - f1score: 0.7653 - val_loss: 0.4924 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4767 - acc: 0.8055 - f1score: 0.8055\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4786 - acc: 0.8048 - f1score: 0.8041 - val_loss: 0.4950 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4786 - acc: 0.8048 - f1score: 0.8041 - val_loss: 0.4950 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4746 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00004: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.49.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4739 - acc: 0.8127 - f1score: 0.8119 - val_loss: 0.4861 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.49.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4739 - acc: 0.8127 - f1score: 0.8119 - val_loss: 0.4861 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4636 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00005: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4620 - acc: 0.8190 - f1score: 0.8196 - val_loss: 0.4867 - val_acc: 0.7961 - val_f1score: 0.7997\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4620 - acc: 0.8190 - f1score: 0.8196 - val_loss: 0.4867 - val_acc: 0.7961 - val_f1score: 0.7997\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4683 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4688 - acc: 0.8116 - f1score: 0.8114 - val_loss: 0.5090 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4688 - acc: 0.8116 - f1score: 0.8114 - val_loss: 0.5090 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4628 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4612 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.5309 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4612 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.5309 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4610 - acc: 0.8153 - f1score: 0.8141 - val_loss: 0.4989 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4610 - acc: 0.8153 - f1score: 0.8141 - val_loss: 0.4989 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4578 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4572 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4804 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4572 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4804 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4602 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4567 - acc: 0.8122 - f1score: 0.8133 - val_loss: 0.4990 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4567 - acc: 0.8122 - f1score: 0.8133 - val_loss: 0.4990 - val_acc: 0.7940 - val_f1score: 0.7959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 15%|█▍        | 14/96 [57:03<5:03:04, 221.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.1209 - acc: 0.7128 - f1score: 0.7128\n",
            "Epoch 00001: val_acc improved from -inf to 0.77468, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.64.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.1102 - acc: 0.7148 - f1score: 0.7165 - val_loss: 0.6431 - val_acc: 0.7747 - val_f1score: 0.7723\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77468, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.64.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.1102 - acc: 0.7148 - f1score: 0.7165 - val_loss: 0.6431 - val_acc: 0.7747 - val_f1score: 0.7723\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6002 - acc: 0.7462 - f1score: 0.7462\n",
            "Epoch 00002: val_acc improved from 0.77468 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.49.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.77468 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.49.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5985 - acc: 0.7460 - f1score: 0.7459 - val_loss: 0.4938 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5985 - acc: 0.7460 - f1score: 0.7459 - val_loss: 0.4938 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4776 - acc: 0.8044 - f1score: 0.8044\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4777 - acc: 0.8042 - f1score: 0.8041 - val_loss: 0.4857 - val_acc: 0.7972 - val_f1score: 0.7999\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4777 - acc: 0.8042 - f1score: 0.8041 - val_loss: 0.4857 - val_acc: 0.7972 - val_f1score: 0.7999\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4601 - acc: 0.8127 - f1score: 0.8138 - val_loss: 0.4896 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4601 - acc: 0.8127 - f1score: 0.8138 - val_loss: 0.4896 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4527 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4547 - acc: 0.8164 - f1score: 0.8161 - val_loss: 0.4894 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4547 - acc: 0.8164 - f1score: 0.8161 - val_loss: 0.4894 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4541 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4554 - acc: 0.8196 - f1score: 0.8192 - val_loss: 0.4809 - val_acc: 0.7983 - val_f1score: 0.7993\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4554 - acc: 0.8196 - f1score: 0.8192 - val_loss: 0.4809 - val_acc: 0.7983 - val_f1score: 0.7993\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4501 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4492 - acc: 0.8153 - f1score: 0.8159 - val_loss: 0.4801 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4492 - acc: 0.8153 - f1score: 0.8159 - val_loss: 0.4801 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4526 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4540 - acc: 0.8196 - f1score: 0.8183 - val_loss: 0.4822 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4540 - acc: 0.8196 - f1score: 0.8183 - val_loss: 0.4822 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4478 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4466 - acc: 0.8190 - f1score: 0.8196 - val_loss: 0.4859 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4466 - acc: 0.8190 - f1score: 0.8196 - val_loss: 0.4859 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4494 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4470 - acc: 0.8233 - f1score: 0.8247 - val_loss: 0.4860 - val_acc: 0.8004 - val_f1score: 0.7973\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4470 - acc: 0.8233 - f1score: 0.8247 - val_loss: 0.4860 - val_acc: 0.8004 - val_f1score: 0.7973\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4444 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4434 - acc: 0.8180 - f1score: 0.8195 - val_loss: 0.4841 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4434 - acc: 0.8180 - f1score: 0.8195 - val_loss: 0.4841 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4448 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4465 - acc: 0.8175 - f1score: 0.8166 - val_loss: 0.4825 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4465 - acc: 0.8175 - f1score: 0.8166 - val_loss: 0.4825 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4489 - acc: 0.8185 - f1score: 0.8181 - val_loss: 0.4798 - val_acc: 0.7822 - val_f1score: 0.7788\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4489 - acc: 0.8185 - f1score: 0.8181 - val_loss: 0.4798 - val_acc: 0.7822 - val_f1score: 0.7788\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4433 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4423 - acc: 0.8180 - f1score: 0.8195 - val_loss: 0.4805 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4423 - acc: 0.8180 - f1score: 0.8195 - val_loss: 0.4805 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4442 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4450 - acc: 0.8254 - f1score: 0.8249 - val_loss: 0.4757 - val_acc: 0.7929 - val_f1score: 0.7909\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4450 - acc: 0.8254 - f1score: 0.8249 - val_loss: 0.4757 - val_acc: 0.7929 - val_f1score: 0.7909\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4470 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4447 - acc: 0.8217 - f1score: 0.8226 - val_loss: 0.4760 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4447 - acc: 0.8217 - f1score: 0.8226 - val_loss: 0.4760 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4473 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4469 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4765 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4469 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4765 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4443 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4451 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4774 - val_acc: 0.7843 - val_f1score: 0.7809\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4451 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4774 - val_acc: 0.7843 - val_f1score: 0.7809\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4476 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00019: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4486 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4747 - val_acc: 0.7908 - val_f1score: 0.7872\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4486 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4747 - val_acc: 0.7908 - val_f1score: 0.7872\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4456 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00020: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4442 - acc: 0.8175 - f1score: 0.8185 - val_loss: 0.4777 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4442 - acc: 0.8175 - f1score: 0.8185 - val_loss: 0.4777 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4486 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00021: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4524 - acc: 0.8190 - f1score: 0.8173 - val_loss: 0.4781 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4524 - acc: 0.8190 - f1score: 0.8173 - val_loss: 0.4781 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4387 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00022: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4391 - acc: 0.8206 - f1score: 0.8207 - val_loss: 0.4736 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4391 - acc: 0.8206 - f1score: 0.8207 - val_loss: 0.4736 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4393 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4395 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4714 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4395 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4714 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4389 - acc: 0.8238 - f1score: 0.8238\n",
            "Epoch 00024: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.24-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4361 - acc: 0.8254 - f1score: 0.8267 - val_loss: 0.4772 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.24-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4361 - acc: 0.8254 - f1score: 0.8267 - val_loss: 0.4772 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4464 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4818 - val_acc: 0.7929 - val_f1score: 0.7949\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4464 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4818 - val_acc: 0.7929 - val_f1score: 0.7949\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4441 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4427 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4838 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4427 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4838 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4402 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4406 - acc: 0.8153 - f1score: 0.8159 - val_loss: 0.4724 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4406 - acc: 0.8153 - f1score: 0.8159 - val_loss: 0.4724 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4443 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4437 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4729 - val_acc: 0.7918 - val_f1score: 0.7963\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4437 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4729 - val_acc: 0.7918 - val_f1score: 0.7963\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4432 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4413 - acc: 0.8175 - f1score: 0.8189 - val_loss: 0.4734 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4413 - acc: 0.8175 - f1score: 0.8189 - val_loss: 0.4734 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4363 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4369 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4750 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4369 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4750 - val_acc: 0.7940 - val_f1score: 0.7959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 16%|█▌        | 15/96 [1:00:59<5:05:18, 226.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.0391 - acc: 0.7193 - f1score: 0.7193\n",
            "Epoch 00001: val_acc improved from -inf to 0.79077, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.62.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.0176 - acc: 0.7222 - f1score: 0.7247 - val_loss: 1.6157 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.79077, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.62.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.0176 - acc: 0.7222 - f1score: 0.7247 - val_loss: 1.6157 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.4965 - acc: 0.7554 - f1score: 0.7554\n",
            "Epoch 00002: val_acc improved from 0.79077 to 0.79721, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.09.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.79077 to 0.79721, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.09.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.5035 - acc: 0.7529 - f1score: 0.7508 - val_loss: 1.0852 - val_acc: 0.7972 - val_f1score: 0.7975\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.5035 - acc: 0.7529 - f1score: 0.7508 - val_loss: 1.0852 - val_acc: 0.7972 - val_f1score: 0.7975\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.1189 - acc: 0.7489 - f1score: 0.7489\n",
            "Epoch 00003: val_acc improved from 0.79721 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.03-1.12.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.1178 - acc: 0.7497 - f1score: 0.7504 - val_loss: 1.1156 - val_acc: 0.8036 - val_f1score: 0.8021\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.79721 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.03-1.12.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.1178 - acc: 0.7497 - f1score: 0.7504 - val_loss: 1.1156 - val_acc: 0.8036 - val_f1score: 0.8021\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.8288 - acc: 0.7446 - f1score: 0.7446\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.8313 - acc: 0.7450 - f1score: 0.7453 - val_loss: 0.6439 - val_acc: 0.8026 - val_f1score: 0.7978\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.8313 - acc: 0.7450 - f1score: 0.7453 - val_loss: 0.6439 - val_acc: 0.8026 - val_f1score: 0.7978\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5361 - acc: 0.7920 - f1score: 0.7920\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5454 - acc: 0.7899 - f1score: 0.7882 - val_loss: 0.6379 - val_acc: 0.7833 - val_f1score: 0.7799\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5454 - acc: 0.7899 - f1score: 0.7882 - val_loss: 0.6379 - val_acc: 0.7833 - val_f1score: 0.7799\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4975 - acc: 0.8050 - f1score: 0.8050\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4960 - acc: 0.8069 - f1score: 0.8085 - val_loss: 0.4910 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4960 - acc: 0.8069 - f1score: 0.8085 - val_loss: 0.4910 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4573 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4595 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.5021 - val_acc: 0.7822 - val_f1score: 0.7796\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4595 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.5021 - val_acc: 0.7822 - val_f1score: 0.7796\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4598 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4594 - acc: 0.8116 - f1score: 0.8123 - val_loss: 0.4891 - val_acc: 0.7865 - val_f1score: 0.7854\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4594 - acc: 0.8116 - f1score: 0.8123 - val_loss: 0.4891 - val_acc: 0.7865 - val_f1score: 0.7854\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4533 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4550 - acc: 0.8138 - f1score: 0.8130 - val_loss: 0.4793 - val_acc: 0.7865 - val_f1score: 0.7797\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4550 - acc: 0.8138 - f1score: 0.8130 - val_loss: 0.4793 - val_acc: 0.7865 - val_f1score: 0.7797\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4491 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4487 - acc: 0.8153 - f1score: 0.8159 - val_loss: 0.4785 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4487 - acc: 0.8153 - f1score: 0.8159 - val_loss: 0.4785 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4535 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4505 - acc: 0.8175 - f1score: 0.8189 - val_loss: 0.4890 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4505 - acc: 0.8175 - f1score: 0.8189 - val_loss: 0.4890 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4543 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4525 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4850 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4525 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4850 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4570 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4568 - acc: 0.8196 - f1score: 0.8192 - val_loss: 0.4761 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4568 - acc: 0.8196 - f1score: 0.8192 - val_loss: 0.4761 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4427 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4474 - acc: 0.8201 - f1score: 0.8174 - val_loss: 0.4809 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4474 - acc: 0.8201 - f1score: 0.8174 - val_loss: 0.4809 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4537 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4543 - acc: 0.8169 - f1score: 0.8157 - val_loss: 0.4867 - val_acc: 0.7940 - val_f1score: 0.7870\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4543 - acc: 0.8169 - f1score: 0.8157 - val_loss: 0.4867 - val_acc: 0.7940 - val_f1score: 0.7870\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4506 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4513 - acc: 0.8206 - f1score: 0.8198 - val_loss: 0.4831 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4513 - acc: 0.8206 - f1score: 0.8198 - val_loss: 0.4831 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4460 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4462 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4715 - val_acc: 0.7983 - val_f1score: 0.7961\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4462 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4715 - val_acc: 0.7983 - val_f1score: 0.7961\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4417 - acc: 0.8201 - f1score: 0.8206 - val_loss: 0.4778 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4417 - acc: 0.8201 - f1score: 0.8206 - val_loss: 0.4778 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4479 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4479 - acc: 0.8190 - f1score: 0.8182 - val_loss: 0.4794 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4479 - acc: 0.8190 - f1score: 0.8182 - val_loss: 0.4794 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4430 - acc: 0.8254 - f1score: 0.8254\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4451 - acc: 0.8238 - f1score: 0.8224 - val_loss: 0.4775 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4451 - acc: 0.8238 - f1score: 0.8224 - val_loss: 0.4775 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4509 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4494 - acc: 0.8143 - f1score: 0.8149 - val_loss: 0.5011 - val_acc: 0.7833 - val_f1score: 0.7807\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4494 - acc: 0.8143 - f1score: 0.8149 - val_loss: 0.5011 - val_acc: 0.7833 - val_f1score: 0.7807\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4442 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4472 - acc: 0.8233 - f1score: 0.8210 - val_loss: 0.4746 - val_acc: 0.7822 - val_f1score: 0.7812\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4472 - acc: 0.8233 - f1score: 0.8210 - val_loss: 0.4746 - val_acc: 0.7822 - val_f1score: 0.7812\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4570 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4565 - acc: 0.8153 - f1score: 0.8159 - val_loss: 0.4764 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4565 - acc: 0.8153 - f1score: 0.8159 - val_loss: 0.4764 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4440 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4431 - acc: 0.8222 - f1score: 0.8222 - val_loss: 0.4748 - val_acc: 0.7886 - val_f1score: 0.7891\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4431 - acc: 0.8222 - f1score: 0.8222 - val_loss: 0.4748 - val_acc: 0.7886 - val_f1score: 0.7891\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4413 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4407 - acc: 0.8206 - f1score: 0.8216 - val_loss: 0.4703 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4407 - acc: 0.8206 - f1score: 0.8216 - val_loss: 0.4703 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4400 - acc: 0.8222 - f1score: 0.8222 - val_loss: 0.4697 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4400 - acc: 0.8222 - f1score: 0.8222 - val_loss: 0.4697 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4432 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4440 - acc: 0.8206 - f1score: 0.8202 - val_loss: 0.4729 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4440 - acc: 0.8206 - f1score: 0.8202 - val_loss: 0.4729 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4420 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4410 - acc: 0.8222 - f1score: 0.8227 - val_loss: 0.4793 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4410 - acc: 0.8222 - f1score: 0.8227 - val_loss: 0.4793 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4425 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4425 - acc: 0.8196 - f1score: 0.8192 - val_loss: 0.4765 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4425 - acc: 0.8196 - f1score: 0.8192 - val_loss: 0.4765 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4445 - acc: 0.8238 - f1score: 0.8238\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4438 - acc: 0.8249 - f1score: 0.8258 - val_loss: 0.4730 - val_acc: 0.7951 - val_f1score: 0.7921\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4438 - acc: 0.8249 - f1score: 0.8258 - val_loss: 0.4730 - val_acc: 0.7951 - val_f1score: 0.7921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 17%|█▋        | 16/96 [1:06:07<5:34:26, 250.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.5360 - acc: 0.6616 - f1score: 0.6616\n",
            "Epoch 00001: val_acc improved from -inf to 0.78219, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.45.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.5211 - acc: 0.6646 - f1score: 0.6670 - val_loss: 2.4479 - val_acc: 0.7822 - val_f1score: 0.7812\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78219, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.45.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.5211 - acc: 0.6646 - f1score: 0.6670 - val_loss: 2.4479 - val_acc: 0.7822 - val_f1score: 0.7812\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.2019 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00002: val_acc improved from 0.78219 to 0.79077, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.38.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.2137 - acc: 0.8079 - f1score: 0.8063 - val_loss: 2.3808 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.78219 to 0.79077, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.38.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.2137 - acc: 0.8079 - f1score: 0.8063 - val_loss: 2.3808 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.0585 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00003: val_acc improved from 0.79077 to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.03-2.36.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.0648 - acc: 0.7947 - f1score: 0.7952 - val_loss: 2.3600 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.79077 to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.03-2.36.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.0648 - acc: 0.7947 - f1score: 0.7952 - val_loss: 2.3600 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.0329 - acc: 0.7920 - f1score: 0.7920\n",
            "Epoch 00004: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.0597 - acc: 0.7910 - f1score: 0.7901 - val_loss: 2.3858 - val_acc: 0.7811 - val_f1score: 0.7810\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.0597 - acc: 0.7910 - f1score: 0.7901 - val_loss: 2.3858 - val_acc: 0.7811 - val_f1score: 0.7810\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.9825 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00005: val_acc improved from 0.79399 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.05-2.28.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.9766 - acc: 0.7942 - f1score: 0.7942 - val_loss: 2.2798 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.79399 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.05-2.28.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.9766 - acc: 0.7942 - f1score: 0.7942 - val_loss: 2.2798 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.8343 - acc: 0.7834 - f1score: 0.7834\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.8349 - acc: 0.7831 - f1score: 0.7828 - val_loss: 2.0608 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.8349 - acc: 0.7831 - f1score: 0.7828 - val_loss: 2.0608 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.7428 - acc: 0.7559 - f1score: 0.7559\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.7287 - acc: 0.7550 - f1score: 0.7543 - val_loss: 1.1675 - val_acc: 0.7511 - val_f1score: 0.7502\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.7287 - acc: 0.7550 - f1score: 0.7543 - val_loss: 1.1675 - val_acc: 0.7511 - val_f1score: 0.7502\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.9822 - acc: 0.7408 - f1score: 0.7408\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.9709 - acc: 0.7429 - f1score: 0.7446 - val_loss: 0.4973 - val_acc: 0.8026 - val_f1score: 0.8051\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.9709 - acc: 0.7429 - f1score: 0.7446 - val_loss: 0.4973 - val_acc: 0.8026 - val_f1score: 0.8051\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5434 - acc: 0.7947 - f1score: 0.7947\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5424 - acc: 0.7947 - f1score: 0.7947 - val_loss: 0.4754 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5424 - acc: 0.7947 - f1score: 0.7947 - val_loss: 0.4754 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4648 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4641 - acc: 0.8138 - f1score: 0.8134 - val_loss: 0.4804 - val_acc: 0.7908 - val_f1score: 0.7944\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4641 - acc: 0.8138 - f1score: 0.8134 - val_loss: 0.4804 - val_acc: 0.7908 - val_f1score: 0.7944\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4582 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4571 - acc: 0.8153 - f1score: 0.8164 - val_loss: 0.4803 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4571 - acc: 0.8153 - f1score: 0.8164 - val_loss: 0.4803 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4570 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4552 - acc: 0.8180 - f1score: 0.8190 - val_loss: 0.4777 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4552 - acc: 0.8180 - f1score: 0.8190 - val_loss: 0.4777 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4572 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00013: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.13-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4563 - acc: 0.8175 - f1score: 0.8180 - val_loss: 0.4776 - val_acc: 0.8047 - val_f1score: 0.8047\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.13-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4563 - acc: 0.8175 - f1score: 0.8180 - val_loss: 0.4776 - val_acc: 0.8047 - val_f1score: 0.8047\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4457 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00014: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4458 - acc: 0.8164 - f1score: 0.8161 - val_loss: 0.4768 - val_acc: 0.7865 - val_f1score: 0.7887\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4458 - acc: 0.8164 - f1score: 0.8161 - val_loss: 0.4768 - val_acc: 0.7865 - val_f1score: 0.7887\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4520 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00015: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4513 - acc: 0.8175 - f1score: 0.8180 - val_loss: 0.4728 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4513 - acc: 0.8175 - f1score: 0.8180 - val_loss: 0.4728 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4446 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00016: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4422 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4795 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4422 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4795 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4492 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00017: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4485 - acc: 0.8212 - f1score: 0.8212 - val_loss: 0.4728 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4485 - acc: 0.8212 - f1score: 0.8212 - val_loss: 0.4728 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4372 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00018: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4372 - acc: 0.8206 - f1score: 0.8207 - val_loss: 0.4956 - val_acc: 0.7929 - val_f1score: 0.7868\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4372 - acc: 0.8206 - f1score: 0.8207 - val_loss: 0.4956 - val_acc: 0.7929 - val_f1score: 0.7868\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4576 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00019: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4549 - acc: 0.8201 - f1score: 0.8211 - val_loss: 0.4845 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4549 - acc: 0.8201 - f1score: 0.8211 - val_loss: 0.4845 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4434 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00020: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4442 - acc: 0.8201 - f1score: 0.8192 - val_loss: 0.4836 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4442 - acc: 0.8201 - f1score: 0.8192 - val_loss: 0.4836 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4449 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00021: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4425 - acc: 0.8222 - f1score: 0.8241 - val_loss: 0.4736 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4425 - acc: 0.8222 - f1score: 0.8241 - val_loss: 0.4736 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4445 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4467 - acc: 0.8190 - f1score: 0.8177 - val_loss: 0.4783 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4467 - acc: 0.8190 - f1score: 0.8177 - val_loss: 0.4783 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4497 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4482 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4730 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4482 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4730 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4393 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4411 - acc: 0.8159 - f1score: 0.8146 - val_loss: 0.4727 - val_acc: 0.7951 - val_f1score: 0.7962\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4411 - acc: 0.8159 - f1score: 0.8146 - val_loss: 0.4727 - val_acc: 0.7951 - val_f1score: 0.7962\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4382 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4398 - acc: 0.8169 - f1score: 0.8157 - val_loss: 0.4797 - val_acc: 0.7897 - val_f1score: 0.7869\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4398 - acc: 0.8169 - f1score: 0.8157 - val_loss: 0.4797 - val_acc: 0.7897 - val_f1score: 0.7869\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4390 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4390 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4713 - val_acc: 0.7897 - val_f1score: 0.7869\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4390 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4713 - val_acc: 0.7897 - val_f1score: 0.7869\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4412 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4407 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4754 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4407 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4754 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4504 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4479 - acc: 0.8164 - f1score: 0.8174 - val_loss: 0.4715 - val_acc: 0.7833 - val_f1score: 0.7847\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4479 - acc: 0.8164 - f1score: 0.8174 - val_loss: 0.4715 - val_acc: 0.7833 - val_f1score: 0.7847\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4378 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4391 - acc: 0.8212 - f1score: 0.8194 - val_loss: 0.4703 - val_acc: 0.7972 - val_f1score: 0.7950\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4391 - acc: 0.8212 - f1score: 0.8194 - val_loss: 0.4703 - val_acc: 0.7972 - val_f1score: 0.7950\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4391 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4396 - acc: 0.8217 - f1score: 0.8213 - val_loss: 0.4714 - val_acc: 0.7961 - val_f1score: 0.7972\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4396 - acc: 0.8217 - f1score: 0.8213 - val_loss: 0.4714 - val_acc: 0.7961 - val_f1score: 0.7972\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4370 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00031: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4358 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4768 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4358 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4768 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4413 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00032: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4419 - acc: 0.8212 - f1score: 0.8212 - val_loss: 0.4794 - val_acc: 0.7876 - val_f1score: 0.7889\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4419 - acc: 0.8212 - f1score: 0.8212 - val_loss: 0.4794 - val_acc: 0.7876 - val_f1score: 0.7889\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4412 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00033: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4413 - acc: 0.8196 - f1score: 0.8187 - val_loss: 0.4746 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4413 - acc: 0.8196 - f1score: 0.8187 - val_loss: 0.4746 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4416 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00034: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4423 - acc: 0.8143 - f1score: 0.8140 - val_loss: 0.4712 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4423 - acc: 0.8143 - f1score: 0.8140 - val_loss: 0.4712 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4357 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00035: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4365 - acc: 0.8164 - f1score: 0.8156 - val_loss: 0.4714 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4365 - acc: 0.8164 - f1score: 0.8156 - val_loss: 0.4714 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4395 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00036: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4387 - acc: 0.8228 - f1score: 0.8232 - val_loss: 0.4727 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4387 - acc: 0.8228 - f1score: 0.8232 - val_loss: 0.4727 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4364 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00037: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4396 - acc: 0.8185 - f1score: 0.8168 - val_loss: 0.4703 - val_acc: 0.7929 - val_f1score: 0.7892\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4396 - acc: 0.8185 - f1score: 0.8168 - val_loss: 0.4703 - val_acc: 0.7929 - val_f1score: 0.7892\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4412 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00038: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4404 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4718 - val_acc: 0.7972 - val_f1score: 0.7991\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4404 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4718 - val_acc: 0.7972 - val_f1score: 0.7991\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4412 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00039: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4391 - acc: 0.8185 - f1score: 0.8195 - val_loss: 0.4723 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4391 - acc: 0.8185 - f1score: 0.8195 - val_loss: 0.4723 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4446 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00040: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4423 - acc: 0.8164 - f1score: 0.8174 - val_loss: 0.4692 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4423 - acc: 0.8164 - f1score: 0.8174 - val_loss: 0.4692 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4527 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00041: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4506 - acc: 0.8169 - f1score: 0.8189 - val_loss: 0.4753 - val_acc: 0.7929 - val_f1score: 0.7949\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4506 - acc: 0.8169 - f1score: 0.8189 - val_loss: 0.4753 - val_acc: 0.7929 - val_f1score: 0.7949\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4438 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00042: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4442 - acc: 0.8233 - f1score: 0.8237 - val_loss: 0.4752 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4442 - acc: 0.8233 - f1score: 0.8237 - val_loss: 0.4752 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4432 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00043: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4413 - acc: 0.8238 - f1score: 0.8247 - val_loss: 0.4721 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4413 - acc: 0.8238 - f1score: 0.8247 - val_loss: 0.4721 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4378 - acc: 0.8254 - f1score: 0.8254\n",
            "Epoch 00044: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4401 - acc: 0.8233 - f1score: 0.8214 - val_loss: 0.4739 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4401 - acc: 0.8233 - f1score: 0.8214 - val_loss: 0.4739 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4402 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00045: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4400 - acc: 0.8217 - f1score: 0.8213 - val_loss: 0.4719 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4400 - acc: 0.8217 - f1score: 0.8213 - val_loss: 0.4719 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4406 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00046: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4397 - acc: 0.8196 - f1score: 0.8206 - val_loss: 0.4734 - val_acc: 0.7833 - val_f1score: 0.7847\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4397 - acc: 0.8196 - f1score: 0.8206 - val_loss: 0.4734 - val_acc: 0.7833 - val_f1score: 0.7847\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4405 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00047: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4398 - acc: 0.8180 - f1score: 0.8185 - val_loss: 0.4708 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4398 - acc: 0.8180 - f1score: 0.8185 - val_loss: 0.4708 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4417 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00048: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4399 - acc: 0.8175 - f1score: 0.8185 - val_loss: 0.4709 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4399 - acc: 0.8175 - f1score: 0.8185 - val_loss: 0.4709 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4319 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00049: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4308 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4731 - val_acc: 0.7897 - val_f1score: 0.7869\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4308 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4731 - val_acc: 0.7897 - val_f1score: 0.7869\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4383 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00050: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4390 - acc: 0.8159 - f1score: 0.8155 - val_loss: 0.4701 - val_acc: 0.7886 - val_f1score: 0.7940\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4390 - acc: 0.8159 - f1score: 0.8155 - val_loss: 0.4701 - val_acc: 0.7886 - val_f1score: 0.7940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 18%|█▊        | 17/96 [1:12:39<6:25:59, 293.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.1241 - acc: 0.7484 - f1score: 0.7484\n",
            "Epoch 00001: val_acc improved from -inf to 0.78648, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.44.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.1083 - acc: 0.7497 - f1score: 0.7509 - val_loss: 1.4418 - val_acc: 0.7865 - val_f1score: 0.7862\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78648, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.44.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.1083 - acc: 0.7497 - f1score: 0.7509 - val_loss: 1.4418 - val_acc: 0.7865 - val_f1score: 0.7862\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.6305 - acc: 0.7662 - f1score: 0.7662\n",
            "Epoch 00002: val_acc improved from 0.78648 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.42.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.6387 - acc: 0.7651 - f1score: 0.7642 - val_loss: 1.4234 - val_acc: 0.8015 - val_f1score: 0.7992\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.78648 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.42.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.6387 - acc: 0.7651 - f1score: 0.7642 - val_loss: 1.4234 - val_acc: 0.8015 - val_f1score: 0.7992\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.4661 - acc: 0.7511 - f1score: 0.7511\n",
            "Epoch 00003: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.4860 - acc: 0.7508 - f1score: 0.7506 - val_loss: 1.6820 - val_acc: 0.7865 - val_f1score: 0.7878\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.4860 - acc: 0.7508 - f1score: 0.7506 - val_loss: 1.6820 - val_acc: 0.7865 - val_f1score: 0.7878\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.9352 - acc: 0.7468 - f1score: 0.7468\n",
            "Epoch 00004: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9251 - acc: 0.7476 - f1score: 0.7483 - val_loss: 0.7424 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9251 - acc: 0.7476 - f1score: 0.7483 - val_loss: 0.7424 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6132 - acc: 0.7694 - f1score: 0.7694\n",
            "Epoch 00005: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6144 - acc: 0.7693 - f1score: 0.7692 - val_loss: 0.5276 - val_acc: 0.7951 - val_f1score: 0.7986\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6144 - acc: 0.7693 - f1score: 0.7692 - val_loss: 0.5276 - val_acc: 0.7951 - val_f1score: 0.7986\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4863 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00006: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4862 - acc: 0.7952 - f1score: 0.7952 - val_loss: 0.4923 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4862 - acc: 0.7952 - f1score: 0.7952 - val_loss: 0.4923 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4438 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00007: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4455 - acc: 0.8127 - f1score: 0.8115 - val_loss: 0.4757 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4455 - acc: 0.8127 - f1score: 0.8115 - val_loss: 0.4757 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4533 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00008: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4526 - acc: 0.8190 - f1score: 0.8205 - val_loss: 0.4824 - val_acc: 0.7961 - val_f1score: 0.7972\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4526 - acc: 0.8190 - f1score: 0.8205 - val_loss: 0.4824 - val_acc: 0.7961 - val_f1score: 0.7972\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4539 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00009: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4543 - acc: 0.8201 - f1score: 0.8206 - val_loss: 0.4958 - val_acc: 0.7843 - val_f1score: 0.7882\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4543 - acc: 0.8201 - f1score: 0.8206 - val_loss: 0.4958 - val_acc: 0.7843 - val_f1score: 0.7882\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4608 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00010: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4594 - acc: 0.8132 - f1score: 0.8143 - val_loss: 0.4799 - val_acc: 0.7854 - val_f1score: 0.7884\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4594 - acc: 0.8132 - f1score: 0.8143 - val_loss: 0.4799 - val_acc: 0.7854 - val_f1score: 0.7884\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4582 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00011: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4574 - acc: 0.8175 - f1score: 0.8185 - val_loss: 0.5023 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4574 - acc: 0.8175 - f1score: 0.8185 - val_loss: 0.5023 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4560 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00012: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4581 - acc: 0.8196 - f1score: 0.8178 - val_loss: 0.4840 - val_acc: 0.8015 - val_f1score: 0.7992\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4581 - acc: 0.8196 - f1score: 0.8178 - val_loss: 0.4840 - val_acc: 0.8015 - val_f1score: 0.7992\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4509 - acc: 0.8244 - f1score: 0.8244\n",
            "Epoch 00013: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4516 - acc: 0.8233 - f1score: 0.8224 - val_loss: 0.4840 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4516 - acc: 0.8233 - f1score: 0.8224 - val_loss: 0.4840 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4496 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00014: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4499 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4907 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4499 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4907 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4443 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00015: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4466 - acc: 0.8212 - f1score: 0.8203 - val_loss: 0.4825 - val_acc: 0.7854 - val_f1score: 0.7884\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4466 - acc: 0.8212 - f1score: 0.8203 - val_loss: 0.4825 - val_acc: 0.7854 - val_f1score: 0.7884\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4527 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00016: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4496 - acc: 0.8196 - f1score: 0.8210 - val_loss: 0.4831 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4496 - acc: 0.8196 - f1score: 0.8210 - val_loss: 0.4831 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4490 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00017: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4485 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4775 - val_acc: 0.7854 - val_f1score: 0.7844\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4485 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4775 - val_acc: 0.7854 - val_f1score: 0.7844\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4522 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00018: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4499 - acc: 0.8206 - f1score: 0.8216 - val_loss: 0.4851 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4499 - acc: 0.8206 - f1score: 0.8216 - val_loss: 0.4851 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4535 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00019: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4530 - acc: 0.8190 - f1score: 0.8191 - val_loss: 0.4851 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4530 - acc: 0.8190 - f1score: 0.8191 - val_loss: 0.4851 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4418 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00020: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4430 - acc: 0.8206 - f1score: 0.8198 - val_loss: 0.4784 - val_acc: 0.7897 - val_f1score: 0.7942\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4430 - acc: 0.8206 - f1score: 0.8198 - val_loss: 0.4784 - val_acc: 0.7897 - val_f1score: 0.7942\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4439 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00021: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4453 - acc: 0.8164 - f1score: 0.8156 - val_loss: 0.4749 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4453 - acc: 0.8164 - f1score: 0.8156 - val_loss: 0.4749 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4480 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00022: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4469 - acc: 0.8212 - f1score: 0.8221 - val_loss: 0.4750 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4469 - acc: 0.8212 - f1score: 0.8221 - val_loss: 0.4750 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4457 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00023: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4455 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4770 - val_acc: 0.7811 - val_f1score: 0.7810\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4455 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4770 - val_acc: 0.7811 - val_f1score: 0.7810\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4412 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00024: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4394 - acc: 0.8164 - f1score: 0.8174 - val_loss: 0.4797 - val_acc: 0.7800 - val_f1score: 0.7759\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4394 - acc: 0.8164 - f1score: 0.8174 - val_loss: 0.4797 - val_acc: 0.7800 - val_f1score: 0.7759\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4443 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00025: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4453 - acc: 0.8143 - f1score: 0.8140 - val_loss: 0.4746 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4453 - acc: 0.8143 - f1score: 0.8140 - val_loss: 0.4746 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4440 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00026: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4417 - acc: 0.8201 - f1score: 0.8211 - val_loss: 0.4744 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4417 - acc: 0.8201 - f1score: 0.8211 - val_loss: 0.4744 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4425 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00027: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4420 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4752 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4420 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4752 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4433 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00028: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4444 - acc: 0.8201 - f1score: 0.8192 - val_loss: 0.4742 - val_acc: 0.7854 - val_f1score: 0.7884\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4444 - acc: 0.8201 - f1score: 0.8192 - val_loss: 0.4742 - val_acc: 0.7854 - val_f1score: 0.7884\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4427 - acc: 0.8276 - f1score: 0.8276\n",
            "Epoch 00029: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4452 - acc: 0.8259 - f1score: 0.8245 - val_loss: 0.4751 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4452 - acc: 0.8259 - f1score: 0.8245 - val_loss: 0.4751 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00030: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4447 - acc: 0.8206 - f1score: 0.8221 - val_loss: 0.4715 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4447 - acc: 0.8206 - f1score: 0.8221 - val_loss: 0.4715 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4407 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00031: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4440 - acc: 0.8169 - f1score: 0.8147 - val_loss: 0.4742 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4440 - acc: 0.8169 - f1score: 0.8147 - val_loss: 0.4742 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4416 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00032: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4413 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4740 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4413 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4740 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4448 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00033: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4437 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4763 - val_acc: 0.7800 - val_f1score: 0.7816\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4437 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4763 - val_acc: 0.7800 - val_f1score: 0.7816\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4493 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00034: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4466 - acc: 0.8159 - f1score: 0.8174 - val_loss: 0.4703 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4466 - acc: 0.8159 - f1score: 0.8174 - val_loss: 0.4703 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00035: val_acc improved from 0.80150 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.35-0.47.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4445 - acc: 0.8196 - f1score: 0.8210 - val_loss: 0.4730 - val_acc: 0.8036 - val_f1score: 0.8078\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.80150 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.35-0.47.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4445 - acc: 0.8196 - f1score: 0.8210 - val_loss: 0.4730 - val_acc: 0.8036 - val_f1score: 0.8078\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4402 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4405 - acc: 0.8169 - f1score: 0.8166 - val_loss: 0.4733 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4405 - acc: 0.8169 - f1score: 0.8166 - val_loss: 0.4733 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4426 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4426 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4686 - val_acc: 0.7961 - val_f1score: 0.7940\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4426 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4686 - val_acc: 0.7961 - val_f1score: 0.7940\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4401 - acc: 0.8249 - f1score: 0.8249\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4414 - acc: 0.8238 - f1score: 0.8229 - val_loss: 0.4693 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4414 - acc: 0.8238 - f1score: 0.8229 - val_loss: 0.4693 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4389 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4373 - acc: 0.8196 - f1score: 0.8210 - val_loss: 0.4700 - val_acc: 0.8036 - val_f1score: 0.8045\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4373 - acc: 0.8196 - f1score: 0.8210 - val_loss: 0.4700 - val_acc: 0.8036 - val_f1score: 0.8045\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4420 - acc: 0.8238 - f1score: 0.8238\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4419 - acc: 0.8233 - f1score: 0.8228 - val_loss: 0.4717 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4419 - acc: 0.8233 - f1score: 0.8228 - val_loss: 0.4717 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4352 - acc: 0.8276 - f1score: 0.8276\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4363 - acc: 0.8259 - f1score: 0.8245 - val_loss: 0.4676 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4363 - acc: 0.8259 - f1score: 0.8245 - val_loss: 0.4676 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4379 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4403 - acc: 0.8190 - f1score: 0.8196 - val_loss: 0.4764 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4403 - acc: 0.8190 - f1score: 0.8196 - val_loss: 0.4764 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4356 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4364 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4688 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4364 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4688 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4439 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4418 - acc: 0.8243 - f1score: 0.8252 - val_loss: 0.4690 - val_acc: 0.7918 - val_f1score: 0.7898\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4418 - acc: 0.8243 - f1score: 0.8252 - val_loss: 0.4690 - val_acc: 0.7918 - val_f1score: 0.7898\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4368 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4342 - acc: 0.8249 - f1score: 0.8262 - val_loss: 0.4693 - val_acc: 0.7940 - val_f1score: 0.7895\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4342 - acc: 0.8249 - f1score: 0.8262 - val_loss: 0.4693 - val_acc: 0.7940 - val_f1score: 0.7895\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4385 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4378 - acc: 0.8201 - f1score: 0.8206 - val_loss: 0.4670 - val_acc: 0.8015 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4378 - acc: 0.8201 - f1score: 0.8206 - val_loss: 0.4670 - val_acc: 0.8015 - val_f1score: 0.7984\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4341 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00047: val_acc improved from 0.80365 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.47-0.47.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4369 - acc: 0.8175 - f1score: 0.8157 - val_loss: 0.4703 - val_acc: 0.8058 - val_f1score: 0.8050\n",
            "\n",
            "Epoch 00047: val_acc improved from 0.80365 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.47-0.47.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4369 - acc: 0.8175 - f1score: 0.8157 - val_loss: 0.4703 - val_acc: 0.8058 - val_f1score: 0.8050\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4368 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00048: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4366 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4692 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4366 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4692 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4434 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00049: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4419 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4732 - val_acc: 0.7790 - val_f1score: 0.7789\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4419 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4732 - val_acc: 0.7790 - val_f1score: 0.7789\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4400 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00050: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4395 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4707 - val_acc: 0.7886 - val_f1score: 0.7859\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4395 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4707 - val_acc: 0.7886 - val_f1score: 0.7859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 19%|█▉        | 18/96 [1:21:07<7:44:56, 357.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 6.7210 - acc: 0.5070 - f1score: 0.5070\n",
            "Epoch 00001: val_acc improved from -inf to 0.77682, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.12.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 6.6349 - acc: 0.5101 - f1score: 0.5127 - val_loss: 2.1161 - val_acc: 0.7768 - val_f1score: 0.7760\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77682, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.12.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 6.6349 - acc: 0.5101 - f1score: 0.5127 - val_loss: 2.1161 - val_acc: 0.7768 - val_f1score: 0.7760\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.5396 - acc: 0.7667 - f1score: 0.7667\n",
            "Epoch 00002: val_acc improved from 0.77682 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.42.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.5263 - acc: 0.7672 - f1score: 0.7676 - val_loss: 2.4177 - val_acc: 0.7929 - val_f1score: 0.7909\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.77682 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.42.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.5263 - acc: 0.7672 - f1score: 0.7676 - val_loss: 2.4177 - val_acc: 0.7929 - val_f1score: 0.7909\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.2876 - acc: 0.7780 - f1score: 0.7780\n",
            "Epoch 00003: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.2875 - acc: 0.7778 - f1score: 0.7776 - val_loss: 2.2939 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.2875 - acc: 0.7778 - f1score: 0.7776 - val_loss: 2.2939 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.0661 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00004: val_acc improved from 0.79292 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.11.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.0621 - acc: 0.7937 - f1score: 0.7932 - val_loss: 2.1061 - val_acc: 0.8026 - val_f1score: 0.8051\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.79292 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.11.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.0621 - acc: 0.7937 - f1score: 0.7932 - val_loss: 2.1061 - val_acc: 0.8026 - val_f1score: 0.8051\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.7273 - acc: 0.8001 - f1score: 0.8001\n",
            "Epoch 00005: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.7227 - acc: 0.8000 - f1score: 0.7999 - val_loss: 1.3546 - val_acc: 0.8015 - val_f1score: 0.8041\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.7227 - acc: 0.8000 - f1score: 0.7999 - val_loss: 1.3546 - val_acc: 0.8015 - val_f1score: 0.8041\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6293 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6265 - acc: 0.8159 - f1score: 0.8151 - val_loss: 0.4952 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6265 - acc: 0.8159 - f1score: 0.8151 - val_loss: 0.4952 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4783 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4782 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4941 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4782 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4941 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4782 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4804 - acc: 0.8206 - f1score: 0.8198 - val_loss: 0.4927 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4804 - acc: 0.8206 - f1score: 0.8198 - val_loss: 0.4927 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4724 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4751 - acc: 0.8228 - f1score: 0.8223 - val_loss: 0.4863 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4751 - acc: 0.8228 - f1score: 0.8223 - val_loss: 0.4863 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4708 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4663 - acc: 0.8190 - f1score: 0.8214 - val_loss: 0.4837 - val_acc: 0.7854 - val_f1score: 0.7884\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4663 - acc: 0.8190 - f1score: 0.8214 - val_loss: 0.4837 - val_acc: 0.7854 - val_f1score: 0.7884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 20%|█▉        | 19/96 [1:22:29<5:52:40, 274.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 3.4685 - acc: 0.6595 - f1score: 0.6595\n",
            "Epoch 00001: val_acc improved from -inf to 0.77468, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.57.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 3.4271 - acc: 0.6630 - f1score: 0.6659 - val_loss: 2.5658 - val_acc: 0.7747 - val_f1score: 0.7772\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77468, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.57.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 3.4271 - acc: 0.6630 - f1score: 0.6659 - val_loss: 2.5658 - val_acc: 0.7747 - val_f1score: 0.7772\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.2570 - acc: 0.7899 - f1score: 0.7899\n",
            "Epoch 00002: val_acc improved from 0.77468 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.34.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.2392 - acc: 0.7905 - f1score: 0.7910 - val_loss: 2.3407 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.77468 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.34.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.2392 - acc: 0.7905 - f1score: 0.7910 - val_loss: 2.3407 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.9509 - acc: 0.7899 - f1score: 0.7899\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.9470 - acc: 0.7884 - f1score: 0.7871 - val_loss: 1.7643 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.9470 - acc: 0.7884 - f1score: 0.7871 - val_loss: 1.7643 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.4936 - acc: 0.7667 - f1score: 0.7667\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.4826 - acc: 0.7656 - f1score: 0.7647 - val_loss: 0.9604 - val_acc: 0.7994 - val_f1score: 0.8012\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.4826 - acc: 0.7656 - f1score: 0.7647 - val_loss: 0.9604 - val_acc: 0.7994 - val_f1score: 0.8012\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.7745 - acc: 0.7543 - f1score: 0.7543\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.7731 - acc: 0.7519 - f1score: 0.7498 - val_loss: 0.5282 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.7731 - acc: 0.7519 - f1score: 0.7498 - val_loss: 0.5282 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4987 - acc: 0.7716 - f1score: 0.7716\n",
            "Epoch 00006: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.50.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4985 - acc: 0.7720 - f1score: 0.7723 - val_loss: 0.5013 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.50.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4985 - acc: 0.7720 - f1score: 0.7723 - val_loss: 0.5013 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4741 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4761 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4926 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4761 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4926 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4793 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4764 - acc: 0.8180 - f1score: 0.8195 - val_loss: 0.4901 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4764 - acc: 0.8180 - f1score: 0.8195 - val_loss: 0.4901 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4679 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4674 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4914 - val_acc: 0.8026 - val_f1score: 0.8043\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4674 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4914 - val_acc: 0.8026 - val_f1score: 0.8043\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4747 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4722 - acc: 0.8180 - f1score: 0.8185 - val_loss: 0.4860 - val_acc: 0.7951 - val_f1score: 0.7962\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4722 - acc: 0.8180 - f1score: 0.8185 - val_loss: 0.4860 - val_acc: 0.7951 - val_f1score: 0.7962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 21%|██        | 20/96 [1:24:14<4:43:46, 224.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.5118 - acc: 0.6724 - f1score: 0.6724\n",
            "Epoch 00001: val_acc improved from -inf to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.05.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.4830 - acc: 0.6757 - f1score: 0.6784 - val_loss: 2.0462 - val_acc: 0.8036 - val_f1score: 0.8021\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.05.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.4830 - acc: 0.6757 - f1score: 0.6784 - val_loss: 2.0462 - val_acc: 0.8036 - val_f1score: 0.8021\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.0219 - acc: 0.7656 - f1score: 0.7656\n",
            "Epoch 00002: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.0096 - acc: 0.7646 - f1score: 0.7636 - val_loss: 1.6479 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.0096 - acc: 0.7646 - f1score: 0.7636 - val_loss: 1.6479 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.2542 - acc: 0.7559 - f1score: 0.7559\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.2428 - acc: 0.7556 - f1score: 0.7552 - val_loss: 0.7831 - val_acc: 0.7403 - val_f1score: 0.7414\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.2428 - acc: 0.7556 - f1score: 0.7552 - val_loss: 0.7831 - val_acc: 0.7403 - val_f1score: 0.7414\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5841 - acc: 0.7268 - f1score: 0.7268\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5823 - acc: 0.7275 - f1score: 0.7281 - val_loss: 0.4965 - val_acc: 0.8026 - val_f1score: 0.8075\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5823 - acc: 0.7275 - f1score: 0.7281 - val_loss: 0.4965 - val_acc: 0.8026 - val_f1score: 0.8075\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5125 - acc: 0.7926 - f1score: 0.7926\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5140 - acc: 0.7915 - f1score: 0.7907 - val_loss: 0.5008 - val_acc: 0.8015 - val_f1score: 0.7992\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5140 - acc: 0.7915 - f1score: 0.7907 - val_loss: 0.5008 - val_acc: 0.8015 - val_f1score: 0.7992\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5036 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5047 - acc: 0.8143 - f1score: 0.8135 - val_loss: 0.4950 - val_acc: 0.8026 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5047 - acc: 0.8143 - f1score: 0.8135 - val_loss: 0.4950 - val_acc: 0.8026 - val_f1score: 0.8059\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5117 - acc: 0.8050 - f1score: 0.8050\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5114 - acc: 0.8063 - f1score: 0.8075 - val_loss: 0.4984 - val_acc: 0.8026 - val_f1score: 0.8010\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5114 - acc: 0.8063 - f1score: 0.8075 - val_loss: 0.4984 - val_acc: 0.8026 - val_f1score: 0.8010\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4950 - acc: 0.8044 - f1score: 0.8044\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4949 - acc: 0.8053 - f1score: 0.8060 - val_loss: 0.4898 - val_acc: 0.8015 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4949 - acc: 0.8053 - f1score: 0.8060 - val_loss: 0.4898 - val_acc: 0.8015 - val_f1score: 0.7984\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4927 - acc: 0.8093 - f1score: 0.8093\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4944 - acc: 0.8085 - f1score: 0.8078 - val_loss: 0.4921 - val_acc: 0.8015 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4944 - acc: 0.8085 - f1score: 0.8078 - val_loss: 0.4921 - val_acc: 0.8015 - val_f1score: 0.7984\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4899 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4902 - acc: 0.8122 - f1score: 0.8110 - val_loss: 0.4873 - val_acc: 0.8015 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4902 - acc: 0.8122 - f1score: 0.8110 - val_loss: 0.4873 - val_acc: 0.8015 - val_f1score: 0.7951\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4823 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4804 - acc: 0.8143 - f1score: 0.8163 - val_loss: 0.4889 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4804 - acc: 0.8143 - f1score: 0.8163 - val_loss: 0.4889 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4854 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4871 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.5063 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4871 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.5063 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4879 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00013: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.13-0.48.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.4860 - acc: 0.8143 - f1score: 0.8153 - val_loss: 0.4810 - val_acc: 0.8047 - val_f1score: 0.8039\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.13-0.48.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.4860 - acc: 0.8143 - f1score: 0.8153 - val_loss: 0.4810 - val_acc: 0.8047 - val_f1score: 0.8039\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4766 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00014: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4763 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4789 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4763 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4789 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4742 - acc: 0.8066 - f1score: 0.8066\n",
            "Epoch 00015: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4732 - acc: 0.8069 - f1score: 0.8071 - val_loss: 0.4808 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4732 - acc: 0.8069 - f1score: 0.8071 - val_loss: 0.4808 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00016: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4673 - acc: 0.8127 - f1score: 0.8124 - val_loss: 0.4791 - val_acc: 0.8036 - val_f1score: 0.8045\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4673 - acc: 0.8127 - f1score: 0.8124 - val_loss: 0.4791 - val_acc: 0.8036 - val_f1score: 0.8045\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4707 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00017: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4690 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4795 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4690 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4795 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4623 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00018: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4659 - acc: 0.8122 - f1score: 0.8110 - val_loss: 0.4801 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4659 - acc: 0.8122 - f1score: 0.8110 - val_loss: 0.4801 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4735 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00019: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4704 - acc: 0.8132 - f1score: 0.8152 - val_loss: 0.4782 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4704 - acc: 0.8132 - f1score: 0.8152 - val_loss: 0.4782 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4667 - acc: 0.8082 - f1score: 0.8082\n",
            "Epoch 00020: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4653 - acc: 0.8090 - f1score: 0.8097 - val_loss: 0.4791 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4653 - acc: 0.8090 - f1score: 0.8097 - val_loss: 0.4791 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4748 - acc: 0.8055 - f1score: 0.8055\n",
            "Epoch 00021: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4738 - acc: 0.8053 - f1score: 0.8051 - val_loss: 0.4789 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4738 - acc: 0.8053 - f1score: 0.8051 - val_loss: 0.4789 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4605 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4607 - acc: 0.8127 - f1score: 0.8124 - val_loss: 0.4780 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4607 - acc: 0.8127 - f1score: 0.8124 - val_loss: 0.4780 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4628 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4630 - acc: 0.8169 - f1score: 0.8166 - val_loss: 0.4766 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4630 - acc: 0.8169 - f1score: 0.8166 - val_loss: 0.4766 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4654 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4646 - acc: 0.8164 - f1score: 0.8174 - val_loss: 0.4780 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4646 - acc: 0.8164 - f1score: 0.8174 - val_loss: 0.4780 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4575 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4566 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4782 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4566 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4782 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4589 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4574 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4784 - val_acc: 0.7854 - val_f1score: 0.7836\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4574 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4784 - val_acc: 0.7854 - val_f1score: 0.7836\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4580 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4562 - acc: 0.8143 - f1score: 0.8158 - val_loss: 0.4765 - val_acc: 0.7961 - val_f1score: 0.7964\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4562 - acc: 0.8143 - f1score: 0.8158 - val_loss: 0.4765 - val_acc: 0.7961 - val_f1score: 0.7964\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4579 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4560 - acc: 0.8175 - f1score: 0.8185 - val_loss: 0.4772 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4560 - acc: 0.8175 - f1score: 0.8185 - val_loss: 0.4772 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4631 - acc: 0.8093 - f1score: 0.8093\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4639 - acc: 0.8079 - f1score: 0.8068 - val_loss: 0.4783 - val_acc: 0.7865 - val_f1score: 0.7846\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4639 - acc: 0.8079 - f1score: 0.8068 - val_loss: 0.4783 - val_acc: 0.7865 - val_f1score: 0.7846\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4694 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4723 - acc: 0.8079 - f1score: 0.8063 - val_loss: 0.4774 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4723 - acc: 0.8079 - f1score: 0.8063 - val_loss: 0.4774 - val_acc: 0.7897 - val_f1score: 0.7885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 22%|██▏       | 21/96 [1:28:11<4:44:47, 227.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.7203 - acc: 0.6956 - f1score: 0.6956\n",
            "Epoch 00001: val_acc improved from -inf to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.34.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.6905 - acc: 0.6989 - f1score: 0.7018 - val_loss: 2.3434 - val_acc: 0.8036 - val_f1score: 0.8078\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.34.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.6905 - acc: 0.6989 - f1score: 0.7018 - val_loss: 2.3434 - val_acc: 0.8036 - val_f1score: 0.8078\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.0354 - acc: 0.7883 - f1score: 0.7883\n",
            "Epoch 00002: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.0441 - acc: 0.7884 - f1score: 0.7884 - val_loss: 1.9488 - val_acc: 0.8026 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.0441 - acc: 0.7884 - f1score: 0.7884 - val_loss: 1.9488 - val_acc: 0.8026 - val_f1score: 0.8059\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.7366 - acc: 0.7737 - f1score: 0.7737\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.7449 - acc: 0.7730 - f1score: 0.7724 - val_loss: 1.5659 - val_acc: 0.7779 - val_f1score: 0.7787\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.7449 - acc: 0.7730 - f1score: 0.7724 - val_loss: 1.5659 - val_acc: 0.7779 - val_f1score: 0.7787\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.2392 - acc: 0.7241 - f1score: 0.7241\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.2274 - acc: 0.7265 - f1score: 0.7284 - val_loss: 0.8524 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.2274 - acc: 0.7265 - f1score: 0.7284 - val_loss: 0.8524 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6451 - acc: 0.7355 - f1score: 0.7355\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6425 - acc: 0.7365 - f1score: 0.7374 - val_loss: 0.5105 - val_acc: 0.7876 - val_f1score: 0.7881\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6425 - acc: 0.7365 - f1score: 0.7374 - val_loss: 0.5105 - val_acc: 0.7876 - val_f1score: 0.7881\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5260 - acc: 0.7705 - f1score: 0.7705\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5268 - acc: 0.7698 - f1score: 0.7693 - val_loss: 0.5233 - val_acc: 0.7994 - val_f1score: 0.8012\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5268 - acc: 0.7698 - f1score: 0.7693 - val_loss: 0.5233 - val_acc: 0.7994 - val_f1score: 0.8012\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5272 - acc: 0.7936 - f1score: 0.7936\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5259 - acc: 0.7952 - f1score: 0.7966 - val_loss: 0.5060 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5259 - acc: 0.7952 - f1score: 0.7966 - val_loss: 0.5060 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5014 - acc: 0.8066 - f1score: 0.8066\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5017 - acc: 0.8079 - f1score: 0.8091 - val_loss: 0.5016 - val_acc: 0.7994 - val_f1score: 0.7947\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5017 - acc: 0.8079 - f1score: 0.8091 - val_loss: 0.5016 - val_acc: 0.7994 - val_f1score: 0.7947\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5004 - acc: 0.8050 - f1score: 0.8050\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4997 - acc: 0.8063 - f1score: 0.8075 - val_loss: 0.4897 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4997 - acc: 0.8063 - f1score: 0.8075 - val_loss: 0.4897 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4950 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4944 - acc: 0.8138 - f1score: 0.8134 - val_loss: 0.4918 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4944 - acc: 0.8138 - f1score: 0.8134 - val_loss: 0.4918 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4833 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4834 - acc: 0.8111 - f1score: 0.8099 - val_loss: 0.4880 - val_acc: 0.8015 - val_f1score: 0.8041\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4834 - acc: 0.8111 - f1score: 0.8099 - val_loss: 0.4880 - val_acc: 0.8015 - val_f1score: 0.8041\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4871 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4893 - acc: 0.8074 - f1score: 0.8077 - val_loss: 0.4897 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4893 - acc: 0.8074 - f1score: 0.8077 - val_loss: 0.4897 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4725 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4729 - acc: 0.8127 - f1score: 0.8119 - val_loss: 0.4824 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4729 - acc: 0.8127 - f1score: 0.8119 - val_loss: 0.4824 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4684 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4689 - acc: 0.8116 - f1score: 0.8118 - val_loss: 0.4857 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4689 - acc: 0.8116 - f1score: 0.8118 - val_loss: 0.4857 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4743 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4748 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4883 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4748 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4883 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4728 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4753 - acc: 0.8116 - f1score: 0.8114 - val_loss: 0.4846 - val_acc: 0.7822 - val_f1score: 0.7853\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4753 - acc: 0.8116 - f1score: 0.8114 - val_loss: 0.4846 - val_acc: 0.7822 - val_f1score: 0.7853\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4642 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4644 - acc: 0.8169 - f1score: 0.8166 - val_loss: 0.4827 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4644 - acc: 0.8169 - f1score: 0.8166 - val_loss: 0.4827 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4686 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4693 - acc: 0.8159 - f1score: 0.8151 - val_loss: 0.4881 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4693 - acc: 0.8159 - f1score: 0.8151 - val_loss: 0.4881 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4644 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4632 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4805 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4632 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4805 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4623 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4637 - acc: 0.8143 - f1score: 0.8135 - val_loss: 0.4818 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4637 - acc: 0.8143 - f1score: 0.8135 - val_loss: 0.4818 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4731 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4710 - acc: 0.8148 - f1score: 0.8159 - val_loss: 0.4801 - val_acc: 0.7843 - val_f1score: 0.7882\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4710 - acc: 0.8148 - f1score: 0.8159 - val_loss: 0.4801 - val_acc: 0.7843 - val_f1score: 0.7882\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4685 - acc: 0.8093 - f1score: 0.8093\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4686 - acc: 0.8090 - f1score: 0.8088 - val_loss: 0.4814 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4686 - acc: 0.8090 - f1score: 0.8088 - val_loss: 0.4814 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4586 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4584 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.4825 - val_acc: 0.7800 - val_f1score: 0.7767\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4584 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.4825 - val_acc: 0.7800 - val_f1score: 0.7767\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4665 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4649 - acc: 0.8143 - f1score: 0.8153 - val_loss: 0.4800 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4649 - acc: 0.8143 - f1score: 0.8153 - val_loss: 0.4800 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4529 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4552 - acc: 0.8148 - f1score: 0.8127 - val_loss: 0.4792 - val_acc: 0.7800 - val_f1score: 0.7824\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4552 - acc: 0.8148 - f1score: 0.8127 - val_loss: 0.4792 - val_acc: 0.7800 - val_f1score: 0.7824\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4619 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4626 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4807 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4626 - acc: 0.8175 - f1score: 0.8171 - val_loss: 0.4807 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4483 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4498 - acc: 0.8127 - f1score: 0.8124 - val_loss: 0.4832 - val_acc: 0.7972 - val_f1score: 0.7942\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4498 - acc: 0.8127 - f1score: 0.8124 - val_loss: 0.4832 - val_acc: 0.7972 - val_f1score: 0.7942\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4671 - acc: 0.8050 - f1score: 0.8050\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4647 - acc: 0.8069 - f1score: 0.8085 - val_loss: 0.4904 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4647 - acc: 0.8069 - f1score: 0.8085 - val_loss: 0.4904 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4556 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4567 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4798 - val_acc: 0.7768 - val_f1score: 0.7736\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4567 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4798 - val_acc: 0.7768 - val_f1score: 0.7736\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4573 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4571 - acc: 0.8153 - f1score: 0.8141 - val_loss: 0.4810 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4571 - acc: 0.8153 - f1score: 0.8141 - val_loss: 0.4810 - val_acc: 0.7940 - val_f1score: 0.7935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 23%|██▎       | 22/96 [1:33:17<5:09:54, 251.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.7270 - acc: 0.6789 - f1score: 0.6789\n",
            "Epoch 00001: val_acc improved from -inf to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.28.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.6918 - acc: 0.6820 - f1score: 0.6847 - val_loss: 2.2824 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.28.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.6918 - acc: 0.6820 - f1score: 0.6847 - val_loss: 2.2824 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.9228 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00002: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.9120 - acc: 0.7963 - f1score: 0.7953 - val_loss: 1.4964 - val_acc: 0.7779 - val_f1score: 0.7738\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.9120 - acc: 0.7963 - f1score: 0.7953 - val_loss: 1.4964 - val_acc: 0.7779 - val_f1score: 0.7738\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.0335 - acc: 0.7376 - f1score: 0.7376\n",
            "Epoch 00003: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.51.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0261 - acc: 0.7365 - f1score: 0.7356 - val_loss: 0.5131 - val_acc: 0.8026 - val_f1score: 0.8019\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.51.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0261 - acc: 0.7365 - f1score: 0.7356 - val_loss: 0.5131 - val_acc: 0.8026 - val_f1score: 0.8019\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4948 - acc: 0.7845 - f1score: 0.7845\n",
            "Epoch 00004: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4946 - acc: 0.7868 - f1score: 0.7887 - val_loss: 0.4968 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4946 - acc: 0.7868 - f1score: 0.7887 - val_loss: 0.4968 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4694 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00005: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4711 - acc: 0.8127 - f1score: 0.8110 - val_loss: 0.4930 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4711 - acc: 0.8127 - f1score: 0.8110 - val_loss: 0.4930 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4766 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4759 - acc: 0.8212 - f1score: 0.8221 - val_loss: 0.4909 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4759 - acc: 0.8212 - f1score: 0.8221 - val_loss: 0.4909 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4670 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4710 - acc: 0.8169 - f1score: 0.8157 - val_loss: 0.4917 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4710 - acc: 0.8169 - f1score: 0.8157 - val_loss: 0.4917 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4695 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4701 - acc: 0.8122 - f1score: 0.8119 - val_loss: 0.4878 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4701 - acc: 0.8122 - f1score: 0.8119 - val_loss: 0.4878 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4717 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4713 - acc: 0.8201 - f1score: 0.8206 - val_loss: 0.4861 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4713 - acc: 0.8201 - f1score: 0.8206 - val_loss: 0.4861 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4567 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4591 - acc: 0.8217 - f1score: 0.8213 - val_loss: 0.4905 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4591 - acc: 0.8217 - f1score: 0.8213 - val_loss: 0.4905 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4623 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00011: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4641 - acc: 0.8185 - f1score: 0.8177 - val_loss: 0.4885 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4641 - acc: 0.8185 - f1score: 0.8177 - val_loss: 0.4885 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4643 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4630 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4860 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4630 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4860 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4633 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4643 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4876 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4643 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4876 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4609 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00014: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4577 - acc: 0.8185 - f1score: 0.8200 - val_loss: 0.4872 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4577 - acc: 0.8185 - f1score: 0.8200 - val_loss: 0.4872 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4542 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00015: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4573 - acc: 0.8190 - f1score: 0.8173 - val_loss: 0.4836 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4573 - acc: 0.8190 - f1score: 0.8173 - val_loss: 0.4836 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4571 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00016: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4563 - acc: 0.8190 - f1score: 0.8191 - val_loss: 0.4860 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4563 - acc: 0.8190 - f1score: 0.8191 - val_loss: 0.4860 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4621 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00017: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4596 - acc: 0.8138 - f1score: 0.8157 - val_loss: 0.4870 - val_acc: 0.7972 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4596 - acc: 0.8138 - f1score: 0.8157 - val_loss: 0.4870 - val_acc: 0.7972 - val_f1score: 0.7975\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4575 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00018: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4569 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4841 - val_acc: 0.7822 - val_f1score: 0.7788\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4569 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4841 - val_acc: 0.7822 - val_f1score: 0.7788\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4620 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00019: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4596 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4839 - val_acc: 0.7908 - val_f1score: 0.7944\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4596 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4839 - val_acc: 0.7908 - val_f1score: 0.7944\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00020: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4591 - acc: 0.8201 - f1score: 0.8211 - val_loss: 0.4856 - val_acc: 0.7800 - val_f1score: 0.7800\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4591 - acc: 0.8201 - f1score: 0.8211 - val_loss: 0.4856 - val_acc: 0.7800 - val_f1score: 0.7800\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4519 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00021: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4542 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4840 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4542 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4840 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4498 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00022: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4533 - acc: 0.8159 - f1score: 0.8142 - val_loss: 0.4827 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4533 - acc: 0.8159 - f1score: 0.8142 - val_loss: 0.4827 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4528 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00023: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4536 - acc: 0.8148 - f1score: 0.8136 - val_loss: 0.4844 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4536 - acc: 0.8148 - f1score: 0.8136 - val_loss: 0.4844 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4437 - acc: 0.8265 - f1score: 0.8265\n",
            "Epoch 00024: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4473 - acc: 0.8249 - f1score: 0.8235 - val_loss: 0.4840 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4473 - acc: 0.8249 - f1score: 0.8235 - val_loss: 0.4840 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4501 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00025: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4511 - acc: 0.8153 - f1score: 0.8141 - val_loss: 0.4815 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4511 - acc: 0.8153 - f1score: 0.8141 - val_loss: 0.4815 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4544 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00026: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4542 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4807 - val_acc: 0.7961 - val_f1score: 0.7932\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4542 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4807 - val_acc: 0.7961 - val_f1score: 0.7932\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00027: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4517 - acc: 0.8116 - f1score: 0.8104 - val_loss: 0.4871 - val_acc: 0.7994 - val_f1score: 0.7922\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4517 - acc: 0.8116 - f1score: 0.8104 - val_loss: 0.4871 - val_acc: 0.7994 - val_f1score: 0.7922\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4602 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00028: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4577 - acc: 0.8148 - f1score: 0.8172 - val_loss: 0.4812 - val_acc: 0.7865 - val_f1score: 0.7887\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4577 - acc: 0.8148 - f1score: 0.8172 - val_loss: 0.4812 - val_acc: 0.7865 - val_f1score: 0.7887\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4555 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00029: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4554 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4818 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4554 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4818 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4491 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00030: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4478 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4834 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4478 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4834 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4487 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00031: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4475 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4814 - val_acc: 0.7843 - val_f1score: 0.7825\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4475 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4814 - val_acc: 0.7843 - val_f1score: 0.7825\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4501 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00032: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4504 - acc: 0.8222 - f1score: 0.8218 - val_loss: 0.4810 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4504 - acc: 0.8222 - f1score: 0.8218 - val_loss: 0.4810 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00033: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4564 - acc: 0.8138 - f1score: 0.8153 - val_loss: 0.4823 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4564 - acc: 0.8138 - f1score: 0.8153 - val_loss: 0.4823 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4395 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00034: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4425 - acc: 0.8206 - f1score: 0.8202 - val_loss: 0.4832 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4425 - acc: 0.8206 - f1score: 0.8202 - val_loss: 0.4832 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4507 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00035: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4518 - acc: 0.8164 - f1score: 0.8156 - val_loss: 0.4798 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4518 - acc: 0.8164 - f1score: 0.8156 - val_loss: 0.4798 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4436 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00036: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4469 - acc: 0.8122 - f1score: 0.8110 - val_loss: 0.4805 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4469 - acc: 0.8122 - f1score: 0.8110 - val_loss: 0.4805 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4499 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00037: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4516 - acc: 0.8164 - f1score: 0.8161 - val_loss: 0.4788 - val_acc: 0.7908 - val_f1score: 0.7872\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4516 - acc: 0.8164 - f1score: 0.8161 - val_loss: 0.4788 - val_acc: 0.7908 - val_f1score: 0.7872\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4418 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00038: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4396 - acc: 0.8196 - f1score: 0.8210 - val_loss: 0.4795 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4396 - acc: 0.8196 - f1score: 0.8210 - val_loss: 0.4795 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4520 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00039: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4526 - acc: 0.8185 - f1score: 0.8181 - val_loss: 0.4800 - val_acc: 0.7800 - val_f1score: 0.7832\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4526 - acc: 0.8185 - f1score: 0.8181 - val_loss: 0.4800 - val_acc: 0.7800 - val_f1score: 0.7832\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4493 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00040: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4476 - acc: 0.8180 - f1score: 0.8185 - val_loss: 0.4786 - val_acc: 0.7929 - val_f1score: 0.7892\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4476 - acc: 0.8180 - f1score: 0.8185 - val_loss: 0.4786 - val_acc: 0.7929 - val_f1score: 0.7892\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4442 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00041: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4432 - acc: 0.8212 - f1score: 0.8226 - val_loss: 0.4790 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4432 - acc: 0.8212 - f1score: 0.8226 - val_loss: 0.4790 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00042: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4456 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4810 - val_acc: 0.7833 - val_f1score: 0.7791\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4456 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4810 - val_acc: 0.7833 - val_f1score: 0.7791\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4495 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00043: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4510 - acc: 0.8159 - f1score: 0.8142 - val_loss: 0.4791 - val_acc: 0.7886 - val_f1score: 0.7916\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4510 - acc: 0.8159 - f1score: 0.8142 - val_loss: 0.4791 - val_acc: 0.7886 - val_f1score: 0.7916\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4434 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00044: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4441 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4788 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4441 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4788 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4457 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00045: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4458 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4790 - val_acc: 0.7908 - val_f1score: 0.7944\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4458 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4790 - val_acc: 0.7908 - val_f1score: 0.7944\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4437 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00046: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4445 - acc: 0.8206 - f1score: 0.8198 - val_loss: 0.4791 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4445 - acc: 0.8206 - f1score: 0.8198 - val_loss: 0.4791 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4440 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00047: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4418 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4775 - val_acc: 0.7961 - val_f1score: 0.7988\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4418 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4775 - val_acc: 0.7961 - val_f1score: 0.7988\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4526 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00048: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4518 - acc: 0.8185 - f1score: 0.8186 - val_loss: 0.4794 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4518 - acc: 0.8185 - f1score: 0.8186 - val_loss: 0.4794 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4476 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00049: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4464 - acc: 0.8164 - f1score: 0.8170 - val_loss: 0.4807 - val_acc: 0.7961 - val_f1score: 0.7940\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4464 - acc: 0.8164 - f1score: 0.8170 - val_loss: 0.4807 - val_acc: 0.7961 - val_f1score: 0.7940\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4401 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00050: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4416 - acc: 0.8175 - f1score: 0.8162 - val_loss: 0.4779 - val_acc: 0.7833 - val_f1score: 0.7872\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4416 - acc: 0.8175 - f1score: 0.8162 - val_loss: 0.4779 - val_acc: 0.7833 - val_f1score: 0.7872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 24%|██▍       | 23/96 [1:39:47<5:56:20, 292.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.1595 - acc: 0.6891 - f1score: 0.6891\n",
            "Epoch 00001: val_acc improved from -inf to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.04.h5\n",
            "1890/1890 [==============================] - 12s 7ms/sample - loss: 2.1419 - acc: 0.6910 - f1score: 0.6926 - val_loss: 1.0436 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.04.h5\n",
            "1890/1890 [==============================] - 12s 7ms/sample - loss: 2.1419 - acc: 0.6910 - f1score: 0.6926 - val_loss: 1.0436 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.8583 - acc: 0.7381 - f1score: 0.7381\n",
            "Epoch 00002: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.8582 - acc: 0.7365 - f1score: 0.7351 - val_loss: 0.5392 - val_acc: 0.7994 - val_f1score: 0.7979\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.8582 - acc: 0.7365 - f1score: 0.7351 - val_loss: 0.5392 - val_acc: 0.7994 - val_f1score: 0.7979\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5146 - acc: 0.7802 - f1score: 0.7802\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5163 - acc: 0.7767 - f1score: 0.7738 - val_loss: 0.5010 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5163 - acc: 0.7767 - f1score: 0.7738 - val_loss: 0.5010 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4885 - acc: 0.7818 - f1score: 0.7818\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4901 - acc: 0.7810 - f1score: 0.7802 - val_loss: 0.4890 - val_acc: 0.7994 - val_f1score: 0.7955\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4901 - acc: 0.7810 - f1score: 0.7802 - val_loss: 0.4890 - val_acc: 0.7994 - val_f1score: 0.7955\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4953 - acc: 0.7872 - f1score: 0.7872\n",
            "Epoch 00005: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.50.h5\n",
            "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.4933 - acc: 0.7884 - f1score: 0.7894 - val_loss: 0.4960 - val_acc: 0.8015 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.50.h5\n",
            "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.4933 - acc: 0.7884 - f1score: 0.7894 - val_loss: 0.4960 - val_acc: 0.8015 - val_f1score: 0.7984\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4923 - acc: 0.7850 - f1score: 0.7850\n",
            "Epoch 00006: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4905 - acc: 0.7862 - f1score: 0.7873 - val_loss: 0.4893 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4905 - acc: 0.7862 - f1score: 0.7873 - val_loss: 0.4893 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4762 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00007: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4733 - acc: 0.7974 - f1score: 0.7991 - val_loss: 0.4835 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4733 - acc: 0.7974 - f1score: 0.7991 - val_loss: 0.4835 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4851 - acc: 0.7893 - f1score: 0.7893\n",
            "Epoch 00008: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4863 - acc: 0.7878 - f1score: 0.7866 - val_loss: 0.4867 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4863 - acc: 0.7878 - f1score: 0.7866 - val_loss: 0.4867 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4816 - acc: 0.7936 - f1score: 0.7936\n",
            "Epoch 00009: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4810 - acc: 0.7942 - f1score: 0.7946 - val_loss: 0.4825 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4810 - acc: 0.7942 - f1score: 0.7946 - val_loss: 0.4825 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4806 - acc: 0.7883 - f1score: 0.7883\n",
            "Epoch 00010: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4798 - acc: 0.7884 - f1score: 0.7884 - val_loss: 0.4862 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4798 - acc: 0.7884 - f1score: 0.7884 - val_loss: 0.4862 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4810 - acc: 0.8006 - f1score: 0.8006\n",
            "Epoch 00011: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4819 - acc: 0.8000 - f1score: 0.7994 - val_loss: 0.4885 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4819 - acc: 0.8000 - f1score: 0.7994 - val_loss: 0.4885 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4771 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00012: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4794 - acc: 0.7974 - f1score: 0.7964 - val_loss: 0.4847 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4794 - acc: 0.7974 - f1score: 0.7964 - val_loss: 0.4847 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4737 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00013: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4727 - acc: 0.7989 - f1score: 0.7993 - val_loss: 0.4848 - val_acc: 0.7951 - val_f1score: 0.7962\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4727 - acc: 0.7989 - f1score: 0.7993 - val_loss: 0.4848 - val_acc: 0.7951 - val_f1score: 0.7962\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4799 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00014: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4792 - acc: 0.7947 - f1score: 0.7952 - val_loss: 0.4816 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4792 - acc: 0.7947 - f1score: 0.7952 - val_loss: 0.4816 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4769 - acc: 0.7920 - f1score: 0.7920\n",
            "Epoch 00015: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4787 - acc: 0.7921 - f1score: 0.7921 - val_loss: 0.4853 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4787 - acc: 0.7921 - f1score: 0.7921 - val_loss: 0.4853 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4865 - acc: 0.7839 - f1score: 0.7839\n",
            "Epoch 00016: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4848 - acc: 0.7862 - f1score: 0.7882 - val_loss: 0.4806 - val_acc: 0.7961 - val_f1score: 0.7956\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4848 - acc: 0.7862 - f1score: 0.7882 - val_loss: 0.4806 - val_acc: 0.7961 - val_f1score: 0.7956\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4762 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00017: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4776 - acc: 0.7952 - f1score: 0.7943 - val_loss: 0.4815 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4776 - acc: 0.7952 - f1score: 0.7943 - val_loss: 0.4815 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4859 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00018: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4865 - acc: 0.7952 - f1score: 0.7952 - val_loss: 0.4805 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4865 - acc: 0.7952 - f1score: 0.7952 - val_loss: 0.4805 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4740 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00019: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4753 - acc: 0.7968 - f1score: 0.7954 - val_loss: 0.4823 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4753 - acc: 0.7968 - f1score: 0.7954 - val_loss: 0.4823 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4754 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00020: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4751 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4852 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4751 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4852 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4779 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00021: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4782 - acc: 0.8116 - f1score: 0.8109 - val_loss: 0.4795 - val_acc: 0.7908 - val_f1score: 0.7872\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4782 - acc: 0.8116 - f1score: 0.8109 - val_loss: 0.4795 - val_acc: 0.7908 - val_f1score: 0.7872\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4618 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00022: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.22-0.48.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4601 - acc: 0.8132 - f1score: 0.8143 - val_loss: 0.4805 - val_acc: 0.8026 - val_f1score: 0.8019\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.22-0.48.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4601 - acc: 0.8132 - f1score: 0.8143 - val_loss: 0.4805 - val_acc: 0.8026 - val_f1score: 0.8019\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4701 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00023: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4705 - acc: 0.8122 - f1score: 0.8123 - val_loss: 0.4819 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4705 - acc: 0.8122 - f1score: 0.8123 - val_loss: 0.4819 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4679 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00024: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.24-0.48.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4660 - acc: 0.8201 - f1score: 0.8206 - val_loss: 0.4786 - val_acc: 0.8036 - val_f1score: 0.8086\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.24-0.48.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4660 - acc: 0.8201 - f1score: 0.8206 - val_loss: 0.4786 - val_acc: 0.8036 - val_f1score: 0.8086\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4738 - acc: 0.8060 - f1score: 0.8060\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4751 - acc: 0.8048 - f1score: 0.8037 - val_loss: 0.4780 - val_acc: 0.7886 - val_f1score: 0.7867\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4751 - acc: 0.8048 - f1score: 0.8037 - val_loss: 0.4780 - val_acc: 0.7886 - val_f1score: 0.7867\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4626 - acc: 0.8077 - f1score: 0.8077\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4597 - acc: 0.8095 - f1score: 0.8111 - val_loss: 0.4788 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4597 - acc: 0.8095 - f1score: 0.8111 - val_loss: 0.4788 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4650 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4618 - acc: 0.8132 - f1score: 0.8152 - val_loss: 0.4769 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4618 - acc: 0.8132 - f1score: 0.8152 - val_loss: 0.4769 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4679 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4682 - acc: 0.8111 - f1score: 0.8113 - val_loss: 0.4780 - val_acc: 0.7854 - val_f1score: 0.7876\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4682 - acc: 0.8111 - f1score: 0.8113 - val_loss: 0.4780 - val_acc: 0.7854 - val_f1score: 0.7876\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4623 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4595 - acc: 0.8159 - f1score: 0.8169 - val_loss: 0.4770 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4595 - acc: 0.8159 - f1score: 0.8169 - val_loss: 0.4770 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4574 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4592 - acc: 0.8106 - f1score: 0.8094 - val_loss: 0.4784 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4592 - acc: 0.8106 - f1score: 0.8094 - val_loss: 0.4784 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4623 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00031: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4621 - acc: 0.8116 - f1score: 0.8118 - val_loss: 0.4781 - val_acc: 0.7865 - val_f1score: 0.7854\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4621 - acc: 0.8116 - f1score: 0.8118 - val_loss: 0.4781 - val_acc: 0.7865 - val_f1score: 0.7854\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4615 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00032: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4615 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4777 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4615 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4777 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4652 - acc: 0.8082 - f1score: 0.8082\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4628 - acc: 0.8101 - f1score: 0.8116 - val_loss: 0.4814 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4628 - acc: 0.8101 - f1score: 0.8116 - val_loss: 0.4814 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4658 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4665 - acc: 0.8069 - f1score: 0.8067 - val_loss: 0.4799 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4665 - acc: 0.8069 - f1score: 0.8067 - val_loss: 0.4799 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4586 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4546 - acc: 0.8143 - f1score: 0.8172 - val_loss: 0.4820 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4546 - acc: 0.8143 - f1score: 0.8172 - val_loss: 0.4820 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4635 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4613 - acc: 0.8101 - f1score: 0.8112 - val_loss: 0.4802 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4613 - acc: 0.8101 - f1score: 0.8112 - val_loss: 0.4802 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4572 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4575 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4786 - val_acc: 0.7865 - val_f1score: 0.7878\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4575 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4786 - val_acc: 0.7865 - val_f1score: 0.7878\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4537 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4543 - acc: 0.8175 - f1score: 0.8166 - val_loss: 0.4777 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4543 - acc: 0.8175 - f1score: 0.8166 - val_loss: 0.4777 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4607 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4596 - acc: 0.8164 - f1score: 0.8170 - val_loss: 0.4771 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4596 - acc: 0.8164 - f1score: 0.8170 - val_loss: 0.4771 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4606 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4608 - acc: 0.8111 - f1score: 0.8113 - val_loss: 0.4743 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4608 - acc: 0.8111 - f1score: 0.8113 - val_loss: 0.4743 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4577 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4589 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4731 - val_acc: 0.7961 - val_f1score: 0.7948\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4589 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4731 - val_acc: 0.7961 - val_f1score: 0.7948\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4560 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00042: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.42-0.48.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4546 - acc: 0.8153 - f1score: 0.8155 - val_loss: 0.4785 - val_acc: 0.8047 - val_f1score: 0.8047\n",
            "\n",
            "Epoch 00042: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.42-0.48.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4546 - acc: 0.8153 - f1score: 0.8155 - val_loss: 0.4785 - val_acc: 0.8047 - val_f1score: 0.8047\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4600 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00043: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4604 - acc: 0.8111 - f1score: 0.8118 - val_loss: 0.4752 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4604 - acc: 0.8111 - f1score: 0.8118 - val_loss: 0.4752 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4666 - acc: 0.8066 - f1score: 0.8066\n",
            "Epoch 00044: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4661 - acc: 0.8069 - f1score: 0.8071 - val_loss: 0.4793 - val_acc: 0.7811 - val_f1score: 0.7786\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4661 - acc: 0.8069 - f1score: 0.8071 - val_loss: 0.4793 - val_acc: 0.7811 - val_f1score: 0.7786\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4575 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00045: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4561 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4751 - val_acc: 0.7983 - val_f1score: 0.8017\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4561 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4751 - val_acc: 0.7983 - val_f1score: 0.8017\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4509 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00046: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4534 - acc: 0.8159 - f1score: 0.8137 - val_loss: 0.4787 - val_acc: 0.7908 - val_f1score: 0.7872\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4534 - acc: 0.8159 - f1score: 0.8137 - val_loss: 0.4787 - val_acc: 0.7908 - val_f1score: 0.7872\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4685 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00047: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4684 - acc: 0.8085 - f1score: 0.8082 - val_loss: 0.4749 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4684 - acc: 0.8085 - f1score: 0.8082 - val_loss: 0.4749 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4668 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00048: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4661 - acc: 0.8106 - f1score: 0.8112 - val_loss: 0.4755 - val_acc: 0.7886 - val_f1score: 0.7843\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4661 - acc: 0.8106 - f1score: 0.8112 - val_loss: 0.4755 - val_acc: 0.7886 - val_f1score: 0.7843\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4600 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00049: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4602 - acc: 0.8116 - f1score: 0.8114 - val_loss: 0.4754 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4602 - acc: 0.8116 - f1score: 0.8114 - val_loss: 0.4754 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4562 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00050: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4574 - acc: 0.8132 - f1score: 0.8125 - val_loss: 0.4783 - val_acc: 0.7865 - val_f1score: 0.7878\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4574 - acc: 0.8132 - f1score: 0.8125 - val_loss: 0.4783 - val_acc: 0.7865 - val_f1score: 0.7878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 25%|██▌       | 24/96 [1:48:19<7:10:20, 358.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 7.9411 - acc: 0.4336 - f1score: 0.4336\n",
            "Epoch 00001: val_acc improved from -inf to 0.43133, saving model to /content/drive/My Drive/LSTM_Model/model.01-8.56.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 7.9384 - acc: 0.4349 - f1score: 0.4353 - val_loss: 8.5578 - val_acc: 0.4313 - val_f1score: 0.4250\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.43133, saving model to /content/drive/My Drive/LSTM_Model/model.01-8.56.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 7.9384 - acc: 0.4349 - f1score: 0.4353 - val_loss: 8.5578 - val_acc: 0.4313 - val_f1score: 0.4250\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 7.8497 - acc: 0.4487 - f1score: 0.4487\n",
            "Epoch 00002: val_acc did not improve from 0.43133\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 7.8812 - acc: 0.4444 - f1score: 0.4432 - val_loss: 8.3878 - val_acc: 0.4313 - val_f1score: 0.4350\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.43133\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 7.8812 - acc: 0.4444 - f1score: 0.4432 - val_loss: 8.3878 - val_acc: 0.4313 - val_f1score: 0.4350\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 7.3016 - acc: 0.3521 - f1score: 0.3521\n",
            "Epoch 00003: val_acc did not improve from 0.43133\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 7.2494 - acc: 0.3460 - f1score: 0.3443 - val_loss: 5.7184 - val_acc: 0.2092 - val_f1score: 0.2104\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.43133\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 7.2494 - acc: 0.3460 - f1score: 0.3443 - val_loss: 5.7184 - val_acc: 0.2092 - val_f1score: 0.2104\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1766 - acc: 0.4492 - f1score: 0.4492\n",
            "Epoch 00004: val_acc improved from 0.43133 to 0.60300, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.90.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1006 - acc: 0.4566 - f1score: 0.4587 - val_loss: 0.9042 - val_acc: 0.6030 - val_f1score: 0.5962\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.43133 to 0.60300, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.90.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1006 - acc: 0.4566 - f1score: 0.4587 - val_loss: 0.9042 - val_acc: 0.6030 - val_f1score: 0.5962\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.7884 - acc: 0.6970 - f1score: 0.6970\n",
            "Epoch 00005: val_acc improved from 0.60300 to 0.77682, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.60.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.7871 - acc: 0.6942 - f1score: 0.6934 - val_loss: 0.5982 - val_acc: 0.7768 - val_f1score: 0.7744\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.60300 to 0.77682, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.60.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.7871 - acc: 0.6942 - f1score: 0.6934 - val_loss: 0.5982 - val_acc: 0.7768 - val_f1score: 0.7744\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6634 - acc: 0.7467 - f1score: 0.7467\n",
            "Epoch 00006: val_acc improved from 0.77682 to 0.77790, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.59.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6633 - acc: 0.7466 - f1score: 0.7465 - val_loss: 0.5916 - val_acc: 0.7779 - val_f1score: 0.7804\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.77682 to 0.77790, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.59.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6633 - acc: 0.7466 - f1score: 0.7465 - val_loss: 0.5916 - val_acc: 0.7779 - val_f1score: 0.7804\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6174 - acc: 0.7550 - f1score: 0.7550\n",
            "Epoch 00007: val_acc improved from 0.77790 to 0.79506, saving model to /content/drive/My Drive/LSTM_Model/model.07-0.57.h5\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.77790 to 0.79506, saving model to /content/drive/My Drive/LSTM_Model/model.07-0.57.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6199 - acc: 0.7529 - f1score: 0.7523 - val_loss: 0.5725 - val_acc: 0.7951 - val_f1score: 0.7810\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6199 - acc: 0.7529 - f1score: 0.7523 - val_loss: 0.5725 - val_acc: 0.7951 - val_f1score: 0.7810\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5830 - acc: 0.7640 - f1score: 0.7640\n",
            "Epoch 00008: val_acc did not improve from 0.79506\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5807 - acc: 0.7651 - f1score: 0.7654 - val_loss: 0.5424 - val_acc: 0.7843 - val_f1score: 0.7937\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.79506\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5807 - acc: 0.7651 - f1score: 0.7654 - val_loss: 0.5424 - val_acc: 0.7843 - val_f1score: 0.7937\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5449 - acc: 0.7757 - f1score: 0.7757\n",
            "Epoch 00009: val_acc improved from 0.79506 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.09-0.52.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5423 - acc: 0.7778 - f1score: 0.7784 - val_loss: 0.5214 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.79506 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.09-0.52.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5423 - acc: 0.7778 - f1score: 0.7784 - val_loss: 0.5214 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5234 - acc: 0.7891 - f1score: 0.7891\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5222 - acc: 0.7905 - f1score: 0.7909 - val_loss: 0.5118 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5222 - acc: 0.7905 - f1score: 0.7909 - val_loss: 0.5118 - val_acc: 0.8004 - val_f1score: 0.7984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 26%|██▌       | 25/96 [1:49:16<5:17:08, 268.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.6143 - acc: 0.6272 - f1score: 0.6272\n",
            "Epoch 00001: val_acc improved from -inf to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.32.h5\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.32.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.6128 - acc: 0.6360 - f1score: 0.6385 - val_loss: 2.3178 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.6128 - acc: 0.6360 - f1score: 0.6385 - val_loss: 2.3178 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.0979 - acc: 0.7924 - f1score: 0.7924\n",
            "Epoch 00002: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.0764 - acc: 0.7921 - f1score: 0.7920 - val_loss: 1.9841 - val_acc: 0.7876 - val_f1score: 0.7842\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.0764 - acc: 0.7921 - f1score: 0.7920 - val_loss: 1.9841 - val_acc: 0.7876 - val_f1score: 0.7842\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.7512 - acc: 0.7539 - f1score: 0.7539\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.7485 - acc: 0.7524 - f1score: 0.7519 - val_loss: 1.3321 - val_acc: 0.7876 - val_f1score: 0.7867\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.7485 - acc: 0.7524 - f1score: 0.7519 - val_loss: 1.3321 - val_acc: 0.7876 - val_f1score: 0.7867\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.4502 - acc: 0.7533 - f1score: 0.7533\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.4644 - acc: 0.7524 - f1score: 0.7521 - val_loss: 1.0638 - val_acc: 0.7876 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.4644 - acc: 0.7524 - f1score: 0.7521 - val_loss: 1.0638 - val_acc: 0.7876 - val_f1score: 0.7917\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.1975 - acc: 0.7288 - f1score: 0.7288\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.1714 - acc: 0.7344 - f1score: 0.7360 - val_loss: 0.8631 - val_acc: 0.7994 - val_f1score: 0.8074\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.1714 - acc: 0.7344 - f1score: 0.7360 - val_loss: 0.8631 - val_acc: 0.7994 - val_f1score: 0.8074\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.9675 - acc: 0.7550 - f1score: 0.7550\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.9448 - acc: 0.7608 - f1score: 0.7625 - val_loss: 0.5963 - val_acc: 0.7994 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.9448 - acc: 0.7608 - f1score: 0.7625 - val_loss: 0.5963 - val_acc: 0.7994 - val_f1score: 0.8024\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6589 - acc: 0.7623 - f1score: 0.7623\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6609 - acc: 0.7571 - f1score: 0.7557 - val_loss: 0.5291 - val_acc: 0.7693 - val_f1score: 0.7751\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6609 - acc: 0.7571 - f1score: 0.7557 - val_loss: 0.5291 - val_acc: 0.7693 - val_f1score: 0.7751\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5799 - acc: 0.7651 - f1score: 0.7651\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5811 - acc: 0.7651 - f1score: 0.7651 - val_loss: 0.5187 - val_acc: 0.7725 - val_f1score: 0.7805\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5811 - acc: 0.7651 - f1score: 0.7651 - val_loss: 0.5187 - val_acc: 0.7725 - val_f1score: 0.7805\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5282 - acc: 0.7751 - f1score: 0.7751\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5207 - acc: 0.7799 - f1score: 0.7813 - val_loss: 0.5137 - val_acc: 0.7876 - val_f1score: 0.7792\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5207 - acc: 0.7799 - f1score: 0.7813 - val_loss: 0.5137 - val_acc: 0.7876 - val_f1score: 0.7792\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5188 - acc: 0.7846 - f1score: 0.7846\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5147 - acc: 0.7873 - f1score: 0.7881 - val_loss: 0.4993 - val_acc: 0.7886 - val_f1score: 0.7852\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5147 - acc: 0.7873 - f1score: 0.7881 - val_loss: 0.4993 - val_acc: 0.7886 - val_f1score: 0.7852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 27%|██▋       | 26/96 [1:50:32<4:05:33, 210.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.9154 - acc: 0.5670 - f1score: 0.5670\n",
            "Epoch 00001: val_acc improved from -inf to 0.77790, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.72.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.9032 - acc: 0.5730 - f1score: 0.5747 - val_loss: 2.7196 - val_acc: 0.7779 - val_f1score: 0.7829\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77790, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.72.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.9032 - acc: 0.5730 - f1score: 0.5747 - val_loss: 2.7196 - val_acc: 0.7779 - val_f1score: 0.7829\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.2689 - acc: 0.7807 - f1score: 0.7807\n",
            "Epoch 00002: val_acc improved from 0.77790 to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.45.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2577 - acc: 0.7836 - f1score: 0.7844 - val_loss: 2.4507 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.77790 to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.45.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2577 - acc: 0.7836 - f1score: 0.7844 - val_loss: 2.4507 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.2561 - acc: 0.8030 - f1score: 0.8030\n",
            "Epoch 00003: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2036 - acc: 0.8058 - f1score: 0.8066 - val_loss: 2.4219 - val_acc: 0.7929 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2036 - acc: 0.8058 - f1score: 0.8066 - val_loss: 2.4219 - val_acc: 0.7929 - val_f1score: 0.7990\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.2221 - acc: 0.8064 - f1score: 0.8064\n",
            "Epoch 00004: val_acc improved from 0.79399 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.38.h5\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.79399 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.38.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1645 - acc: 0.8111 - f1score: 0.8125 - val_loss: 2.3827 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1645 - acc: 0.8111 - f1score: 0.8125 - val_loss: 2.3827 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.2019 - acc: 0.8086 - f1score: 0.8086\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1968 - acc: 0.8085 - f1score: 0.8084 - val_loss: 2.3625 - val_acc: 0.8004 - val_f1score: 0.8134\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1968 - acc: 0.8085 - f1score: 0.8084 - val_loss: 2.3625 - val_acc: 0.8004 - val_f1score: 0.8134\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.0941 - acc: 0.8092 - f1score: 0.8092\n",
            "Epoch 00006: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.06-2.31.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.0686 - acc: 0.8085 - f1score: 0.8083 - val_loss: 2.3068 - val_acc: 0.8026 - val_f1score: 0.7954\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.06-2.31.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.0686 - acc: 0.8085 - f1score: 0.8083 - val_loss: 2.3068 - val_acc: 0.8026 - val_f1score: 0.7954\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.9978 - acc: 0.7946 - f1score: 0.7946\n",
            "Epoch 00007: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.07-2.15.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.9706 - acc: 0.7989 - f1score: 0.8002 - val_loss: 2.1495 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.07-2.15.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.9706 - acc: 0.7989 - f1score: 0.8002 - val_loss: 2.1495 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.7722 - acc: 0.7891 - f1score: 0.7891\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.7768 - acc: 0.7847 - f1score: 0.7834 - val_loss: 1.8588 - val_acc: 0.7994 - val_f1score: 0.7999\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.7768 - acc: 0.7847 - f1score: 0.7834 - val_loss: 1.8588 - val_acc: 0.7994 - val_f1score: 0.7999\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.6727 - acc: 0.7667 - f1score: 0.7667\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.6489 - acc: 0.7667 - f1score: 0.7666 - val_loss: 1.6238 - val_acc: 0.7876 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.6489 - acc: 0.7667 - f1score: 0.7666 - val_loss: 1.6238 - val_acc: 0.7876 - val_f1score: 0.7917\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.3452 - acc: 0.7533 - f1score: 0.7533\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.3336 - acc: 0.7497 - f1score: 0.7487 - val_loss: 1.2050 - val_acc: 0.7554 - val_f1score: 0.7599\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.3336 - acc: 0.7497 - f1score: 0.7487 - val_loss: 1.2050 - val_acc: 0.7554 - val_f1score: 0.7599\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.0310 - acc: 0.7277 - f1score: 0.7277\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.0127 - acc: 0.7307 - f1score: 0.7315 - val_loss: 0.8038 - val_acc: 0.7876 - val_f1score: 0.7867\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.0127 - acc: 0.7307 - f1score: 0.7315 - val_loss: 0.8038 - val_acc: 0.7876 - val_f1score: 0.7867\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6624 - acc: 0.7338 - f1score: 0.7338\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6552 - acc: 0.7354 - f1score: 0.7359 - val_loss: 0.5351 - val_acc: 0.8026 - val_f1score: 0.7979\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6552 - acc: 0.7354 - f1score: 0.7359 - val_loss: 0.5351 - val_acc: 0.8026 - val_f1score: 0.7979\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5341 - acc: 0.8069 - f1score: 0.8069\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5318 - acc: 0.8079 - f1score: 0.8082 - val_loss: 0.5503 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5318 - acc: 0.8079 - f1score: 0.8082 - val_loss: 0.5503 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5147 - acc: 0.8019 - f1score: 0.8019\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5061 - acc: 0.8053 - f1score: 0.8063 - val_loss: 0.4837 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5061 - acc: 0.8053 - f1score: 0.8063 - val_loss: 0.4837 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4947 - acc: 0.7991 - f1score: 0.7991\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4919 - acc: 0.8005 - f1score: 0.8009 - val_loss: 0.4901 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4919 - acc: 0.8005 - f1score: 0.8009 - val_loss: 0.4901 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4781 - acc: 0.8008 - f1score: 0.8008\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4803 - acc: 0.8005 - f1score: 0.8005 - val_loss: 0.4942 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4803 - acc: 0.8005 - f1score: 0.8005 - val_loss: 0.4942 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4697 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4725 - acc: 0.8127 - f1score: 0.8116 - val_loss: 0.4912 - val_acc: 0.7994 - val_f1score: 0.8099\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4725 - acc: 0.8127 - f1score: 0.8116 - val_loss: 0.4912 - val_acc: 0.7994 - val_f1score: 0.8099\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4727 - acc: 0.8047 - f1score: 0.8047\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4726 - acc: 0.8053 - f1score: 0.8055 - val_loss: 0.4807 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4726 - acc: 0.8053 - f1score: 0.8055 - val_loss: 0.4807 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4665 - acc: 0.8080 - f1score: 0.8080\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4666 - acc: 0.8085 - f1score: 0.8086 - val_loss: 0.4809 - val_acc: 0.7972 - val_f1score: 0.7930\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4666 - acc: 0.8085 - f1score: 0.8086 - val_loss: 0.4809 - val_acc: 0.7972 - val_f1score: 0.7930\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4647 - acc: 0.8047 - f1score: 0.8047\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4623 - acc: 0.8085 - f1score: 0.8095 - val_loss: 0.4781 - val_acc: 0.7908 - val_f1score: 0.7821\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4623 - acc: 0.8085 - f1score: 0.8095 - val_loss: 0.4781 - val_acc: 0.7908 - val_f1score: 0.7821\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4600 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4612 - acc: 0.8122 - f1score: 0.8121 - val_loss: 0.4835 - val_acc: 0.7897 - val_f1score: 0.7886\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4612 - acc: 0.8122 - f1score: 0.8121 - val_loss: 0.4835 - val_acc: 0.7897 - val_f1score: 0.7886\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4657 - acc: 0.8058 - f1score: 0.8058\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4640 - acc: 0.8079 - f1score: 0.8085 - val_loss: 0.4776 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4640 - acc: 0.8079 - f1score: 0.8085 - val_loss: 0.4776 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4554 - acc: 0.8198 - f1score: 0.8198\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4546 - acc: 0.8196 - f1score: 0.8195 - val_loss: 0.4757 - val_acc: 0.7961 - val_f1score: 0.7945\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4546 - acc: 0.8196 - f1score: 0.8195 - val_loss: 0.4757 - val_acc: 0.7961 - val_f1score: 0.7945\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4481 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4513 - acc: 0.8111 - f1score: 0.8104 - val_loss: 0.4741 - val_acc: 0.8015 - val_f1score: 0.8094\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4513 - acc: 0.8111 - f1score: 0.8104 - val_loss: 0.4741 - val_acc: 0.8015 - val_f1score: 0.8094\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4589 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4598 - acc: 0.8159 - f1score: 0.8162 - val_loss: 0.4802 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4598 - acc: 0.8159 - f1score: 0.8162 - val_loss: 0.4802 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4680 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4689 - acc: 0.8148 - f1score: 0.8152 - val_loss: 0.4882 - val_acc: 0.7897 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4689 - acc: 0.8148 - f1score: 0.8152 - val_loss: 0.4882 - val_acc: 0.7897 - val_f1score: 0.7936\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4639 - acc: 0.8186 - f1score: 0.8186\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4652 - acc: 0.8190 - f1score: 0.8192 - val_loss: 0.4945 - val_acc: 0.7811 - val_f1score: 0.7758\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4652 - acc: 0.8190 - f1score: 0.8192 - val_loss: 0.4945 - val_acc: 0.7811 - val_f1score: 0.7758\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4538 - acc: 0.8259 - f1score: 0.8259\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4648 - acc: 0.8185 - f1score: 0.8164 - val_loss: 0.4903 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4648 - acc: 0.8185 - f1score: 0.8164 - val_loss: 0.4903 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4625 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4592 - acc: 0.8190 - f1score: 0.8196 - val_loss: 0.4744 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4592 - acc: 0.8190 - f1score: 0.8196 - val_loss: 0.4744 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4619 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4615 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4767 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4615 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4767 - val_acc: 0.7940 - val_f1score: 0.7900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 28%|██▊       | 27/96 [1:53:12<3:44:33, 195.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.2613 - acc: 0.7165 - f1score: 0.7165\n",
            "Epoch 00001: val_acc improved from -inf to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.58.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.2054 - acc: 0.7222 - f1score: 0.7239 - val_loss: 1.5812 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.58.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.2054 - acc: 0.7222 - f1score: 0.7239 - val_loss: 1.5812 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.3921 - acc: 0.7121 - f1score: 0.7121\n",
            "Epoch 00002: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.3902 - acc: 0.7106 - f1score: 0.7102 - val_loss: 0.7884 - val_acc: 0.7446 - val_f1score: 0.7451\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.3902 - acc: 0.7106 - f1score: 0.7102 - val_loss: 0.7884 - val_acc: 0.7446 - val_f1score: 0.7451\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.9759 - acc: 0.7243 - f1score: 0.7243\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.9761 - acc: 0.7233 - f1score: 0.7230 - val_loss: 0.5958 - val_acc: 0.7318 - val_f1score: 0.7284\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.9761 - acc: 0.7233 - f1score: 0.7230 - val_loss: 0.5958 - val_acc: 0.7318 - val_f1score: 0.7284\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.7297 - acc: 0.7483 - f1score: 0.7483\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.7259 - acc: 0.7455 - f1score: 0.7447 - val_loss: 0.5565 - val_acc: 0.7167 - val_f1score: 0.7197\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.7259 - acc: 0.7455 - f1score: 0.7447 - val_loss: 0.5565 - val_acc: 0.7167 - val_f1score: 0.7197\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6071 - acc: 0.7517 - f1score: 0.7517\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5981 - acc: 0.7556 - f1score: 0.7567 - val_loss: 0.5206 - val_acc: 0.7929 - val_f1score: 0.8015\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5981 - acc: 0.7556 - f1score: 0.7567 - val_loss: 0.5206 - val_acc: 0.7929 - val_f1score: 0.8015\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5039 - acc: 0.8108 - f1score: 0.8108\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5087 - acc: 0.8058 - f1score: 0.8044 - val_loss: 0.5406 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5087 - acc: 0.8058 - f1score: 0.8044 - val_loss: 0.5406 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4929 - acc: 0.8203 - f1score: 0.8203\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4936 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.5146 - val_acc: 0.7833 - val_f1score: 0.7878\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4936 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.5146 - val_acc: 0.7833 - val_f1score: 0.7878\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4746 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4727 - acc: 0.8201 - f1score: 0.8208 - val_loss: 0.5004 - val_acc: 0.7833 - val_f1score: 0.7828\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4727 - acc: 0.8201 - f1score: 0.8208 - val_loss: 0.5004 - val_acc: 0.7833 - val_f1score: 0.7828\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4612 - acc: 0.8198 - f1score: 0.8198\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4607 - acc: 0.8212 - f1score: 0.8216 - val_loss: 0.4904 - val_acc: 0.7811 - val_f1score: 0.7833\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4607 - acc: 0.8212 - f1score: 0.8216 - val_loss: 0.4904 - val_acc: 0.7811 - val_f1score: 0.7833\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4605 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4589 - acc: 0.8180 - f1score: 0.8188 - val_loss: 0.4886 - val_acc: 0.7886 - val_f1score: 0.7827\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4589 - acc: 0.8180 - f1score: 0.8188 - val_loss: 0.4886 - val_acc: 0.7886 - val_f1score: 0.7827\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4546 - acc: 0.8198 - f1score: 0.8198\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4590 - acc: 0.8180 - f1score: 0.8175 - val_loss: 0.4850 - val_acc: 0.7886 - val_f1score: 0.7827\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4590 - acc: 0.8180 - f1score: 0.8175 - val_loss: 0.4850 - val_acc: 0.7886 - val_f1score: 0.7827\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4507 - acc: 0.8209 - f1score: 0.8209\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4537 - acc: 0.8201 - f1score: 0.8199 - val_loss: 0.4865 - val_acc: 0.7843 - val_f1score: 0.7862\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4537 - acc: 0.8201 - f1score: 0.8199 - val_loss: 0.4865 - val_acc: 0.7843 - val_f1score: 0.7862\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4528 - acc: 0.8265 - f1score: 0.8265\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4570 - acc: 0.8228 - f1score: 0.8217 - val_loss: 0.4855 - val_acc: 0.7908 - val_f1score: 0.7946\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4570 - acc: 0.8228 - f1score: 0.8217 - val_loss: 0.4855 - val_acc: 0.7908 - val_f1score: 0.7946\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4566 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4561 - acc: 0.8180 - f1score: 0.8186 - val_loss: 0.4841 - val_acc: 0.7854 - val_f1score: 0.7722\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4561 - acc: 0.8180 - f1score: 0.8186 - val_loss: 0.4841 - val_acc: 0.7854 - val_f1score: 0.7722\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4589 - acc: 0.8203 - f1score: 0.8203\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4566 - acc: 0.8212 - f1score: 0.8214 - val_loss: 0.4824 - val_acc: 0.7929 - val_f1score: 0.7866\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4566 - acc: 0.8212 - f1score: 0.8214 - val_loss: 0.4824 - val_acc: 0.7929 - val_f1score: 0.7866\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4590 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4605 - acc: 0.8153 - f1score: 0.8154 - val_loss: 0.4877 - val_acc: 0.7843 - val_f1score: 0.7763\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4605 - acc: 0.8153 - f1score: 0.8154 - val_loss: 0.4877 - val_acc: 0.7843 - val_f1score: 0.7763\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4647 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4639 - acc: 0.8180 - f1score: 0.8184 - val_loss: 0.4826 - val_acc: 0.7908 - val_f1score: 0.7821\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4639 - acc: 0.8180 - f1score: 0.8184 - val_loss: 0.4826 - val_acc: 0.7908 - val_f1score: 0.7821\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4564 - acc: 0.8181 - f1score: 0.8181\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4538 - acc: 0.8212 - f1score: 0.8220 - val_loss: 0.4798 - val_acc: 0.7908 - val_f1score: 0.7871\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4538 - acc: 0.8212 - f1score: 0.8220 - val_loss: 0.4798 - val_acc: 0.7908 - val_f1score: 0.7871\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4518 - acc: 0.8270 - f1score: 0.8270\n",
            "Epoch 00019: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.19-0.49.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4547 - acc: 0.8233 - f1score: 0.8222 - val_loss: 0.4907 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.19-0.49.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4547 - acc: 0.8233 - f1score: 0.8222 - val_loss: 0.4907 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4495 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00020: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4528 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4792 - val_acc: 0.7929 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4528 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4792 - val_acc: 0.7929 - val_f1score: 0.7990\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4559 - acc: 0.8192 - f1score: 0.8192\n",
            "Epoch 00021: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4539 - acc: 0.8201 - f1score: 0.8204 - val_loss: 0.4812 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4539 - acc: 0.8201 - f1score: 0.8204 - val_loss: 0.4812 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4534 - acc: 0.8181 - f1score: 0.8181\n",
            "Epoch 00022: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4492 - acc: 0.8196 - f1score: 0.8200 - val_loss: 0.4849 - val_acc: 0.7908 - val_f1score: 0.7946\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4492 - acc: 0.8196 - f1score: 0.8200 - val_loss: 0.4849 - val_acc: 0.7908 - val_f1score: 0.7946\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4513 - acc: 0.8214 - f1score: 0.8214\n",
            "Epoch 00023: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4531 - acc: 0.8190 - f1score: 0.8184 - val_loss: 0.4808 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4531 - acc: 0.8190 - f1score: 0.8184 - val_loss: 0.4808 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4596 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00024: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4571 - acc: 0.8159 - f1score: 0.8168 - val_loss: 0.4786 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4571 - acc: 0.8159 - f1score: 0.8168 - val_loss: 0.4786 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4637 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00025: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4632 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4818 - val_acc: 0.7843 - val_f1score: 0.7812\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4632 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4818 - val_acc: 0.7843 - val_f1score: 0.7812\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4627 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00026: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4592 - acc: 0.8201 - f1score: 0.8208 - val_loss: 0.4787 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4592 - acc: 0.8201 - f1score: 0.8208 - val_loss: 0.4787 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4409 - acc: 0.8276 - f1score: 0.8276\n",
            "Epoch 00027: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4460 - acc: 0.8243 - f1score: 0.8234 - val_loss: 0.4814 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4460 - acc: 0.8243 - f1score: 0.8234 - val_loss: 0.4814 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4500 - acc: 0.8220 - f1score: 0.8220\n",
            "Epoch 00028: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4552 - acc: 0.8175 - f1score: 0.8162 - val_loss: 0.4793 - val_acc: 0.7854 - val_f1score: 0.7772\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4552 - acc: 0.8175 - f1score: 0.8162 - val_loss: 0.4793 - val_acc: 0.7854 - val_f1score: 0.7772\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4489 - acc: 0.8225 - f1score: 0.8225\n",
            "Epoch 00029: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4518 - acc: 0.8212 - f1score: 0.8208 - val_loss: 0.5013 - val_acc: 0.7908 - val_f1score: 0.7996\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4518 - acc: 0.8212 - f1score: 0.8208 - val_loss: 0.5013 - val_acc: 0.7908 - val_f1score: 0.7996\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4524 - acc: 0.8259 - f1score: 0.8259\n",
            "Epoch 00030: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4557 - acc: 0.8217 - f1score: 0.8205 - val_loss: 0.4787 - val_acc: 0.7865 - val_f1score: 0.7857\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4557 - acc: 0.8217 - f1score: 0.8205 - val_loss: 0.4787 - val_acc: 0.7865 - val_f1score: 0.7857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 29%|██▉       | 28/96 [1:56:50<3:49:13, 202.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 4.0650 - acc: 0.5592 - f1score: 0.5592\n",
            "Epoch 00001: val_acc improved from -inf to 0.57082, saving model to /content/drive/My Drive/LSTM_Model/model.01-3.68.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 4.0256 - acc: 0.5614 - f1score: 0.5620 - val_loss: 3.6817 - val_acc: 0.5708 - val_f1score: 0.5645\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.57082, saving model to /content/drive/My Drive/LSTM_Model/model.01-3.68.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 4.0256 - acc: 0.5614 - f1score: 0.5620 - val_loss: 3.6817 - val_acc: 0.5708 - val_f1score: 0.5645\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.5711 - acc: 0.7634 - f1score: 0.7634\n",
            "Epoch 00002: val_acc improved from 0.57082 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.43.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.4964 - acc: 0.7693 - f1score: 0.7710 - val_loss: 2.4321 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.57082 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.43.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.4964 - acc: 0.7693 - f1score: 0.7710 - val_loss: 2.4321 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.3161 - acc: 0.8036 - f1score: 0.8036\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2683 - acc: 0.8074 - f1score: 0.8085 - val_loss: 2.4518 - val_acc: 0.7886 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2683 - acc: 0.8074 - f1score: 0.8085 - val_loss: 2.4518 - val_acc: 0.7886 - val_f1score: 0.7951\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1944 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00004: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.38.h5\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.38.h5\n",
            "1890/1890 [==============================] - 6s 3ms/sample - loss: 2.2053 - acc: 0.8169 - f1score: 0.8171 - val_loss: 2.3844 - val_acc: 0.8026 - val_f1score: 0.8128\n",
            "1890/1890 [==============================] - 6s 3ms/sample - loss: 2.2053 - acc: 0.8169 - f1score: 0.8171 - val_loss: 2.3844 - val_acc: 0.8026 - val_f1score: 0.8128\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1317 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00005: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1378 - acc: 0.8127 - f1score: 0.8124 - val_loss: 2.3097 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1378 - acc: 0.8127 - f1score: 0.8124 - val_loss: 2.3097 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.9537 - acc: 0.8025 - f1score: 0.8025\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.9617 - acc: 0.7989 - f1score: 0.7979 - val_loss: 1.8559 - val_acc: 0.7983 - val_f1score: 0.7989\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.9617 - acc: 0.7989 - f1score: 0.7979 - val_loss: 1.8559 - val_acc: 0.7983 - val_f1score: 0.7989\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.6262 - acc: 0.7662 - f1score: 0.7662\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.6308 - acc: 0.7656 - f1score: 0.7654 - val_loss: 1.6026 - val_acc: 0.7918 - val_f1score: 0.7806\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.6308 - acc: 0.7656 - f1score: 0.7654 - val_loss: 1.6026 - val_acc: 0.7918 - val_f1score: 0.7806\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.2442 - acc: 0.7556 - f1score: 0.7556\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.2383 - acc: 0.7545 - f1score: 0.7542 - val_loss: 0.9044 - val_acc: 0.7457 - val_f1score: 0.7436\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.2383 - acc: 0.7545 - f1score: 0.7542 - val_loss: 0.9044 - val_acc: 0.7457 - val_f1score: 0.7436\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.8134 - acc: 0.7383 - f1score: 0.7383\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.8064 - acc: 0.7429 - f1score: 0.7442 - val_loss: 0.7960 - val_acc: 0.7929 - val_f1score: 0.8015\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.8064 - acc: 0.7429 - f1score: 0.7442 - val_loss: 0.7960 - val_acc: 0.7929 - val_f1score: 0.8015\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5825 - acc: 0.7773 - f1score: 0.7773\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5744 - acc: 0.7794 - f1score: 0.7799 - val_loss: 0.5120 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5744 - acc: 0.7794 - f1score: 0.7799 - val_loss: 0.5120 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4766 - acc: 0.7740 - f1score: 0.7740\n",
            "Epoch 00011: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4777 - acc: 0.7709 - f1score: 0.7700 - val_loss: 0.5088 - val_acc: 0.8026 - val_f1score: 0.8053\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4777 - acc: 0.7709 - f1score: 0.7700 - val_loss: 0.5088 - val_acc: 0.8026 - val_f1score: 0.8053\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4668 - acc: 0.7846 - f1score: 0.7846\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4718 - acc: 0.7804 - f1score: 0.7792 - val_loss: 0.5000 - val_acc: 0.7994 - val_f1score: 0.8074\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4718 - acc: 0.7804 - f1score: 0.7792 - val_loss: 0.5000 - val_acc: 0.7994 - val_f1score: 0.8074\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4596 - acc: 0.7863 - f1score: 0.7863\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4653 - acc: 0.7857 - f1score: 0.7856 - val_loss: 0.4986 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4653 - acc: 0.7857 - f1score: 0.7856 - val_loss: 0.4986 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4689 - acc: 0.7857 - f1score: 0.7857\n",
            "Epoch 00014: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4662 - acc: 0.7873 - f1score: 0.7878 - val_loss: 0.4978 - val_acc: 0.7994 - val_f1score: 0.7924\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4662 - acc: 0.7873 - f1score: 0.7878 - val_loss: 0.4978 - val_acc: 0.7994 - val_f1score: 0.7924\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4586 - acc: 0.7829 - f1score: 0.7829\n",
            "Epoch 00015: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4667 - acc: 0.7767 - f1score: 0.7749 - val_loss: 0.4965 - val_acc: 0.7994 - val_f1score: 0.7999\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4667 - acc: 0.7767 - f1score: 0.7749 - val_loss: 0.4965 - val_acc: 0.7994 - val_f1score: 0.7999\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4634 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00016: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4650 - acc: 0.8169 - f1score: 0.8172 - val_loss: 0.4945 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4650 - acc: 0.8169 - f1score: 0.8172 - val_loss: 0.4945 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4640 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00017: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4660 - acc: 0.8164 - f1score: 0.8162 - val_loss: 0.4929 - val_acc: 0.7994 - val_f1score: 0.7949\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4660 - acc: 0.8164 - f1score: 0.8162 - val_loss: 0.4929 - val_acc: 0.7994 - val_f1score: 0.7949\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4581 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00018: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4617 - acc: 0.8138 - f1score: 0.8130 - val_loss: 0.4910 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4617 - acc: 0.8138 - f1score: 0.8130 - val_loss: 0.4910 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4509 - acc: 0.8209 - f1score: 0.8209\n",
            "Epoch 00019: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4570 - acc: 0.8180 - f1score: 0.8172 - val_loss: 0.4914 - val_acc: 0.7929 - val_f1score: 0.7965\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4570 - acc: 0.8180 - f1score: 0.8172 - val_loss: 0.4914 - val_acc: 0.7929 - val_f1score: 0.7965\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4605 - acc: 0.8198 - f1score: 0.8198\n",
            "Epoch 00020: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4611 - acc: 0.8185 - f1score: 0.8182 - val_loss: 0.4876 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4611 - acc: 0.8185 - f1score: 0.8182 - val_loss: 0.4876 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4552 - acc: 0.8198 - f1score: 0.8198\n",
            "Epoch 00021: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4537 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4851 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4537 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4851 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4567 - acc: 0.8192 - f1score: 0.8192\n",
            "Epoch 00022: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4587 - acc: 0.8175 - f1score: 0.8170 - val_loss: 0.4840 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4587 - acc: 0.8175 - f1score: 0.8170 - val_loss: 0.4840 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4603 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00023: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4562 - acc: 0.8169 - f1score: 0.8176 - val_loss: 0.4833 - val_acc: 0.8015 - val_f1score: 0.7944\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4562 - acc: 0.8169 - f1score: 0.8176 - val_loss: 0.4833 - val_acc: 0.8015 - val_f1score: 0.7944\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4563 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00024: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4592 - acc: 0.8159 - f1score: 0.8154 - val_loss: 0.4827 - val_acc: 0.7929 - val_f1score: 0.7866\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4592 - acc: 0.8159 - f1score: 0.8154 - val_loss: 0.4827 - val_acc: 0.7929 - val_f1score: 0.7866\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4485 - acc: 0.8186 - f1score: 0.8186\n",
            "Epoch 00025: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4484 - acc: 0.8196 - f1score: 0.8198 - val_loss: 0.4818 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4484 - acc: 0.8196 - f1score: 0.8198 - val_loss: 0.4818 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4613 - acc: 0.8181 - f1score: 0.8181\n",
            "Epoch 00026: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4566 - acc: 0.8206 - f1score: 0.8214 - val_loss: 0.4814 - val_acc: 0.7940 - val_f1score: 0.7801\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4566 - acc: 0.8206 - f1score: 0.8214 - val_loss: 0.4814 - val_acc: 0.7940 - val_f1score: 0.7801\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4626 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00027: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4611 - acc: 0.8169 - f1score: 0.8169 - val_loss: 0.4808 - val_acc: 0.7940 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4611 - acc: 0.8169 - f1score: 0.8169 - val_loss: 0.4808 - val_acc: 0.7940 - val_f1score: 0.8000\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4576 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00028: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4536 - acc: 0.8159 - f1score: 0.8167 - val_loss: 0.4798 - val_acc: 0.7918 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4536 - acc: 0.8159 - f1score: 0.8167 - val_loss: 0.4798 - val_acc: 0.7918 - val_f1score: 0.8006\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4511 - acc: 0.8198 - f1score: 0.8198\n",
            "Epoch 00029: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4548 - acc: 0.8175 - f1score: 0.8168 - val_loss: 0.4803 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4548 - acc: 0.8175 - f1score: 0.8168 - val_loss: 0.4803 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4589 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00030: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4650 - acc: 0.8085 - f1score: 0.8076 - val_loss: 0.4793 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4650 - acc: 0.8085 - f1score: 0.8076 - val_loss: 0.4793 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4524 - acc: 0.8192 - f1score: 0.8192\n",
            "Epoch 00031: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4516 - acc: 0.8196 - f1score: 0.8197 - val_loss: 0.4794 - val_acc: 0.8004 - val_f1score: 0.8109\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4516 - acc: 0.8196 - f1score: 0.8197 - val_loss: 0.4794 - val_acc: 0.8004 - val_f1score: 0.8109\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4556 - acc: 0.8209 - f1score: 0.8209\n",
            "Epoch 00032: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4599 - acc: 0.8153 - f1score: 0.8138 - val_loss: 0.4781 - val_acc: 0.7918 - val_f1score: 0.7881\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4599 - acc: 0.8153 - f1score: 0.8138 - val_loss: 0.4781 - val_acc: 0.7918 - val_f1score: 0.7881\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4481 - acc: 0.8181 - f1score: 0.8181\n",
            "Epoch 00033: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4563 - acc: 0.8127 - f1score: 0.8112 - val_loss: 0.4787 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4563 - acc: 0.8127 - f1score: 0.8112 - val_loss: 0.4787 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4503 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00034: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4536 - acc: 0.8159 - f1score: 0.8156 - val_loss: 0.4779 - val_acc: 0.7918 - val_f1score: 0.7881\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4536 - acc: 0.8159 - f1score: 0.8156 - val_loss: 0.4779 - val_acc: 0.7918 - val_f1score: 0.7881\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4599 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00035: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4596 - acc: 0.8143 - f1score: 0.8146 - val_loss: 0.4782 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4596 - acc: 0.8143 - f1score: 0.8146 - val_loss: 0.4782 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4554 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00036: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4579 - acc: 0.8153 - f1score: 0.8147 - val_loss: 0.4758 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4579 - acc: 0.8153 - f1score: 0.8147 - val_loss: 0.4758 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4512 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00037: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4533 - acc: 0.8169 - f1score: 0.8168 - val_loss: 0.4769 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4533 - acc: 0.8169 - f1score: 0.8168 - val_loss: 0.4769 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4538 - acc: 0.8181 - f1score: 0.8181\n",
            "Epoch 00038: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4524 - acc: 0.8180 - f1score: 0.8180 - val_loss: 0.4756 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4524 - acc: 0.8180 - f1score: 0.8180 - val_loss: 0.4756 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4539 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00039: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4485 - acc: 0.8190 - f1score: 0.8203 - val_loss: 0.4752 - val_acc: 0.7983 - val_f1score: 0.8139\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4485 - acc: 0.8190 - f1score: 0.8203 - val_loss: 0.4752 - val_acc: 0.7983 - val_f1score: 0.8139\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4449 - acc: 0.8186 - f1score: 0.8186\n",
            "Epoch 00040: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4462 - acc: 0.8190 - f1score: 0.8192 - val_loss: 0.4765 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4462 - acc: 0.8190 - f1score: 0.8192 - val_loss: 0.4765 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4528 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00041: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4526 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4762 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4526 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4762 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4495 - acc: 0.8186 - f1score: 0.8186\n",
            "Epoch 00042: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4455 - acc: 0.8196 - f1score: 0.8198 - val_loss: 0.4748 - val_acc: 0.7929 - val_f1score: 0.7891\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4455 - acc: 0.8196 - f1score: 0.8198 - val_loss: 0.4748 - val_acc: 0.7929 - val_f1score: 0.7891\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4515 - acc: 0.8203 - f1score: 0.8203\n",
            "Epoch 00043: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4497 - acc: 0.8206 - f1score: 0.8207 - val_loss: 0.4752 - val_acc: 0.7951 - val_f1score: 0.8010\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4497 - acc: 0.8206 - f1score: 0.8207 - val_loss: 0.4752 - val_acc: 0.7951 - val_f1score: 0.8010\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4520 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00044: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4528 - acc: 0.8159 - f1score: 0.8156 - val_loss: 0.4757 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4528 - acc: 0.8159 - f1score: 0.8156 - val_loss: 0.4757 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4530 - acc: 0.8242 - f1score: 0.8242\n",
            "Epoch 00045: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4541 - acc: 0.8228 - f1score: 0.8223 - val_loss: 0.4753 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4541 - acc: 0.8228 - f1score: 0.8223 - val_loss: 0.4753 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4522 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00046: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4507 - acc: 0.8169 - f1score: 0.8176 - val_loss: 0.4737 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4507 - acc: 0.8169 - f1score: 0.8176 - val_loss: 0.4737 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4433 - acc: 0.8214 - f1score: 0.8214\n",
            "Epoch 00047: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4471 - acc: 0.8196 - f1score: 0.8190 - val_loss: 0.4738 - val_acc: 0.7940 - val_f1score: 0.8050\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4471 - acc: 0.8196 - f1score: 0.8190 - val_loss: 0.4738 - val_acc: 0.7940 - val_f1score: 0.8050\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4471 - acc: 0.8192 - f1score: 0.8192\n",
            "Epoch 00048: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4451 - acc: 0.8190 - f1score: 0.8190 - val_loss: 0.4748 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4451 - acc: 0.8190 - f1score: 0.8190 - val_loss: 0.4748 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4502 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00049: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4478 - acc: 0.8153 - f1score: 0.8158 - val_loss: 0.4748 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4478 - acc: 0.8153 - f1score: 0.8158 - val_loss: 0.4748 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4407 - acc: 0.8209 - f1score: 0.8209\n",
            "Epoch 00050: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4409 - acc: 0.8201 - f1score: 0.8199 - val_loss: 0.4746 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4409 - acc: 0.8201 - f1score: 0.8199 - val_loss: 0.4746 - val_acc: 0.7940 - val_f1score: 0.7925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 30%|███       | 29/96 [2:01:12<4:05:53, 220.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 7.6845 - acc: 0.4526 - f1score: 0.4526\n",
            "Epoch 00001: val_acc improved from -inf to 0.43026, saving model to /content/drive/My Drive/LSTM_Model/model.01-8.39.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 7.6765 - acc: 0.4534 - f1score: 0.4537 - val_loss: 8.3854 - val_acc: 0.4303 - val_f1score: 0.4365\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.43026, saving model to /content/drive/My Drive/LSTM_Model/model.01-8.39.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 7.6765 - acc: 0.4534 - f1score: 0.4537 - val_loss: 8.3854 - val_acc: 0.4303 - val_f1score: 0.4365\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 7.6631 - acc: 0.4464 - f1score: 0.4464\n",
            "Epoch 00002: val_acc did not improve from 0.43026\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 7.6649 - acc: 0.4434 - f1score: 0.4425 - val_loss: 7.3797 - val_acc: 0.4034 - val_f1score: 0.4046\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.43026\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 7.6649 - acc: 0.4434 - f1score: 0.4425 - val_loss: 7.3797 - val_acc: 0.4034 - val_f1score: 0.4046\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 4.0065 - acc: 0.4727 - f1score: 0.4727\n",
            "Epoch 00003: val_acc improved from 0.43026 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.03-1.77.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 3.9360 - acc: 0.4868 - f1score: 0.4908 - val_loss: 1.7700 - val_acc: 0.8004 - val_f1score: 0.8109\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.43026 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.03-1.77.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 3.9360 - acc: 0.4868 - f1score: 0.4908 - val_loss: 1.7700 - val_acc: 0.8004 - val_f1score: 0.8109\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.2785 - acc: 0.7439 - f1score: 0.7439\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.2826 - acc: 0.7376 - f1score: 0.7358 - val_loss: 0.6766 - val_acc: 0.5826 - val_f1score: 0.5752\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.2826 - acc: 0.7376 - f1score: 0.7358 - val_loss: 0.6766 - val_acc: 0.5826 - val_f1score: 0.5752\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.7495 - acc: 0.6953 - f1score: 0.6953\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.7373 - acc: 0.6979 - f1score: 0.6986 - val_loss: 0.5868 - val_acc: 0.7886 - val_f1score: 0.7901\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.7373 - acc: 0.6979 - f1score: 0.6986 - val_loss: 0.5868 - val_acc: 0.7886 - val_f1score: 0.7901\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5816 - acc: 0.7422 - f1score: 0.7422\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5847 - acc: 0.7354 - f1score: 0.7335 - val_loss: 0.5615 - val_acc: 0.7682 - val_f1score: 0.7641\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5847 - acc: 0.7354 - f1score: 0.7335 - val_loss: 0.5615 - val_acc: 0.7682 - val_f1score: 0.7641\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5501 - acc: 0.7539 - f1score: 0.7539\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5519 - acc: 0.7524 - f1score: 0.7519 - val_loss: 0.5419 - val_acc: 0.7865 - val_f1score: 0.7857\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5519 - acc: 0.7524 - f1score: 0.7519 - val_loss: 0.5419 - val_acc: 0.7865 - val_f1score: 0.7857\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5417 - acc: 0.7444 - f1score: 0.7444\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5399 - acc: 0.7444 - f1score: 0.7445 - val_loss: 0.5326 - val_acc: 0.7779 - val_f1score: 0.7829\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5399 - acc: 0.7444 - f1score: 0.7445 - val_loss: 0.5326 - val_acc: 0.7779 - val_f1score: 0.7829\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5291 - acc: 0.7288 - f1score: 0.7288\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5244 - acc: 0.7317 - f1score: 0.7326 - val_loss: 0.5268 - val_acc: 0.7736 - val_f1score: 0.7690\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5244 - acc: 0.7317 - f1score: 0.7326 - val_loss: 0.5268 - val_acc: 0.7736 - val_f1score: 0.7690\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5142 - acc: 0.7500 - f1score: 0.7500\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5134 - acc: 0.7508 - f1score: 0.7510 - val_loss: 0.5220 - val_acc: 0.7758 - val_f1score: 0.7809\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5134 - acc: 0.7508 - f1score: 0.7510 - val_loss: 0.5220 - val_acc: 0.7758 - val_f1score: 0.7809\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5211 - acc: 0.7282 - f1score: 0.7282\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5216 - acc: 0.7259 - f1score: 0.7253 - val_loss: 0.5181 - val_acc: 0.7790 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5216 - acc: 0.7259 - f1score: 0.7253 - val_loss: 0.5181 - val_acc: 0.7790 - val_f1score: 0.7888\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5145 - acc: 0.7455 - f1score: 0.7455\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5141 - acc: 0.7455 - f1score: 0.7455 - val_loss: 0.5157 - val_acc: 0.7811 - val_f1score: 0.7808\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5141 - acc: 0.7455 - f1score: 0.7455 - val_loss: 0.5157 - val_acc: 0.7811 - val_f1score: 0.7808\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5093 - acc: 0.7444 - f1score: 0.7444\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5113 - acc: 0.7423 - f1score: 0.7417 - val_loss: 0.5119 - val_acc: 0.7876 - val_f1score: 0.7692\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5113 - acc: 0.7423 - f1score: 0.7417 - val_loss: 0.5119 - val_acc: 0.7876 - val_f1score: 0.7692\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5157 - acc: 0.7193 - f1score: 0.7193\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5133 - acc: 0.7217 - f1score: 0.7224 - val_loss: 0.5099 - val_acc: 0.7865 - val_f1score: 0.7932\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5133 - acc: 0.7217 - f1score: 0.7224 - val_loss: 0.5099 - val_acc: 0.7865 - val_f1score: 0.7932\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5131 - acc: 0.7433 - f1score: 0.7433\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5125 - acc: 0.7455 - f1score: 0.7461 - val_loss: 0.5068 - val_acc: 0.7897 - val_f1score: 0.7961\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5125 - acc: 0.7455 - f1score: 0.7461 - val_loss: 0.5068 - val_acc: 0.7897 - val_f1score: 0.7961\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5029 - acc: 0.7734 - f1score: 0.7734\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5025 - acc: 0.7735 - f1score: 0.7736 - val_loss: 0.5043 - val_acc: 0.7897 - val_f1score: 0.7886\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5025 - acc: 0.7735 - f1score: 0.7736 - val_loss: 0.5043 - val_acc: 0.7897 - val_f1score: 0.7886\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5019 - acc: 0.7712 - f1score: 0.7712\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4985 - acc: 0.7757 - f1score: 0.7769 - val_loss: 0.5030 - val_acc: 0.7961 - val_f1score: 0.7970\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4985 - acc: 0.7757 - f1score: 0.7769 - val_loss: 0.5030 - val_acc: 0.7961 - val_f1score: 0.7970\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4974 - acc: 0.7863 - f1score: 0.7863\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4949 - acc: 0.7889 - f1score: 0.7896 - val_loss: 0.5003 - val_acc: 0.7972 - val_f1score: 0.7955\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4949 - acc: 0.7889 - f1score: 0.7896 - val_loss: 0.5003 - val_acc: 0.7972 - val_f1score: 0.7955\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4920 - acc: 0.7801 - f1score: 0.7801\n",
            "Epoch 00019: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4893 - acc: 0.7820 - f1score: 0.7825 - val_loss: 0.4979 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4893 - acc: 0.7820 - f1score: 0.7825 - val_loss: 0.4979 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4867 - acc: 0.7868 - f1score: 0.7868\n",
            "Epoch 00020: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4882 - acc: 0.7857 - f1score: 0.7854 - val_loss: 0.4958 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4882 - acc: 0.7857 - f1score: 0.7854 - val_loss: 0.4958 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4916 - acc: 0.7885 - f1score: 0.7885\n",
            "Epoch 00021: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4918 - acc: 0.7889 - f1score: 0.7890 - val_loss: 0.4953 - val_acc: 0.7994 - val_f1score: 0.7999\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4918 - acc: 0.7889 - f1score: 0.7890 - val_loss: 0.4953 - val_acc: 0.7994 - val_f1score: 0.7999\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4924 - acc: 0.7790 - f1score: 0.7790\n",
            "Epoch 00022: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4898 - acc: 0.7820 - f1score: 0.7829 - val_loss: 0.4932 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4898 - acc: 0.7820 - f1score: 0.7829 - val_loss: 0.4932 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4874 - acc: 0.7935 - f1score: 0.7935\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4838 - acc: 0.7963 - f1score: 0.7971 - val_loss: 0.4939 - val_acc: 0.7994 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4838 - acc: 0.7963 - f1score: 0.7971 - val_loss: 0.4939 - val_acc: 0.7994 - val_f1score: 0.8024\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4845 - acc: 0.7807 - f1score: 0.7807\n",
            "Epoch 00024: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.24-0.49.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4819 - acc: 0.7815 - f1score: 0.7817 - val_loss: 0.4892 - val_acc: 0.8015 - val_f1score: 0.7969\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.24-0.49.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4819 - acc: 0.7815 - f1score: 0.7817 - val_loss: 0.4892 - val_acc: 0.8015 - val_f1score: 0.7969\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4930 - acc: 0.7863 - f1score: 0.7863\n",
            "Epoch 00025: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.25-0.49.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4905 - acc: 0.7889 - f1score: 0.7896 - val_loss: 0.4890 - val_acc: 0.8026 - val_f1score: 0.8053\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.25-0.49.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4905 - acc: 0.7889 - f1score: 0.7896 - val_loss: 0.4890 - val_acc: 0.8026 - val_f1score: 0.8053\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4811 - acc: 0.7896 - f1score: 0.7896\n",
            "Epoch 00026: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4880 - acc: 0.7852 - f1score: 0.7839 - val_loss: 0.4883 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4880 - acc: 0.7852 - f1score: 0.7839 - val_loss: 0.4883 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4846 - acc: 0.7857 - f1score: 0.7857\n",
            "Epoch 00027: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4839 - acc: 0.7862 - f1score: 0.7864 - val_loss: 0.4901 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4839 - acc: 0.7862 - f1score: 0.7864 - val_loss: 0.4901 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4764 - acc: 0.7952 - f1score: 0.7952\n",
            "Epoch 00028: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4755 - acc: 0.7947 - f1score: 0.7946 - val_loss: 0.4858 - val_acc: 0.8026 - val_f1score: 0.8003\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4755 - acc: 0.7947 - f1score: 0.7946 - val_loss: 0.4858 - val_acc: 0.8026 - val_f1score: 0.8003\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4769 - acc: 0.7924 - f1score: 0.7924\n",
            "Epoch 00029: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4778 - acc: 0.7931 - f1score: 0.7933 - val_loss: 0.4844 - val_acc: 0.8015 - val_f1score: 0.8069\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4778 - acc: 0.7931 - f1score: 0.7933 - val_loss: 0.4844 - val_acc: 0.8015 - val_f1score: 0.8069\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4709 - acc: 0.7991 - f1score: 0.7991\n",
            "Epoch 00030: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4743 - acc: 0.7963 - f1score: 0.7955 - val_loss: 0.4836 - val_acc: 0.7994 - val_f1score: 0.7999\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4743 - acc: 0.7963 - f1score: 0.7955 - val_loss: 0.4836 - val_acc: 0.7994 - val_f1score: 0.7999\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4654 - acc: 0.7941 - f1score: 0.7941\n",
            "Epoch 00031: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4693 - acc: 0.7910 - f1score: 0.7901 - val_loss: 0.4828 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4693 - acc: 0.7910 - f1score: 0.7901 - val_loss: 0.4828 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4716 - acc: 0.7907 - f1score: 0.7907\n",
            "Epoch 00032: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.32-0.48.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4688 - acc: 0.7947 - f1score: 0.7958 - val_loss: 0.4826 - val_acc: 0.8036 - val_f1score: 0.8113\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.32-0.48.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4688 - acc: 0.7947 - f1score: 0.7958 - val_loss: 0.4826 - val_acc: 0.8036 - val_f1score: 0.8113\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4766 - acc: 0.7868 - f1score: 0.7868\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4768 - acc: 0.7884 - f1score: 0.7888 - val_loss: 0.4833 - val_acc: 0.8036 - val_f1score: 0.7988\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4768 - acc: 0.7884 - f1score: 0.7888 - val_loss: 0.4833 - val_acc: 0.8036 - val_f1score: 0.7988\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4621 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4602 - acc: 0.7989 - f1score: 0.7997 - val_loss: 0.4811 - val_acc: 0.8015 - val_f1score: 0.8069\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4602 - acc: 0.7989 - f1score: 0.7997 - val_loss: 0.4811 - val_acc: 0.8015 - val_f1score: 0.8069\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4742 - acc: 0.7835 - f1score: 0.7835\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4770 - acc: 0.7810 - f1score: 0.7802 - val_loss: 0.4814 - val_acc: 0.8015 - val_f1score: 0.8019\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4770 - acc: 0.7810 - f1score: 0.7802 - val_loss: 0.4814 - val_acc: 0.8015 - val_f1score: 0.8019\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4687 - acc: 0.7935 - f1score: 0.7935\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4691 - acc: 0.7931 - f1score: 0.7930 - val_loss: 0.4802 - val_acc: 0.8015 - val_f1score: 0.8044\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4691 - acc: 0.7931 - f1score: 0.7930 - val_loss: 0.4802 - val_acc: 0.8015 - val_f1score: 0.8044\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4704 - acc: 0.7930 - f1score: 0.7930\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4673 - acc: 0.7947 - f1score: 0.7952 - val_loss: 0.4810 - val_acc: 0.7961 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4673 - acc: 0.7947 - f1score: 0.7952 - val_loss: 0.4810 - val_acc: 0.7961 - val_f1score: 0.7920\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4721 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4704 - acc: 0.7979 - f1score: 0.7982 - val_loss: 0.4807 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4704 - acc: 0.7979 - f1score: 0.7982 - val_loss: 0.4807 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4710 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4686 - acc: 0.7968 - f1score: 0.7970 - val_loss: 0.4792 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4686 - acc: 0.7968 - f1score: 0.7970 - val_loss: 0.4792 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4616 - acc: 0.7958 - f1score: 0.7958\n",
            "Epoch 00040: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.40-0.48.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4666 - acc: 0.7915 - f1score: 0.7903 - val_loss: 0.4785 - val_acc: 0.8047 - val_f1score: 0.8073\n",
            "\n",
            "Epoch 00040: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.40-0.48.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4666 - acc: 0.7915 - f1score: 0.7903 - val_loss: 0.4785 - val_acc: 0.8047 - val_f1score: 0.8073\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4667 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00041: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4684 - acc: 0.7952 - f1score: 0.7949 - val_loss: 0.4799 - val_acc: 0.7929 - val_f1score: 0.7866\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4684 - acc: 0.7952 - f1score: 0.7949 - val_loss: 0.4799 - val_acc: 0.7929 - val_f1score: 0.7866\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4658 - acc: 0.7946 - f1score: 0.7946\n",
            "Epoch 00042: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4621 - acc: 0.7979 - f1score: 0.7988 - val_loss: 0.4794 - val_acc: 0.7961 - val_f1score: 0.7895\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4621 - acc: 0.7979 - f1score: 0.7988 - val_loss: 0.4794 - val_acc: 0.7961 - val_f1score: 0.7895\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4646 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00043: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4658 - acc: 0.7958 - f1score: 0.7955 - val_loss: 0.4797 - val_acc: 0.7929 - val_f1score: 0.7816\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4658 - acc: 0.7958 - f1score: 0.7955 - val_loss: 0.4797 - val_acc: 0.7929 - val_f1score: 0.7816\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4507 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00044: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4530 - acc: 0.8101 - f1score: 0.8097 - val_loss: 0.4813 - val_acc: 0.8015 - val_f1score: 0.8143\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4530 - acc: 0.8101 - f1score: 0.8097 - val_loss: 0.4813 - val_acc: 0.8015 - val_f1score: 0.8143\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4623 - acc: 0.7946 - f1score: 0.7946\n",
            "Epoch 00045: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4658 - acc: 0.7926 - f1score: 0.7920 - val_loss: 0.4798 - val_acc: 0.7961 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4658 - acc: 0.7926 - f1score: 0.7920 - val_loss: 0.4798 - val_acc: 0.7961 - val_f1score: 0.7920\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4584 - acc: 0.8013 - f1score: 0.8013\n",
            "Epoch 00046: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4599 - acc: 0.8021 - f1score: 0.8023 - val_loss: 0.4793 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4599 - acc: 0.8021 - f1score: 0.8023 - val_loss: 0.4793 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4553 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00047: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4557 - acc: 0.7974 - f1score: 0.7975 - val_loss: 0.4776 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4557 - acc: 0.7974 - f1score: 0.7975 - val_loss: 0.4776 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4667 - acc: 0.7997 - f1score: 0.7997\n",
            "Epoch 00048: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4685 - acc: 0.7974 - f1score: 0.7967 - val_loss: 0.4772 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4685 - acc: 0.7974 - f1score: 0.7967 - val_loss: 0.4772 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4634 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00049: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4658 - acc: 0.7952 - f1score: 0.7943 - val_loss: 0.4832 - val_acc: 0.7929 - val_f1score: 0.7866\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4658 - acc: 0.7952 - f1score: 0.7943 - val_loss: 0.4832 - val_acc: 0.7929 - val_f1score: 0.7866\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4700 - acc: 0.7952 - f1score: 0.7952\n",
            "Epoch 00050: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4668 - acc: 0.7947 - f1score: 0.7946 - val_loss: 0.4778 - val_acc: 0.7994 - val_f1score: 0.8049\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4668 - acc: 0.7947 - f1score: 0.7946 - val_loss: 0.4778 - val_acc: 0.7994 - val_f1score: 0.8049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 31%|███▏      | 30/96 [2:07:14<4:48:58, 262.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 6.3610 - acc: 0.4598 - f1score: 0.4598\n",
            "Epoch 00001: val_acc improved from -inf to 0.43240, saving model to /content/drive/My Drive/LSTM_Model/model.01-6.18.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 6.3613 - acc: 0.4561 - f1score: 0.4550 - val_loss: 6.1794 - val_acc: 0.4324 - val_f1score: 0.4335\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.43240, saving model to /content/drive/My Drive/LSTM_Model/model.01-6.18.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 6.3613 - acc: 0.4561 - f1score: 0.4550 - val_loss: 6.1794 - val_acc: 0.4324 - val_f1score: 0.4335\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 4.8134 - acc: 0.5664 - f1score: 0.5664\n",
            "Epoch 00002: val_acc improved from 0.43240 to 0.78112, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.28.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 4.7440 - acc: 0.5709 - f1score: 0.5722 - val_loss: 2.2803 - val_acc: 0.7811 - val_f1score: 0.7858\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.43240 to 0.78112, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.28.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 4.7440 - acc: 0.5709 - f1score: 0.5722 - val_loss: 2.2803 - val_acc: 0.7811 - val_f1score: 0.7858\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 3.5514 - acc: 0.7154 - f1score: 0.7154\n",
            "Epoch 00003: val_acc improved from 0.78112 to 0.78326, saving model to /content/drive/My Drive/LSTM_Model/model.03-2.43.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 3.5563 - acc: 0.7148 - f1score: 0.7146 - val_loss: 2.4346 - val_acc: 0.7833 - val_f1score: 0.7803\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.78112 to 0.78326, saving model to /content/drive/My Drive/LSTM_Model/model.03-2.43.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 3.5563 - acc: 0.7148 - f1score: 0.7146 - val_loss: 2.4346 - val_acc: 0.7833 - val_f1score: 0.7803\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 3.5092 - acc: 0.7266 - f1score: 0.7266\n",
            "Epoch 00004: val_acc improved from 0.78326 to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.43.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 3.4784 - acc: 0.7270 - f1score: 0.7271 - val_loss: 2.4292 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.78326 to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.43.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 3.4784 - acc: 0.7270 - f1score: 0.7271 - val_loss: 2.4292 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.9487 - acc: 0.7506 - f1score: 0.7506\n",
            "Epoch 00005: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.9426 - acc: 0.7513 - f1score: 0.7515 - val_loss: 2.4922 - val_acc: 0.7790 - val_f1score: 0.7714\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.9426 - acc: 0.7513 - f1score: 0.7515 - val_loss: 2.4922 - val_acc: 0.7790 - val_f1score: 0.7714\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.6875 - acc: 0.7662 - f1score: 0.7662\n",
            "Epoch 00006: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.7073 - acc: 0.7646 - f1score: 0.7641 - val_loss: 2.4495 - val_acc: 0.7800 - val_f1score: 0.7773\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.7073 - acc: 0.7646 - f1score: 0.7641 - val_loss: 2.4495 - val_acc: 0.7800 - val_f1score: 0.7773\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.4188 - acc: 0.7946 - f1score: 0.7946\n",
            "Epoch 00007: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.4004 - acc: 0.7968 - f1score: 0.7974 - val_loss: 2.4424 - val_acc: 0.7833 - val_f1score: 0.7828\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.4004 - acc: 0.7968 - f1score: 0.7974 - val_loss: 2.4424 - val_acc: 0.7833 - val_f1score: 0.7828\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.3099 - acc: 0.8047 - f1score: 0.8047\n",
            "Epoch 00008: val_acc improved from 0.79399 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.08-2.42.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2981 - acc: 0.8048 - f1score: 0.8048 - val_loss: 2.4209 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.79399 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.08-2.42.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2981 - acc: 0.8048 - f1score: 0.8048 - val_loss: 2.4209 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.3588 - acc: 0.8019 - f1score: 0.8019\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.3000 - acc: 0.8063 - f1score: 0.8076 - val_loss: 2.4177 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.3000 - acc: 0.8063 - f1score: 0.8076 - val_loss: 2.4177 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.2935 - acc: 0.7991 - f1score: 0.7991\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2592 - acc: 0.8016 - f1score: 0.8023 - val_loss: 2.4102 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2592 - acc: 0.8016 - f1score: 0.8023 - val_loss: 2.4102 - val_acc: 0.7908 - val_f1score: 0.7896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 32%|███▏      | 31/96 [2:08:11<3:37:40, 200.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 3.9174 - acc: 0.4436 - f1score: 0.4423\n",
            "Epoch 00001: val_acc improved from -inf to 0.44528, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.15.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 3.8292 - acc: 0.4460 - f1score: 0.4455 - val_loss: 2.1500 - val_acc: 0.4453 - val_f1score: 0.4402\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.44528, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.15.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 3.8292 - acc: 0.4460 - f1score: 0.4455 - val_loss: 2.1500 - val_acc: 0.4453 - val_f1score: 0.4402\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.2350 - acc: 0.5463 - f1score: 0.5463\n",
            "Epoch 00002: val_acc improved from 0.44528 to 0.71996, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.67.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.2065 - acc: 0.5561 - f1score: 0.5589 - val_loss: 0.6742 - val_acc: 0.7200 - val_f1score: 0.7227\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.44528 to 0.71996, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.67.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.2065 - acc: 0.5561 - f1score: 0.5589 - val_loss: 0.6742 - val_acc: 0.7200 - val_f1score: 0.7227\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6160 - acc: 0.7606 - f1score: 0.7606\n",
            "Epoch 00003: val_acc improved from 0.71996 to 0.78541, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.58.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6120 - acc: 0.7619 - f1score: 0.7623 - val_loss: 0.5779 - val_acc: 0.7854 - val_f1score: 0.7872\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.71996 to 0.78541, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.58.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6120 - acc: 0.7619 - f1score: 0.7623 - val_loss: 0.5779 - val_acc: 0.7854 - val_f1score: 0.7872\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5653 - acc: 0.8036 - f1score: 0.8036\n",
            "Epoch 00004: val_acc improved from 0.78541 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.57.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5639 - acc: 0.8048 - f1score: 0.8051 - val_loss: 0.5717 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.78541 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.57.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5639 - acc: 0.8048 - f1score: 0.8051 - val_loss: 0.5717 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5593 - acc: 0.8069 - f1score: 0.8069\n",
            "Epoch 00005: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.57.h5\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.57.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5575 - acc: 0.8095 - f1score: 0.8103 - val_loss: 0.5682 - val_acc: 0.8026 - val_f1score: 0.7979\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5575 - acc: 0.8095 - f1score: 0.8103 - val_loss: 0.5682 - val_acc: 0.8026 - val_f1score: 0.7979\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5593 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00006: val_acc improved from 0.80258 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.56.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5567 - acc: 0.8148 - f1score: 0.8152 - val_loss: 0.5637 - val_acc: 0.8047 - val_f1score: 0.8023\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.80258 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.56.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5567 - acc: 0.8148 - f1score: 0.8152 - val_loss: 0.5637 - val_acc: 0.8047 - val_f1score: 0.8023\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5388 - acc: 0.8108 - f1score: 0.8108\n",
            "Epoch 00007: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5392 - acc: 0.8122 - f1score: 0.8126 - val_loss: 0.5611 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5392 - acc: 0.8122 - f1score: 0.8126 - val_loss: 0.5611 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5312 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00008: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5304 - acc: 0.8159 - f1score: 0.8165 - val_loss: 0.5576 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5304 - acc: 0.8159 - f1score: 0.8165 - val_loss: 0.5576 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5375 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5389 - acc: 0.8106 - f1score: 0.8099 - val_loss: 0.5531 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5389 - acc: 0.8106 - f1score: 0.8099 - val_loss: 0.5531 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5346 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5345 - acc: 0.8116 - f1score: 0.8117 - val_loss: 0.5489 - val_acc: 0.7951 - val_f1score: 0.7960\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5345 - acc: 0.8116 - f1score: 0.8117 - val_loss: 0.5489 - val_acc: 0.7951 - val_f1score: 0.7960\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 32/96 [2:09:27<2:54:30, 163.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1754 - acc: 0.6094 - f1score: 0.6094\n",
            "Epoch 00001: val_acc improved from -inf to 0.77682, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.97.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.1634 - acc: 0.6159 - f1score: 0.6177 - val_loss: 1.9721 - val_acc: 0.7768 - val_f1score: 0.7769\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77682, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.97.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.1634 - acc: 0.6159 - f1score: 0.6177 - val_loss: 1.9721 - val_acc: 0.7768 - val_f1score: 0.7769\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.3306 - acc: 0.7991 - f1score: 0.7991\n",
            "Epoch 00002: val_acc improved from 0.77682 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.22.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.3289 - acc: 0.7963 - f1score: 0.7955 - val_loss: 1.2228 - val_acc: 0.8036 - val_f1score: 0.8088\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.77682 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.22.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.3289 - acc: 0.7963 - f1score: 0.7955 - val_loss: 1.2228 - val_acc: 0.8036 - val_f1score: 0.8088\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.0148 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.9863 - acc: 0.7995 - f1score: 0.7999 - val_loss: 0.7496 - val_acc: 0.7983 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.9863 - acc: 0.7995 - f1score: 0.7999 - val_loss: 0.7496 - val_acc: 0.7983 - val_f1score: 0.8014\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6467 - acc: 0.7679 - f1score: 0.7679\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6468 - acc: 0.7635 - f1score: 0.7622 - val_loss: 0.5704 - val_acc: 0.7800 - val_f1score: 0.7699\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6468 - acc: 0.7635 - f1score: 0.7622 - val_loss: 0.5704 - val_acc: 0.7800 - val_f1score: 0.7699\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5740 - acc: 0.7176 - f1score: 0.7176\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5723 - acc: 0.7190 - f1score: 0.7195 - val_loss: 0.5346 - val_acc: 0.7575 - val_f1score: 0.7419\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5723 - acc: 0.7190 - f1score: 0.7195 - val_loss: 0.5346 - val_acc: 0.7575 - val_f1score: 0.7419\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5312 - acc: 0.7254 - f1score: 0.7254\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5316 - acc: 0.7270 - f1score: 0.7274 - val_loss: 0.5326 - val_acc: 0.7457 - val_f1score: 0.7236\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5316 - acc: 0.7270 - f1score: 0.7274 - val_loss: 0.5326 - val_acc: 0.7457 - val_f1score: 0.7236\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5360 - acc: 0.7360 - f1score: 0.7360\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5346 - acc: 0.7381 - f1score: 0.7387 - val_loss: 0.5281 - val_acc: 0.7532 - val_f1score: 0.7554\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5346 - acc: 0.7381 - f1score: 0.7387 - val_loss: 0.5281 - val_acc: 0.7532 - val_f1score: 0.7554\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5304 - acc: 0.7567 - f1score: 0.7567\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5283 - acc: 0.7561 - f1score: 0.7559 - val_loss: 0.5229 - val_acc: 0.7897 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5283 - acc: 0.7561 - f1score: 0.7559 - val_loss: 0.5229 - val_acc: 0.7897 - val_f1score: 0.7936\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5277 - acc: 0.7673 - f1score: 0.7673\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5253 - acc: 0.7698 - f1score: 0.7706 - val_loss: 0.5190 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5253 - acc: 0.7698 - f1score: 0.7706 - val_loss: 0.5190 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5053 - acc: 0.7879 - f1score: 0.7879\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5078 - acc: 0.7868 - f1score: 0.7864 - val_loss: 0.5152 - val_acc: 0.7918 - val_f1score: 0.7881\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5078 - acc: 0.7868 - f1score: 0.7864 - val_loss: 0.5152 - val_acc: 0.7918 - val_f1score: 0.7881\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4834 - acc: 0.7997 - f1score: 0.7997\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4873 - acc: 0.7995 - f1score: 0.7994 - val_loss: 0.5126 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4873 - acc: 0.7995 - f1score: 0.7994 - val_loss: 0.5126 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4978 - acc: 0.8058 - f1score: 0.8058\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4989 - acc: 0.8011 - f1score: 0.7997 - val_loss: 0.5093 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4989 - acc: 0.8011 - f1score: 0.7997 - val_loss: 0.5093 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5061 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5003 - acc: 0.8011 - f1score: 0.8018 - val_loss: 0.5078 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5003 - acc: 0.8011 - f1score: 0.8018 - val_loss: 0.5078 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4885 - acc: 0.8013 - f1score: 0.8013\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4919 - acc: 0.7989 - f1score: 0.7983 - val_loss: 0.5055 - val_acc: 0.7897 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4919 - acc: 0.7989 - f1score: 0.7983 - val_loss: 0.5055 - val_acc: 0.7897 - val_f1score: 0.7936\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4968 - acc: 0.7958 - f1score: 0.7958\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4960 - acc: 0.7958 - f1score: 0.7958 - val_loss: 0.5041 - val_acc: 0.7876 - val_f1score: 0.7892\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4960 - acc: 0.7958 - f1score: 0.7958 - val_loss: 0.5041 - val_acc: 0.7876 - val_f1score: 0.7892\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4964 - acc: 0.7896 - f1score: 0.7896\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4939 - acc: 0.7910 - f1score: 0.7914 - val_loss: 0.5020 - val_acc: 0.7800 - val_f1score: 0.7823\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4939 - acc: 0.7910 - f1score: 0.7914 - val_loss: 0.5020 - val_acc: 0.7800 - val_f1score: 0.7823\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4964 - acc: 0.8041 - f1score: 0.8041\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4973 - acc: 0.8016 - f1score: 0.8009 - val_loss: 0.5027 - val_acc: 0.7811 - val_f1score: 0.7833\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4973 - acc: 0.8016 - f1score: 0.8009 - val_loss: 0.5027 - val_acc: 0.7811 - val_f1score: 0.7833\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4822 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4824 - acc: 0.7958 - f1score: 0.7953 - val_loss: 0.5014 - val_acc: 0.7833 - val_f1score: 0.7828\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4824 - acc: 0.7958 - f1score: 0.7953 - val_loss: 0.5014 - val_acc: 0.7833 - val_f1score: 0.7828\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4890 - acc: 0.7896 - f1score: 0.7896\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4873 - acc: 0.7921 - f1score: 0.7928 - val_loss: 0.5000 - val_acc: 0.7833 - val_f1score: 0.7778\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4873 - acc: 0.7921 - f1score: 0.7928 - val_loss: 0.5000 - val_acc: 0.7833 - val_f1score: 0.7778\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4852 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4876 - acc: 0.7947 - f1score: 0.7942 - val_loss: 0.4994 - val_acc: 0.7811 - val_f1score: 0.7858\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4876 - acc: 0.7947 - f1score: 0.7942 - val_loss: 0.4994 - val_acc: 0.7811 - val_f1score: 0.7858\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4910 - acc: 0.7902 - f1score: 0.7902\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4900 - acc: 0.7894 - f1score: 0.7892 - val_loss: 0.5017 - val_acc: 0.7779 - val_f1score: 0.7879\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4900 - acc: 0.7894 - f1score: 0.7892 - val_loss: 0.5017 - val_acc: 0.7779 - val_f1score: 0.7879\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4891 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4881 - acc: 0.7947 - f1score: 0.7942 - val_loss: 0.4980 - val_acc: 0.7876 - val_f1score: 0.7942\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4881 - acc: 0.7947 - f1score: 0.7942 - val_loss: 0.4980 - val_acc: 0.7876 - val_f1score: 0.7942\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4800 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4829 - acc: 0.7963 - f1score: 0.7960 - val_loss: 0.4944 - val_acc: 0.7833 - val_f1score: 0.7853\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4829 - acc: 0.7963 - f1score: 0.7960 - val_loss: 0.4944 - val_acc: 0.7833 - val_f1score: 0.7853\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4882 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4879 - acc: 0.7963 - f1score: 0.7960 - val_loss: 0.4934 - val_acc: 0.7800 - val_f1score: 0.7848\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4879 - acc: 0.7963 - f1score: 0.7960 - val_loss: 0.4934 - val_acc: 0.7800 - val_f1score: 0.7848\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4887 - acc: 0.7891 - f1score: 0.7891\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4887 - acc: 0.7889 - f1score: 0.7888 - val_loss: 0.4926 - val_acc: 0.7822 - val_f1score: 0.7793\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4887 - acc: 0.7889 - f1score: 0.7888 - val_loss: 0.4926 - val_acc: 0.7822 - val_f1score: 0.7793\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4905 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4899 - acc: 0.7963 - f1score: 0.7960 - val_loss: 0.4928 - val_acc: 0.7822 - val_f1score: 0.7843\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4899 - acc: 0.7963 - f1score: 0.7960 - val_loss: 0.4928 - val_acc: 0.7822 - val_f1score: 0.7843\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4848 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4827 - acc: 0.7958 - f1score: 0.7956 - val_loss: 0.4981 - val_acc: 0.7833 - val_f1score: 0.7903\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4827 - acc: 0.7958 - f1score: 0.7956 - val_loss: 0.4981 - val_acc: 0.7833 - val_f1score: 0.7903\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5585 - acc: 0.7612 - f1score: 0.7612\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5559 - acc: 0.7603 - f1score: 0.7601 - val_loss: 0.4934 - val_acc: 0.7833 - val_f1score: 0.7753\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5559 - acc: 0.7603 - f1score: 0.7601 - val_loss: 0.4934 - val_acc: 0.7833 - val_f1score: 0.7753\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4818 - acc: 0.7958 - f1score: 0.7958\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4811 - acc: 0.7952 - f1score: 0.7951 - val_loss: 0.4937 - val_acc: 0.7843 - val_f1score: 0.7862\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4811 - acc: 0.7952 - f1score: 0.7951 - val_loss: 0.4937 - val_acc: 0.7843 - val_f1score: 0.7862\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4887 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4934 - acc: 0.7952 - f1score: 0.7949 - val_loss: 0.4902 - val_acc: 0.7822 - val_f1score: 0.7793\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4934 - acc: 0.7952 - f1score: 0.7949 - val_loss: 0.4902 - val_acc: 0.7822 - val_f1score: 0.7793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 34%|███▍      | 33/96 [2:12:08<2:50:39, 162.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 3.1090 - acc: 0.6217 - f1score: 0.6218\n",
            "Epoch 00001: val_acc improved from -inf to 0.79614, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.40.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 3.0504 - acc: 0.6333 - f1score: 0.6368 - val_loss: 2.4004 - val_acc: 0.7961 - val_f1score: 0.8020\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.79614, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.40.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 3.0504 - acc: 0.6333 - f1score: 0.6368 - val_loss: 2.4004 - val_acc: 0.7961 - val_f1score: 0.8020\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.5225 - acc: 0.7768 - f1score: 0.7768\n",
            "Epoch 00002: val_acc did not improve from 0.79614\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.5232 - acc: 0.7772 - f1score: 0.7774 - val_loss: 2.3775 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.79614\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.5232 - acc: 0.7772 - f1score: 0.7774 - val_loss: 2.3775 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.4238 - acc: 0.7628 - f1score: 0.7628\n",
            "Epoch 00003: val_acc improved from 0.79614 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.03-2.13.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.4322 - acc: 0.7593 - f1score: 0.7582 - val_loss: 2.1306 - val_acc: 0.8015 - val_f1score: 0.8094\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.79614 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.03-2.13.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.4322 - acc: 0.7593 - f1score: 0.7582 - val_loss: 2.1306 - val_acc: 0.8015 - val_f1score: 0.8094\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.9672 - acc: 0.7935 - f1score: 0.7935\n",
            "Epoch 00004: val_acc improved from 0.80150 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.09.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.9775 - acc: 0.7942 - f1score: 0.7944 - val_loss: 2.0906 - val_acc: 0.8036 - val_f1score: 0.7963\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.80150 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.09.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.9775 - acc: 0.7942 - f1score: 0.7944 - val_loss: 2.0906 - val_acc: 0.8036 - val_f1score: 0.7963\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.6807 - acc: 0.7846 - f1score: 0.7846\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.6648 - acc: 0.7868 - f1score: 0.7874 - val_loss: 1.6007 - val_acc: 0.7876 - val_f1score: 0.7892\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.6648 - acc: 0.7868 - f1score: 0.7874 - val_loss: 1.6007 - val_acc: 0.7876 - val_f1score: 0.7892\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.3043 - acc: 0.7227 - f1score: 0.7227\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.3051 - acc: 0.7180 - f1score: 0.7167 - val_loss: 0.8541 - val_acc: 0.7060 - val_f1score: 0.7000\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.3051 - acc: 0.7180 - f1score: 0.7167 - val_loss: 0.8541 - val_acc: 0.7060 - val_f1score: 0.7000\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.7713 - acc: 0.6975 - f1score: 0.6975\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.7632 - acc: 0.6889 - f1score: 0.6864 - val_loss: 0.6242 - val_acc: 0.7017 - val_f1score: 0.6936\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.7632 - acc: 0.6889 - f1score: 0.6864 - val_loss: 0.6242 - val_acc: 0.7017 - val_f1score: 0.6936\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5324 - acc: 0.7679 - f1score: 0.7679\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5276 - acc: 0.7725 - f1score: 0.7738 - val_loss: 0.4968 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5276 - acc: 0.7725 - f1score: 0.7738 - val_loss: 0.4968 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5074 - acc: 0.8058 - f1score: 0.8058\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5044 - acc: 0.8085 - f1score: 0.8092 - val_loss: 0.4954 - val_acc: 0.8015 - val_f1score: 0.8044\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5044 - acc: 0.8085 - f1score: 0.8092 - val_loss: 0.4954 - val_acc: 0.8015 - val_f1score: 0.8044\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5070 - acc: 0.8075 - f1score: 0.8075\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5054 - acc: 0.8079 - f1score: 0.8081 - val_loss: 0.5058 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5054 - acc: 0.8079 - f1score: 0.8081 - val_loss: 0.5058 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5022 - acc: 0.8064 - f1score: 0.8064\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4997 - acc: 0.8085 - f1score: 0.8091 - val_loss: 0.4955 - val_acc: 0.7972 - val_f1score: 0.7930\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4997 - acc: 0.8085 - f1score: 0.8091 - val_loss: 0.4955 - val_acc: 0.7972 - val_f1score: 0.7930\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4880 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4894 - acc: 0.8116 - f1score: 0.8117 - val_loss: 0.4982 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4894 - acc: 0.8116 - f1score: 0.8117 - val_loss: 0.4982 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4919 - acc: 0.8064 - f1score: 0.8064\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4913 - acc: 0.8058 - f1score: 0.8057 - val_loss: 0.4932 - val_acc: 0.8004 - val_f1score: 0.8109\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4913 - acc: 0.8058 - f1score: 0.8057 - val_loss: 0.4932 - val_acc: 0.8004 - val_f1score: 0.8109\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4828 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4794 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4924 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4794 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4924 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4801 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4782 - acc: 0.8106 - f1score: 0.8107 - val_loss: 0.4914 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4782 - acc: 0.8106 - f1score: 0.8107 - val_loss: 0.4914 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4957 - acc: 0.8069 - f1score: 0.8069\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4958 - acc: 0.8079 - f1score: 0.8082 - val_loss: 0.4961 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4958 - acc: 0.8079 - f1score: 0.8082 - val_loss: 0.4961 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4809 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4814 - acc: 0.8132 - f1score: 0.8133 - val_loss: 0.4910 - val_acc: 0.7940 - val_f1score: 0.8025\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4814 - acc: 0.8132 - f1score: 0.8133 - val_loss: 0.4910 - val_acc: 0.7940 - val_f1score: 0.8025\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4843 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4831 - acc: 0.8127 - f1score: 0.8131 - val_loss: 0.4888 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4831 - acc: 0.8127 - f1score: 0.8131 - val_loss: 0.4888 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4865 - acc: 0.8025 - f1score: 0.8025\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4834 - acc: 0.8042 - f1score: 0.8047 - val_loss: 0.4939 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4834 - acc: 0.8042 - f1score: 0.8047 - val_loss: 0.4939 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4804 - acc: 0.8097 - f1score: 0.8097\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4846 - acc: 0.8058 - f1score: 0.8047 - val_loss: 0.4891 - val_acc: 0.7929 - val_f1score: 0.7841\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4846 - acc: 0.8058 - f1score: 0.8047 - val_loss: 0.4891 - val_acc: 0.7929 - val_f1score: 0.7841\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4785 - acc: 0.8058 - f1score: 0.8058\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4776 - acc: 0.8069 - f1score: 0.8072 - val_loss: 0.4877 - val_acc: 0.7929 - val_f1score: 0.7965\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4776 - acc: 0.8069 - f1score: 0.8072 - val_loss: 0.4877 - val_acc: 0.7929 - val_f1score: 0.7965\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4822 - acc: 0.8019 - f1score: 0.8019\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4836 - acc: 0.8026 - f1score: 0.8029 - val_loss: 0.4886 - val_acc: 0.7897 - val_f1score: 0.7836\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4836 - acc: 0.8026 - f1score: 0.8029 - val_loss: 0.4886 - val_acc: 0.7897 - val_f1score: 0.7836\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4740 - acc: 0.8108 - f1score: 0.8108\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4737 - acc: 0.8101 - f1score: 0.8098 - val_loss: 0.4933 - val_acc: 0.7811 - val_f1score: 0.7758\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4737 - acc: 0.8101 - f1score: 0.8098 - val_loss: 0.4933 - val_acc: 0.7811 - val_f1score: 0.7758\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4768 - acc: 0.8025 - f1score: 0.8025\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4762 - acc: 0.8042 - f1score: 0.8047 - val_loss: 0.4876 - val_acc: 0.7800 - val_f1score: 0.7773\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4762 - acc: 0.8042 - f1score: 0.8047 - val_loss: 0.4876 - val_acc: 0.7800 - val_f1score: 0.7773\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4815 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4806 - acc: 0.8106 - f1score: 0.8107 - val_loss: 0.4877 - val_acc: 0.7897 - val_f1score: 0.7986\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4806 - acc: 0.8106 - f1score: 0.8107 - val_loss: 0.4877 - val_acc: 0.7897 - val_f1score: 0.7986\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4753 - acc: 0.8069 - f1score: 0.8069\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4743 - acc: 0.8053 - f1score: 0.8048 - val_loss: 0.4882 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4743 - acc: 0.8053 - f1score: 0.8048 - val_loss: 0.4882 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4744 - acc: 0.8047 - f1score: 0.8047\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4752 - acc: 0.8048 - f1score: 0.8048 - val_loss: 0.4872 - val_acc: 0.7843 - val_f1score: 0.7788\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4752 - acc: 0.8048 - f1score: 0.8048 - val_loss: 0.4872 - val_acc: 0.7843 - val_f1score: 0.7788\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4707 - acc: 0.8097 - f1score: 0.8097\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4717 - acc: 0.8085 - f1score: 0.8081 - val_loss: 0.4849 - val_acc: 0.7843 - val_f1score: 0.7887\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4717 - acc: 0.8085 - f1score: 0.8081 - val_loss: 0.4849 - val_acc: 0.7843 - val_f1score: 0.7887\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4698 - acc: 0.8064 - f1score: 0.8064\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4684 - acc: 0.8085 - f1score: 0.8091 - val_loss: 0.4868 - val_acc: 0.7822 - val_f1score: 0.7893\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4684 - acc: 0.8085 - f1score: 0.8091 - val_loss: 0.4868 - val_acc: 0.7822 - val_f1score: 0.7893\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4744 - acc: 0.8086 - f1score: 0.8086\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4744 - acc: 0.8090 - f1score: 0.8091 - val_loss: 0.4848 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4744 - acc: 0.8090 - f1score: 0.8091 - val_loss: 0.4848 - val_acc: 0.7908 - val_f1score: 0.7921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 35%|███▌      | 34/96 [2:15:47<3:05:35, 179.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 6.4445 - acc: 0.4916 - f1score: 0.4913\n",
            "Epoch 00001: val_acc improved from -inf to 0.43133, saving model to /content/drive/My Drive/LSTM_Model/model.01-8.48.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 6.4677 - acc: 0.4915 - f1score: 0.4912 - val_loss: 8.4789 - val_acc: 0.4313 - val_f1score: 0.4175\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.43133, saving model to /content/drive/My Drive/LSTM_Model/model.01-8.48.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 6.4677 - acc: 0.4915 - f1score: 0.4912 - val_loss: 8.4789 - val_acc: 0.4313 - val_f1score: 0.4175\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 6.2208 - acc: 0.4894 - f1score: 0.4894\n",
            "Epoch 00002: val_acc did not improve from 0.43133\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 6.2116 - acc: 0.4915 - f1score: 0.4921 - val_loss: 8.3555 - val_acc: 0.4303 - val_f1score: 0.4290\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.43133\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 6.2116 - acc: 0.4915 - f1score: 0.4921 - val_loss: 8.3555 - val_acc: 0.4303 - val_f1score: 0.4290\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 6.3799 - acc: 0.4738 - f1score: 0.4738\n",
            "Epoch 00003: val_acc improved from 0.43133 to 0.43240, saving model to /content/drive/My Drive/LSTM_Model/model.03-8.21.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 6.3703 - acc: 0.4746 - f1score: 0.4748 - val_loss: 8.2149 - val_acc: 0.4324 - val_f1score: 0.4360\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.43133 to 0.43240, saving model to /content/drive/My Drive/LSTM_Model/model.03-8.21.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 6.3703 - acc: 0.4746 - f1score: 0.4748 - val_loss: 8.2149 - val_acc: 0.4324 - val_f1score: 0.4360\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 5.9013 - acc: 0.5067 - f1score: 0.5067\n",
            "Epoch 00004: val_acc did not improve from 0.43240\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 5.9988 - acc: 0.4995 - f1score: 0.4974 - val_loss: 7.9536 - val_acc: 0.4313 - val_f1score: 0.4350\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.43240\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 5.9988 - acc: 0.4995 - f1score: 0.4974 - val_loss: 7.9536 - val_acc: 0.4313 - val_f1score: 0.4350\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 5.8434 - acc: 0.5296 - f1score: 0.5296\n",
            "Epoch 00005: val_acc did not improve from 0.43240\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 5.7853 - acc: 0.5312 - f1score: 0.5317 - val_loss: 6.2708 - val_acc: 0.4313 - val_f1score: 0.4325\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.43240\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 5.7853 - acc: 0.5312 - f1score: 0.5317 - val_loss: 6.2708 - val_acc: 0.4313 - val_f1score: 0.4325\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 3.8861 - acc: 0.5597 - f1score: 0.5597\n",
            "Epoch 00006: val_acc improved from 0.43240 to 0.70708, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.89.h5\n",
            "1890/1890 [==============================] - 6s 3ms/sample - loss: 3.7937 - acc: 0.5624 - f1score: 0.5632 - val_loss: 0.8894 - val_acc: 0.7071 - val_f1score: 0.7059\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.43240 to 0.70708, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.89.h5\n",
            "1890/1890 [==============================] - 6s 3ms/sample - loss: 3.7937 - acc: 0.5624 - f1score: 0.5632 - val_loss: 0.8894 - val_acc: 0.7071 - val_f1score: 0.7059\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.1837 - acc: 0.7790 - f1score: 0.7790\n",
            "Epoch 00007: val_acc improved from 0.70708 to 0.79936, saving model to /content/drive/My Drive/LSTM_Model/model.07-0.88.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.1927 - acc: 0.7783 - f1score: 0.7781 - val_loss: 0.8769 - val_acc: 0.7994 - val_f1score: 0.8074\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.70708 to 0.79936, saving model to /content/drive/My Drive/LSTM_Model/model.07-0.88.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.1927 - acc: 0.7783 - f1score: 0.7781 - val_loss: 0.8769 - val_acc: 0.7994 - val_f1score: 0.8074\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.7718 - acc: 0.7695 - f1score: 0.7695\n",
            "Epoch 00008: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.7701 - acc: 0.7677 - f1score: 0.7672 - val_loss: 0.5390 - val_acc: 0.7790 - val_f1score: 0.7839\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.7701 - acc: 0.7677 - f1score: 0.7672 - val_loss: 0.5390 - val_acc: 0.7790 - val_f1score: 0.7839\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5779 - acc: 0.7868 - f1score: 0.7868\n",
            "Epoch 00009: val_acc improved from 0.79936 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.09-0.52.h5\n",
            "1890/1890 [==============================] - 6s 3ms/sample - loss: 0.5772 - acc: 0.7852 - f1score: 0.7847 - val_loss: 0.5176 - val_acc: 0.8058 - val_f1score: 0.8058\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.79936 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.09-0.52.h5\n",
            "1890/1890 [==============================] - 6s 3ms/sample - loss: 0.5772 - acc: 0.7852 - f1score: 0.7847 - val_loss: 0.5176 - val_acc: 0.8058 - val_f1score: 0.8058\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5242 - acc: 0.7896 - f1score: 0.7896\n",
            "Epoch 00010: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5253 - acc: 0.7889 - f1score: 0.7887 - val_loss: 0.5189 - val_acc: 0.7994 - val_f1score: 0.7924\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5253 - acc: 0.7889 - f1score: 0.7887 - val_loss: 0.5189 - val_acc: 0.7994 - val_f1score: 0.7924\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5321 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00011: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5334 - acc: 0.7958 - f1score: 0.7956 - val_loss: 0.5087 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5334 - acc: 0.7958 - f1score: 0.7956 - val_loss: 0.5087 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4997 - acc: 0.7997 - f1score: 0.7997\n",
            "Epoch 00012: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5067 - acc: 0.7989 - f1score: 0.7987 - val_loss: 0.5067 - val_acc: 0.8036 - val_f1score: 0.7963\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5067 - acc: 0.7989 - f1score: 0.7987 - val_loss: 0.5067 - val_acc: 0.8036 - val_f1score: 0.7963\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5082 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00013: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5049 - acc: 0.7979 - f1score: 0.7982 - val_loss: 0.5008 - val_acc: 0.8026 - val_f1score: 0.8003\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5049 - acc: 0.7979 - f1score: 0.7982 - val_loss: 0.5008 - val_acc: 0.8026 - val_f1score: 0.8003\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5010 - acc: 0.7991 - f1score: 0.7991\n",
            "Epoch 00014: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4989 - acc: 0.8000 - f1score: 0.8003 - val_loss: 0.5067 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4989 - acc: 0.8000 - f1score: 0.8003 - val_loss: 0.5067 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4974 - acc: 0.8064 - f1score: 0.8064\n",
            "Epoch 00015: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4981 - acc: 0.8037 - f1score: 0.8029 - val_loss: 0.5110 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4981 - acc: 0.8037 - f1score: 0.8029 - val_loss: 0.5110 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4979 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00016: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5006 - acc: 0.8074 - f1score: 0.8066 - val_loss: 0.5084 - val_acc: 0.7972 - val_f1score: 0.7930\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5006 - acc: 0.8074 - f1score: 0.8066 - val_loss: 0.5084 - val_acc: 0.7972 - val_f1score: 0.7930\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4876 - acc: 0.8052 - f1score: 0.8052\n",
            "Epoch 00017: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4885 - acc: 0.8063 - f1score: 0.8067 - val_loss: 0.5099 - val_acc: 0.7983 - val_f1score: 0.8064\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4885 - acc: 0.8063 - f1score: 0.8067 - val_loss: 0.5099 - val_acc: 0.7983 - val_f1score: 0.8064\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4960 - acc: 0.8002 - f1score: 0.8002\n",
            "Epoch 00018: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4936 - acc: 0.8026 - f1score: 0.8033 - val_loss: 0.5080 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4936 - acc: 0.8026 - f1score: 0.8033 - val_loss: 0.5080 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5080 - acc: 0.8019 - f1score: 0.8019\n",
            "Epoch 00019: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5017 - acc: 0.8048 - f1score: 0.8056 - val_loss: 0.5026 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5017 - acc: 0.8048 - f1score: 0.8056 - val_loss: 0.5026 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4994 - acc: 0.8013 - f1score: 0.8013\n",
            "Epoch 00020: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4974 - acc: 0.8026 - f1score: 0.8030 - val_loss: 0.5078 - val_acc: 0.7983 - val_f1score: 0.7989\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4974 - acc: 0.8026 - f1score: 0.8030 - val_loss: 0.5078 - val_acc: 0.7983 - val_f1score: 0.7989\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4914 - acc: 0.8030 - f1score: 0.8030\n",
            "Epoch 00021: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4989 - acc: 0.7974 - f1score: 0.7957 - val_loss: 0.5011 - val_acc: 0.8004 - val_f1score: 0.7934\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4989 - acc: 0.7974 - f1score: 0.7957 - val_loss: 0.5011 - val_acc: 0.8004 - val_f1score: 0.7934\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4829 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00022: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4835 - acc: 0.8090 - f1score: 0.8086 - val_loss: 0.5006 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4835 - acc: 0.8090 - f1score: 0.8086 - val_loss: 0.5006 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4806 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00023: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4815 - acc: 0.8090 - f1score: 0.8086 - val_loss: 0.5055 - val_acc: 0.7983 - val_f1score: 0.8039\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4815 - acc: 0.8090 - f1score: 0.8086 - val_loss: 0.5055 - val_acc: 0.7983 - val_f1score: 0.8039\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4915 - acc: 0.8019 - f1score: 0.8019\n",
            "Epoch 00024: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4885 - acc: 0.8016 - f1score: 0.8015 - val_loss: 0.4996 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4885 - acc: 0.8016 - f1score: 0.8015 - val_loss: 0.4996 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4920 - acc: 0.8036 - f1score: 0.8036\n",
            "Epoch 00025: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4886 - acc: 0.8048 - f1score: 0.8051 - val_loss: 0.5053 - val_acc: 0.7886 - val_f1score: 0.7877\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4886 - acc: 0.8048 - f1score: 0.8051 - val_loss: 0.5053 - val_acc: 0.7886 - val_f1score: 0.7877\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4912 - acc: 0.8008 - f1score: 0.8008\n",
            "Epoch 00026: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4890 - acc: 0.8021 - f1score: 0.8025 - val_loss: 0.5047 - val_acc: 0.7886 - val_f1score: 0.7901\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4890 - acc: 0.8021 - f1score: 0.8025 - val_loss: 0.5047 - val_acc: 0.7886 - val_f1score: 0.7901\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4855 - acc: 0.8086 - f1score: 0.8086\n",
            "Epoch 00027: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4834 - acc: 0.8079 - f1score: 0.8077 - val_loss: 0.4959 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4834 - acc: 0.8079 - f1score: 0.8077 - val_loss: 0.4959 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4759 - acc: 0.8030 - f1score: 0.8030\n",
            "Epoch 00028: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4771 - acc: 0.8000 - f1score: 0.7991 - val_loss: 0.4962 - val_acc: 0.7908 - val_f1score: 0.7771\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4771 - acc: 0.8000 - f1score: 0.7991 - val_loss: 0.4962 - val_acc: 0.7908 - val_f1score: 0.7771\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4778 - acc: 0.8069 - f1score: 0.8069\n",
            "Epoch 00029: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4827 - acc: 0.8058 - f1score: 0.8055 - val_loss: 0.4950 - val_acc: 0.7854 - val_f1score: 0.7897\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4827 - acc: 0.8058 - f1score: 0.8055 - val_loss: 0.4950 - val_acc: 0.7854 - val_f1score: 0.7897\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4757 - acc: 0.8052 - f1score: 0.8052\n",
            "Epoch 00030: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4748 - acc: 0.8069 - f1score: 0.8073 - val_loss: 0.4936 - val_acc: 0.7833 - val_f1score: 0.7903\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4748 - acc: 0.8069 - f1score: 0.8073 - val_loss: 0.4936 - val_acc: 0.7833 - val_f1score: 0.7903\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4781 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00031: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4845 - acc: 0.8074 - f1score: 0.8066 - val_loss: 0.5033 - val_acc: 0.7811 - val_f1score: 0.7808\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4845 - acc: 0.8074 - f1score: 0.8066 - val_loss: 0.5033 - val_acc: 0.7811 - val_f1score: 0.7808\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4756 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00032: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4779 - acc: 0.8111 - f1score: 0.8101 - val_loss: 0.4937 - val_acc: 0.7940 - val_f1score: 0.8100\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4779 - acc: 0.8111 - f1score: 0.8101 - val_loss: 0.4937 - val_acc: 0.7940 - val_f1score: 0.8100\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4690 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00033: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4680 - acc: 0.8153 - f1score: 0.8158 - val_loss: 0.4913 - val_acc: 0.7854 - val_f1score: 0.7822\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4680 - acc: 0.8153 - f1score: 0.8158 - val_loss: 0.4913 - val_acc: 0.7854 - val_f1score: 0.7822\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4821 - acc: 0.8069 - f1score: 0.8069\n",
            "Epoch 00034: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4772 - acc: 0.8085 - f1score: 0.8089 - val_loss: 0.4920 - val_acc: 0.7843 - val_f1score: 0.7837\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4772 - acc: 0.8085 - f1score: 0.8089 - val_loss: 0.4920 - val_acc: 0.7843 - val_f1score: 0.7837\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4785 - acc: 0.8080 - f1score: 0.8080\n",
            "Epoch 00035: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4795 - acc: 0.8069 - f1score: 0.8065 - val_loss: 0.4937 - val_acc: 0.7811 - val_f1score: 0.7658\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4795 - acc: 0.8069 - f1score: 0.8065 - val_loss: 0.4937 - val_acc: 0.7811 - val_f1score: 0.7658\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4680 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00036: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4728 - acc: 0.8079 - f1score: 0.8063 - val_loss: 0.4927 - val_acc: 0.7833 - val_f1score: 0.7853\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4728 - acc: 0.8079 - f1score: 0.8063 - val_loss: 0.4927 - val_acc: 0.7833 - val_f1score: 0.7853\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4701 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00037: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4688 - acc: 0.8106 - f1score: 0.8107 - val_loss: 0.4878 - val_acc: 0.7908 - val_f1score: 0.7971\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4688 - acc: 0.8106 - f1score: 0.8107 - val_loss: 0.4878 - val_acc: 0.7908 - val_f1score: 0.7971\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4689 - acc: 0.8108 - f1score: 0.8108\n",
            "Epoch 00038: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4713 - acc: 0.8074 - f1score: 0.8064 - val_loss: 0.4856 - val_acc: 0.7908 - val_f1score: 0.7846\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4713 - acc: 0.8074 - f1score: 0.8064 - val_loss: 0.4856 - val_acc: 0.7908 - val_f1score: 0.7846\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4756 - acc: 0.8058 - f1score: 0.8058\n",
            "Epoch 00039: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4727 - acc: 0.8085 - f1score: 0.8092 - val_loss: 0.4851 - val_acc: 0.7843 - val_f1score: 0.7837\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4727 - acc: 0.8085 - f1score: 0.8092 - val_loss: 0.4851 - val_acc: 0.7843 - val_f1score: 0.7837\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4692 - acc: 0.8092 - f1score: 0.8092\n",
            "Epoch 00040: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4703 - acc: 0.8111 - f1score: 0.8117 - val_loss: 0.4874 - val_acc: 0.7854 - val_f1score: 0.7922\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4703 - acc: 0.8111 - f1score: 0.8117 - val_loss: 0.4874 - val_acc: 0.7854 - val_f1score: 0.7922\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4576 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00041: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4608 - acc: 0.8132 - f1score: 0.8126 - val_loss: 0.4870 - val_acc: 0.7843 - val_f1score: 0.7937\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4608 - acc: 0.8132 - f1score: 0.8126 - val_loss: 0.4870 - val_acc: 0.7843 - val_f1score: 0.7937\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4655 - acc: 0.8092 - f1score: 0.8092\n",
            "Epoch 00042: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4634 - acc: 0.8122 - f1score: 0.8130 - val_loss: 0.4866 - val_acc: 0.7811 - val_f1score: 0.7833\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4634 - acc: 0.8122 - f1score: 0.8130 - val_loss: 0.4866 - val_acc: 0.7811 - val_f1score: 0.7833\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4634 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00043: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4663 - acc: 0.8127 - f1score: 0.8124 - val_loss: 0.4863 - val_acc: 0.7854 - val_f1score: 0.7822\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4663 - acc: 0.8127 - f1score: 0.8124 - val_loss: 0.4863 - val_acc: 0.7854 - val_f1score: 0.7822\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4704 - acc: 0.8058 - f1score: 0.8058\n",
            "Epoch 00044: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4656 - acc: 0.8101 - f1score: 0.8113 - val_loss: 0.4863 - val_acc: 0.7843 - val_f1score: 0.7713\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4656 - acc: 0.8101 - f1score: 0.8113 - val_loss: 0.4863 - val_acc: 0.7843 - val_f1score: 0.7713\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4606 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00045: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4615 - acc: 0.8153 - f1score: 0.8152 - val_loss: 0.4866 - val_acc: 0.7854 - val_f1score: 0.7797\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4615 - acc: 0.8153 - f1score: 0.8152 - val_loss: 0.4866 - val_acc: 0.7854 - val_f1score: 0.7797\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4634 - acc: 0.8119 - f1score: 0.8119\n",
            "Epoch 00046: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4611 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4863 - val_acc: 0.7865 - val_f1score: 0.7907\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4611 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4863 - val_acc: 0.7865 - val_f1score: 0.7907\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4638 - acc: 0.8080 - f1score: 0.8080\n",
            "Epoch 00047: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4631 - acc: 0.8095 - f1score: 0.8099 - val_loss: 0.4864 - val_acc: 0.7822 - val_f1score: 0.7718\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4631 - acc: 0.8095 - f1score: 0.8099 - val_loss: 0.4864 - val_acc: 0.7822 - val_f1score: 0.7718\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4685 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00048: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4674 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4863 - val_acc: 0.7843 - val_f1score: 0.7862\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4674 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4863 - val_acc: 0.7843 - val_f1score: 0.7862\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4639 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00049: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4649 - acc: 0.8148 - f1score: 0.8153 - val_loss: 0.4863 - val_acc: 0.7833 - val_f1score: 0.7803\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4649 - acc: 0.8148 - f1score: 0.8153 - val_loss: 0.4863 - val_acc: 0.7833 - val_f1score: 0.7803\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4687 - acc: 0.8036 - f1score: 0.8036\n",
            "Epoch 00050: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4667 - acc: 0.8058 - f1score: 0.8065 - val_loss: 0.4869 - val_acc: 0.7833 - val_f1score: 0.7903\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4667 - acc: 0.8058 - f1score: 0.8065 - val_loss: 0.4869 - val_acc: 0.7833 - val_f1score: 0.7903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 36%|███▋      | 35/96 [2:20:10<3:27:57, 204.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.0018 - acc: 0.5441 - f1score: 0.5430\n",
            "Epoch 00001: val_acc improved from -inf to 0.70708, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.60.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.9829 - acc: 0.5434 - f1score: 0.5422 - val_loss: 0.6003 - val_acc: 0.7071 - val_f1score: 0.7059\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.70708, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.60.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.9829 - acc: 0.5434 - f1score: 0.5422 - val_loss: 0.6003 - val_acc: 0.7071 - val_f1score: 0.7059\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6076 - acc: 0.6892 - f1score: 0.6892\n",
            "Epoch 00002: val_acc improved from 0.70708 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.54.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6029 - acc: 0.6937 - f1score: 0.6949 - val_loss: 0.5442 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.70708 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.54.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6029 - acc: 0.6937 - f1score: 0.6949 - val_loss: 0.5442 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5503 - acc: 0.6953 - f1score: 0.6953\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5495 - acc: 0.6958 - f1score: 0.6959 - val_loss: 0.5067 - val_acc: 0.8015 - val_f1score: 0.8044\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5495 - acc: 0.6958 - f1score: 0.6959 - val_loss: 0.5067 - val_acc: 0.8015 - val_f1score: 0.8044\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5223 - acc: 0.7076 - f1score: 0.7076\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5199 - acc: 0.7069 - f1score: 0.7067 - val_loss: 0.5015 - val_acc: 0.7994 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5199 - acc: 0.7069 - f1score: 0.7067 - val_loss: 0.5015 - val_acc: 0.7994 - val_f1score: 0.8024\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5197 - acc: 0.6925 - f1score: 0.6925\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5200 - acc: 0.6931 - f1score: 0.6933 - val_loss: 0.5079 - val_acc: 0.8026 - val_f1score: 0.8053\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5200 - acc: 0.6931 - f1score: 0.6933 - val_loss: 0.5079 - val_acc: 0.8026 - val_f1score: 0.8053\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5158 - acc: 0.7165 - f1score: 0.7165\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5149 - acc: 0.7217 - f1score: 0.7232 - val_loss: 0.5031 - val_acc: 0.8036 - val_f1score: 0.8063\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5149 - acc: 0.7217 - f1score: 0.7232 - val_loss: 0.5031 - val_acc: 0.8036 - val_f1score: 0.8063\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5019 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4998 - acc: 0.8011 - f1score: 0.8019 - val_loss: 0.4984 - val_acc: 0.7994 - val_f1score: 0.7949\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4998 - acc: 0.8011 - f1score: 0.8019 - val_loss: 0.4984 - val_acc: 0.7994 - val_f1score: 0.7949\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4925 - acc: 0.8002 - f1score: 0.8002\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4924 - acc: 0.7995 - f1score: 0.7993 - val_loss: 0.4999 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4924 - acc: 0.7995 - f1score: 0.7993 - val_loss: 0.4999 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5094 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5087 - acc: 0.7995 - f1score: 0.8001 - val_loss: 0.5003 - val_acc: 0.8036 - val_f1score: 0.8063\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5087 - acc: 0.7995 - f1score: 0.8001 - val_loss: 0.5003 - val_acc: 0.8036 - val_f1score: 0.8063\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4956 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5024 - acc: 0.7963 - f1score: 0.7960 - val_loss: 0.4976 - val_acc: 0.7994 - val_f1score: 0.8049\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5024 - acc: 0.7963 - f1score: 0.7960 - val_loss: 0.4976 - val_acc: 0.7994 - val_f1score: 0.8049\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5131 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5144 - acc: 0.7952 - f1score: 0.7949 - val_loss: 0.5024 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5144 - acc: 0.7952 - f1score: 0.7949 - val_loss: 0.5024 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4827 - acc: 0.8002 - f1score: 0.8002\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4835 - acc: 0.8000 - f1score: 0.7999 - val_loss: 0.4973 - val_acc: 0.7897 - val_f1score: 0.7886\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4835 - acc: 0.8000 - f1score: 0.7999 - val_loss: 0.4973 - val_acc: 0.7897 - val_f1score: 0.7886\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5007 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5003 - acc: 0.7947 - f1score: 0.7938 - val_loss: 0.5019 - val_acc: 0.7843 - val_f1score: 0.7812\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5003 - acc: 0.7947 - f1score: 0.7938 - val_loss: 0.5019 - val_acc: 0.7843 - val_f1score: 0.7812\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4868 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4881 - acc: 0.7937 - f1score: 0.7929 - val_loss: 0.4955 - val_acc: 0.7822 - val_f1score: 0.7868\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4881 - acc: 0.7937 - f1score: 0.7929 - val_loss: 0.4955 - val_acc: 0.7822 - val_f1score: 0.7868\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4954 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4942 - acc: 0.7995 - f1score: 0.7997 - val_loss: 0.5007 - val_acc: 0.7854 - val_f1score: 0.7947\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4942 - acc: 0.7995 - f1score: 0.7997 - val_loss: 0.5007 - val_acc: 0.7854 - val_f1score: 0.7947\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4991 - acc: 0.7997 - f1score: 0.7997\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4960 - acc: 0.8005 - f1score: 0.8008 - val_loss: 0.4971 - val_acc: 0.7822 - val_f1score: 0.7868\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4960 - acc: 0.8005 - f1score: 0.8008 - val_loss: 0.4971 - val_acc: 0.7822 - val_f1score: 0.7868\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4968 - acc: 0.7919 - f1score: 0.7919\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4946 - acc: 0.7942 - f1score: 0.7948 - val_loss: 0.4981 - val_acc: 0.7854 - val_f1score: 0.7822\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4946 - acc: 0.7942 - f1score: 0.7948 - val_loss: 0.4981 - val_acc: 0.7854 - val_f1score: 0.7822\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4857 - acc: 0.7946 - f1score: 0.7946\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4871 - acc: 0.7942 - f1score: 0.7940 - val_loss: 0.4969 - val_acc: 0.7854 - val_f1score: 0.7922\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4871 - acc: 0.7942 - f1score: 0.7940 - val_loss: 0.4969 - val_acc: 0.7854 - val_f1score: 0.7922\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4946 - acc: 0.7896 - f1score: 0.7896\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4960 - acc: 0.7905 - f1score: 0.7907 - val_loss: 0.4969 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4960 - acc: 0.7905 - f1score: 0.7907 - val_loss: 0.4969 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5039 - acc: 0.7902 - f1score: 0.7902\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5036 - acc: 0.7899 - f1score: 0.7899 - val_loss: 0.4984 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5036 - acc: 0.7899 - f1score: 0.7899 - val_loss: 0.4984 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4930 - acc: 0.7913 - f1score: 0.7913\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4974 - acc: 0.7899 - f1score: 0.7896 - val_loss: 0.4986 - val_acc: 0.7800 - val_f1score: 0.7773\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4974 - acc: 0.7899 - f1score: 0.7896 - val_loss: 0.4986 - val_acc: 0.7800 - val_f1score: 0.7773\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4848 - acc: 0.8058 - f1score: 0.8058\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4898 - acc: 0.8026 - f1score: 0.8017 - val_loss: 0.4987 - val_acc: 0.7822 - val_f1score: 0.7768\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4898 - acc: 0.8026 - f1score: 0.8017 - val_loss: 0.4987 - val_acc: 0.7822 - val_f1score: 0.7768\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4838 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4810 - acc: 0.8011 - f1score: 0.8021 - val_loss: 0.4941 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4810 - acc: 0.8011 - f1score: 0.8021 - val_loss: 0.4941 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4899 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4905 - acc: 0.7958 - f1score: 0.7956 - val_loss: 0.4987 - val_acc: 0.7833 - val_f1score: 0.7828\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4905 - acc: 0.7958 - f1score: 0.7956 - val_loss: 0.4987 - val_acc: 0.7833 - val_f1score: 0.7828\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4812 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4854 - acc: 0.7958 - f1score: 0.7953 - val_loss: 0.4952 - val_acc: 0.7800 - val_f1score: 0.7724\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4854 - acc: 0.7958 - f1score: 0.7953 - val_loss: 0.4952 - val_acc: 0.7800 - val_f1score: 0.7724\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4871 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4868 - acc: 0.7974 - f1score: 0.7973 - val_loss: 0.4951 - val_acc: 0.7790 - val_f1score: 0.7814\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4868 - acc: 0.7974 - f1score: 0.7973 - val_loss: 0.4951 - val_acc: 0.7790 - val_f1score: 0.7814\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4795 - acc: 0.7991 - f1score: 0.7991\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4782 - acc: 0.8005 - f1score: 0.8009 - val_loss: 0.4944 - val_acc: 0.7800 - val_f1score: 0.7773\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4782 - acc: 0.8005 - f1score: 0.8009 - val_loss: 0.4944 - val_acc: 0.7800 - val_f1score: 0.7773\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4935 - acc: 0.7958 - f1score: 0.7958\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4942 - acc: 0.7947 - f1score: 0.7944 - val_loss: 0.4933 - val_acc: 0.7822 - val_f1score: 0.7718\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4942 - acc: 0.7947 - f1score: 0.7944 - val_loss: 0.4933 - val_acc: 0.7822 - val_f1score: 0.7718\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4890 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4885 - acc: 0.7937 - f1score: 0.7929 - val_loss: 0.4945 - val_acc: 0.7865 - val_f1score: 0.7782\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4885 - acc: 0.7937 - f1score: 0.7929 - val_loss: 0.4945 - val_acc: 0.7865 - val_f1score: 0.7782\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4848 - acc: 0.7941 - f1score: 0.7941\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4870 - acc: 0.7942 - f1score: 0.7942 - val_loss: 0.4942 - val_acc: 0.7800 - val_f1score: 0.7748\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4870 - acc: 0.7942 - f1score: 0.7942 - val_loss: 0.4942 - val_acc: 0.7800 - val_f1score: 0.7748\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4852 - acc: 0.7919 - f1score: 0.7919\n",
            "Epoch 00031: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4859 - acc: 0.7921 - f1score: 0.7921 - val_loss: 0.4935 - val_acc: 0.7811 - val_f1score: 0.7883\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4859 - acc: 0.7921 - f1score: 0.7921 - val_loss: 0.4935 - val_acc: 0.7811 - val_f1score: 0.7883\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4879 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00032: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4889 - acc: 0.7984 - f1score: 0.7985 - val_loss: 0.4948 - val_acc: 0.7833 - val_f1score: 0.7878\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4889 - acc: 0.7984 - f1score: 0.7985 - val_loss: 0.4948 - val_acc: 0.7833 - val_f1score: 0.7878\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4840 - acc: 0.7952 - f1score: 0.7952\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4826 - acc: 0.7984 - f1score: 0.7993 - val_loss: 0.4934 - val_acc: 0.7800 - val_f1score: 0.7748\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4826 - acc: 0.7984 - f1score: 0.7993 - val_loss: 0.4934 - val_acc: 0.7800 - val_f1score: 0.7748\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4902 - acc: 0.7946 - f1score: 0.7946\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4903 - acc: 0.7942 - f1score: 0.7940 - val_loss: 0.4931 - val_acc: 0.7779 - val_f1score: 0.7754\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4903 - acc: 0.7942 - f1score: 0.7940 - val_loss: 0.4931 - val_acc: 0.7779 - val_f1score: 0.7754\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4820 - acc: 0.7935 - f1score: 0.7935\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4834 - acc: 0.7952 - f1score: 0.7957 - val_loss: 0.4948 - val_acc: 0.7800 - val_f1score: 0.7823\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4834 - acc: 0.7952 - f1score: 0.7957 - val_loss: 0.4948 - val_acc: 0.7800 - val_f1score: 0.7823\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4811 - acc: 0.7946 - f1score: 0.7946\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4812 - acc: 0.7931 - f1score: 0.7927 - val_loss: 0.4919 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4812 - acc: 0.7931 - f1score: 0.7927 - val_loss: 0.4919 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4876 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4893 - acc: 0.7963 - f1score: 0.7963 - val_loss: 0.4905 - val_acc: 0.7833 - val_f1score: 0.7878\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4893 - acc: 0.7963 - f1score: 0.7963 - val_loss: 0.4905 - val_acc: 0.7833 - val_f1score: 0.7878\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4742 - acc: 0.7919 - f1score: 0.7919\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4720 - acc: 0.7952 - f1score: 0.7962 - val_loss: 0.4927 - val_acc: 0.7822 - val_f1score: 0.7768\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4720 - acc: 0.7952 - f1score: 0.7962 - val_loss: 0.4927 - val_acc: 0.7822 - val_f1score: 0.7768\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4970 - acc: 0.7919 - f1score: 0.7919\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4952 - acc: 0.7910 - f1score: 0.7908 - val_loss: 0.4916 - val_acc: 0.7800 - val_f1score: 0.7724\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4952 - acc: 0.7910 - f1score: 0.7908 - val_loss: 0.4916 - val_acc: 0.7800 - val_f1score: 0.7724\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4730 - acc: 0.7991 - f1score: 0.7991\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4796 - acc: 0.7952 - f1score: 0.7941 - val_loss: 0.4926 - val_acc: 0.7822 - val_f1score: 0.7818\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4796 - acc: 0.7952 - f1score: 0.7941 - val_loss: 0.4926 - val_acc: 0.7822 - val_f1score: 0.7818\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4743 - acc: 0.8013 - f1score: 0.8013\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4731 - acc: 0.8011 - f1score: 0.8010 - val_loss: 0.4932 - val_acc: 0.7833 - val_f1score: 0.7803\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4731 - acc: 0.8011 - f1score: 0.8010 - val_loss: 0.4932 - val_acc: 0.7833 - val_f1score: 0.7803\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4862 - acc: 0.7913 - f1score: 0.7913\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4829 - acc: 0.7947 - f1score: 0.7957 - val_loss: 0.4929 - val_acc: 0.7822 - val_f1score: 0.7818\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4829 - acc: 0.7947 - f1score: 0.7957 - val_loss: 0.4929 - val_acc: 0.7822 - val_f1score: 0.7818\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4669 - acc: 0.8036 - f1score: 0.8036\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4743 - acc: 0.8000 - f1score: 0.7990 - val_loss: 0.4924 - val_acc: 0.7800 - val_f1score: 0.7898\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4743 - acc: 0.8000 - f1score: 0.7990 - val_loss: 0.4924 - val_acc: 0.7800 - val_f1score: 0.7898\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4829 - acc: 0.7930 - f1score: 0.7930\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4854 - acc: 0.7889 - f1score: 0.7877 - val_loss: 0.4934 - val_acc: 0.7790 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4854 - acc: 0.7889 - f1score: 0.7877 - val_loss: 0.4934 - val_acc: 0.7790 - val_f1score: 0.7888\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4736 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4733 - acc: 0.7968 - f1score: 0.7968 - val_loss: 0.4918 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4733 - acc: 0.7968 - f1score: 0.7968 - val_loss: 0.4918 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4701 - acc: 0.8008 - f1score: 0.8008\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4698 - acc: 0.7995 - f1score: 0.7991 - val_loss: 0.4902 - val_acc: 0.7822 - val_f1score: 0.7843\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4698 - acc: 0.7995 - f1score: 0.7991 - val_loss: 0.4902 - val_acc: 0.7822 - val_f1score: 0.7843\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4742 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00047: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4729 - acc: 0.7989 - f1score: 0.7994 - val_loss: 0.4892 - val_acc: 0.7822 - val_f1score: 0.7743\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4729 - acc: 0.7989 - f1score: 0.7994 - val_loss: 0.4892 - val_acc: 0.7822 - val_f1score: 0.7743\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4927 - acc: 0.7857 - f1score: 0.7857\n",
            "Epoch 00048: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4899 - acc: 0.7862 - f1score: 0.7864 - val_loss: 0.4923 - val_acc: 0.7822 - val_f1score: 0.7768\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4899 - acc: 0.7862 - f1score: 0.7864 - val_loss: 0.4923 - val_acc: 0.7822 - val_f1score: 0.7768\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4671 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00049: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4718 - acc: 0.7963 - f1score: 0.7961 - val_loss: 0.4915 - val_acc: 0.7822 - val_f1score: 0.7793\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4718 - acc: 0.7963 - f1score: 0.7961 - val_loss: 0.4915 - val_acc: 0.7822 - val_f1score: 0.7793\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4832 - acc: 0.7941 - f1score: 0.7941\n",
            "Epoch 00050: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4855 - acc: 0.7963 - f1score: 0.7969 - val_loss: 0.4937 - val_acc: 0.7800 - val_f1score: 0.7898\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4855 - acc: 0.7963 - f1score: 0.7969 - val_loss: 0.4937 - val_acc: 0.7800 - val_f1score: 0.7898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 38%|███▊      | 36/96 [2:26:10<4:11:22, 251.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1762 - acc: 0.7210 - f1score: 0.7210\n",
            "Epoch 00001: val_acc improved from -inf to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.74.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.1455 - acc: 0.7249 - f1score: 0.7260 - val_loss: 1.7375 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.74.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.1455 - acc: 0.7249 - f1score: 0.7260 - val_loss: 1.7375 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.6298 - acc: 0.7712 - f1score: 0.7712\n",
            "Epoch 00002: val_acc improved from 0.79292 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.43.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.6494 - acc: 0.7693 - f1score: 0.7688 - val_loss: 1.4305 - val_acc: 0.8004 - val_f1score: 0.8109\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.79292 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.43.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.6494 - acc: 0.7693 - f1score: 0.7688 - val_loss: 1.4305 - val_acc: 0.8004 - val_f1score: 0.8109\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.2678 - acc: 0.7483 - f1score: 0.7483\n",
            "Epoch 00003: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.92.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.2463 - acc: 0.7508 - f1score: 0.7515 - val_loss: 0.9175 - val_acc: 0.8036 - val_f1score: 0.8063\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.92.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.2463 - acc: 0.7508 - f1score: 0.7515 - val_loss: 0.9175 - val_acc: 0.8036 - val_f1score: 0.8063\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.9012 - acc: 0.7567 - f1score: 0.7567\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.8846 - acc: 0.7608 - f1score: 0.7620 - val_loss: 0.6890 - val_acc: 0.7908 - val_f1score: 0.7996\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.8846 - acc: 0.7608 - f1score: 0.7620 - val_loss: 0.6890 - val_acc: 0.7908 - val_f1score: 0.7996\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6798 - acc: 0.7506 - f1score: 0.7506\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6819 - acc: 0.7513 - f1score: 0.7515 - val_loss: 0.5189 - val_acc: 0.8026 - val_f1score: 0.7979\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6819 - acc: 0.7513 - f1score: 0.7515 - val_loss: 0.5189 - val_acc: 0.8026 - val_f1score: 0.7979\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6053 - acc: 0.7701 - f1score: 0.7701\n",
            "Epoch 00006: val_acc improved from 0.80365 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.50.h5\n",
            "1890/1890 [==============================] - 6s 3ms/sample - loss: 0.6066 - acc: 0.7677 - f1score: 0.7670 - val_loss: 0.4982 - val_acc: 0.8058 - val_f1score: 0.7958\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.80365 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.50.h5\n",
            "1890/1890 [==============================] - 6s 3ms/sample - loss: 0.6066 - acc: 0.7677 - f1score: 0.7670 - val_loss: 0.4982 - val_acc: 0.8058 - val_f1score: 0.7958\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5447 - acc: 0.7863 - f1score: 0.7863\n",
            "Epoch 00007: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5399 - acc: 0.7868 - f1score: 0.7869 - val_loss: 0.5145 - val_acc: 0.7951 - val_f1score: 0.7960\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5399 - acc: 0.7868 - f1score: 0.7869 - val_loss: 0.5145 - val_acc: 0.7951 - val_f1score: 0.7960\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5213 - acc: 0.7913 - f1score: 0.7913\n",
            "Epoch 00008: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5190 - acc: 0.7915 - f1score: 0.7916 - val_loss: 0.5033 - val_acc: 0.7897 - val_f1score: 0.7836\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5190 - acc: 0.7915 - f1score: 0.7916 - val_loss: 0.5033 - val_acc: 0.7897 - val_f1score: 0.7836\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4898 - acc: 0.7991 - f1score: 0.7991\n",
            "Epoch 00009: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4859 - acc: 0.8000 - f1score: 0.8003 - val_loss: 0.5017 - val_acc: 0.7854 - val_f1score: 0.7947\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4859 - acc: 0.8000 - f1score: 0.8003 - val_loss: 0.5017 - val_acc: 0.7854 - val_f1score: 0.7947\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4699 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00010: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4770 - acc: 0.8116 - f1score: 0.8111 - val_loss: 0.4914 - val_acc: 0.7951 - val_f1score: 0.8060\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4770 - acc: 0.8116 - f1score: 0.8111 - val_loss: 0.4914 - val_acc: 0.7951 - val_f1score: 0.8060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 39%|███▊      | 37/96 [2:27:08<3:09:56, 193.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.9018 - acc: 0.6959 - f1score: 0.6959\n",
            "Epoch 00001: val_acc improved from -inf to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.07.h5\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.07.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.8893 - acc: 0.6958 - f1score: 0.6957 - val_loss: 1.0679 - val_acc: 0.8047 - val_f1score: 0.8098\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.8893 - acc: 0.6958 - f1score: 0.6957 - val_loss: 1.0679 - val_acc: 0.8047 - val_f1score: 0.8098\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.3400 - acc: 0.7282 - f1score: 0.7282\n",
            "Epoch 00002: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.3308 - acc: 0.7317 - f1score: 0.7327 - val_loss: 1.0425 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.3308 - acc: 0.7317 - f1score: 0.7327 - val_loss: 1.0425 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.0253 - acc: 0.7556 - f1score: 0.7556\n",
            "Epoch 00003: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.0179 - acc: 0.7529 - f1score: 0.7521 - val_loss: 0.6127 - val_acc: 0.7736 - val_f1score: 0.7715\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.0179 - acc: 0.7529 - f1score: 0.7521 - val_loss: 0.6127 - val_acc: 0.7736 - val_f1score: 0.7715\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.7330 - acc: 0.7556 - f1score: 0.7556\n",
            "Epoch 00004: val_acc improved from 0.80472 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.60.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.7247 - acc: 0.7582 - f1score: 0.7589 - val_loss: 0.5992 - val_acc: 0.8069 - val_f1score: 0.7968\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.80472 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.60.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.7247 - acc: 0.7582 - f1score: 0.7589 - val_loss: 0.5992 - val_acc: 0.8069 - val_f1score: 0.7968\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6490 - acc: 0.7773 - f1score: 0.7773\n",
            "Epoch 00005: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6698 - acc: 0.7778 - f1score: 0.7779 - val_loss: 0.5326 - val_acc: 0.8058 - val_f1score: 0.8158\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6698 - acc: 0.7778 - f1score: 0.7779 - val_loss: 0.5326 - val_acc: 0.8058 - val_f1score: 0.8158\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5782 - acc: 0.7684 - f1score: 0.7684\n",
            "Epoch 00006: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5850 - acc: 0.7693 - f1score: 0.7696 - val_loss: 0.5832 - val_acc: 0.8069 - val_f1score: 0.8043\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5850 - acc: 0.7693 - f1score: 0.7696 - val_loss: 0.5832 - val_acc: 0.8069 - val_f1score: 0.8043\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5486 - acc: 0.7846 - f1score: 0.7846\n",
            "Epoch 00007: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5466 - acc: 0.7836 - f1score: 0.7833 - val_loss: 0.4959 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5466 - acc: 0.7836 - f1score: 0.7833 - val_loss: 0.4959 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5229 - acc: 0.7857 - f1score: 0.7857\n",
            "Epoch 00008: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5204 - acc: 0.7868 - f1score: 0.7871 - val_loss: 0.5051 - val_acc: 0.7886 - val_f1score: 0.7852\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5204 - acc: 0.7868 - f1score: 0.7871 - val_loss: 0.5051 - val_acc: 0.7886 - val_f1score: 0.7852\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4918 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00009: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4931 - acc: 0.8106 - f1score: 0.8104 - val_loss: 0.4801 - val_acc: 0.8004 - val_f1score: 0.7909\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4931 - acc: 0.8106 - f1score: 0.8104 - val_loss: 0.4801 - val_acc: 0.8004 - val_f1score: 0.7909\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4751 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00010: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4748 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4940 - val_acc: 0.7994 - val_f1score: 0.7999\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4748 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4940 - val_acc: 0.7994 - val_f1score: 0.7999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 40%|███▉      | 38/96 [2:28:24<2:32:45, 158.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 3.1617 - acc: 0.5458 - f1score: 0.5458\n",
            "Epoch 00001: val_acc improved from -inf to 0.77253, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.48.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 3.1512 - acc: 0.5513 - f1score: 0.5529 - val_loss: 2.4757 - val_acc: 0.7725 - val_f1score: 0.7755\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77253, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.48.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 3.1512 - acc: 0.5513 - f1score: 0.5529 - val_loss: 2.4757 - val_acc: 0.7725 - val_f1score: 0.7755\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1747 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00002: val_acc improved from 0.77253 to 0.78004, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.48.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2330 - acc: 0.7931 - f1score: 0.7922 - val_loss: 2.4819 - val_acc: 0.7800 - val_f1score: 0.7898\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.77253 to 0.78004, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.48.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2330 - acc: 0.7931 - f1score: 0.7922 - val_loss: 2.4819 - val_acc: 0.7800 - val_f1score: 0.7898\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.2905 - acc: 0.8047 - f1score: 0.8047\n",
            "Epoch 00003: val_acc improved from 0.78004 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.03-2.42.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2813 - acc: 0.8053 - f1score: 0.8055 - val_loss: 2.4212 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.78004 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.03-2.42.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2813 - acc: 0.8053 - f1score: 0.8055 - val_loss: 2.4212 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.2579 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00004: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.35.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2370 - acc: 0.8000 - f1score: 0.8009 - val_loss: 2.3512 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.35.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2370 - acc: 0.8000 - f1score: 0.8009 - val_loss: 2.3512 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1402 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1760 - acc: 0.7931 - f1score: 0.7920 - val_loss: 2.3394 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1760 - acc: 0.7931 - f1score: 0.7920 - val_loss: 2.3394 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1898 - acc: 0.8052 - f1score: 0.8052\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1925 - acc: 0.8063 - f1score: 0.8067 - val_loss: 2.3434 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1925 - acc: 0.8063 - f1score: 0.8067 - val_loss: 2.3434 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.0153 - acc: 0.7997 - f1score: 0.7997\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.0144 - acc: 0.7968 - f1score: 0.7960 - val_loss: 1.9410 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.0144 - acc: 0.7968 - f1score: 0.7960 - val_loss: 1.9410 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.9975 - acc: 0.7746 - f1score: 0.7746\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.9760 - acc: 0.7788 - f1score: 0.7801 - val_loss: 2.2506 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.9760 - acc: 0.7788 - f1score: 0.7801 - val_loss: 2.2506 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.8039 - acc: 0.7768 - f1score: 0.7768\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.7913 - acc: 0.7788 - f1score: 0.7794 - val_loss: 2.1186 - val_acc: 0.7779 - val_f1score: 0.7779\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.7913 - acc: 0.7788 - f1score: 0.7794 - val_loss: 2.1186 - val_acc: 0.7779 - val_f1score: 0.7779\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.7196 - acc: 0.7779 - f1score: 0.7779\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.7034 - acc: 0.7746 - f1score: 0.7737 - val_loss: 1.2371 - val_acc: 0.7650 - val_f1score: 0.7662\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.7034 - acc: 0.7746 - f1score: 0.7737 - val_loss: 1.2371 - val_acc: 0.7650 - val_f1score: 0.7662\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.5623 - acc: 0.7567 - f1score: 0.7567\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.5313 - acc: 0.7598 - f1score: 0.7607 - val_loss: 1.1335 - val_acc: 0.7886 - val_f1score: 0.7877\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.5313 - acc: 0.7598 - f1score: 0.7607 - val_loss: 1.1335 - val_acc: 0.7886 - val_f1score: 0.7877\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.1703 - acc: 0.7467 - f1score: 0.7467\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.1718 - acc: 0.7444 - f1score: 0.7438 - val_loss: 1.0645 - val_acc: 0.7800 - val_f1score: 0.7674\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.1718 - acc: 0.7444 - f1score: 0.7438 - val_loss: 1.0645 - val_acc: 0.7800 - val_f1score: 0.7674\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.8576 - acc: 0.7673 - f1score: 0.7673\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.8572 - acc: 0.7630 - f1score: 0.7617 - val_loss: 0.5197 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.8572 - acc: 0.7630 - f1score: 0.7617 - val_loss: 0.5197 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6548 - acc: 0.7768 - f1score: 0.7768\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6502 - acc: 0.7762 - f1score: 0.7760 - val_loss: 0.4984 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6502 - acc: 0.7762 - f1score: 0.7760 - val_loss: 0.4984 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5438 - acc: 0.7807 - f1score: 0.7807\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5347 - acc: 0.7847 - f1score: 0.7858 - val_loss: 0.4780 - val_acc: 0.8015 - val_f1score: 0.8143\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5347 - acc: 0.7847 - f1score: 0.7858 - val_loss: 0.4780 - val_acc: 0.8015 - val_f1score: 0.8143\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5125 - acc: 0.7919 - f1score: 0.7919\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5112 - acc: 0.7921 - f1score: 0.7921 - val_loss: 0.4963 - val_acc: 0.7994 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5112 - acc: 0.7921 - f1score: 0.7921 - val_loss: 0.4963 - val_acc: 0.7994 - val_f1score: 0.8024\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4688 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4711 - acc: 0.8143 - f1score: 0.8143 - val_loss: 0.5329 - val_acc: 0.7940 - val_f1score: 0.8025\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4711 - acc: 0.8143 - f1score: 0.8143 - val_loss: 0.5329 - val_acc: 0.7940 - val_f1score: 0.8025\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4679 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4628 - acc: 0.8153 - f1score: 0.8157 - val_loss: 0.4879 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4628 - acc: 0.8153 - f1score: 0.8157 - val_loss: 0.4879 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4542 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4526 - acc: 0.8159 - f1score: 0.8159 - val_loss: 0.4809 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4526 - acc: 0.8159 - f1score: 0.8159 - val_loss: 0.4809 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4453 - acc: 0.8186 - f1score: 0.8186\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4472 - acc: 0.8159 - f1score: 0.8151 - val_loss: 0.4778 - val_acc: 0.7908 - val_f1score: 0.7971\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4472 - acc: 0.8159 - f1score: 0.8151 - val_loss: 0.4778 - val_acc: 0.7908 - val_f1score: 0.7971\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4549 - acc: 0.8119 - f1score: 0.8119\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4565 - acc: 0.8106 - f1score: 0.8102 - val_loss: 0.4928 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4565 - acc: 0.8106 - f1score: 0.8102 - val_loss: 0.4928 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4424 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4500 - acc: 0.8132 - f1score: 0.8123 - val_loss: 0.4822 - val_acc: 0.7908 - val_f1score: 0.7796\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4500 - acc: 0.8132 - f1score: 0.8123 - val_loss: 0.4822 - val_acc: 0.7908 - val_f1score: 0.7796\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4492 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4504 - acc: 0.8127 - f1score: 0.8128 - val_loss: 0.4907 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4504 - acc: 0.8127 - f1score: 0.8128 - val_loss: 0.4907 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4564 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4552 - acc: 0.8127 - f1score: 0.8123 - val_loss: 0.4825 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4552 - acc: 0.8127 - f1score: 0.8123 - val_loss: 0.4825 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4563 - acc: 0.8097 - f1score: 0.8097\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4474 - acc: 0.8164 - f1score: 0.8183 - val_loss: 0.4816 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4474 - acc: 0.8164 - f1score: 0.8183 - val_loss: 0.4816 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4519 - acc: 0.8092 - f1score: 0.8092\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4458 - acc: 0.8143 - f1score: 0.8158 - val_loss: 0.4820 - val_acc: 0.7908 - val_f1score: 0.7846\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4458 - acc: 0.8143 - f1score: 0.8158 - val_loss: 0.4820 - val_acc: 0.7908 - val_f1score: 0.7846\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4452 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4497 - acc: 0.8153 - f1score: 0.8147 - val_loss: 0.4811 - val_acc: 0.7822 - val_f1score: 0.7918\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4497 - acc: 0.8153 - f1score: 0.8147 - val_loss: 0.4811 - val_acc: 0.7822 - val_f1score: 0.7918\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4516 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4460 - acc: 0.8185 - f1score: 0.8196 - val_loss: 0.4784 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4460 - acc: 0.8185 - f1score: 0.8196 - val_loss: 0.4784 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4495 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4444 - acc: 0.8180 - f1score: 0.8186 - val_loss: 0.4832 - val_acc: 0.7843 - val_f1score: 0.7812\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4444 - acc: 0.8180 - f1score: 0.8186 - val_loss: 0.4832 - val_acc: 0.7843 - val_f1score: 0.7812\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4419 - acc: 0.8214 - f1score: 0.8214\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4451 - acc: 0.8190 - f1score: 0.8184 - val_loss: 0.4780 - val_acc: 0.7833 - val_f1score: 0.7703\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4451 - acc: 0.8190 - f1score: 0.8184 - val_loss: 0.4780 - val_acc: 0.7833 - val_f1score: 0.7703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 41%|████      | 39/96 [2:31:03<2:30:26, 158.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.9449 - acc: 0.6523 - f1score: 0.6523\n",
            "Epoch 00001: val_acc improved from -inf to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.42.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.9033 - acc: 0.6608 - f1score: 0.6633 - val_loss: 2.4245 - val_acc: 0.8026 - val_f1score: 0.7979\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.42.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.9033 - acc: 0.6608 - f1score: 0.6633 - val_loss: 2.4245 - val_acc: 0.8026 - val_f1score: 0.7979\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1347 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00002: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.1814 - acc: 0.7952 - f1score: 0.7943 - val_loss: 2.2982 - val_acc: 0.7972 - val_f1score: 0.7955\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.1814 - acc: 0.7952 - f1score: 0.7943 - val_loss: 2.2982 - val_acc: 0.7972 - val_f1score: 0.7955\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.0093 - acc: 0.7891 - f1score: 0.7891\n",
            "Epoch 00003: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.0009 - acc: 0.7873 - f1score: 0.7868 - val_loss: 1.9106 - val_acc: 0.7929 - val_f1score: 0.8065\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.0009 - acc: 0.7873 - f1score: 0.7868 - val_loss: 1.9106 - val_acc: 0.7929 - val_f1score: 0.8065\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.6708 - acc: 0.7679 - f1score: 0.7679\n",
            "Epoch 00004: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.6774 - acc: 0.7683 - f1score: 0.7684 - val_loss: 1.4500 - val_acc: 0.7994 - val_f1score: 0.7949\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.6774 - acc: 0.7683 - f1score: 0.7684 - val_loss: 1.4500 - val_acc: 0.7994 - val_f1score: 0.7949\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.1078 - acc: 0.7701 - f1score: 0.7701\n",
            "Epoch 00005: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.1134 - acc: 0.7672 - f1score: 0.7664 - val_loss: 0.9238 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.1134 - acc: 0.7672 - f1score: 0.7664 - val_loss: 0.9238 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.8198 - acc: 0.7433 - f1score: 0.7433\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.8042 - acc: 0.7434 - f1score: 0.7434 - val_loss: 0.5272 - val_acc: 0.7994 - val_f1score: 0.7874\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.8042 - acc: 0.7434 - f1score: 0.7434 - val_loss: 0.5272 - val_acc: 0.7994 - val_f1score: 0.7874\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6031 - acc: 0.7796 - f1score: 0.7796\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6050 - acc: 0.7783 - f1score: 0.7779 - val_loss: 0.5036 - val_acc: 0.7983 - val_f1score: 0.7989\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6050 - acc: 0.7783 - f1score: 0.7779 - val_loss: 0.5036 - val_acc: 0.7983 - val_f1score: 0.7989\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5359 - acc: 0.7896 - f1score: 0.7896\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5334 - acc: 0.7915 - f1score: 0.7921 - val_loss: 0.4926 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5334 - acc: 0.7915 - f1score: 0.7921 - val_loss: 0.4926 - val_acc: 0.8015 - val_f1score: 0.7994\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4836 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4838 - acc: 0.8148 - f1score: 0.8145 - val_loss: 0.4766 - val_acc: 0.8015 - val_f1score: 0.7969\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4838 - acc: 0.8148 - f1score: 0.8145 - val_loss: 0.4766 - val_acc: 0.8015 - val_f1score: 0.7969\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4623 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4645 - acc: 0.8111 - f1score: 0.8107 - val_loss: 0.4787 - val_acc: 0.7983 - val_f1score: 0.7964\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4645 - acc: 0.8111 - f1score: 0.8107 - val_loss: 0.4787 - val_acc: 0.7983 - val_f1score: 0.7964\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4545 - acc: 0.8119 - f1score: 0.8119\n",
            "Epoch 00011: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4523 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4801 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4523 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4801 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4542 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4540 - acc: 0.8148 - f1score: 0.8147 - val_loss: 0.4768 - val_acc: 0.7983 - val_f1score: 0.8039\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4540 - acc: 0.8148 - f1score: 0.8147 - val_loss: 0.4768 - val_acc: 0.7983 - val_f1score: 0.8039\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4572 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4546 - acc: 0.8127 - f1score: 0.8131 - val_loss: 0.4766 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4546 - acc: 0.8127 - f1score: 0.8131 - val_loss: 0.4766 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4521 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00014: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4500 - acc: 0.8169 - f1score: 0.8174 - val_loss: 0.4807 - val_acc: 0.7972 - val_f1score: 0.7930\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4500 - acc: 0.8169 - f1score: 0.8174 - val_loss: 0.4807 - val_acc: 0.7972 - val_f1score: 0.7930\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4526 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00015: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4479 - acc: 0.8169 - f1score: 0.8177 - val_loss: 0.4849 - val_acc: 0.8004 - val_f1score: 0.8109\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4479 - acc: 0.8169 - f1score: 0.8177 - val_loss: 0.4849 - val_acc: 0.8004 - val_f1score: 0.8109\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4574 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00016: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4514 - acc: 0.8190 - f1score: 0.8201 - val_loss: 0.4796 - val_acc: 0.7940 - val_f1score: 0.7826\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4514 - acc: 0.8190 - f1score: 0.8201 - val_loss: 0.4796 - val_acc: 0.7940 - val_f1score: 0.7826\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4497 - acc: 0.8192 - f1score: 0.8192\n",
            "Epoch 00017: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4476 - acc: 0.8196 - f1score: 0.8197 - val_loss: 0.4818 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4476 - acc: 0.8196 - f1score: 0.8197 - val_loss: 0.4818 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4506 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00018: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4471 - acc: 0.8143 - f1score: 0.8146 - val_loss: 0.4810 - val_acc: 0.7897 - val_f1score: 0.7886\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4471 - acc: 0.8143 - f1score: 0.8146 - val_loss: 0.4810 - val_acc: 0.7897 - val_f1score: 0.7886\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4461 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00019: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4493 - acc: 0.8153 - f1score: 0.8149 - val_loss: 0.4831 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4493 - acc: 0.8153 - f1score: 0.8149 - val_loss: 0.4831 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4476 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00020: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4512 - acc: 0.8127 - f1score: 0.8128 - val_loss: 0.4807 - val_acc: 0.7854 - val_f1score: 0.7922\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4512 - acc: 0.8127 - f1score: 0.8128 - val_loss: 0.4807 - val_acc: 0.7854 - val_f1score: 0.7922\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4531 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00021: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4515 - acc: 0.8153 - f1score: 0.8162 - val_loss: 0.4805 - val_acc: 0.7897 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4515 - acc: 0.8153 - f1score: 0.8162 - val_loss: 0.4805 - val_acc: 0.7897 - val_f1score: 0.7936\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4497 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00022: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4479 - acc: 0.8175 - f1score: 0.8181 - val_loss: 0.4856 - val_acc: 0.7843 - val_f1score: 0.7788\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4479 - acc: 0.8175 - f1score: 0.8181 - val_loss: 0.4856 - val_acc: 0.7843 - val_f1score: 0.7788\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4408 - acc: 0.8231 - f1score: 0.8231\n",
            "Epoch 00023: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4410 - acc: 0.8228 - f1score: 0.8227 - val_loss: 0.4809 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4410 - acc: 0.8228 - f1score: 0.8227 - val_loss: 0.4809 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4452 - acc: 0.8192 - f1score: 0.8192\n",
            "Epoch 00024: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4502 - acc: 0.8159 - f1score: 0.8149 - val_loss: 0.4822 - val_acc: 0.7897 - val_f1score: 0.7737\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4502 - acc: 0.8159 - f1score: 0.8149 - val_loss: 0.4822 - val_acc: 0.7897 - val_f1score: 0.7737\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4462 - acc: 0.8192 - f1score: 0.8192\n",
            "Epoch 00025: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4453 - acc: 0.8196 - f1score: 0.8197 - val_loss: 0.4832 - val_acc: 0.7854 - val_f1score: 0.7722\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4453 - acc: 0.8196 - f1score: 0.8197 - val_loss: 0.4832 - val_acc: 0.7854 - val_f1score: 0.7722\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4474 - acc: 0.8181 - f1score: 0.8181\n",
            "Epoch 00026: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4444 - acc: 0.8206 - f1score: 0.8214 - val_loss: 0.4800 - val_acc: 0.7843 - val_f1score: 0.7812\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4444 - acc: 0.8206 - f1score: 0.8214 - val_loss: 0.4800 - val_acc: 0.7843 - val_f1score: 0.7812\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4522 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00027: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4482 - acc: 0.8153 - f1score: 0.8158 - val_loss: 0.4794 - val_acc: 0.7854 - val_f1score: 0.7847\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4482 - acc: 0.8153 - f1score: 0.8158 - val_loss: 0.4794 - val_acc: 0.7854 - val_f1score: 0.7847\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4544 - acc: 0.8181 - f1score: 0.8181\n",
            "Epoch 00028: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4469 - acc: 0.8222 - f1score: 0.8234 - val_loss: 0.4814 - val_acc: 0.7897 - val_f1score: 0.7786\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4469 - acc: 0.8222 - f1score: 0.8234 - val_loss: 0.4814 - val_acc: 0.7897 - val_f1score: 0.7786\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4391 - acc: 0.8220 - f1score: 0.8220\n",
            "Epoch 00029: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4424 - acc: 0.8201 - f1score: 0.8196 - val_loss: 0.4821 - val_acc: 0.7822 - val_f1score: 0.7768\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4424 - acc: 0.8201 - f1score: 0.8196 - val_loss: 0.4821 - val_acc: 0.7822 - val_f1score: 0.7768\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4449 - acc: 0.8198 - f1score: 0.8198\n",
            "Epoch 00030: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4433 - acc: 0.8222 - f1score: 0.8229 - val_loss: 0.4786 - val_acc: 0.7908 - val_f1score: 0.7871\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4433 - acc: 0.8222 - f1score: 0.8229 - val_loss: 0.4786 - val_acc: 0.7908 - val_f1score: 0.7871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 42%|████▏     | 40/96 [2:34:41<2:44:28, 176.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.9892 - acc: 0.5184 - f1score: 0.5184\n",
            "Epoch 00001: val_acc improved from -inf to 0.56867, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.41.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.9147 - acc: 0.5212 - f1score: 0.5219 - val_loss: 2.4066 - val_acc: 0.5687 - val_f1score: 0.5725\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.56867, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.41.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.9147 - acc: 0.5212 - f1score: 0.5219 - val_loss: 2.4066 - val_acc: 0.5687 - val_f1score: 0.5725\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.3669 - acc: 0.6289 - f1score: 0.6289\n",
            "Epoch 00002: val_acc improved from 0.56867 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.90.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.3264 - acc: 0.6381 - f1score: 0.6407 - val_loss: 1.9045 - val_acc: 0.7929 - val_f1score: 0.7965\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.56867 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.90.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.3264 - acc: 0.6381 - f1score: 0.6407 - val_loss: 1.9045 - val_acc: 0.7929 - val_f1score: 0.7965\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.8720 - acc: 0.7868 - f1score: 0.7868\n",
            "Epoch 00003: val_acc improved from 0.79292 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.03-1.88.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.8768 - acc: 0.7862 - f1score: 0.7861 - val_loss: 1.8840 - val_acc: 0.8036 - val_f1score: 0.8088\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.79292 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.03-1.88.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.8768 - acc: 0.7862 - f1score: 0.7861 - val_loss: 1.8840 - val_acc: 0.8036 - val_f1score: 0.8088\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.7425 - acc: 0.7868 - f1score: 0.7868\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.7781 - acc: 0.7825 - f1score: 0.7813 - val_loss: 1.7998 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.7781 - acc: 0.7825 - f1score: 0.7813 - val_loss: 1.7998 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.6999 - acc: 0.7623 - f1score: 0.7623\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.6626 - acc: 0.7656 - f1score: 0.7666 - val_loss: 1.5925 - val_acc: 0.7876 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.6626 - acc: 0.7656 - f1score: 0.7666 - val_loss: 1.5925 - val_acc: 0.7876 - val_f1score: 0.7917\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.4550 - acc: 0.7640 - f1score: 0.7640\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.4545 - acc: 0.7630 - f1score: 0.7627 - val_loss: 1.3691 - val_acc: 0.7811 - val_f1score: 0.7758\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.4545 - acc: 0.7630 - f1score: 0.7627 - val_loss: 1.3691 - val_acc: 0.7811 - val_f1score: 0.7758\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.3354 - acc: 0.7288 - f1score: 0.7288\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.3261 - acc: 0.7291 - f1score: 0.7292 - val_loss: 1.0281 - val_acc: 0.7876 - val_f1score: 0.7867\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.3261 - acc: 0.7291 - f1score: 0.7292 - val_loss: 1.0281 - val_acc: 0.7876 - val_f1score: 0.7867\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.0741 - acc: 0.7494 - f1score: 0.7494\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.0649 - acc: 0.7481 - f1score: 0.7478 - val_loss: 0.9111 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.0649 - acc: 0.7481 - f1score: 0.7478 - val_loss: 0.9111 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.9714 - acc: 0.7550 - f1score: 0.7550\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.9656 - acc: 0.7582 - f1score: 0.7591 - val_loss: 1.0547 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.9656 - acc: 0.7582 - f1score: 0.7591 - val_loss: 1.0547 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.8642 - acc: 0.7573 - f1score: 0.7573\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.8542 - acc: 0.7566 - f1score: 0.7564 - val_loss: 0.7849 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.8542 - acc: 0.7566 - f1score: 0.7564 - val_loss: 0.7849 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.7667 - acc: 0.7634 - f1score: 0.7634\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.7569 - acc: 0.7672 - f1score: 0.7683 - val_loss: 0.6632 - val_acc: 0.8004 - val_f1score: 0.8159\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.7569 - acc: 0.7672 - f1score: 0.7683 - val_loss: 0.6632 - val_acc: 0.8004 - val_f1score: 0.8159\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.7302 - acc: 0.7757 - f1score: 0.7757\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.7354 - acc: 0.7741 - f1score: 0.7736 - val_loss: 0.6547 - val_acc: 0.7929 - val_f1score: 0.7965\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.7354 - acc: 0.7741 - f1score: 0.7736 - val_loss: 0.6547 - val_acc: 0.7929 - val_f1score: 0.7965\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6633 - acc: 0.7634 - f1score: 0.7634\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6573 - acc: 0.7672 - f1score: 0.7683 - val_loss: 0.5595 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6573 - acc: 0.7672 - f1score: 0.7683 - val_loss: 0.5595 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6549 - acc: 0.7712 - f1score: 0.7712\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6490 - acc: 0.7698 - f1score: 0.7695 - val_loss: 0.5601 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6490 - acc: 0.7698 - f1score: 0.7695 - val_loss: 0.5601 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5828 - acc: 0.7919 - f1score: 0.7919\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5779 - acc: 0.7905 - f1score: 0.7901 - val_loss: 0.5272 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5779 - acc: 0.7905 - f1score: 0.7901 - val_loss: 0.5272 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5285 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5286 - acc: 0.7958 - f1score: 0.7951 - val_loss: 0.4975 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5286 - acc: 0.7958 - f1score: 0.7951 - val_loss: 0.4975 - val_acc: 0.8004 - val_f1score: 0.7959\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4964 - acc: 0.8025 - f1score: 0.8025\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4994 - acc: 0.8011 - f1score: 0.8007 - val_loss: 0.4836 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4994 - acc: 0.8011 - f1score: 0.8007 - val_loss: 0.4836 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4733 - acc: 0.8097 - f1score: 0.8097\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4719 - acc: 0.8095 - f1score: 0.8095 - val_loss: 0.4757 - val_acc: 0.7940 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4719 - acc: 0.8095 - f1score: 0.8095 - val_loss: 0.4757 - val_acc: 0.7940 - val_f1score: 0.8000\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4880 - acc: 0.8080 - f1score: 0.8080\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4878 - acc: 0.8106 - f1score: 0.8113 - val_loss: 0.4799 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4878 - acc: 0.8106 - f1score: 0.8113 - val_loss: 0.4799 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4750 - acc: 0.8058 - f1score: 0.8058\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4691 - acc: 0.8106 - f1score: 0.8119 - val_loss: 0.4794 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4691 - acc: 0.8106 - f1score: 0.8119 - val_loss: 0.4794 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4526 - acc: 0.8119 - f1score: 0.8119\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4543 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4768 - val_acc: 0.7951 - val_f1score: 0.7985\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4543 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4768 - val_acc: 0.7951 - val_f1score: 0.7985\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4680 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4634 - acc: 0.8169 - f1score: 0.8176 - val_loss: 0.4773 - val_acc: 0.7940 - val_f1score: 0.7875\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4634 - acc: 0.8169 - f1score: 0.8176 - val_loss: 0.4773 - val_acc: 0.7940 - val_f1score: 0.7875\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4452 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4495 - acc: 0.8111 - f1score: 0.8106 - val_loss: 0.4830 - val_acc: 0.7908 - val_f1score: 0.7946\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4495 - acc: 0.8111 - f1score: 0.8106 - val_loss: 0.4830 - val_acc: 0.7908 - val_f1score: 0.7946\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4599 - acc: 0.8097 - f1score: 0.8097\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4580 - acc: 0.8116 - f1score: 0.8122 - val_loss: 0.4841 - val_acc: 0.7876 - val_f1score: 0.7892\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4580 - acc: 0.8116 - f1score: 0.8122 - val_loss: 0.4841 - val_acc: 0.7876 - val_f1score: 0.7892\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4530 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4558 - acc: 0.8138 - f1score: 0.8132 - val_loss: 0.4885 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4558 - acc: 0.8138 - f1score: 0.8132 - val_loss: 0.4885 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4590 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4571 - acc: 0.8169 - f1score: 0.8171 - val_loss: 0.4832 - val_acc: 0.7908 - val_f1score: 0.7971\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4571 - acc: 0.8169 - f1score: 0.8171 - val_loss: 0.4832 - val_acc: 0.7908 - val_f1score: 0.7971\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4435 - acc: 0.8198 - f1score: 0.8198\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4460 - acc: 0.8185 - f1score: 0.8182 - val_loss: 0.4893 - val_acc: 0.7843 - val_f1score: 0.7987\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4460 - acc: 0.8185 - f1score: 0.8182 - val_loss: 0.4893 - val_acc: 0.7843 - val_f1score: 0.7987\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4399 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4386 - acc: 0.8185 - f1score: 0.8193 - val_loss: 0.4828 - val_acc: 0.7908 - val_f1score: 0.7846\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4386 - acc: 0.8185 - f1score: 0.8193 - val_loss: 0.4828 - val_acc: 0.7908 - val_f1score: 0.7846\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4409 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4454 - acc: 0.8132 - f1score: 0.8128 - val_loss: 0.4840 - val_acc: 0.7897 - val_f1score: 0.7961\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4454 - acc: 0.8132 - f1score: 0.8128 - val_loss: 0.4840 - val_acc: 0.7897 - val_f1score: 0.7961\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4498 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4521 - acc: 0.8127 - f1score: 0.8121 - val_loss: 0.4820 - val_acc: 0.7897 - val_f1score: 0.7886\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4521 - acc: 0.8127 - f1score: 0.8121 - val_loss: 0.4820 - val_acc: 0.7897 - val_f1score: 0.7886\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4441 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00031: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4434 - acc: 0.8143 - f1score: 0.8143 - val_loss: 0.4843 - val_acc: 0.7897 - val_f1score: 0.7961\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4434 - acc: 0.8143 - f1score: 0.8143 - val_loss: 0.4843 - val_acc: 0.7897 - val_f1score: 0.7961\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4423 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00032: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4429 - acc: 0.8148 - f1score: 0.8145 - val_loss: 0.4822 - val_acc: 0.7876 - val_f1score: 0.7792\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4429 - acc: 0.8148 - f1score: 0.8145 - val_loss: 0.4822 - val_acc: 0.7876 - val_f1score: 0.7792\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4347 - acc: 0.8209 - f1score: 0.8209\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4394 - acc: 0.8180 - f1score: 0.8172 - val_loss: 0.4812 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4394 - acc: 0.8180 - f1score: 0.8172 - val_loss: 0.4812 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4480 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4474 - acc: 0.8164 - f1score: 0.8162 - val_loss: 0.4800 - val_acc: 0.7843 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4474 - acc: 0.8164 - f1score: 0.8162 - val_loss: 0.4800 - val_acc: 0.7843 - val_f1score: 0.7912\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4416 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4409 - acc: 0.8190 - f1score: 0.8195 - val_loss: 0.4821 - val_acc: 0.7833 - val_f1score: 0.7728\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4409 - acc: 0.8190 - f1score: 0.8195 - val_loss: 0.4821 - val_acc: 0.7833 - val_f1score: 0.7728\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4442 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4404 - acc: 0.8159 - f1score: 0.8167 - val_loss: 0.4807 - val_acc: 0.7833 - val_f1score: 0.7903\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4404 - acc: 0.8159 - f1score: 0.8167 - val_loss: 0.4807 - val_acc: 0.7833 - val_f1score: 0.7903\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4538 - acc: 0.8119 - f1score: 0.8119\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4504 - acc: 0.8148 - f1score: 0.8156 - val_loss: 0.4878 - val_acc: 0.7843 - val_f1score: 0.7862\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4504 - acc: 0.8148 - f1score: 0.8156 - val_loss: 0.4878 - val_acc: 0.7843 - val_f1score: 0.7862\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4464 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4481 - acc: 0.8116 - f1score: 0.8117 - val_loss: 0.4806 - val_acc: 0.7822 - val_f1score: 0.7768\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4481 - acc: 0.8116 - f1score: 0.8117 - val_loss: 0.4806 - val_acc: 0.7822 - val_f1score: 0.7768\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4422 - acc: 0.8181 - f1score: 0.8181\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4434 - acc: 0.8180 - f1score: 0.8180 - val_loss: 0.4815 - val_acc: 0.7854 - val_f1score: 0.7872\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4434 - acc: 0.8180 - f1score: 0.8180 - val_loss: 0.4815 - val_acc: 0.7854 - val_f1score: 0.7872\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4452 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4444 - acc: 0.8180 - f1score: 0.8184 - val_loss: 0.4820 - val_acc: 0.7811 - val_f1score: 0.7858\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4444 - acc: 0.8180 - f1score: 0.8184 - val_loss: 0.4820 - val_acc: 0.7811 - val_f1score: 0.7858\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4323 - acc: 0.8203 - f1score: 0.8203\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4336 - acc: 0.8206 - f1score: 0.8207 - val_loss: 0.4820 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4336 - acc: 0.8206 - f1score: 0.8207 - val_loss: 0.4820 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4378 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4342 - acc: 0.8196 - f1score: 0.8203 - val_loss: 0.4776 - val_acc: 0.7833 - val_f1score: 0.7977\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4342 - acc: 0.8196 - f1score: 0.8203 - val_loss: 0.4776 - val_acc: 0.7833 - val_f1score: 0.7977\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4428 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4469 - acc: 0.8132 - f1score: 0.8125 - val_loss: 0.4806 - val_acc: 0.7876 - val_f1score: 0.7867\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4469 - acc: 0.8132 - f1score: 0.8125 - val_loss: 0.4806 - val_acc: 0.7876 - val_f1score: 0.7867\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4415 - acc: 0.8192 - f1score: 0.8192\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4396 - acc: 0.8196 - f1score: 0.8197 - val_loss: 0.4851 - val_acc: 0.7811 - val_f1score: 0.7808\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4396 - acc: 0.8196 - f1score: 0.8197 - val_loss: 0.4851 - val_acc: 0.7811 - val_f1score: 0.7808\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4441 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4385 - acc: 0.8159 - f1score: 0.8164 - val_loss: 0.4792 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4385 - acc: 0.8159 - f1score: 0.8164 - val_loss: 0.4792 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4372 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4414 - acc: 0.8159 - f1score: 0.8159 - val_loss: 0.4746 - val_acc: 0.7833 - val_f1score: 0.7828\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4414 - acc: 0.8159 - f1score: 0.8159 - val_loss: 0.4746 - val_acc: 0.7833 - val_f1score: 0.7828\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4490 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00047: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4459 - acc: 0.8159 - f1score: 0.8164 - val_loss: 0.4807 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4459 - acc: 0.8159 - f1score: 0.8164 - val_loss: 0.4807 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4420 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00048: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4392 - acc: 0.8153 - f1score: 0.8158 - val_loss: 0.4735 - val_acc: 0.7865 - val_f1score: 0.7832\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4392 - acc: 0.8153 - f1score: 0.8158 - val_loss: 0.4735 - val_acc: 0.7865 - val_f1score: 0.7832\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4449 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00049: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4456 - acc: 0.8127 - f1score: 0.8126 - val_loss: 0.4742 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4456 - acc: 0.8127 - f1score: 0.8126 - val_loss: 0.4742 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4304 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00050: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4329 - acc: 0.8159 - f1score: 0.8156 - val_loss: 0.4696 - val_acc: 0.7876 - val_f1score: 0.7817\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4329 - acc: 0.8159 - f1score: 0.8156 - val_loss: 0.4696 - val_acc: 0.7876 - val_f1score: 0.7817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 43%|████▎     | 41/96 [2:39:02<3:04:54, 201.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.2115 - acc: 0.6116 - f1score: 0.6116\n",
            "Epoch 00001: val_acc improved from -inf to 0.77361, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.15.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.2482 - acc: 0.6164 - f1score: 0.6178 - val_loss: 1.1458 - val_acc: 0.7736 - val_f1score: 0.7715\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77361, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.15.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.2482 - acc: 0.6164 - f1score: 0.6178 - val_loss: 1.1458 - val_acc: 0.7736 - val_f1score: 0.7715\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.8807 - acc: 0.7316 - f1score: 0.7316\n",
            "Epoch 00002: val_acc improved from 0.77361 to 0.77468, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.56.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.77361 to 0.77468, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.56.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 1.8718 - acc: 0.7296 - f1score: 0.7291 - val_loss: 0.5599 - val_acc: 0.7747 - val_f1score: 0.7799\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 1.8718 - acc: 0.7296 - f1score: 0.7291 - val_loss: 0.5599 - val_acc: 0.7747 - val_f1score: 0.7799\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.6883 - acc: 0.7227 - f1score: 0.7227\n",
            "Epoch 00003: val_acc did not improve from 0.77468\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.7020 - acc: 0.7217 - f1score: 0.7214 - val_loss: 0.5937 - val_acc: 0.6341 - val_f1score: 0.6246\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.77468\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.7020 - acc: 0.7217 - f1score: 0.7214 - val_loss: 0.5937 - val_acc: 0.6341 - val_f1score: 0.6246\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.5475 - acc: 0.7411 - f1score: 0.7411\n",
            "Epoch 00004: val_acc improved from 0.77468 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.50.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 1.5279 - acc: 0.7392 - f1score: 0.7386 - val_loss: 0.5002 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.77468 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.50.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 1.5279 - acc: 0.7392 - f1score: 0.7386 - val_loss: 0.5002 - val_acc: 0.8004 - val_f1score: 0.8009\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.4580 - acc: 0.7355 - f1score: 0.7355\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.4862 - acc: 0.7360 - f1score: 0.7361 - val_loss: 0.6240 - val_acc: 0.7822 - val_f1score: 0.7868\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.4862 - acc: 0.7360 - f1score: 0.7361 - val_loss: 0.6240 - val_acc: 0.7822 - val_f1score: 0.7868\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.2784 - acc: 0.7656 - f1score: 0.7656\n",
            "Epoch 00006: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.50.h5\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.50.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.2794 - acc: 0.7640 - f1score: 0.7636 - val_loss: 0.4974 - val_acc: 0.8036 - val_f1score: 0.8088\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.2794 - acc: 0.7640 - f1score: 0.7636 - val_loss: 0.4974 - val_acc: 0.8036 - val_f1score: 0.8088\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.0185 - acc: 0.7656 - f1score: 0.7656\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.0242 - acc: 0.7593 - f1score: 0.7574 - val_loss: 0.5097 - val_acc: 0.7897 - val_f1score: 0.7986\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.0242 - acc: 0.7593 - f1score: 0.7574 - val_loss: 0.5097 - val_acc: 0.7897 - val_f1score: 0.7986\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6639 - acc: 0.7595 - f1score: 0.7595\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6521 - acc: 0.7624 - f1score: 0.7633 - val_loss: 0.5387 - val_acc: 0.7972 - val_f1score: 0.7930\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6521 - acc: 0.7624 - f1score: 0.7633 - val_loss: 0.5387 - val_acc: 0.7972 - val_f1score: 0.7930\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5424 - acc: 0.7885 - f1score: 0.7885\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5365 - acc: 0.7910 - f1score: 0.7917 - val_loss: 0.4979 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5365 - acc: 0.7910 - f1score: 0.7917 - val_loss: 0.4979 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4631 - acc: 0.8119 - f1score: 0.8119\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4720 - acc: 0.8085 - f1score: 0.8075 - val_loss: 0.4841 - val_acc: 0.7876 - val_f1score: 0.7692\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4720 - acc: 0.8085 - f1score: 0.8075 - val_loss: 0.4841 - val_acc: 0.7876 - val_f1score: 0.7692\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4772 - acc: 0.8080 - f1score: 0.8080\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4721 - acc: 0.8111 - f1score: 0.8120 - val_loss: 0.4853 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4721 - acc: 0.8111 - f1score: 0.8120 - val_loss: 0.4853 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4677 - acc: 0.8097 - f1score: 0.8097\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4667 - acc: 0.8111 - f1score: 0.8115 - val_loss: 0.4808 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4667 - acc: 0.8111 - f1score: 0.8115 - val_loss: 0.4808 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4498 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4496 - acc: 0.8169 - f1score: 0.8171 - val_loss: 0.4835 - val_acc: 0.7779 - val_f1score: 0.7779\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4496 - acc: 0.8169 - f1score: 0.8171 - val_loss: 0.4835 - val_acc: 0.7779 - val_f1score: 0.7779\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4499 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4509 - acc: 0.8164 - f1score: 0.8166 - val_loss: 0.4845 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4509 - acc: 0.8164 - f1score: 0.8166 - val_loss: 0.4845 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4503 - acc: 0.8198 - f1score: 0.8198\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4485 - acc: 0.8196 - f1score: 0.8195 - val_loss: 0.4762 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4485 - acc: 0.8196 - f1score: 0.8195 - val_loss: 0.4762 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4469 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4467 - acc: 0.8148 - f1score: 0.8147 - val_loss: 0.4757 - val_acc: 0.8004 - val_f1score: 0.7909\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4467 - acc: 0.8148 - f1score: 0.8147 - val_loss: 0.4757 - val_acc: 0.8004 - val_f1score: 0.7909\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4500 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4456 - acc: 0.8180 - f1score: 0.8188 - val_loss: 0.4749 - val_acc: 0.7972 - val_f1score: 0.8054\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4456 - acc: 0.8180 - f1score: 0.8188 - val_loss: 0.4749 - val_acc: 0.7972 - val_f1score: 0.8054\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4447 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4473 - acc: 0.8153 - f1score: 0.8155 - val_loss: 0.4762 - val_acc: 0.7951 - val_f1score: 0.8010\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4473 - acc: 0.8153 - f1score: 0.8155 - val_loss: 0.4762 - val_acc: 0.7951 - val_f1score: 0.8010\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4448 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4485 - acc: 0.8143 - f1score: 0.8137 - val_loss: 0.4757 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4485 - acc: 0.8143 - f1score: 0.8137 - val_loss: 0.4757 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4432 - acc: 0.8186 - f1score: 0.8186\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4451 - acc: 0.8180 - f1score: 0.8178 - val_loss: 0.4730 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4451 - acc: 0.8180 - f1score: 0.8178 - val_loss: 0.4730 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4372 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4381 - acc: 0.8169 - f1score: 0.8168 - val_loss: 0.4726 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4381 - acc: 0.8169 - f1score: 0.8168 - val_loss: 0.4726 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4485 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4492 - acc: 0.8127 - f1score: 0.8121 - val_loss: 0.4752 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4492 - acc: 0.8127 - f1score: 0.8121 - val_loss: 0.4752 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4422 - acc: 0.8225 - f1score: 0.8225\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4474 - acc: 0.8185 - f1score: 0.8174 - val_loss: 0.4758 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4474 - acc: 0.8185 - f1score: 0.8174 - val_loss: 0.4758 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4477 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4457 - acc: 0.8148 - f1score: 0.8148 - val_loss: 0.4813 - val_acc: 0.7908 - val_f1score: 0.7971\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4457 - acc: 0.8148 - f1score: 0.8148 - val_loss: 0.4813 - val_acc: 0.7908 - val_f1score: 0.7971\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4412 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4410 - acc: 0.8180 - f1score: 0.8186 - val_loss: 0.4766 - val_acc: 0.7940 - val_f1score: 0.8025\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4410 - acc: 0.8180 - f1score: 0.8186 - val_loss: 0.4766 - val_acc: 0.7940 - val_f1score: 0.8025\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4419 - acc: 0.8203 - f1score: 0.8203\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4438 - acc: 0.8175 - f1score: 0.8166 - val_loss: 0.4745 - val_acc: 0.7908 - val_f1score: 0.7971\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4438 - acc: 0.8175 - f1score: 0.8166 - val_loss: 0.4745 - val_acc: 0.7908 - val_f1score: 0.7971\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4484 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4459 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4770 - val_acc: 0.7972 - val_f1score: 0.7980\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4459 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4770 - val_acc: 0.7972 - val_f1score: 0.7980\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4394 - acc: 0.8192 - f1score: 0.8192\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4420 - acc: 0.8196 - f1score: 0.8197 - val_loss: 0.4773 - val_acc: 0.8015 - val_f1score: 0.7969\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4420 - acc: 0.8196 - f1score: 0.8197 - val_loss: 0.4773 - val_acc: 0.8015 - val_f1score: 0.7969\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4418 - acc: 0.8181 - f1score: 0.8181\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4397 - acc: 0.8185 - f1score: 0.8186 - val_loss: 0.4717 - val_acc: 0.7940 - val_f1score: 0.7875\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4397 - acc: 0.8185 - f1score: 0.8186 - val_loss: 0.4717 - val_acc: 0.7940 - val_f1score: 0.7875\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4408 - acc: 0.8192 - f1score: 0.8192\n",
            "Epoch 00030: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.30-0.47.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4373 - acc: 0.8212 - f1score: 0.8217 - val_loss: 0.4722 - val_acc: 0.8047 - val_f1score: 0.8048\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.30-0.47.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4373 - acc: 0.8212 - f1score: 0.8217 - val_loss: 0.4722 - val_acc: 0.8047 - val_f1score: 0.8048\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4411 - acc: 0.8186 - f1score: 0.8186\n",
            "Epoch 00031: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4384 - acc: 0.8206 - f1score: 0.8212 - val_loss: 0.4746 - val_acc: 0.7822 - val_f1score: 0.7868\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4384 - acc: 0.8206 - f1score: 0.8212 - val_loss: 0.4746 - val_acc: 0.7822 - val_f1score: 0.7868\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4437 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00032: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4396 - acc: 0.8190 - f1score: 0.8196 - val_loss: 0.4736 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4396 - acc: 0.8190 - f1score: 0.8196 - val_loss: 0.4736 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4404 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00033: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4372 - acc: 0.8190 - f1score: 0.8195 - val_loss: 0.4708 - val_acc: 0.8015 - val_f1score: 0.8044\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4372 - acc: 0.8190 - f1score: 0.8195 - val_loss: 0.4708 - val_acc: 0.8015 - val_f1score: 0.8044\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4440 - acc: 0.8181 - f1score: 0.8181\n",
            "Epoch 00034: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4401 - acc: 0.8201 - f1score: 0.8207 - val_loss: 0.4698 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4401 - acc: 0.8201 - f1score: 0.8207 - val_loss: 0.4698 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4385 - acc: 0.8209 - f1score: 0.8209\n",
            "Epoch 00035: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4397 - acc: 0.8201 - f1score: 0.8199 - val_loss: 0.4728 - val_acc: 0.7951 - val_f1score: 0.7960\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4397 - acc: 0.8201 - f1score: 0.8199 - val_loss: 0.4728 - val_acc: 0.7951 - val_f1score: 0.7960\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4453 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00036: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4403 - acc: 0.8190 - f1score: 0.8198 - val_loss: 0.4710 - val_acc: 0.7994 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4403 - acc: 0.8190 - f1score: 0.8198 - val_loss: 0.4710 - val_acc: 0.7994 - val_f1score: 0.8024\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4416 - acc: 0.8209 - f1score: 0.8209\n",
            "Epoch 00037: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4440 - acc: 0.8190 - f1score: 0.8185 - val_loss: 0.4721 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4440 - acc: 0.8190 - f1score: 0.8185 - val_loss: 0.4721 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4385 - acc: 0.8192 - f1score: 0.8192\n",
            "Epoch 00038: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4366 - acc: 0.8201 - f1score: 0.8204 - val_loss: 0.4787 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4366 - acc: 0.8201 - f1score: 0.8204 - val_loss: 0.4787 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4415 - acc: 0.8220 - f1score: 0.8220\n",
            "Epoch 00039: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4426 - acc: 0.8190 - f1score: 0.8182 - val_loss: 0.4698 - val_acc: 0.7983 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4426 - acc: 0.8190 - f1score: 0.8182 - val_loss: 0.4698 - val_acc: 0.7983 - val_f1score: 0.8014\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4377 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00040: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4392 - acc: 0.8159 - f1score: 0.8156 - val_loss: 0.4719 - val_acc: 0.7961 - val_f1score: 0.8045\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4392 - acc: 0.8159 - f1score: 0.8156 - val_loss: 0.4719 - val_acc: 0.7961 - val_f1score: 0.8045\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4398 - acc: 0.8209 - f1score: 0.8209\n",
            "Epoch 00041: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4377 - acc: 0.8212 - f1score: 0.8212 - val_loss: 0.4726 - val_acc: 0.8004 - val_f1score: 0.7859\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4377 - acc: 0.8212 - f1score: 0.8212 - val_loss: 0.4726 - val_acc: 0.8004 - val_f1score: 0.7859\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4388 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00042: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4388 - acc: 0.8164 - f1score: 0.8164 - val_loss: 0.4686 - val_acc: 0.7908 - val_f1score: 0.7996\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4388 - acc: 0.8164 - f1score: 0.8164 - val_loss: 0.4686 - val_acc: 0.7908 - val_f1score: 0.7996\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4385 - acc: 0.8237 - f1score: 0.8237\n",
            "Epoch 00043: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4369 - acc: 0.8243 - f1score: 0.8245 - val_loss: 0.4725 - val_acc: 0.8026 - val_f1score: 0.8053\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4369 - acc: 0.8243 - f1score: 0.8245 - val_loss: 0.4725 - val_acc: 0.8026 - val_f1score: 0.8053\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4443 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00044: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4406 - acc: 0.8164 - f1score: 0.8170 - val_loss: 0.4694 - val_acc: 0.7908 - val_f1score: 0.8021\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4406 - acc: 0.8164 - f1score: 0.8170 - val_loss: 0.4694 - val_acc: 0.7908 - val_f1score: 0.8021\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4344 - acc: 0.8231 - f1score: 0.8231\n",
            "Epoch 00045: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4389 - acc: 0.8185 - f1score: 0.8172 - val_loss: 0.4697 - val_acc: 0.8015 - val_f1score: 0.8019\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4389 - acc: 0.8185 - f1score: 0.8172 - val_loss: 0.4697 - val_acc: 0.8015 - val_f1score: 0.8019\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4406 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00046: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4406 - acc: 0.8175 - f1score: 0.8181 - val_loss: 0.4698 - val_acc: 0.7951 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4406 - acc: 0.8175 - f1score: 0.8181 - val_loss: 0.4698 - val_acc: 0.7951 - val_f1score: 0.7885\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4359 - acc: 0.8225 - f1score: 0.8225\n",
            "Epoch 00047: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4378 - acc: 0.8228 - f1score: 0.8228 - val_loss: 0.4706 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4378 - acc: 0.8228 - f1score: 0.8228 - val_loss: 0.4706 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4402 - acc: 0.8237 - f1score: 0.8237\n",
            "Epoch 00048: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4412 - acc: 0.8217 - f1score: 0.8211 - val_loss: 0.4664 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4412 - acc: 0.8217 - f1score: 0.8211 - val_loss: 0.4664 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4438 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00049: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4412 - acc: 0.8201 - f1score: 0.8208 - val_loss: 0.4667 - val_acc: 0.7983 - val_f1score: 0.7865\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4412 - acc: 0.8201 - f1score: 0.8208 - val_loss: 0.4667 - val_acc: 0.7983 - val_f1score: 0.7865\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4301 - acc: 0.8203 - f1score: 0.8203\n",
            "Epoch 00050: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4355 - acc: 0.8180 - f1score: 0.8173 - val_loss: 0.4679 - val_acc: 0.7865 - val_f1score: 0.7857\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4355 - acc: 0.8180 - f1score: 0.8173 - val_loss: 0.4679 - val_acc: 0.7865 - val_f1score: 0.7857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 44%|████▍     | 42/96 [2:45:10<3:46:20, 251.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 6.3696 - acc: 0.4860 - f1score: 0.4860\n",
            "Epoch 00001: val_acc improved from -inf to 0.77682, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.18.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 6.2769 - acc: 0.4894 - f1score: 0.4904 - val_loss: 1.1821 - val_acc: 0.7768 - val_f1score: 0.7744\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77682, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.18.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 6.2769 - acc: 0.4894 - f1score: 0.4904 - val_loss: 1.1821 - val_acc: 0.7768 - val_f1score: 0.7744\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 3.5272 - acc: 0.6881 - f1score: 0.6881\n",
            "Epoch 00002: val_acc improved from 0.77682 to 0.78219, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.38.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 3.5069 - acc: 0.6915 - f1score: 0.6925 - val_loss: 2.3825 - val_acc: 0.7822 - val_f1score: 0.7718\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.77682 to 0.78219, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.38.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 3.5069 - acc: 0.6915 - f1score: 0.6925 - val_loss: 2.3825 - val_acc: 0.7822 - val_f1score: 0.7718\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.9311 - acc: 0.7450 - f1score: 0.7450\n",
            "Epoch 00003: val_acc did not improve from 0.78219\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.8762 - acc: 0.7503 - f1score: 0.7518 - val_loss: 2.5380 - val_acc: 0.7736 - val_f1score: 0.7815\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.78219\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.8762 - acc: 0.7503 - f1score: 0.7518 - val_loss: 2.5380 - val_acc: 0.7736 - val_f1score: 0.7815\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.3054 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00004: val_acc did not improve from 0.78219\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2916 - acc: 0.7974 - f1score: 0.7977 - val_loss: 2.4926 - val_acc: 0.7800 - val_f1score: 0.7973\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.78219\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2916 - acc: 0.7974 - f1score: 0.7977 - val_loss: 2.4926 - val_acc: 0.7800 - val_f1score: 0.7973\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1892 - acc: 0.8069 - f1score: 0.8069\n",
            "Epoch 00005: val_acc improved from 0.78219 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.05-2.43.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1993 - acc: 0.8058 - f1score: 0.8055 - val_loss: 2.4278 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.78219 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.05-2.43.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1993 - acc: 0.8058 - f1score: 0.8055 - val_loss: 2.4278 - val_acc: 0.7929 - val_f1score: 0.7916\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1296 - acc: 0.8075 - f1score: 0.8075\n",
            "Epoch 00006: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1251 - acc: 0.8079 - f1score: 0.8081 - val_loss: 2.4051 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1251 - acc: 0.8079 - f1score: 0.8081 - val_loss: 2.4051 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1567 - acc: 0.8064 - f1score: 0.8064\n",
            "Epoch 00007: val_acc improved from 0.79292 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.07-2.29.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1238 - acc: 0.8090 - f1score: 0.8097 - val_loss: 2.2921 - val_acc: 0.8026 - val_f1score: 0.7929\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.79292 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.07-2.29.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1238 - acc: 0.8090 - f1score: 0.8097 - val_loss: 2.2921 - val_acc: 0.8026 - val_f1score: 0.7929\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.8866 - acc: 0.7924 - f1score: 0.7924\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.8672 - acc: 0.7910 - f1score: 0.7906 - val_loss: 1.8597 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.8672 - acc: 0.7910 - f1score: 0.7906 - val_loss: 1.8597 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.4790 - acc: 0.7662 - f1score: 0.7662\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.4607 - acc: 0.7619 - f1score: 0.7607 - val_loss: 0.8599 - val_acc: 0.7661 - val_f1score: 0.7746\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.4607 - acc: 0.7619 - f1score: 0.7607 - val_loss: 0.8599 - val_acc: 0.7661 - val_f1score: 0.7746\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.7173 - acc: 0.7271 - f1score: 0.7271\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.7167 - acc: 0.7259 - f1score: 0.7256 - val_loss: 0.5771 - val_acc: 0.7854 - val_f1score: 0.7822\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.7167 - acc: 0.7259 - f1score: 0.7256 - val_loss: 0.5771 - val_acc: 0.7854 - val_f1score: 0.7822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 45%|████▍     | 43/96 [2:46:09<2:51:12, 193.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 4.8851 - acc: 0.4503 - f1score: 0.4503\n",
            "Epoch 00001: val_acc improved from -inf to 0.57833, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.48.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 4.7716 - acc: 0.4508 - f1score: 0.4509 - val_loss: 1.4791 - val_acc: 0.5783 - val_f1score: 0.5788\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.57833, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.48.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 4.7716 - acc: 0.4508 - f1score: 0.4509 - val_loss: 1.4791 - val_acc: 0.5783 - val_f1score: 0.5788\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1584 - acc: 0.6479 - f1score: 0.6479\n",
            "Epoch 00002: val_acc improved from 0.57833 to 0.75966, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.21.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.1011 - acc: 0.6577 - f1score: 0.6605 - val_loss: 2.2146 - val_acc: 0.7597 - val_f1score: 0.7663\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.57833 to 0.75966, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.21.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.1011 - acc: 0.6577 - f1score: 0.6605 - val_loss: 2.2146 - val_acc: 0.7597 - val_f1score: 0.7663\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.9335 - acc: 0.7383 - f1score: 0.7383\n",
            "Epoch 00003: val_acc improved from 0.75966 to 0.77253, saving model to /content/drive/My Drive/LSTM_Model/model.03-1.64.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.9125 - acc: 0.7402 - f1score: 0.7408 - val_loss: 1.6397 - val_acc: 0.7725 - val_f1score: 0.7680\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.75966 to 0.77253, saving model to /content/drive/My Drive/LSTM_Model/model.03-1.64.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.9125 - acc: 0.7402 - f1score: 0.7408 - val_loss: 1.6397 - val_acc: 0.7725 - val_f1score: 0.7680\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.5259 - acc: 0.7461 - f1score: 0.7461\n",
            "Epoch 00004: val_acc improved from 0.77253 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.04-1.17.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.5202 - acc: 0.7455 - f1score: 0.7453 - val_loss: 1.1719 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.77253 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.04-1.17.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.5202 - acc: 0.7455 - f1score: 0.7453 - val_loss: 1.1719 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.0128 - acc: 0.7533 - f1score: 0.7533\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.0076 - acc: 0.7550 - f1score: 0.7555 - val_loss: 0.6473 - val_acc: 0.7865 - val_f1score: 0.7857\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.0076 - acc: 0.7550 - f1score: 0.7555 - val_loss: 0.6473 - val_acc: 0.7865 - val_f1score: 0.7857\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.7544 - acc: 0.7294 - f1score: 0.7294\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.7435 - acc: 0.7317 - f1score: 0.7324 - val_loss: 0.5990 - val_acc: 0.7994 - val_f1score: 0.7924\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.7435 - acc: 0.7317 - f1score: 0.7324 - val_loss: 0.5990 - val_acc: 0.7994 - val_f1score: 0.7924\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5778 - acc: 0.7511 - f1score: 0.7511\n",
            "Epoch 00007: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.07-0.52.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5802 - acc: 0.7492 - f1score: 0.7487 - val_loss: 0.5178 - val_acc: 0.8026 - val_f1score: 0.8078\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.07-0.52.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5802 - acc: 0.7492 - f1score: 0.7487 - val_loss: 0.5178 - val_acc: 0.8026 - val_f1score: 0.8078\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5080 - acc: 0.7896 - f1score: 0.7896\n",
            "Epoch 00008: val_acc improved from 0.80258 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.49.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5107 - acc: 0.7884 - f1score: 0.7880 - val_loss: 0.4935 - val_acc: 0.8047 - val_f1score: 0.8048\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80258 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.49.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5107 - acc: 0.7884 - f1score: 0.7880 - val_loss: 0.4935 - val_acc: 0.8047 - val_f1score: 0.8048\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4885 - acc: 0.8036 - f1score: 0.8036\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4852 - acc: 0.8058 - f1score: 0.8065 - val_loss: 0.4969 - val_acc: 0.8004 - val_f1score: 0.7884\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4852 - acc: 0.8058 - f1score: 0.8065 - val_loss: 0.4969 - val_acc: 0.8004 - val_f1score: 0.7884\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4872 - acc: 0.8097 - f1score: 0.8097\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4858 - acc: 0.8101 - f1score: 0.8102 - val_loss: 0.4870 - val_acc: 0.7929 - val_f1score: 0.7866\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4858 - acc: 0.8101 - f1score: 0.8102 - val_loss: 0.4870 - val_acc: 0.7929 - val_f1score: 0.7866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 46%|████▌     | 44/96 [2:47:26<2:17:39, 158.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.3079 - acc: 0.6680 - f1score: 0.6680\n",
            "Epoch 00001: val_acc improved from -inf to 0.77039, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.89.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.2985 - acc: 0.6698 - f1score: 0.6704 - val_loss: 1.8897 - val_acc: 0.7704 - val_f1score: 0.7661\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77039, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.89.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.2985 - acc: 0.6698 - f1score: 0.6704 - val_loss: 1.8897 - val_acc: 0.7704 - val_f1score: 0.7661\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.9756 - acc: 0.7567 - f1score: 0.7567\n",
            "Epoch 00002: val_acc improved from 0.77039 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.60.h5\n",
            "1890/1890 [==============================]\n",
            "Epoch 00002: val_acc improved from 0.77039 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.60.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.9849 - acc: 0.7561 - f1score: 0.7559 - val_loss: 1.5974 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            " - 5s 3ms/sample - loss: 1.9849 - acc: 0.7561 - f1score: 0.7559 - val_loss: 1.5974 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.5511 - acc: 0.7573 - f1score: 0.7573\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.5716 - acc: 0.7561 - f1score: 0.7558 - val_loss: 1.1375 - val_acc: 0.7876 - val_f1score: 0.7817\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.5716 - acc: 0.7561 - f1score: 0.7558 - val_loss: 1.1375 - val_acc: 0.7876 - val_f1score: 0.7817\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.1106 - acc: 0.6959 - f1score: 0.6959\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.1218 - acc: 0.6989 - f1score: 0.6998 - val_loss: 0.8554 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.1218 - acc: 0.6989 - f1score: 0.6998 - val_loss: 0.8554 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.7197 - acc: 0.7494 - f1score: 0.7494\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.7136 - acc: 0.7481 - f1score: 0.7478 - val_loss: 0.5110 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.7136 - acc: 0.7481 - f1score: 0.7478 - val_loss: 0.5110 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5463 - acc: 0.7606 - f1score: 0.7606\n",
            "Epoch 00006: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.48.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5372 - acc: 0.7656 - f1score: 0.7670 - val_loss: 0.4827 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.48.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5372 - acc: 0.7656 - f1score: 0.7670 - val_loss: 0.4827 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4841 - acc: 0.7946 - f1score: 0.7946\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4854 - acc: 0.7942 - f1score: 0.7940 - val_loss: 0.4902 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4854 - acc: 0.7942 - f1score: 0.7940 - val_loss: 0.4902 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4752 - acc: 0.8047 - f1score: 0.8047\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4743 - acc: 0.8032 - f1score: 0.8027 - val_loss: 0.4913 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4743 - acc: 0.8032 - f1score: 0.8027 - val_loss: 0.4913 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4663 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4692 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4895 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4692 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4895 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4754 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4793 - acc: 0.8101 - f1score: 0.8092 - val_loss: 0.4895 - val_acc: 0.8015 - val_f1score: 0.7969\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4793 - acc: 0.8101 - f1score: 0.8092 - val_loss: 0.4895 - val_acc: 0.8015 - val_f1score: 0.7969\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4750 - acc: 0.8069 - f1score: 0.8069\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4719 - acc: 0.8085 - f1score: 0.8089 - val_loss: 0.4884 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4719 - acc: 0.8085 - f1score: 0.8089 - val_loss: 0.4884 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4753 - acc: 0.8075 - f1score: 0.8075\n",
            "Epoch 00012: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.12-0.49.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4720 - acc: 0.8090 - f1score: 0.8094 - val_loss: 0.4885 - val_acc: 0.8047 - val_f1score: 0.8073\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.12-0.49.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4720 - acc: 0.8090 - f1score: 0.8094 - val_loss: 0.4885 - val_acc: 0.8047 - val_f1score: 0.8073\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4727 - acc: 0.8119 - f1score: 0.8119\n",
            "Epoch 00013: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4757 - acc: 0.8101 - f1score: 0.8095 - val_loss: 0.4860 - val_acc: 0.7929 - val_f1score: 0.7841\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4757 - acc: 0.8101 - f1score: 0.8095 - val_loss: 0.4860 - val_acc: 0.7929 - val_f1score: 0.7841\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4633 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00014: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4656 - acc: 0.8122 - f1score: 0.8114 - val_loss: 0.4862 - val_acc: 0.7951 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4656 - acc: 0.8122 - f1score: 0.8114 - val_loss: 0.4862 - val_acc: 0.7951 - val_f1score: 0.7935\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4643 - acc: 0.8108 - f1score: 0.8108\n",
            "Epoch 00015: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4639 - acc: 0.8116 - f1score: 0.8119 - val_loss: 0.4861 - val_acc: 0.7908 - val_f1score: 0.7871\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4639 - acc: 0.8116 - f1score: 0.8119 - val_loss: 0.4861 - val_acc: 0.7908 - val_f1score: 0.7871\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4565 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00016: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4627 - acc: 0.8079 - f1score: 0.8070 - val_loss: 0.4843 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4627 - acc: 0.8079 - f1score: 0.8070 - val_loss: 0.4843 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4697 - acc: 0.8097 - f1score: 0.8097\n",
            "Epoch 00017: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4694 - acc: 0.8079 - f1score: 0.8074 - val_loss: 0.4898 - val_acc: 0.7843 - val_f1score: 0.7887\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4694 - acc: 0.8079 - f1score: 0.8074 - val_loss: 0.4898 - val_acc: 0.7843 - val_f1score: 0.7887\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4716 - acc: 0.8036 - f1score: 0.8036\n",
            "Epoch 00018: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4695 - acc: 0.8032 - f1score: 0.8031 - val_loss: 0.4852 - val_acc: 0.7897 - val_f1score: 0.7986\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4695 - acc: 0.8032 - f1score: 0.8031 - val_loss: 0.4852 - val_acc: 0.7897 - val_f1score: 0.7986\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4686 - acc: 0.8036 - f1score: 0.8036\n",
            "Epoch 00019: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4704 - acc: 0.8037 - f1score: 0.8037 - val_loss: 0.4852 - val_acc: 0.7822 - val_f1score: 0.7768\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4704 - acc: 0.8037 - f1score: 0.8037 - val_loss: 0.4852 - val_acc: 0.7822 - val_f1score: 0.7768\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4701 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00020: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4698 - acc: 0.8069 - f1score: 0.8059 - val_loss: 0.4828 - val_acc: 0.8004 - val_f1score: 0.7934\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4698 - acc: 0.8069 - f1score: 0.8059 - val_loss: 0.4828 - val_acc: 0.8004 - val_f1score: 0.7934\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4755 - acc: 0.8058 - f1score: 0.8058\n",
            "Epoch 00021: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4743 - acc: 0.8053 - f1score: 0.8051 - val_loss: 0.4818 - val_acc: 0.7940 - val_f1score: 0.8025\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4743 - acc: 0.8053 - f1score: 0.8051 - val_loss: 0.4818 - val_acc: 0.7940 - val_f1score: 0.8025\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4572 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4607 - acc: 0.8095 - f1score: 0.8090 - val_loss: 0.4832 - val_acc: 0.7897 - val_f1score: 0.7836\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4607 - acc: 0.8095 - f1score: 0.8090 - val_loss: 0.4832 - val_acc: 0.7897 - val_f1score: 0.7836\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4657 - acc: 0.8092 - f1score: 0.8092\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4628 - acc: 0.8106 - f1score: 0.8110 - val_loss: 0.4818 - val_acc: 0.7908 - val_f1score: 0.7871\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4628 - acc: 0.8106 - f1score: 0.8110 - val_loss: 0.4818 - val_acc: 0.7908 - val_f1score: 0.7871\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4672 - acc: 0.8075 - f1score: 0.8075\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4661 - acc: 0.8074 - f1score: 0.8074 - val_loss: 0.4820 - val_acc: 0.7897 - val_f1score: 0.8011\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4661 - acc: 0.8074 - f1score: 0.8074 - val_loss: 0.4820 - val_acc: 0.7897 - val_f1score: 0.8011\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4612 - acc: 0.8097 - f1score: 0.8097\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4641 - acc: 0.8074 - f1score: 0.8067 - val_loss: 0.4822 - val_acc: 0.7833 - val_f1score: 0.7803\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4641 - acc: 0.8074 - f1score: 0.8067 - val_loss: 0.4822 - val_acc: 0.7833 - val_f1score: 0.7803\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4738 - acc: 0.8092 - f1score: 0.8092\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4724 - acc: 0.8111 - f1score: 0.8117 - val_loss: 0.4811 - val_acc: 0.7897 - val_f1score: 0.7811\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4724 - acc: 0.8111 - f1score: 0.8117 - val_loss: 0.4811 - val_acc: 0.7897 - val_f1score: 0.7811\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4679 - acc: 0.8058 - f1score: 0.8058\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4661 - acc: 0.8069 - f1score: 0.8072 - val_loss: 0.4810 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4661 - acc: 0.8069 - f1score: 0.8072 - val_loss: 0.4810 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4703 - acc: 0.8075 - f1score: 0.8075\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4704 - acc: 0.8079 - f1score: 0.8081 - val_loss: 0.4806 - val_acc: 0.7843 - val_f1score: 0.7862\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4704 - acc: 0.8079 - f1score: 0.8081 - val_loss: 0.4806 - val_acc: 0.7843 - val_f1score: 0.7862\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4674 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4680 - acc: 0.8079 - f1score: 0.8070 - val_loss: 0.4793 - val_acc: 0.7940 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4680 - acc: 0.8079 - f1score: 0.8070 - val_loss: 0.4793 - val_acc: 0.7940 - val_f1score: 0.8000\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4762 - acc: 0.8030 - f1score: 0.8030\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4739 - acc: 0.8042 - f1score: 0.8046 - val_loss: 0.4809 - val_acc: 0.7811 - val_f1score: 0.7808\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4739 - acc: 0.8042 - f1score: 0.8046 - val_loss: 0.4809 - val_acc: 0.7811 - val_f1score: 0.7808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 47%|████▋     | 45/96 [2:50:05<2:14:57, 158.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 3.3588 - acc: 0.5430 - f1score: 0.5430\n",
            "Epoch 00001: val_acc improved from -inf to 0.75322, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.03.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 3.3429 - acc: 0.5497 - f1score: 0.5517 - val_loss: 1.0301 - val_acc: 0.7532 - val_f1score: 0.7604\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.75322, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.03.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 3.3429 - acc: 0.5497 - f1score: 0.5517 - val_loss: 1.0301 - val_acc: 0.7532 - val_f1score: 0.7604\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.6542 - acc: 0.7015 - f1score: 0.7015\n",
            "Epoch 00002: val_acc improved from 0.75322 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.71.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.5852 - acc: 0.7085 - f1score: 0.7105 - val_loss: 1.7120 - val_acc: 0.8036 - val_f1score: 0.7963\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.75322 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.71.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 2.5852 - acc: 0.7085 - f1score: 0.7105 - val_loss: 1.7120 - val_acc: 0.8036 - val_f1score: 0.7963\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.2831 - acc: 0.6925 - f1score: 0.6925\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.2772 - acc: 0.6889 - f1score: 0.6879 - val_loss: 0.7563 - val_acc: 0.7961 - val_f1score: 0.8045\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.2772 - acc: 0.6889 - f1score: 0.6879 - val_loss: 0.7563 - val_acc: 0.7961 - val_f1score: 0.8045\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.7431 - acc: 0.7461 - f1score: 0.7461\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.7386 - acc: 0.7466 - f1score: 0.7467 - val_loss: 0.5939 - val_acc: 0.7983 - val_f1score: 0.8064\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.7386 - acc: 0.7466 - f1score: 0.7467 - val_loss: 0.5939 - val_acc: 0.7983 - val_f1score: 0.8064\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.6470 - acc: 0.7411 - f1score: 0.7411\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6421 - acc: 0.7455 - f1score: 0.7468 - val_loss: 0.5778 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6421 - acc: 0.7455 - f1score: 0.7468 - val_loss: 0.5778 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5971 - acc: 0.7667 - f1score: 0.7667\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5997 - acc: 0.7651 - f1score: 0.7646 - val_loss: 0.5629 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5997 - acc: 0.7651 - f1score: 0.7646 - val_loss: 0.5629 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5736 - acc: 0.7176 - f1score: 0.7176\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5715 - acc: 0.7159 - f1score: 0.7154 - val_loss: 0.5392 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5715 - acc: 0.7159 - f1score: 0.7154 - val_loss: 0.5392 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5386 - acc: 0.7450 - f1score: 0.7450\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5368 - acc: 0.7476 - f1score: 0.7484 - val_loss: 0.5199 - val_acc: 0.8004 - val_f1score: 0.8134\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5368 - acc: 0.7476 - f1score: 0.7484 - val_loss: 0.5199 - val_acc: 0.8004 - val_f1score: 0.8134\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5265 - acc: 0.7801 - f1score: 0.7801\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5289 - acc: 0.7772 - f1score: 0.7764 - val_loss: 0.5102 - val_acc: 0.8004 - val_f1score: 0.8134\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5289 - acc: 0.7772 - f1score: 0.7764 - val_loss: 0.5102 - val_acc: 0.8004 - val_f1score: 0.8134\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5192 - acc: 0.7857 - f1score: 0.7857\n",
            "Epoch 00010: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.10-0.50.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5192 - acc: 0.7847 - f1score: 0.7844 - val_loss: 0.5029 - val_acc: 0.8047 - val_f1score: 0.7998\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.10-0.50.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5192 - acc: 0.7847 - f1score: 0.7844 - val_loss: 0.5029 - val_acc: 0.8047 - val_f1score: 0.7998\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4988 - acc: 0.7818 - f1score: 0.7818\n",
            "Epoch 00011: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4981 - acc: 0.7825 - f1score: 0.7827 - val_loss: 0.4991 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4981 - acc: 0.7825 - f1score: 0.7827 - val_loss: 0.4991 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4988 - acc: 0.7751 - f1score: 0.7751\n",
            "Epoch 00012: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4980 - acc: 0.7767 - f1score: 0.7772 - val_loss: 0.4977 - val_acc: 0.8036 - val_f1score: 0.8088\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4980 - acc: 0.7767 - f1score: 0.7772 - val_loss: 0.4977 - val_acc: 0.8036 - val_f1score: 0.8088\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4900 - acc: 0.7640 - f1score: 0.7640\n",
            "Epoch 00013: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4944 - acc: 0.7608 - f1score: 0.7600 - val_loss: 0.4970 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4944 - acc: 0.7608 - f1score: 0.7600 - val_loss: 0.4970 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4882 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00014: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4884 - acc: 0.7974 - f1score: 0.7977 - val_loss: 0.4968 - val_acc: 0.8026 - val_f1score: 0.8028\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4884 - acc: 0.7974 - f1score: 0.7977 - val_loss: 0.4968 - val_acc: 0.8026 - val_f1score: 0.8028\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4830 - acc: 0.7935 - f1score: 0.7935\n",
            "Epoch 00015: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4859 - acc: 0.7937 - f1score: 0.7937 - val_loss: 0.4968 - val_acc: 0.8036 - val_f1score: 0.8113\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4859 - acc: 0.7937 - f1score: 0.7937 - val_loss: 0.4968 - val_acc: 0.8036 - val_f1score: 0.8113\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4935 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00016: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4947 - acc: 0.7974 - f1score: 0.7970 - val_loss: 0.4945 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4947 - acc: 0.7974 - f1score: 0.7970 - val_loss: 0.4945 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4832 - acc: 0.8013 - f1score: 0.8013\n",
            "Epoch 00017: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4807 - acc: 0.8032 - f1score: 0.8037 - val_loss: 0.4934 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4807 - acc: 0.8032 - f1score: 0.8037 - val_loss: 0.4934 - val_acc: 0.8004 - val_f1score: 0.7984\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4804 - acc: 0.7935 - f1score: 0.7935\n",
            "Epoch 00018: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4885 - acc: 0.7889 - f1score: 0.7876 - val_loss: 0.4922 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4885 - acc: 0.7889 - f1score: 0.7876 - val_loss: 0.4922 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4949 - acc: 0.7958 - f1score: 0.7958\n",
            "Epoch 00019: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4926 - acc: 0.7952 - f1score: 0.7951 - val_loss: 0.4933 - val_acc: 0.7908 - val_f1score: 0.7821\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4926 - acc: 0.7952 - f1score: 0.7951 - val_loss: 0.4933 - val_acc: 0.7908 - val_f1score: 0.7821\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4898 - acc: 0.7997 - f1score: 0.7997\n",
            "Epoch 00020: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4889 - acc: 0.7995 - f1score: 0.7994 - val_loss: 0.4936 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4889 - acc: 0.7995 - f1score: 0.7994 - val_loss: 0.4936 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4849 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00021: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4814 - acc: 0.8005 - f1score: 0.8016 - val_loss: 0.4910 - val_acc: 0.7929 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4814 - acc: 0.8005 - f1score: 0.8016 - val_loss: 0.4910 - val_acc: 0.7929 - val_f1score: 0.7990\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4705 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4838 - acc: 0.8058 - f1score: 0.8033 - val_loss: 0.4913 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4838 - acc: 0.8058 - f1score: 0.8033 - val_loss: 0.4913 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4874 - acc: 0.7913 - f1score: 0.7913\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4876 - acc: 0.7942 - f1score: 0.7950 - val_loss: 0.4920 - val_acc: 0.7908 - val_f1score: 0.7946\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4876 - acc: 0.7942 - f1score: 0.7950 - val_loss: 0.4920 - val_acc: 0.7908 - val_f1score: 0.7946\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4862 - acc: 0.7930 - f1score: 0.7930\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4843 - acc: 0.7937 - f1score: 0.7938 - val_loss: 0.4902 - val_acc: 0.7897 - val_f1score: 0.7911\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4843 - acc: 0.7937 - f1score: 0.7938 - val_loss: 0.4902 - val_acc: 0.7897 - val_f1score: 0.7911\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4819 - acc: 0.7924 - f1score: 0.7924\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4834 - acc: 0.7905 - f1score: 0.7899 - val_loss: 0.4903 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4834 - acc: 0.7905 - f1score: 0.7899 - val_loss: 0.4903 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4890 - acc: 0.7885 - f1score: 0.7885\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4856 - acc: 0.7931 - f1score: 0.7944 - val_loss: 0.4895 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4856 - acc: 0.7931 - f1score: 0.7944 - val_loss: 0.4895 - val_acc: 0.7940 - val_f1score: 0.7950\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4747 - acc: 0.8019 - f1score: 0.8019\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4795 - acc: 0.8000 - f1score: 0.7995 - val_loss: 0.4888 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4795 - acc: 0.8000 - f1score: 0.7995 - val_loss: 0.4888 - val_acc: 0.7908 - val_f1score: 0.7921\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4855 - acc: 0.7935 - f1score: 0.7935\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4852 - acc: 0.7947 - f1score: 0.7950 - val_loss: 0.4898 - val_acc: 0.7897 - val_f1score: 0.7911\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4852 - acc: 0.7947 - f1score: 0.7950 - val_loss: 0.4898 - val_acc: 0.7897 - val_f1score: 0.7911\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4671 - acc: 0.8069 - f1score: 0.8069\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4736 - acc: 0.8000 - f1score: 0.7980 - val_loss: 0.4927 - val_acc: 0.8015 - val_f1score: 0.8143\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4736 - acc: 0.8000 - f1score: 0.7980 - val_loss: 0.4927 - val_acc: 0.8015 - val_f1score: 0.8143\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4775 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4784 - acc: 0.7984 - f1score: 0.7987 - val_loss: 0.4882 - val_acc: 0.7929 - val_f1score: 0.7866\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4784 - acc: 0.7984 - f1score: 0.7987 - val_loss: 0.4882 - val_acc: 0.7929 - val_f1score: 0.7866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 48%|████▊     | 46/96 [2:53:42<2:27:02, 176.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 5.5992 - acc: 0.5547 - f1score: 0.5547\n",
            "Epoch 00001: val_acc improved from -inf to 0.74356, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.68.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 5.4862 - acc: 0.5614 - f1score: 0.5633 - val_loss: 2.6765 - val_acc: 0.7436 - val_f1score: 0.7391\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.74356, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.68.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 5.4862 - acc: 0.5614 - f1score: 0.5633 - val_loss: 2.6765 - val_acc: 0.7436 - val_f1score: 0.7391\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 3.8938 - acc: 0.6445 - f1score: 0.6445\n",
            "Epoch 00002: val_acc improved from 0.74356 to 0.75644, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.90.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 3.8503 - acc: 0.6492 - f1score: 0.6505 - val_loss: 2.8988 - val_acc: 0.7564 - val_f1score: 0.7609\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.74356 to 0.75644, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.90.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 3.8503 - acc: 0.6492 - f1score: 0.6505 - val_loss: 2.8988 - val_acc: 0.7564 - val_f1score: 0.7609\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.7713 - acc: 0.7662 - f1score: 0.7662\n",
            "Epoch 00003: val_acc improved from 0.75644 to 0.77682, saving model to /content/drive/My Drive/LSTM_Model/model.03-2.69.h5\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.75644 to 0.77682, saving model to /content/drive/My Drive/LSTM_Model/model.03-2.69.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.7665 - acc: 0.7667 - f1score: 0.7668 - val_loss: 2.6893 - val_acc: 0.7768 - val_f1score: 0.7769\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.7665 - acc: 0.7667 - f1score: 0.7668 - val_loss: 2.6893 - val_acc: 0.7768 - val_f1score: 0.7769\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.3880 - acc: 0.8052 - f1score: 0.8052\n",
            "Epoch 00004: val_acc improved from 0.77682 to 0.78004, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.60.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.3538 - acc: 0.8042 - f1score: 0.8039 - val_loss: 2.5971 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.77682 to 0.78004, saving model to /content/drive/My Drive/LSTM_Model/model.04-2.60.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.3538 - acc: 0.8042 - f1score: 0.8039 - val_loss: 2.5971 - val_acc: 0.7800 - val_f1score: 0.7798\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.3380 - acc: 0.8108 - f1score: 0.8108\n",
            "Epoch 00005: val_acc improved from 0.78004 to 0.78326, saving model to /content/drive/My Drive/LSTM_Model/model.05-2.54.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.3279 - acc: 0.8122 - f1score: 0.8126 - val_loss: 2.5371 - val_acc: 0.7833 - val_f1score: 0.7778\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.78004 to 0.78326, saving model to /content/drive/My Drive/LSTM_Model/model.05-2.54.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.3279 - acc: 0.8122 - f1score: 0.8126 - val_loss: 2.5371 - val_acc: 0.7833 - val_f1score: 0.7778\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.2839 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00006: val_acc improved from 0.78326 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.06-2.47.h5\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.78326 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.06-2.47.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2625 - acc: 0.8164 - f1score: 0.8172 - val_loss: 2.4674 - val_acc: 0.7929 - val_f1score: 0.8015\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.2625 - acc: 0.8164 - f1score: 0.8172 - val_loss: 2.4674 - val_acc: 0.7929 - val_f1score: 0.8015\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1875 - acc: 0.8231 - f1score: 0.8231\n",
            "Epoch 00007: val_acc improved from 0.79292 to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.07-2.43.h5\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.79292 to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.07-2.43.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1940 - acc: 0.8206 - f1score: 0.8199 - val_loss: 2.4313 - val_acc: 0.7940 - val_f1score: 0.8025\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1940 - acc: 0.8206 - f1score: 0.8199 - val_loss: 2.4313 - val_acc: 0.7940 - val_f1score: 0.8025\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1682 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00008: val_acc improved from 0.79399 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.08-2.38.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1727 - acc: 0.8159 - f1score: 0.8157 - val_loss: 2.3783 - val_acc: 0.8026 - val_f1score: 0.8053\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.79399 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.08-2.38.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1727 - acc: 0.8159 - f1score: 0.8157 - val_loss: 2.3783 - val_acc: 0.8026 - val_f1score: 0.8053\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.1471 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00009: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.09-2.33.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1481 - acc: 0.8111 - f1score: 0.8114 - val_loss: 2.3260 - val_acc: 0.8036 - val_f1score: 0.8088\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.09-2.33.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.1481 - acc: 0.8111 - f1score: 0.8114 - val_loss: 2.3260 - val_acc: 0.8036 - val_f1score: 0.8088\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 2.0427 - acc: 0.8036 - f1score: 0.8036\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.0054 - acc: 0.8053 - f1score: 0.8058 - val_loss: 1.8507 - val_acc: 0.7790 - val_f1score: 0.7863\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 2.0054 - acc: 0.8053 - f1score: 0.8058 - val_loss: 1.8507 - val_acc: 0.7790 - val_f1score: 0.7863\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.4259 - acc: 0.7645 - f1score: 0.7645\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.3977 - acc: 0.7656 - f1score: 0.7659 - val_loss: 0.8737 - val_acc: 0.7586 - val_f1score: 0.7603\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 1.3977 - acc: 0.7656 - f1score: 0.7659 - val_loss: 0.8737 - val_acc: 0.7586 - val_f1score: 0.7603\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.7018 - acc: 0.7132 - f1score: 0.7132\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6947 - acc: 0.7127 - f1score: 0.7126 - val_loss: 0.5226 - val_acc: 0.7575 - val_f1score: 0.7568\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.6947 - acc: 0.7127 - f1score: 0.7126 - val_loss: 0.5226 - val_acc: 0.7575 - val_f1score: 0.7568\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5336 - acc: 0.7684 - f1score: 0.7684\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5303 - acc: 0.7720 - f1score: 0.7730 - val_loss: 0.5090 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5303 - acc: 0.7720 - f1score: 0.7730 - val_loss: 0.5090 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5156 - acc: 0.7740 - f1score: 0.7740\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5112 - acc: 0.7783 - f1score: 0.7795 - val_loss: 0.5042 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5112 - acc: 0.7783 - f1score: 0.7795 - val_loss: 0.5042 - val_acc: 0.8004 - val_f1score: 0.8084\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5103 - acc: 0.7874 - f1score: 0.7874\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5111 - acc: 0.7899 - f1score: 0.7907 - val_loss: 0.4968 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.5111 - acc: 0.7899 - f1score: 0.7907 - val_loss: 0.4968 - val_acc: 0.8004 - val_f1score: 0.8034\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4980 - acc: 0.8080 - f1score: 0.8080\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4971 - acc: 0.8079 - f1score: 0.8079 - val_loss: 0.4940 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4971 - acc: 0.8079 - f1score: 0.8079 - val_loss: 0.4940 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4874 - acc: 0.8058 - f1score: 0.8058\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4877 - acc: 0.8063 - f1score: 0.8065 - val_loss: 0.4905 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4877 - acc: 0.8063 - f1score: 0.8065 - val_loss: 0.4905 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4760 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4807 - acc: 0.8116 - f1score: 0.8117 - val_loss: 0.4884 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4807 - acc: 0.8116 - f1score: 0.8117 - val_loss: 0.4884 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4748 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4724 - acc: 0.8138 - f1score: 0.8138 - val_loss: 0.4862 - val_acc: 0.8036 - val_f1score: 0.7963\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4724 - acc: 0.8138 - f1score: 0.8138 - val_loss: 0.4862 - val_acc: 0.8036 - val_f1score: 0.7963\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4797 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4807 - acc: 0.8122 - f1score: 0.8118 - val_loss: 0.4848 - val_acc: 0.8036 - val_f1score: 0.7988\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4807 - acc: 0.8122 - f1score: 0.8118 - val_loss: 0.4848 - val_acc: 0.8036 - val_f1score: 0.7988\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4726 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00021: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.21-0.48.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4715 - acc: 0.8111 - f1score: 0.8110 - val_loss: 0.4841 - val_acc: 0.8047 - val_f1score: 0.8198\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.21-0.48.h5\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4715 - acc: 0.8111 - f1score: 0.8110 - val_loss: 0.4841 - val_acc: 0.8047 - val_f1score: 0.8198\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4753 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4730 - acc: 0.8122 - f1score: 0.8127 - val_loss: 0.4850 - val_acc: 0.8036 - val_f1score: 0.8063\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4730 - acc: 0.8122 - f1score: 0.8127 - val_loss: 0.4850 - val_acc: 0.8036 - val_f1score: 0.8063\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4781 - acc: 0.8086 - f1score: 0.8086\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4804 - acc: 0.8085 - f1score: 0.8084 - val_loss: 0.4836 - val_acc: 0.7940 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4804 - acc: 0.8085 - f1score: 0.8084 - val_loss: 0.4836 - val_acc: 0.7940 - val_f1score: 0.8000\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4734 - acc: 0.8097 - f1score: 0.8097\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4698 - acc: 0.8132 - f1score: 0.8142 - val_loss: 0.4819 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4698 - acc: 0.8132 - f1score: 0.8142 - val_loss: 0.4819 - val_acc: 0.7940 - val_f1score: 0.7900\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4712 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4706 - acc: 0.8111 - f1score: 0.8114 - val_loss: 0.4810 - val_acc: 0.8015 - val_f1score: 0.8143\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4706 - acc: 0.8111 - f1score: 0.8114 - val_loss: 0.4810 - val_acc: 0.8015 - val_f1score: 0.8143\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4739 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4713 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4806 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4713 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4806 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4685 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4634 - acc: 0.8190 - f1score: 0.8204 - val_loss: 0.4804 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4634 - acc: 0.8190 - f1score: 0.8204 - val_loss: 0.4804 - val_acc: 0.8004 - val_f1score: 0.8059\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4584 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4596 - acc: 0.8132 - f1score: 0.8133 - val_loss: 0.4820 - val_acc: 0.7940 - val_f1score: 0.7875\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4596 - acc: 0.8132 - f1score: 0.8133 - val_loss: 0.4820 - val_acc: 0.7940 - val_f1score: 0.7875\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4637 - acc: 0.8080 - f1score: 0.8080\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4612 - acc: 0.8111 - f1score: 0.8120 - val_loss: 0.4801 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4612 - acc: 0.8111 - f1score: 0.8120 - val_loss: 0.4801 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4624 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4622 - acc: 0.8148 - f1score: 0.8153 - val_loss: 0.4792 - val_acc: 0.7951 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4622 - acc: 0.8148 - f1score: 0.8153 - val_loss: 0.4792 - val_acc: 0.7951 - val_f1score: 0.7885\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4740 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00031: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4750 - acc: 0.8175 - f1score: 0.8174 - val_loss: 0.4803 - val_acc: 0.7908 - val_f1score: 0.7971\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4750 - acc: 0.8175 - f1score: 0.8174 - val_loss: 0.4803 - val_acc: 0.7908 - val_f1score: 0.7971\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4644 - acc: 0.8119 - f1score: 0.8119\n",
            "Epoch 00032: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4621 - acc: 0.8132 - f1score: 0.8136 - val_loss: 0.4809 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4621 - acc: 0.8132 - f1score: 0.8136 - val_loss: 0.4809 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4640 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00033: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4611 - acc: 0.8185 - f1score: 0.8190 - val_loss: 0.4787 - val_acc: 0.7951 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4611 - acc: 0.8185 - f1score: 0.8190 - val_loss: 0.4787 - val_acc: 0.7951 - val_f1score: 0.7935\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4700 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00034: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4690 - acc: 0.8127 - f1score: 0.8126 - val_loss: 0.4794 - val_acc: 0.7908 - val_f1score: 0.7946\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4690 - acc: 0.8127 - f1score: 0.8126 - val_loss: 0.4794 - val_acc: 0.7908 - val_f1score: 0.7946\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4671 - acc: 0.8119 - f1score: 0.8119\n",
            "Epoch 00035: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4658 - acc: 0.8132 - f1score: 0.8136 - val_loss: 0.4766 - val_acc: 0.8026 - val_f1score: 0.8003\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4658 - acc: 0.8132 - f1score: 0.8136 - val_loss: 0.4766 - val_acc: 0.8026 - val_f1score: 0.8003\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4574 - acc: 0.8092 - f1score: 0.8092\n",
            "Epoch 00036: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4575 - acc: 0.8106 - f1score: 0.8110 - val_loss: 0.4765 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4575 - acc: 0.8106 - f1score: 0.8110 - val_loss: 0.4765 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4607 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00037: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4614 - acc: 0.8169 - f1score: 0.8169 - val_loss: 0.4776 - val_acc: 0.7918 - val_f1score: 0.7956\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4614 - acc: 0.8169 - f1score: 0.8169 - val_loss: 0.4776 - val_acc: 0.7918 - val_f1score: 0.7956\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4533 - acc: 0.8198 - f1score: 0.8198\n",
            "Epoch 00038: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4565 - acc: 0.8159 - f1score: 0.8148 - val_loss: 0.4769 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4565 - acc: 0.8159 - f1score: 0.8148 - val_loss: 0.4769 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4600 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00039: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4593 - acc: 0.8148 - f1score: 0.8148 - val_loss: 0.4765 - val_acc: 0.7961 - val_f1score: 0.7995\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4593 - acc: 0.8148 - f1score: 0.8148 - val_loss: 0.4765 - val_acc: 0.7961 - val_f1score: 0.7995\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4528 - acc: 0.8186 - f1score: 0.8186\n",
            "Epoch 00040: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4577 - acc: 0.8159 - f1score: 0.8151 - val_loss: 0.4750 - val_acc: 0.7951 - val_f1score: 0.7985\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4577 - acc: 0.8159 - f1score: 0.8151 - val_loss: 0.4750 - val_acc: 0.7951 - val_f1score: 0.7985\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4598 - acc: 0.8203 - f1score: 0.8203\n",
            "Epoch 00041: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4636 - acc: 0.8164 - f1score: 0.8153 - val_loss: 0.4756 - val_acc: 0.7908 - val_f1score: 0.8046\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4636 - acc: 0.8164 - f1score: 0.8153 - val_loss: 0.4756 - val_acc: 0.7908 - val_f1score: 0.8046\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4576 - acc: 0.8175 - f1score: 0.8175\n",
            "Epoch 00042: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4574 - acc: 0.8159 - f1score: 0.8154 - val_loss: 0.4752 - val_acc: 0.7940 - val_f1score: 0.7826\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4574 - acc: 0.8159 - f1score: 0.8154 - val_loss: 0.4752 - val_acc: 0.7940 - val_f1score: 0.7826\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4486 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00043: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4600 - acc: 0.8132 - f1score: 0.8126 - val_loss: 0.4745 - val_acc: 0.7940 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4600 - acc: 0.8132 - f1score: 0.8126 - val_loss: 0.4745 - val_acc: 0.7940 - val_f1score: 0.8000\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4554 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00044: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4601 - acc: 0.8127 - f1score: 0.8123 - val_loss: 0.4761 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4601 - acc: 0.8127 - f1score: 0.8123 - val_loss: 0.4761 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4548 - acc: 0.8198 - f1score: 0.8198\n",
            "Epoch 00045: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4567 - acc: 0.8206 - f1score: 0.8209 - val_loss: 0.4745 - val_acc: 0.7961 - val_f1score: 0.8020\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4567 - acc: 0.8206 - f1score: 0.8209 - val_loss: 0.4745 - val_acc: 0.7961 - val_f1score: 0.8020\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4436 - acc: 0.8220 - f1score: 0.8220\n",
            "Epoch 00046: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4548 - acc: 0.8164 - f1score: 0.8148 - val_loss: 0.4745 - val_acc: 0.7918 - val_f1score: 0.7881\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4548 - acc: 0.8164 - f1score: 0.8148 - val_loss: 0.4745 - val_acc: 0.7918 - val_f1score: 0.7881\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4629 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00047: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4639 - acc: 0.8127 - f1score: 0.8123 - val_loss: 0.4732 - val_acc: 0.7994 - val_f1score: 0.7924\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4639 - acc: 0.8127 - f1score: 0.8123 - val_loss: 0.4732 - val_acc: 0.7994 - val_f1score: 0.7924\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4552 - acc: 0.8170 - f1score: 0.8170\n",
            "Epoch 00048: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4552 - acc: 0.8164 - f1score: 0.8162 - val_loss: 0.4732 - val_acc: 0.7961 - val_f1score: 0.7945\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4552 - acc: 0.8164 - f1score: 0.8162 - val_loss: 0.4732 - val_acc: 0.7961 - val_f1score: 0.7945\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4544 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00049: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4545 - acc: 0.8148 - f1score: 0.8153 - val_loss: 0.4755 - val_acc: 0.7854 - val_f1score: 0.7872\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4545 - acc: 0.8148 - f1score: 0.8153 - val_loss: 0.4755 - val_acc: 0.7854 - val_f1score: 0.7872\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4527 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00050: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4552 - acc: 0.8148 - f1score: 0.8144 - val_loss: 0.4733 - val_acc: 0.7961 - val_f1score: 0.8020\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 5s 3ms/sample - loss: 0.4552 - acc: 0.8148 - f1score: 0.8144 - val_loss: 0.4733 - val_acc: 0.7961 - val_f1score: 0.8020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 49%|████▉     | 47/96 [2:58:03<2:44:42, 201.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 4.2236 - acc: 0.4570 - f1score: 0.4570\n",
            "Epoch 00001: val_acc improved from -inf to 0.56867, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.07.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 4.1314 - acc: 0.4566 - f1score: 0.4565 - val_loss: 1.0738 - val_acc: 0.5687 - val_f1score: 0.5650\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.56867, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.07.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 4.1314 - acc: 0.4566 - f1score: 0.4565 - val_loss: 1.0738 - val_acc: 0.5687 - val_f1score: 0.5650\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.8248 - acc: 0.6462 - f1score: 0.6462\n",
            "Epoch 00002: val_acc improved from 0.56867 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.35.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.7703 - acc: 0.6545 - f1score: 0.6569 - val_loss: 1.3511 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.56867 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.35.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.7703 - acc: 0.6545 - f1score: 0.6569 - val_loss: 1.3511 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.3775 - acc: 0.7556 - f1score: 0.7556\n",
            "Epoch 00003: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.3968 - acc: 0.7519 - f1score: 0.7508 - val_loss: 1.0452 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.3968 - acc: 0.7519 - f1score: 0.7508 - val_loss: 1.0452 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 1.1406 - acc: 0.7266 - f1score: 0.7266\n",
            "Epoch 00004: val_acc improved from 0.79292 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.73.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.1311 - acc: 0.7317 - f1score: 0.7332 - val_loss: 0.7344 - val_acc: 0.8015 - val_f1score: 0.7969\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.79292 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.73.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.1311 - acc: 0.7317 - f1score: 0.7332 - val_loss: 0.7344 - val_acc: 0.8015 - val_f1score: 0.7969\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.8412 - acc: 0.7221 - f1score: 0.7221\n",
            "Epoch 00005: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.56.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.8299 - acc: 0.7243 - f1score: 0.7250 - val_loss: 0.5569 - val_acc: 0.8026 - val_f1score: 0.8078\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.56.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.8299 - acc: 0.7243 - f1score: 0.7250 - val_loss: 0.5569 - val_acc: 0.8026 - val_f1score: 0.8078\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5595 - acc: 0.7729 - f1score: 0.7729\n",
            "Epoch 00006: val_acc improved from 0.80258 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.49.h5\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.80258 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.49.h5\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5693 - acc: 0.7730 - f1score: 0.7731 - val_loss: 0.4922 - val_acc: 0.8047 - val_f1score: 0.8073\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5693 - acc: 0.7730 - f1score: 0.7731 - val_loss: 0.4922 - val_acc: 0.8047 - val_f1score: 0.8073\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5192 - acc: 0.7946 - f1score: 0.7946\n",
            "Epoch 00007: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5218 - acc: 0.7926 - f1score: 0.7920 - val_loss: 0.4852 - val_acc: 0.7994 - val_f1score: 0.7949\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.5218 - acc: 0.7926 - f1score: 0.7920 - val_loss: 0.4852 - val_acc: 0.7994 - val_f1score: 0.7949\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.5127 - acc: 0.7907 - f1score: 0.7907\n",
            "Epoch 00008: val_acc improved from 0.80472 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.49.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5135 - acc: 0.7926 - f1score: 0.7931 - val_loss: 0.4889 - val_acc: 0.8058 - val_f1score: 0.8083\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80472 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.49.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5135 - acc: 0.7926 - f1score: 0.7931 - val_loss: 0.4889 - val_acc: 0.8058 - val_f1score: 0.8083\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4930 - acc: 0.8008 - f1score: 0.8008\n",
            "Epoch 00009: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4907 - acc: 0.8026 - f1score: 0.8032 - val_loss: 0.4870 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4907 - acc: 0.8026 - f1score: 0.8032 - val_loss: 0.4870 - val_acc: 0.8036 - val_f1score: 0.8038\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4833 - acc: 0.8108 - f1score: 0.8108\n",
            "Epoch 00010: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4841 - acc: 0.8085 - f1score: 0.8078 - val_loss: 0.4883 - val_acc: 0.7951 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4841 - acc: 0.8085 - f1score: 0.8078 - val_loss: 0.4883 - val_acc: 0.7951 - val_f1score: 0.7885\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4936 - acc: 0.8092 - f1score: 0.8092\n",
            "Epoch 00011: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4915 - acc: 0.8095 - f1score: 0.8096 - val_loss: 0.4881 - val_acc: 0.7951 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4915 - acc: 0.8095 - f1score: 0.8096 - val_loss: 0.4881 - val_acc: 0.7951 - val_f1score: 0.7885\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4772 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00012: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4791 - acc: 0.8143 - f1score: 0.8145 - val_loss: 0.4844 - val_acc: 0.7983 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4791 - acc: 0.8143 - f1score: 0.8145 - val_loss: 0.4844 - val_acc: 0.7983 - val_f1score: 0.8014\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4759 - acc: 0.8075 - f1score: 0.8075\n",
            "Epoch 00013: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4740 - acc: 0.8090 - f1score: 0.8094 - val_loss: 0.4857 - val_acc: 0.7951 - val_f1score: 0.7910\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4740 - acc: 0.8090 - f1score: 0.8094 - val_loss: 0.4857 - val_acc: 0.7951 - val_f1score: 0.7910\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4685 - acc: 0.8181 - f1score: 0.8181\n",
            "Epoch 00014: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4695 - acc: 0.8169 - f1score: 0.8166 - val_loss: 0.4849 - val_acc: 0.7951 - val_f1score: 0.7985\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4695 - acc: 0.8169 - f1score: 0.8166 - val_loss: 0.4849 - val_acc: 0.7951 - val_f1score: 0.7985\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4777 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00015: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4769 - acc: 0.8153 - f1score: 0.8154 - val_loss: 0.4816 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4769 - acc: 0.8153 - f1score: 0.8154 - val_loss: 0.4816 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4674 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00016: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4695 - acc: 0.8143 - f1score: 0.8138 - val_loss: 0.4823 - val_acc: 0.7951 - val_f1score: 0.7960\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4695 - acc: 0.8143 - f1score: 0.8138 - val_loss: 0.4823 - val_acc: 0.7951 - val_f1score: 0.7960\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4566 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00017: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4631 - acc: 0.8116 - f1score: 0.8104 - val_loss: 0.4820 - val_acc: 0.7994 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4631 - acc: 0.8116 - f1score: 0.8104 - val_loss: 0.4820 - val_acc: 0.7994 - val_f1score: 0.8024\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4732 - acc: 0.8108 - f1score: 0.8108\n",
            "Epoch 00018: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4713 - acc: 0.8122 - f1score: 0.8126 - val_loss: 0.4806 - val_acc: 0.7897 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4713 - acc: 0.8122 - f1score: 0.8126 - val_loss: 0.4806 - val_acc: 0.7897 - val_f1score: 0.7936\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4801 - acc: 0.8075 - f1score: 0.8075\n",
            "Epoch 00019: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4787 - acc: 0.8106 - f1score: 0.8115 - val_loss: 0.4821 - val_acc: 0.7961 - val_f1score: 0.8020\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4787 - acc: 0.8106 - f1score: 0.8115 - val_loss: 0.4821 - val_acc: 0.7961 - val_f1score: 0.8020\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4785 - acc: 0.8092 - f1score: 0.8092\n",
            "Epoch 00020: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4781 - acc: 0.8106 - f1score: 0.8110 - val_loss: 0.4855 - val_acc: 0.7854 - val_f1score: 0.7847\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4781 - acc: 0.8106 - f1score: 0.8110 - val_loss: 0.4855 - val_acc: 0.7854 - val_f1score: 0.7847\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4620 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00021: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4625 - acc: 0.8143 - f1score: 0.8143 - val_loss: 0.4798 - val_acc: 0.7940 - val_f1score: 0.7875\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4625 - acc: 0.8143 - f1score: 0.8143 - val_loss: 0.4798 - val_acc: 0.7940 - val_f1score: 0.7875\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4595 - acc: 0.8119 - f1score: 0.8119\n",
            "Epoch 00022: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4599 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4804 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4599 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4804 - val_acc: 0.7940 - val_f1score: 0.7975\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4613 - acc: 0.8108 - f1score: 0.8108\n",
            "Epoch 00023: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4607 - acc: 0.8111 - f1score: 0.8112 - val_loss: 0.4813 - val_acc: 0.7897 - val_f1score: 0.7961\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4607 - acc: 0.8111 - f1score: 0.8112 - val_loss: 0.4813 - val_acc: 0.7897 - val_f1score: 0.7961\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4720 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00024: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4690 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4810 - val_acc: 0.7897 - val_f1score: 0.7886\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4690 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4810 - val_acc: 0.7897 - val_f1score: 0.7886\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4628 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00025: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4620 - acc: 0.8138 - f1score: 0.8136 - val_loss: 0.4799 - val_acc: 0.7951 - val_f1score: 0.7960\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4620 - acc: 0.8138 - f1score: 0.8136 - val_loss: 0.4799 - val_acc: 0.7951 - val_f1score: 0.7960\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4674 - acc: 0.8131 - f1score: 0.8131\n",
            "Epoch 00026: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4630 - acc: 0.8164 - f1score: 0.8174 - val_loss: 0.4767 - val_acc: 0.7897 - val_f1score: 0.7836\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4630 - acc: 0.8164 - f1score: 0.8174 - val_loss: 0.4767 - val_acc: 0.7897 - val_f1score: 0.7836\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4618 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00027: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4616 - acc: 0.8138 - f1score: 0.8136 - val_loss: 0.4772 - val_acc: 0.7961 - val_f1score: 0.7970\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4616 - acc: 0.8138 - f1score: 0.8136 - val_loss: 0.4772 - val_acc: 0.7961 - val_f1score: 0.7970\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4602 - acc: 0.8142 - f1score: 0.8142\n",
            "Epoch 00028: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4612 - acc: 0.8132 - f1score: 0.8130 - val_loss: 0.4742 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4612 - acc: 0.8132 - f1score: 0.8130 - val_loss: 0.4742 - val_acc: 0.7994 - val_f1score: 0.7974\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4582 - acc: 0.8097 - f1score: 0.8097\n",
            "Epoch 00029: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4570 - acc: 0.8116 - f1score: 0.8122 - val_loss: 0.4793 - val_acc: 0.7897 - val_f1score: 0.7911\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4570 - acc: 0.8116 - f1score: 0.8122 - val_loss: 0.4793 - val_acc: 0.7897 - val_f1score: 0.7911\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4513 - acc: 0.8181 - f1score: 0.8181\n",
            "Epoch 00030: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4559 - acc: 0.8153 - f1score: 0.8146 - val_loss: 0.4800 - val_acc: 0.7961 - val_f1score: 0.7995\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4559 - acc: 0.8153 - f1score: 0.8146 - val_loss: 0.4800 - val_acc: 0.7961 - val_f1score: 0.7995\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4579 - acc: 0.8119 - f1score: 0.8119\n",
            "Epoch 00031: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4584 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4766 - val_acc: 0.7833 - val_f1score: 0.7878\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4584 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4766 - val_acc: 0.7833 - val_f1score: 0.7878\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4488 - acc: 0.8248 - f1score: 0.8248\n",
            "Epoch 00032: val_acc improved from 0.80579 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.32-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4513 - acc: 0.8217 - f1score: 0.8208 - val_loss: 0.4788 - val_acc: 0.8069 - val_f1score: 0.8117\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.80579 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.32-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4513 - acc: 0.8217 - f1score: 0.8208 - val_loss: 0.4788 - val_acc: 0.8069 - val_f1score: 0.8117\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4607 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00033: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4612 - acc: 0.8143 - f1score: 0.8137 - val_loss: 0.4765 - val_acc: 0.7811 - val_f1score: 0.7808\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4612 - acc: 0.8143 - f1score: 0.8137 - val_loss: 0.4765 - val_acc: 0.7811 - val_f1score: 0.7808\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4645 - acc: 0.8058 - f1score: 0.8058\n",
            "Epoch 00034: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4579 - acc: 0.8111 - f1score: 0.8126 - val_loss: 0.4742 - val_acc: 0.8004 - val_f1score: 0.7909\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4579 - acc: 0.8111 - f1score: 0.8126 - val_loss: 0.4742 - val_acc: 0.8004 - val_f1score: 0.7909\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4646 - acc: 0.8097 - f1score: 0.8097\n",
            "Epoch 00035: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4593 - acc: 0.8122 - f1score: 0.8129 - val_loss: 0.4754 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4593 - acc: 0.8122 - f1score: 0.8129 - val_loss: 0.4754 - val_acc: 0.7940 - val_f1score: 0.7925\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4569 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00036: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4555 - acc: 0.8164 - f1score: 0.8164 - val_loss: 0.4739 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4555 - acc: 0.8164 - f1score: 0.8164 - val_loss: 0.4739 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4519 - acc: 0.8242 - f1score: 0.8242\n",
            "Epoch 00037: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4524 - acc: 0.8238 - f1score: 0.8237 - val_loss: 0.4729 - val_acc: 0.7972 - val_f1score: 0.7905\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4524 - acc: 0.8238 - f1score: 0.8237 - val_loss: 0.4729 - val_acc: 0.7972 - val_f1score: 0.7905\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4560 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00038: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4546 - acc: 0.8127 - f1score: 0.8128 - val_loss: 0.4730 - val_acc: 0.7897 - val_f1score: 0.8036\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4546 - acc: 0.8127 - f1score: 0.8128 - val_loss: 0.4730 - val_acc: 0.7897 - val_f1score: 0.8036\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4589 - acc: 0.8119 - f1score: 0.8119\n",
            "Epoch 00039: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4580 - acc: 0.8132 - f1score: 0.8136 - val_loss: 0.4743 - val_acc: 0.7972 - val_f1score: 0.7930\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4580 - acc: 0.8132 - f1score: 0.8136 - val_loss: 0.4743 - val_acc: 0.7972 - val_f1score: 0.7930\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4550 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00040: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4592 - acc: 0.8143 - f1score: 0.8138 - val_loss: 0.4759 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4592 - acc: 0.8143 - f1score: 0.8138 - val_loss: 0.4759 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4547 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00041: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4564 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4727 - val_acc: 0.8015 - val_f1score: 0.8069\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4564 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4727 - val_acc: 0.8015 - val_f1score: 0.8069\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4527 - acc: 0.8203 - f1score: 0.8203\n",
            "Epoch 00042: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4548 - acc: 0.8185 - f1score: 0.8180 - val_loss: 0.4762 - val_acc: 0.7886 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4548 - acc: 0.8185 - f1score: 0.8180 - val_loss: 0.4762 - val_acc: 0.7886 - val_f1score: 0.7951\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4614 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00043: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4610 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4735 - val_acc: 0.7983 - val_f1score: 0.7989\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4610 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4735 - val_acc: 0.7983 - val_f1score: 0.7989\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4680 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00044: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4648 - acc: 0.8122 - f1score: 0.8124 - val_loss: 0.4699 - val_acc: 0.7972 - val_f1score: 0.8005\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4648 - acc: 0.8122 - f1score: 0.8124 - val_loss: 0.4699 - val_acc: 0.7972 - val_f1score: 0.8005\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4527 - acc: 0.8153 - f1score: 0.8153\n",
            "Epoch 00045: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4536 - acc: 0.8132 - f1score: 0.8126 - val_loss: 0.4706 - val_acc: 0.7983 - val_f1score: 0.7914\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4536 - acc: 0.8132 - f1score: 0.8126 - val_loss: 0.4706 - val_acc: 0.7983 - val_f1score: 0.7914\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4565 - acc: 0.8164 - f1score: 0.8164\n",
            "Epoch 00046: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4572 - acc: 0.8159 - f1score: 0.8157 - val_loss: 0.4735 - val_acc: 0.7886 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4572 - acc: 0.8159 - f1score: 0.8157 - val_loss: 0.4735 - val_acc: 0.7886 - val_f1score: 0.7951\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4479 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00047: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4481 - acc: 0.8138 - f1score: 0.8141 - val_loss: 0.4719 - val_acc: 0.8036 - val_f1score: 0.7988\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4481 - acc: 0.8138 - f1score: 0.8141 - val_loss: 0.4719 - val_acc: 0.8036 - val_f1score: 0.7988\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4628 - acc: 0.8158 - f1score: 0.8158\n",
            "Epoch 00048: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4646 - acc: 0.8138 - f1score: 0.8132 - val_loss: 0.4748 - val_acc: 0.7800 - val_f1score: 0.7823\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4646 - acc: 0.8138 - f1score: 0.8132 - val_loss: 0.4748 - val_acc: 0.7800 - val_f1score: 0.7823\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4475 - acc: 0.8186 - f1score: 0.8186\n",
            "Epoch 00049: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4499 - acc: 0.8185 - f1score: 0.8185 - val_loss: 0.4724 - val_acc: 0.8015 - val_f1score: 0.7919\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4499 - acc: 0.8185 - f1score: 0.8185 - val_loss: 0.4724 - val_acc: 0.8015 - val_f1score: 0.7919\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1792/1890 [===========================>..] - ETA: 0s - loss: 0.4572 - acc: 0.8214 - f1score: 0.8214\n",
            "Epoch 00050: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4558 - acc: 0.8217 - f1score: 0.8218 - val_loss: 0.4708 - val_acc: 0.7886 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4558 - acc: 0.8217 - f1score: 0.8218 - val_loss: 0.4708 - val_acc: 0.7886 - val_f1score: 0.7951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|█████     | 48/96 [3:04:03<3:19:19, 249.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 8.7073 - acc: 0.4380 - f1score: 0.4380\n",
            "Epoch 00001: val_acc improved from -inf to 0.43026, saving model to /content/drive/My Drive/LSTM_Model/model.01-8.67.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 8.7083 - acc: 0.4376 - f1score: 0.4372 - val_loss: 8.6688 - val_acc: 0.4303 - val_f1score: 0.4299\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.43026, saving model to /content/drive/My Drive/LSTM_Model/model.01-8.67.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 8.7083 - acc: 0.4376 - f1score: 0.4372 - val_loss: 8.6688 - val_acc: 0.4303 - val_f1score: 0.4299\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 8.1281 - acc: 0.4154 - f1score: 0.4154\n",
            "Epoch 00002: val_acc did not improve from 0.43026\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 8.0794 - acc: 0.4185 - f1score: 0.4212 - val_loss: 7.4590 - val_acc: 0.4281 - val_f1score: 0.4270\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.43026\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 8.0794 - acc: 0.4185 - f1score: 0.4212 - val_loss: 7.4590 - val_acc: 0.4281 - val_f1score: 0.4270\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 3.1040 - acc: 0.6223 - f1score: 0.6223\n",
            "Epoch 00003: val_acc improved from 0.43026 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.61.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 3.0953 - acc: 0.6249 - f1score: 0.6271 - val_loss: 0.6130 - val_acc: 0.8036 - val_f1score: 0.8045\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.43026 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.61.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 3.0953 - acc: 0.6249 - f1score: 0.6271 - val_loss: 0.6130 - val_acc: 0.8036 - val_f1score: 0.8045\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.9144 - acc: 0.7414 - f1score: 0.7414\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.8987 - acc: 0.7429 - f1score: 0.7441 - val_loss: 0.4953 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.8987 - acc: 0.7429 - f1score: 0.7441 - val_loss: 0.4953 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.5463 - acc: 0.7414 - f1score: 0.7414\n",
            "Epoch 00005: val_acc improved from 0.80365 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.53.h5\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.80365 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.53.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.5568 - acc: 0.7402 - f1score: 0.7392 - val_loss: 0.5338 - val_acc: 0.8058 - val_f1score: 0.8098\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.5568 - acc: 0.7402 - f1score: 0.7392 - val_loss: 0.5338 - val_acc: 0.8058 - val_f1score: 0.8098\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.1818 - acc: 0.7645 - f1score: 0.7645\n",
            "Epoch 00006: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1858 - acc: 0.7640 - f1score: 0.7636 - val_loss: 0.5510 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1858 - acc: 0.7640 - f1score: 0.7636 - val_loss: 0.5510 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.8151 - acc: 0.7446 - f1score: 0.7446\n",
            "Epoch 00007: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.8135 - acc: 0.7450 - f1score: 0.7453 - val_loss: 0.5551 - val_acc: 0.7715 - val_f1score: 0.7733\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.8135 - acc: 0.7450 - f1score: 0.7453 - val_loss: 0.5551 - val_acc: 0.7715 - val_f1score: 0.7733\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5621 - acc: 0.7570 - f1score: 0.7570\n",
            "Epoch 00008: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5634 - acc: 0.7561 - f1score: 0.7553 - val_loss: 0.5079 - val_acc: 0.7650 - val_f1score: 0.7654\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5634 - acc: 0.7561 - f1score: 0.7553 - val_loss: 0.5079 - val_acc: 0.7650 - val_f1score: 0.7654\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5080 - acc: 0.7780 - f1score: 0.7780\n",
            "Epoch 00009: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5079 - acc: 0.7767 - f1score: 0.7756 - val_loss: 0.5139 - val_acc: 0.7961 - val_f1score: 0.7980\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5079 - acc: 0.7767 - f1score: 0.7756 - val_loss: 0.5139 - val_acc: 0.7961 - val_f1score: 0.7980\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5048 - acc: 0.7931 - f1score: 0.7931\n",
            "Epoch 00010: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5058 - acc: 0.7921 - f1score: 0.7912 - val_loss: 0.5005 - val_acc: 0.7994 - val_f1score: 0.8003\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5058 - acc: 0.7921 - f1score: 0.7912 - val_loss: 0.5005 - val_acc: 0.7994 - val_f1score: 0.8003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 51%|█████     | 49/96 [3:05:25<2:35:59, 199.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.2650 - acc: 0.7360 - f1score: 0.7360\n",
            "Epoch 00001: val_acc improved from -inf to 0.77897, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.53.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 1.2740 - acc: 0.7365 - f1score: 0.7369 - val_loss: 0.5342 - val_acc: 0.7790 - val_f1score: 0.7789\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77897, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.53.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 1.2740 - acc: 0.7365 - f1score: 0.7369 - val_loss: 0.5342 - val_acc: 0.7790 - val_f1score: 0.7789\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.1840 - acc: 0.7311 - f1score: 0.7311\n",
            "Epoch 00002: val_acc improved from 0.77897 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.52.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.77897 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.52.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 1.1769 - acc: 0.7312 - f1score: 0.7313 - val_loss: 0.5196 - val_acc: 0.8036 - val_f1score: 0.8045\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 1.1769 - acc: 0.7312 - f1score: 0.7313 - val_loss: 0.5196 - val_acc: 0.8036 - val_f1score: 0.8045\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.7078 - acc: 0.7877 - f1score: 0.7877\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.7008 - acc: 0.7884 - f1score: 0.7889 - val_loss: 0.5506 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.7008 - acc: 0.7884 - f1score: 0.7889 - val_loss: 0.5506 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4761 - acc: 0.8066 - f1score: 0.8066\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4770 - acc: 0.8074 - f1score: 0.8081 - val_loss: 0.5267 - val_acc: 0.7972 - val_f1score: 0.7926\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4770 - acc: 0.8074 - f1score: 0.8081 - val_loss: 0.5267 - val_acc: 0.7972 - val_f1score: 0.7926\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4601 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4646 - acc: 0.8127 - f1score: 0.8101 - val_loss: 0.4807 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4646 - acc: 0.8127 - f1score: 0.8101 - val_loss: 0.4807 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4605 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4602 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4861 - val_acc: 0.8004 - val_f1score: 0.7965\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4602 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4861 - val_acc: 0.8004 - val_f1score: 0.7965\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4596 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4622 - acc: 0.8074 - f1score: 0.8054 - val_loss: 0.4924 - val_acc: 0.7715 - val_f1score: 0.7733\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4622 - acc: 0.8074 - f1score: 0.8054 - val_loss: 0.4924 - val_acc: 0.7715 - val_f1score: 0.7733\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4624 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4617 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4853 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4617 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4853 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4527 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4526 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4858 - val_acc: 0.7865 - val_f1score: 0.7854\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4526 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4858 - val_acc: 0.7865 - val_f1score: 0.7854\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4583 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4588 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4872 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4588 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4872 - val_acc: 0.7843 - val_f1score: 0.7833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 52%|█████▏    | 50/96 [3:07:10<2:11:03, 170.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.6951 - acc: 0.6692 - f1score: 0.6692\n",
            "Epoch 00001: val_acc improved from -inf to 0.78219, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.48.h5\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78219, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.48.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.6778 - acc: 0.6709 - f1score: 0.6724 - val_loss: 1.4756 - val_acc: 0.7822 - val_f1score: 0.7812\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.6778 - acc: 0.6709 - f1score: 0.6724 - val_loss: 1.4756 - val_acc: 0.7822 - val_f1score: 0.7812\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.6452 - acc: 0.7365 - f1score: 0.7365\n",
            "Epoch 00002: val_acc improved from 0.78219 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.56.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.78219 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.56.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.6266 - acc: 0.7365 - f1score: 0.7365 - val_loss: 0.5632 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.6266 - acc: 0.7365 - f1score: 0.7365 - val_loss: 0.5632 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.5049 - acc: 0.7554 - f1score: 0.7554\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.4953 - acc: 0.7566 - f1score: 0.7577 - val_loss: 0.5204 - val_acc: 0.7886 - val_f1score: 0.7899\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.4953 - acc: 0.7566 - f1score: 0.7577 - val_loss: 0.5204 - val_acc: 0.7886 - val_f1score: 0.7899\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.3768 - acc: 0.7769 - f1score: 0.7769\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3666 - acc: 0.7778 - f1score: 0.7785 - val_loss: 0.5004 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3666 - acc: 0.7778 - f1score: 0.7785 - val_loss: 0.5004 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.2915 - acc: 0.7796 - f1score: 0.7796\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.2864 - acc: 0.7804 - f1score: 0.7811 - val_loss: 0.5267 - val_acc: 0.7822 - val_f1score: 0.7821\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.2864 - acc: 0.7804 - f1score: 0.7811 - val_loss: 0.5267 - val_acc: 0.7822 - val_f1score: 0.7821\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.3510 - acc: 0.7689 - f1score: 0.7689\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3519 - acc: 0.7693 - f1score: 0.7697 - val_loss: 0.4883 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3519 - acc: 0.7693 - f1score: 0.7697 - val_loss: 0.4883 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.1816 - acc: 0.7548 - f1score: 0.7548\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1747 - acc: 0.7566 - f1score: 0.7581 - val_loss: 0.4850 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1747 - acc: 0.7566 - f1score: 0.7581 - val_loss: 0.4850 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.3348 - acc: 0.7845 - f1score: 0.7845\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3195 - acc: 0.7831 - f1score: 0.7819 - val_loss: 0.4828 - val_acc: 0.7940 - val_f1score: 0.7895\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3195 - acc: 0.7831 - f1score: 0.7819 - val_loss: 0.4828 - val_acc: 0.7940 - val_f1score: 0.7895\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.3049 - acc: 0.7834 - f1score: 0.7834\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3052 - acc: 0.7825 - f1score: 0.7818 - val_loss: 0.5054 - val_acc: 0.7886 - val_f1score: 0.7875\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3052 - acc: 0.7825 - f1score: 0.7818 - val_loss: 0.5054 - val_acc: 0.7886 - val_f1score: 0.7875\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.3934 - acc: 0.7678 - f1score: 0.7678\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3830 - acc: 0.7698 - f1score: 0.7716 - val_loss: 0.4804 - val_acc: 0.7854 - val_f1score: 0.7828\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3830 - acc: 0.7698 - f1score: 0.7716 - val_loss: 0.4804 - val_acc: 0.7854 - val_f1score: 0.7828\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.1540 - acc: 0.7883 - f1score: 0.7883\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1507 - acc: 0.7873 - f1score: 0.7865 - val_loss: 0.5112 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1507 - acc: 0.7873 - f1score: 0.7865 - val_loss: 0.5112 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.3899 - acc: 0.7732 - f1score: 0.7732\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.4039 - acc: 0.7735 - f1score: 0.7739 - val_loss: 0.4885 - val_acc: 0.7886 - val_f1score: 0.7916\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.4039 - acc: 0.7735 - f1score: 0.7739 - val_loss: 0.4885 - val_acc: 0.7886 - val_f1score: 0.7916\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.3417 - acc: 0.7807 - f1score: 0.7807\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3521 - acc: 0.7794 - f1score: 0.7782 - val_loss: 0.4789 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3521 - acc: 0.7794 - f1score: 0.7782 - val_loss: 0.4789 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.1147 - acc: 0.7888 - f1score: 0.7888\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1241 - acc: 0.7884 - f1score: 0.7880 - val_loss: 0.4798 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1241 - acc: 0.7884 - f1score: 0.7880 - val_loss: 0.4798 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.1098 - acc: 0.7856 - f1score: 0.7856\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1155 - acc: 0.7857 - f1score: 0.7858 - val_loss: 0.4964 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1155 - acc: 0.7857 - f1score: 0.7858 - val_loss: 0.4964 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.2233 - acc: 0.7904 - f1score: 0.7904\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.2371 - acc: 0.7894 - f1score: 0.7886 - val_loss: 0.5305 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.2371 - acc: 0.7894 - f1score: 0.7886 - val_loss: 0.5305 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.1464 - acc: 0.7899 - f1score: 0.7899\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1508 - acc: 0.7899 - f1score: 0.7900 - val_loss: 0.4714 - val_acc: 0.7940 - val_f1score: 0.7911\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1508 - acc: 0.7899 - f1score: 0.7900 - val_loss: 0.4714 - val_acc: 0.7940 - val_f1score: 0.7911\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.1204 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00018: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.18-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1149 - acc: 0.7979 - f1score: 0.7983 - val_loss: 0.4793 - val_acc: 0.8026 - val_f1score: 0.7986\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.18-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1149 - acc: 0.7979 - f1score: 0.7983 - val_loss: 0.4793 - val_acc: 0.8026 - val_f1score: 0.7986\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.0297 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00019: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.19-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0179 - acc: 0.7963 - f1score: 0.7972 - val_loss: 0.4740 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.19-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0179 - acc: 0.7963 - f1score: 0.7972 - val_loss: 0.4740 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.9999 - acc: 0.7786 - f1score: 0.7786\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.9967 - acc: 0.7788 - f1score: 0.7791 - val_loss: 0.4763 - val_acc: 0.8015 - val_f1score: 0.7976\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.9967 - acc: 0.7788 - f1score: 0.7791 - val_loss: 0.4763 - val_acc: 0.8015 - val_f1score: 0.7976\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.7755 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7706 - acc: 0.7968 - f1score: 0.7968 - val_loss: 0.4990 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7706 - acc: 0.7968 - f1score: 0.7968 - val_loss: 0.4990 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5562 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5533 - acc: 0.7974 - f1score: 0.7978 - val_loss: 0.4888 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5533 - acc: 0.7974 - f1score: 0.7978 - val_loss: 0.4888 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5138 - acc: 0.8001 - f1score: 0.8001\n",
            "Epoch 00023: val_acc improved from 0.80365 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.23-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5099 - acc: 0.8021 - f1score: 0.8038 - val_loss: 0.4734 - val_acc: 0.8069 - val_f1score: 0.8084\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.80365 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.23-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5099 - acc: 0.8021 - f1score: 0.8038 - val_loss: 0.4734 - val_acc: 0.8069 - val_f1score: 0.8084\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4555 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00024: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4548 - acc: 0.8138 - f1score: 0.8134 - val_loss: 0.4754 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4548 - acc: 0.8138 - f1score: 0.8134 - val_loss: 0.4754 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4537 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00025: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4548 - acc: 0.8138 - f1score: 0.8125 - val_loss: 0.4732 - val_acc: 0.8069 - val_f1score: 0.8052\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4548 - acc: 0.8138 - f1score: 0.8125 - val_loss: 0.4732 - val_acc: 0.8069 - val_f1score: 0.8052\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4459 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00026: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4443 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4681 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4443 - acc: 0.8169 - f1score: 0.8170 - val_loss: 0.4681 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4477 - acc: 0.8093 - f1score: 0.8093\n",
            "Epoch 00027: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4465 - acc: 0.8101 - f1score: 0.8107 - val_loss: 0.4707 - val_acc: 0.7972 - val_f1score: 0.7991\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4465 - acc: 0.8101 - f1score: 0.8107 - val_loss: 0.4707 - val_acc: 0.7972 - val_f1score: 0.7991\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4512 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00028: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4487 - acc: 0.8185 - f1score: 0.8191 - val_loss: 0.4691 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4487 - acc: 0.8185 - f1score: 0.8191 - val_loss: 0.4691 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00029: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4473 - acc: 0.8127 - f1score: 0.8124 - val_loss: 0.4701 - val_acc: 0.7951 - val_f1score: 0.7946\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4473 - acc: 0.8127 - f1score: 0.8124 - val_loss: 0.4701 - val_acc: 0.7951 - val_f1score: 0.7946\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4432 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00030: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4432 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4677 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4432 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4677 - val_acc: 0.7897 - val_f1score: 0.7926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 53%|█████▎    | 51/96 [3:11:04<2:22:23, 189.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.5990 - acc: 0.7064 - f1score: 0.7064\n",
            "Epoch 00001: val_acc improved from -inf to 0.74249, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.78.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 1.5994 - acc: 0.7032 - f1score: 0.7005 - val_loss: 0.7810 - val_acc: 0.7425 - val_f1score: 0.7443\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.74249, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.78.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 1.5994 - acc: 0.7032 - f1score: 0.7005 - val_loss: 0.7810 - val_acc: 0.7425 - val_f1score: 0.7443\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.7381 - acc: 0.7328 - f1score: 0.7328\n",
            "Epoch 00002: val_acc improved from 0.74249 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.54.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.7330 - acc: 0.7333 - f1score: 0.7338 - val_loss: 0.5377 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.74249 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.54.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.7330 - acc: 0.7333 - f1score: 0.7338 - val_loss: 0.5377 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5303 - acc: 0.7861 - f1score: 0.7861\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5309 - acc: 0.7868 - f1score: 0.7873 - val_loss: 0.4979 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5309 - acc: 0.7868 - f1score: 0.7873 - val_loss: 0.4979 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4889 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4871 - acc: 0.7974 - f1score: 0.7978 - val_loss: 0.4860 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4871 - acc: 0.7974 - f1score: 0.7978 - val_loss: 0.4860 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4671 - acc: 0.8028 - f1score: 0.8028\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4679 - acc: 0.8021 - f1score: 0.8015 - val_loss: 0.4859 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4679 - acc: 0.8021 - f1score: 0.8015 - val_loss: 0.4859 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4558 - acc: 0.8082 - f1score: 0.8082\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4559 - acc: 0.8074 - f1score: 0.8067 - val_loss: 0.4899 - val_acc: 0.7833 - val_f1score: 0.7855\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4559 - acc: 0.8074 - f1score: 0.8067 - val_loss: 0.4899 - val_acc: 0.7833 - val_f1score: 0.7855\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4541 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4526 - acc: 0.8148 - f1score: 0.8154 - val_loss: 0.4856 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4526 - acc: 0.8148 - f1score: 0.8154 - val_loss: 0.4856 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4580 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4588 - acc: 0.8159 - f1score: 0.8155 - val_loss: 0.4837 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4588 - acc: 0.8159 - f1score: 0.8155 - val_loss: 0.4837 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4501 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4499 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.4973 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4499 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.4973 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4613 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4588 - acc: 0.8132 - f1score: 0.8148 - val_loss: 0.4789 - val_acc: 0.7854 - val_f1score: 0.7836\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4588 - acc: 0.8132 - f1score: 0.8148 - val_loss: 0.4789 - val_acc: 0.7854 - val_f1score: 0.7836\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4482 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4479 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4795 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4479 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4795 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4563 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4531 - acc: 0.8106 - f1score: 0.8122 - val_loss: 0.5070 - val_acc: 0.7843 - val_f1score: 0.7866\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4531 - acc: 0.8106 - f1score: 0.8122 - val_loss: 0.5070 - val_acc: 0.7843 - val_f1score: 0.7866\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4530 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4520 - acc: 0.8116 - f1score: 0.8114 - val_loss: 0.4966 - val_acc: 0.7886 - val_f1score: 0.7907\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4520 - acc: 0.8116 - f1score: 0.8114 - val_loss: 0.4966 - val_acc: 0.7886 - val_f1score: 0.7907\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4548 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4531 - acc: 0.8164 - f1score: 0.8170 - val_loss: 0.4879 - val_acc: 0.7876 - val_f1score: 0.7897\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4531 - acc: 0.8164 - f1score: 0.8170 - val_loss: 0.4879 - val_acc: 0.7876 - val_f1score: 0.7897\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4623 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4630 - acc: 0.8069 - f1score: 0.8067 - val_loss: 0.4807 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4630 - acc: 0.8069 - f1score: 0.8067 - val_loss: 0.4807 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4637 - acc: 0.8066 - f1score: 0.8066\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4616 - acc: 0.8074 - f1score: 0.8081 - val_loss: 0.5098 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4616 - acc: 0.8074 - f1score: 0.8081 - val_loss: 0.5098 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4487 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4515 - acc: 0.8143 - f1score: 0.8135 - val_loss: 0.4810 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4515 - acc: 0.8143 - f1score: 0.8135 - val_loss: 0.4810 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4473 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4456 - acc: 0.8180 - f1score: 0.8195 - val_loss: 0.4796 - val_acc: 0.7800 - val_f1score: 0.7800\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4456 - acc: 0.8180 - f1score: 0.8195 - val_loss: 0.4796 - val_acc: 0.7800 - val_f1score: 0.7800\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4502 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00019: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4470 - acc: 0.8153 - f1score: 0.8173 - val_loss: 0.4846 - val_acc: 0.7929 - val_f1score: 0.7965\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4470 - acc: 0.8153 - f1score: 0.8173 - val_loss: 0.4846 - val_acc: 0.7929 - val_f1score: 0.7965\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4450 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00020: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4468 - acc: 0.8111 - f1score: 0.8104 - val_loss: 0.4806 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4468 - acc: 0.8111 - f1score: 0.8104 - val_loss: 0.4806 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00021: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4475 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4831 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4475 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4831 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4500 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00022: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4472 - acc: 0.8153 - f1score: 0.8169 - val_loss: 0.4885 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4472 - acc: 0.8153 - f1score: 0.8169 - val_loss: 0.4885 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4447 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4454 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4739 - val_acc: 0.7972 - val_f1score: 0.7958\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4454 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4739 - val_acc: 0.7972 - val_f1score: 0.7958\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4437 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00024: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4437 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4769 - val_acc: 0.7854 - val_f1score: 0.7828\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4437 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4769 - val_acc: 0.7854 - val_f1score: 0.7828\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4498 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00025: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4478 - acc: 0.8116 - f1score: 0.8127 - val_loss: 0.4778 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4478 - acc: 0.8116 - f1score: 0.8127 - val_loss: 0.4778 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4455 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00026: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4445 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4953 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4445 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4953 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4488 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00027: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4501 - acc: 0.8148 - f1score: 0.8150 - val_loss: 0.4764 - val_acc: 0.7972 - val_f1score: 0.7983\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4501 - acc: 0.8148 - f1score: 0.8150 - val_loss: 0.4764 - val_acc: 0.7972 - val_f1score: 0.7983\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4448 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00028: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4463 - acc: 0.8180 - f1score: 0.8167 - val_loss: 0.4773 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4463 - acc: 0.8180 - f1score: 0.8167 - val_loss: 0.4773 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4389 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00029: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4391 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4782 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4391 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4782 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4381 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00030: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4356 - acc: 0.8201 - f1score: 0.8215 - val_loss: 0.4760 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4356 - acc: 0.8201 - f1score: 0.8215 - val_loss: 0.4760 - val_acc: 0.7908 - val_f1score: 0.7896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 54%|█████▍    | 52/96 [3:16:10<2:44:34, 224.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 3.4771 - acc: 0.5318 - f1score: 0.5318\n",
            "Epoch 00001: val_acc improved from -inf to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.83.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 3.4299 - acc: 0.5370 - f1score: 0.5415 - val_loss: 0.8335 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.83.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 3.4299 - acc: 0.5370 - f1score: 0.5415 - val_loss: 0.8335 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.8410 - acc: 0.7651 - f1score: 0.7651\n",
            "Epoch 00002: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.8425 - acc: 0.7651 - f1score: 0.7651 - val_loss: 0.7561 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.8425 - acc: 0.7651 - f1score: 0.7651 - val_loss: 0.7561 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6416 - acc: 0.7769 - f1score: 0.7769\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6397 - acc: 0.7778 - f1score: 0.7785 - val_loss: 0.5107 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6397 - acc: 0.7778 - f1score: 0.7785 - val_loss: 0.5107 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5935 - acc: 0.7683 - f1score: 0.7683\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5877 - acc: 0.7709 - f1score: 0.7731 - val_loss: 0.6000 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5877 - acc: 0.7709 - f1score: 0.7731 - val_loss: 0.6000 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5233 - acc: 0.7888 - f1score: 0.7888\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5205 - acc: 0.7899 - f1score: 0.7909 - val_loss: 0.4865 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5205 - acc: 0.7899 - f1score: 0.7909 - val_loss: 0.4865 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4959 - acc: 0.7990 - f1score: 0.7990\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4946 - acc: 0.8000 - f1score: 0.8008 - val_loss: 0.4911 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4946 - acc: 0.8000 - f1score: 0.8008 - val_loss: 0.4911 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4724 - acc: 0.8012 - f1score: 0.8012\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4683 - acc: 0.8037 - f1score: 0.8059 - val_loss: 0.4833 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4683 - acc: 0.8037 - f1score: 0.8059 - val_loss: 0.4833 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4620 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00008: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.48.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4626 - acc: 0.8095 - f1score: 0.8088 - val_loss: 0.4811 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.48.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4626 - acc: 0.8095 - f1score: 0.8088 - val_loss: 0.4811 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4653 - acc: 0.8077 - f1score: 0.8077\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4639 - acc: 0.8085 - f1score: 0.8092 - val_loss: 0.4794 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4639 - acc: 0.8085 - f1score: 0.8092 - val_loss: 0.4794 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4658 - acc: 0.8060 - f1score: 0.8060\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4666 - acc: 0.8058 - f1score: 0.8056 - val_loss: 0.4765 - val_acc: 0.7940 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4666 - acc: 0.8058 - f1score: 0.8056 - val_loss: 0.4765 - val_acc: 0.7940 - val_f1score: 0.7984\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4697 - acc: 0.8012 - f1score: 0.8012\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4663 - acc: 0.8026 - f1score: 0.8039 - val_loss: 0.4793 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4663 - acc: 0.8026 - f1score: 0.8039 - val_loss: 0.4793 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4570 - acc: 0.8060 - f1score: 0.8060\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4571 - acc: 0.8063 - f1score: 0.8066 - val_loss: 0.4780 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4571 - acc: 0.8063 - f1score: 0.8066 - val_loss: 0.4780 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4614 - acc: 0.8055 - f1score: 0.8055\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4616 - acc: 0.8053 - f1score: 0.8051 - val_loss: 0.4820 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4616 - acc: 0.8053 - f1score: 0.8051 - val_loss: 0.4820 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4451 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4463 - acc: 0.8111 - f1score: 0.8108 - val_loss: 0.4845 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4463 - acc: 0.8111 - f1score: 0.8108 - val_loss: 0.4845 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4572 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4571 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4776 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4571 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4776 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4575 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4586 - acc: 0.8148 - f1score: 0.8145 - val_loss: 0.4881 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4586 - acc: 0.8148 - f1score: 0.8145 - val_loss: 0.4881 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4681 - acc: 0.7990 - f1score: 0.7990\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4706 - acc: 0.7984 - f1score: 0.7979 - val_loss: 0.4808 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4706 - acc: 0.7984 - f1score: 0.7979 - val_loss: 0.4808 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4525 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4502 - acc: 0.8143 - f1score: 0.8149 - val_loss: 0.4770 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4502 - acc: 0.8143 - f1score: 0.8149 - val_loss: 0.4770 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4489 - acc: 0.8082 - f1score: 0.8082\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4535 - acc: 0.8069 - f1score: 0.8058 - val_loss: 0.4816 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4535 - acc: 0.8069 - f1score: 0.8058 - val_loss: 0.4816 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4518 - acc: 0.8116 - f1score: 0.8109 - val_loss: 0.4738 - val_acc: 0.7972 - val_f1score: 0.7991\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4518 - acc: 0.8116 - f1score: 0.8109 - val_loss: 0.4738 - val_acc: 0.7972 - val_f1score: 0.7991\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4462 - acc: 0.8122 - f1score: 0.8123 - val_loss: 0.4738 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4462 - acc: 0.8122 - f1score: 0.8123 - val_loss: 0.4738 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4517 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4508 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.4767 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4508 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.4767 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4520 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4569 - acc: 0.8101 - f1score: 0.8084 - val_loss: 0.4785 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4569 - acc: 0.8101 - f1score: 0.8084 - val_loss: 0.4785 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4544 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4554 - acc: 0.8122 - f1score: 0.8123 - val_loss: 0.4743 - val_acc: 0.7940 - val_f1score: 0.7903\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4554 - acc: 0.8122 - f1score: 0.8123 - val_loss: 0.4743 - val_acc: 0.7940 - val_f1score: 0.7903\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4461 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4487 - acc: 0.8122 - f1score: 0.8119 - val_loss: 0.4807 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4487 - acc: 0.8122 - f1score: 0.8119 - val_loss: 0.4807 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4512 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4513 - acc: 0.8148 - f1score: 0.8145 - val_loss: 0.4762 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4513 - acc: 0.8148 - f1score: 0.8145 - val_loss: 0.4762 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4506 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4538 - acc: 0.8127 - f1score: 0.8110 - val_loss: 0.4725 - val_acc: 0.7972 - val_f1score: 0.7950\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4538 - acc: 0.8127 - f1score: 0.8110 - val_loss: 0.4725 - val_acc: 0.7972 - val_f1score: 0.7950\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4582 - acc: 0.8060 - f1score: 0.8060\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4567 - acc: 0.8074 - f1score: 0.8086 - val_loss: 0.4752 - val_acc: 0.7854 - val_f1score: 0.7876\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4567 - acc: 0.8074 - f1score: 0.8086 - val_loss: 0.4752 - val_acc: 0.7854 - val_f1score: 0.7876\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4485 - acc: 0.8249 - f1score: 0.8249\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4492 - acc: 0.8233 - f1score: 0.8219 - val_loss: 0.4734 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4492 - acc: 0.8233 - f1score: 0.8219 - val_loss: 0.4734 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4468 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4453 - acc: 0.8148 - f1score: 0.8154 - val_loss: 0.4741 - val_acc: 0.7972 - val_f1score: 0.7999\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4453 - acc: 0.8148 - f1score: 0.8154 - val_loss: 0.4741 - val_acc: 0.7972 - val_f1score: 0.7999\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4585 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00031: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4567 - acc: 0.8127 - f1score: 0.8133 - val_loss: 0.4742 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4567 - acc: 0.8127 - f1score: 0.8133 - val_loss: 0.4742 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4455 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00032: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4460 - acc: 0.8175 - f1score: 0.8166 - val_loss: 0.4723 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4460 - acc: 0.8175 - f1score: 0.8166 - val_loss: 0.4723 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4422 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4439 - acc: 0.8153 - f1score: 0.8146 - val_loss: 0.4756 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4439 - acc: 0.8153 - f1score: 0.8146 - val_loss: 0.4756 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4438 - acc: 0.8109 - f1score: 0.81091856/1890 [============================>.] - ETA: 0s - loss: 0.4438 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4439 - acc: 0.8111 - f1score: 0.8113 - val_loss: 0.4719 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4439 - acc: 0.8111 - f1score: 0.8113 - val_loss: 0.4719 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4557 - acc: 0.8093 - f1score: 0.8093\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4538 - acc: 0.8106 - f1score: 0.8117 - val_loss: 0.4723 - val_acc: 0.7929 - val_f1score: 0.7957\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4538 - acc: 0.8106 - f1score: 0.8117 - val_loss: 0.4723 - val_acc: 0.7929 - val_f1score: 0.7957\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4442 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4475 - acc: 0.8122 - f1score: 0.8105 - val_loss: 0.4831 - val_acc: 0.7811 - val_f1score: 0.7778\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4475 - acc: 0.8122 - f1score: 0.8105 - val_loss: 0.4831 - val_acc: 0.7811 - val_f1score: 0.7778\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4475 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4518 - acc: 0.8143 - f1score: 0.8121 - val_loss: 0.4747 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4518 - acc: 0.8143 - f1score: 0.8121 - val_loss: 0.4747 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4441 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4451 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4760 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4451 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4760 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4416 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4411 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4703 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4411 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4703 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4440 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4432 - acc: 0.8190 - f1score: 0.8191 - val_loss: 0.4707 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4432 - acc: 0.8190 - f1score: 0.8191 - val_loss: 0.4707 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4476 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4486 - acc: 0.8138 - f1score: 0.8134 - val_loss: 0.4721 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4486 - acc: 0.8138 - f1score: 0.8134 - val_loss: 0.4721 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4357 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4391 - acc: 0.8196 - f1score: 0.8178 - val_loss: 0.4723 - val_acc: 0.7918 - val_f1score: 0.7955\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4391 - acc: 0.8196 - f1score: 0.8178 - val_loss: 0.4723 - val_acc: 0.7918 - val_f1score: 0.7955\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4508 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4491 - acc: 0.8175 - f1score: 0.8189 - val_loss: 0.4747 - val_acc: 0.7865 - val_f1score: 0.7862\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4491 - acc: 0.8175 - f1score: 0.8189 - val_loss: 0.4747 - val_acc: 0.7865 - val_f1score: 0.7862\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4421 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4388 - acc: 0.8196 - f1score: 0.8215 - val_loss: 0.4731 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4388 - acc: 0.8196 - f1score: 0.8215 - val_loss: 0.4731 - val_acc: 0.7897 - val_f1score: 0.7918\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4388 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4382 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4706 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4382 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4706 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4496 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4471 - acc: 0.8106 - f1score: 0.8122 - val_loss: 0.4732 - val_acc: 0.7854 - val_f1score: 0.7868\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4471 - acc: 0.8106 - f1score: 0.8122 - val_loss: 0.4732 - val_acc: 0.7854 - val_f1score: 0.7868\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4424 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00047: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4434 - acc: 0.8222 - f1score: 0.8213 - val_loss: 0.4698 - val_acc: 0.7961 - val_f1score: 0.7948\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4434 - acc: 0.8222 - f1score: 0.8213 - val_loss: 0.4698 - val_acc: 0.7961 - val_f1score: 0.7948\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4484 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00048: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4474 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4722 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4474 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4722 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4405 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00049: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4382 - acc: 0.8222 - f1score: 0.8241 - val_loss: 0.4695 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4382 - acc: 0.8222 - f1score: 0.8241 - val_loss: 0.4695 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4451 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00050: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4468 - acc: 0.8169 - f1score: 0.8161 - val_loss: 0.4688 - val_acc: 0.8036 - val_f1score: 0.8021\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4468 - acc: 0.8169 - f1score: 0.8161 - val_loss: 0.4688 - val_acc: 0.8036 - val_f1score: 0.8021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 55%|█████▌    | 53/96 [3:22:36<3:15:45, 273.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.1925 - acc: 0.7015 - f1score: 0.7015\n",
            "Epoch 00001: val_acc improved from -inf to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.96.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.1699 - acc: 0.7053 - f1score: 0.7085 - val_loss: 1.9569 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.96.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.1699 - acc: 0.7053 - f1score: 0.7085 - val_loss: 1.9569 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.6668 - acc: 0.7532 - f1score: 0.7532\n",
            "Epoch 00002: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.6524 - acc: 0.7545 - f1score: 0.7556 - val_loss: 1.2072 - val_acc: 0.7800 - val_f1score: 0.7808\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.6524 - acc: 0.7545 - f1score: 0.7556 - val_loss: 1.2072 - val_acc: 0.7800 - val_f1score: 0.7808\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.3373 - acc: 0.7527 - f1score: 0.7527\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.3312 - acc: 0.7524 - f1score: 0.7521 - val_loss: 0.6687 - val_acc: 0.6470 - val_f1score: 0.6411\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.3312 - acc: 0.7524 - f1score: 0.7521 - val_loss: 0.6687 - val_acc: 0.6470 - val_f1score: 0.6411\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.0611 - acc: 0.7624 - f1score: 0.7624\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.0492 - acc: 0.7640 - f1score: 0.7654 - val_loss: 0.9382 - val_acc: 0.7929 - val_f1score: 0.7909\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.0492 - acc: 0.7640 - f1score: 0.7654 - val_loss: 0.9382 - val_acc: 0.7929 - val_f1score: 0.7909\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.8094 - acc: 0.7554 - f1score: 0.7554\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.8119 - acc: 0.7571 - f1score: 0.7586 - val_loss: 0.6460 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.8119 - acc: 0.7571 - f1score: 0.7586 - val_loss: 0.6460 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6512 - acc: 0.7678 - f1score: 0.7678\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6463 - acc: 0.7698 - f1score: 0.7716 - val_loss: 0.5019 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6463 - acc: 0.7698 - f1score: 0.7716 - val_loss: 0.5019 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5176 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5153 - acc: 0.7952 - f1score: 0.7952 - val_loss: 0.4958 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5153 - acc: 0.7952 - f1score: 0.7952 - val_loss: 0.4958 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4784 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4756 - acc: 0.7989 - f1score: 0.7998 - val_loss: 0.4882 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4756 - acc: 0.7989 - f1score: 0.7998 - val_loss: 0.4882 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4620 - acc: 0.8012 - f1score: 0.8012\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4630 - acc: 0.8016 - f1score: 0.8019 - val_loss: 0.4812 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4630 - acc: 0.8016 - f1score: 0.8019 - val_loss: 0.4812 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4613 - acc: 0.8077 - f1score: 0.8077\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4615 - acc: 0.8079 - f1score: 0.8082 - val_loss: 0.5129 - val_acc: 0.7425 - val_f1score: 0.7443\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4615 - acc: 0.8079 - f1score: 0.8082 - val_loss: 0.5129 - val_acc: 0.7425 - val_f1score: 0.7443\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4600 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4611 - acc: 0.8095 - f1score: 0.8088 - val_loss: 0.5017 - val_acc: 0.7822 - val_f1score: 0.7780\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4611 - acc: 0.8095 - f1score: 0.8088 - val_loss: 0.5017 - val_acc: 0.7822 - val_f1score: 0.7780\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4594 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.5045 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4594 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.5045 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4579 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4572 - acc: 0.8079 - f1score: 0.8086 - val_loss: 0.4821 - val_acc: 0.7800 - val_f1score: 0.7784\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4572 - acc: 0.8079 - f1score: 0.8086 - val_loss: 0.4821 - val_acc: 0.7800 - val_f1score: 0.7784\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4417 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4408 - acc: 0.8185 - f1score: 0.8186 - val_loss: 0.4845 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4408 - acc: 0.8185 - f1score: 0.8186 - val_loss: 0.4845 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4564 - acc: 0.8093 - f1score: 0.8093\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4561 - acc: 0.8090 - f1score: 0.8088 - val_loss: 0.4835 - val_acc: 0.7994 - val_f1score: 0.7979\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4561 - acc: 0.8090 - f1score: 0.8088 - val_loss: 0.4835 - val_acc: 0.7994 - val_f1score: 0.7979\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4426 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4457 - acc: 0.8106 - f1score: 0.8094 - val_loss: 0.4850 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4457 - acc: 0.8106 - f1score: 0.8094 - val_loss: 0.4850 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4604 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4570 - acc: 0.8090 - f1score: 0.8106 - val_loss: 0.4851 - val_acc: 0.7758 - val_f1score: 0.7726\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4570 - acc: 0.8090 - f1score: 0.8106 - val_loss: 0.4851 - val_acc: 0.7758 - val_f1score: 0.7726\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4580 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4565 - acc: 0.8101 - f1score: 0.8103 - val_loss: 0.4805 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4565 - acc: 0.8101 - f1score: 0.8103 - val_loss: 0.4805 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4532 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00019: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4526 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4792 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4526 - acc: 0.8127 - f1score: 0.8129 - val_loss: 0.4792 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4576 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00020: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4594 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4829 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4594 - acc: 0.8153 - f1score: 0.8150 - val_loss: 0.4829 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4517 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00021: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4528 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4845 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4528 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4845 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4527 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00022: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4501 - acc: 0.8148 - f1score: 0.8163 - val_loss: 0.4780 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4501 - acc: 0.8148 - f1score: 0.8163 - val_loss: 0.4780 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4482 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4472 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4822 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4472 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4822 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4401 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00024: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4409 - acc: 0.8116 - f1score: 0.8109 - val_loss: 0.4745 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4409 - acc: 0.8116 - f1score: 0.8109 - val_loss: 0.4745 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4506 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00025: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4506 - acc: 0.8180 - f1score: 0.8176 - val_loss: 0.4759 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4506 - acc: 0.8180 - f1score: 0.8176 - val_loss: 0.4759 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4471 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00026: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4470 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4860 - val_acc: 0.7876 - val_f1score: 0.7865\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4470 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4860 - val_acc: 0.7876 - val_f1score: 0.7865\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4490 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00027: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4485 - acc: 0.8169 - f1score: 0.8161 - val_loss: 0.4755 - val_acc: 0.7865 - val_f1score: 0.7878\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4485 - acc: 0.8169 - f1score: 0.8161 - val_loss: 0.4755 - val_acc: 0.7865 - val_f1score: 0.7878\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4410 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00028: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4432 - acc: 0.8175 - f1score: 0.8162 - val_loss: 0.4755 - val_acc: 0.7865 - val_f1score: 0.7846\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4432 - acc: 0.8175 - f1score: 0.8162 - val_loss: 0.4755 - val_acc: 0.7865 - val_f1score: 0.7846\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4487 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00029: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4499 - acc: 0.8196 - f1score: 0.8192 - val_loss: 0.4731 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4499 - acc: 0.8196 - f1score: 0.8192 - val_loss: 0.4731 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4432 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00030: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4463 - acc: 0.8148 - f1score: 0.8136 - val_loss: 0.4715 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4463 - acc: 0.8148 - f1score: 0.8136 - val_loss: 0.4715 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4423 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00031: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4429 - acc: 0.8201 - f1score: 0.8197 - val_loss: 0.4744 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4429 - acc: 0.8201 - f1score: 0.8197 - val_loss: 0.4744 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4502 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00032: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4470 - acc: 0.8169 - f1score: 0.8189 - val_loss: 0.4763 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4470 - acc: 0.8169 - f1score: 0.8189 - val_loss: 0.4763 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4464 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00033: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4458 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4721 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4458 - acc: 0.8132 - f1score: 0.8134 - val_loss: 0.4721 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4416 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00034: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4437 - acc: 0.8180 - f1score: 0.8176 - val_loss: 0.4777 - val_acc: 0.7843 - val_f1score: 0.7866\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4437 - acc: 0.8180 - f1score: 0.8176 - val_loss: 0.4777 - val_acc: 0.7843 - val_f1score: 0.7866\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4446 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00035: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4433 - acc: 0.8212 - f1score: 0.8221 - val_loss: 0.4721 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4433 - acc: 0.8212 - f1score: 0.8221 - val_loss: 0.4721 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4443 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00036: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4439 - acc: 0.8127 - f1score: 0.8133 - val_loss: 0.4719 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4439 - acc: 0.8127 - f1score: 0.8133 - val_loss: 0.4719 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4449 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00037: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4439 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4735 - val_acc: 0.7951 - val_f1score: 0.7946\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4439 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4735 - val_acc: 0.7951 - val_f1score: 0.7946\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4398 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00038: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4398 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4744 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4398 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4744 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4500 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00039: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4496 - acc: 0.8095 - f1score: 0.8093 - val_loss: 0.4718 - val_acc: 0.7833 - val_f1score: 0.7791\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4496 - acc: 0.8095 - f1score: 0.8093 - val_loss: 0.4718 - val_acc: 0.7833 - val_f1score: 0.7791\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4391 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00040: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.40-0.47.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4397 - acc: 0.8138 - f1score: 0.8130 - val_loss: 0.4742 - val_acc: 0.8015 - val_f1score: 0.8016\n",
            "\n",
            "Epoch 00040: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.40-0.47.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4397 - acc: 0.8138 - f1score: 0.8130 - val_loss: 0.4742 - val_acc: 0.8015 - val_f1score: 0.8016\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4533 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00041: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4509 - acc: 0.8175 - f1score: 0.8189 - val_loss: 0.4734 - val_acc: 0.7897 - val_f1score: 0.7934\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4509 - acc: 0.8175 - f1score: 0.8189 - val_loss: 0.4734 - val_acc: 0.7897 - val_f1score: 0.7934\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00042: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4452 - acc: 0.8201 - f1score: 0.8192 - val_loss: 0.4728 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4452 - acc: 0.8201 - f1score: 0.8192 - val_loss: 0.4728 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4452 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00043: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4462 - acc: 0.8212 - f1score: 0.8203 - val_loss: 0.4718 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4462 - acc: 0.8212 - f1score: 0.8203 - val_loss: 0.4718 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4411 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00044: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4402 - acc: 0.8164 - f1score: 0.8170 - val_loss: 0.4710 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4402 - acc: 0.8164 - f1score: 0.8170 - val_loss: 0.4710 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4369 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00045: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4352 - acc: 0.8217 - f1score: 0.8231 - val_loss: 0.4722 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4352 - acc: 0.8217 - f1score: 0.8231 - val_loss: 0.4722 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4415 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00046: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4437 - acc: 0.8201 - f1score: 0.8192 - val_loss: 0.4735 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4437 - acc: 0.8201 - f1score: 0.8192 - val_loss: 0.4735 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4487 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00047: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4453 - acc: 0.8164 - f1score: 0.8179 - val_loss: 0.4726 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4453 - acc: 0.8164 - f1score: 0.8179 - val_loss: 0.4726 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4438 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00048: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4423 - acc: 0.8185 - f1score: 0.8195 - val_loss: 0.4749 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4423 - acc: 0.8185 - f1score: 0.8195 - val_loss: 0.4749 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4474 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00049: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4477 - acc: 0.8164 - f1score: 0.8161 - val_loss: 0.4726 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4477 - acc: 0.8164 - f1score: 0.8161 - val_loss: 0.4726 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4462 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00050: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4449 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4725 - val_acc: 0.7822 - val_f1score: 0.7796\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4449 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4725 - val_acc: 0.7822 - val_f1score: 0.7796\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 56%|█████▋    | 54/96 [3:31:01<3:59:53, 342.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.0776 - acc: 0.6024 - f1score: 0.6024\n",
            "Epoch 00001: val_acc improved from -inf to 0.74785, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.73.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.0483 - acc: 0.6063 - f1score: 0.6097 - val_loss: 0.7300 - val_acc: 0.7479 - val_f1score: 0.7455\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.74785, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.73.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.0483 - acc: 0.6063 - f1score: 0.6097 - val_loss: 0.7300 - val_acc: 0.7479 - val_f1score: 0.7455\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6489 - acc: 0.7037 - f1score: 0.7037\n",
            "Epoch 00002: val_acc improved from 0.74785 to 0.77361, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.53.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.74785 to 0.77361, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.53.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6445 - acc: 0.7048 - f1score: 0.7057 - val_loss: 0.5279 - val_acc: 0.7736 - val_f1score: 0.7737\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6445 - acc: 0.7048 - f1score: 0.7057 - val_loss: 0.5279 - val_acc: 0.7736 - val_f1score: 0.7737\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5705 - acc: 0.7468 - f1score: 0.7468\n",
            "Epoch 00003: val_acc improved from 0.77361 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.53.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.5776 - acc: 0.7466 - f1score: 0.7464 - val_loss: 0.5257 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.77361 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.53.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.5776 - acc: 0.7466 - f1score: 0.7464 - val_loss: 0.5257 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5244 - acc: 0.7742 - f1score: 0.7742\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5259 - acc: 0.7730 - f1score: 0.7720 - val_loss: 0.4805 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5259 - acc: 0.7730 - f1score: 0.7720 - val_loss: 0.4805 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5086 - acc: 0.7823 - f1score: 0.7823\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5105 - acc: 0.7810 - f1score: 0.7798 - val_loss: 0.4915 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5105 - acc: 0.7810 - f1score: 0.7798 - val_loss: 0.4915 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4988 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5016 - acc: 0.7974 - f1score: 0.7973 - val_loss: 0.5375 - val_acc: 0.7790 - val_f1score: 0.7806\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5016 - acc: 0.7974 - f1score: 0.7973 - val_loss: 0.5375 - val_acc: 0.7790 - val_f1score: 0.7806\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5189 - acc: 0.7856 - f1score: 0.7856\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5184 - acc: 0.7857 - f1score: 0.7858 - val_loss: 0.4838 - val_acc: 0.7768 - val_f1score: 0.7752\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5184 - acc: 0.7857 - f1score: 0.7858 - val_loss: 0.4838 - val_acc: 0.7768 - val_f1score: 0.7752\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4833 - acc: 0.7931 - f1score: 0.7931\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4866 - acc: 0.7926 - f1score: 0.7922 - val_loss: 0.5225 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4866 - acc: 0.7926 - f1score: 0.7922 - val_loss: 0.5225 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4873 - acc: 0.7958 - f1score: 0.7958\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4845 - acc: 0.7979 - f1score: 0.7997 - val_loss: 0.4778 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4845 - acc: 0.7979 - f1score: 0.7997 - val_loss: 0.4778 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4908 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4905 - acc: 0.7952 - f1score: 0.7952 - val_loss: 0.4778 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4905 - acc: 0.7952 - f1score: 0.7952 - val_loss: 0.4778 - val_acc: 0.8004 - val_f1score: 0.7990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 57%|█████▋    | 55/96 [3:32:24<3:00:49, 264.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.3310 - acc: 0.7134 - f1score: 0.7134\n",
            "Epoch 00001: val_acc improved from -inf to 0.78433, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.09.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.3166 - acc: 0.7148 - f1score: 0.7161 - val_loss: 2.0927 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78433, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.09.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.3166 - acc: 0.7148 - f1score: 0.7161 - val_loss: 2.0927 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.6025 - acc: 0.7802 - f1score: 0.7802\n",
            "Epoch 00002: val_acc improved from 0.78433 to 0.78863, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.42.h5\n",
            "1890/1890 [==============================] - 13s 7ms/sample - loss: 1.6133 - acc: 0.7799 - f1score: 0.7797 - val_loss: 1.4248 - val_acc: 0.7886 - val_f1score: 0.7875\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.78433 to 0.78863, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.42.h5\n",
            "1890/1890 [==============================] - 13s 7ms/sample - loss: 1.6133 - acc: 0.7799 - f1score: 0.7797 - val_loss: 1.4248 - val_acc: 0.7886 - val_f1score: 0.7875\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.9902 - acc: 0.7565 - f1score: 0.7565\n",
            "Epoch 00003: val_acc did not improve from 0.78863\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9851 - acc: 0.7545 - f1score: 0.7528 - val_loss: 0.6513 - val_acc: 0.7693 - val_f1score: 0.7712\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.78863\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9851 - acc: 0.7545 - f1score: 0.7528 - val_loss: 0.6513 - val_acc: 0.7693 - val_f1score: 0.7712\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6499 - acc: 0.7279 - f1score: 0.7279\n",
            "Epoch 00004: val_acc improved from 0.78863 to 0.79185, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.49.h5\n",
            "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.6490 - acc: 0.7286 - f1score: 0.7291 - val_loss: 0.4937 - val_acc: 0.7918 - val_f1score: 0.7922\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.78863 to 0.79185, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.49.h5\n",
            "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.6490 - acc: 0.7286 - f1score: 0.7291 - val_loss: 0.4937 - val_acc: 0.7918 - val_f1score: 0.7922\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5593 - acc: 0.7554 - f1score: 0.7554\n",
            "Epoch 00005: val_acc improved from 0.79185 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.49.h5\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.79185 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.49.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5625 - acc: 0.7529 - f1score: 0.7508 - val_loss: 0.4935 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5625 - acc: 0.7529 - f1score: 0.7508 - val_loss: 0.4935 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5301 - acc: 0.7672 - f1score: 0.7672\n",
            "Epoch 00006: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5333 - acc: 0.7656 - f1score: 0.7642 - val_loss: 0.4965 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5333 - acc: 0.7656 - f1score: 0.7642 - val_loss: 0.4965 - val_acc: 0.8004 - val_f1score: 0.8030\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5255 - acc: 0.7689 - f1score: 0.7689\n",
            "Epoch 00007: val_acc improved from 0.80150 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.07-0.49.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5299 - acc: 0.7661 - f1score: 0.7638 - val_loss: 0.4856 - val_acc: 0.8047 - val_f1score: 0.8056\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.80150 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.07-0.49.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5299 - acc: 0.7661 - f1score: 0.7638 - val_loss: 0.4856 - val_acc: 0.8047 - val_f1score: 0.8056\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5263 - acc: 0.7662 - f1score: 0.7662\n",
            "Epoch 00008: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5244 - acc: 0.7672 - f1score: 0.7681 - val_loss: 0.4863 - val_acc: 0.8036 - val_f1score: 0.8021\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5244 - acc: 0.7672 - f1score: 0.7681 - val_loss: 0.4863 - val_acc: 0.8036 - val_f1score: 0.8021\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5170 - acc: 0.7753 - f1score: 0.7753\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5178 - acc: 0.7757 - f1score: 0.7759 - val_loss: 0.4815 - val_acc: 0.7972 - val_f1score: 0.7966\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5178 - acc: 0.7757 - f1score: 0.7759 - val_loss: 0.4815 - val_acc: 0.7972 - val_f1score: 0.7966\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5153 - acc: 0.7796 - f1score: 0.7796\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5178 - acc: 0.7783 - f1score: 0.7772 - val_loss: 0.4861 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5178 - acc: 0.7783 - f1score: 0.7772 - val_loss: 0.4861 - val_acc: 0.7940 - val_f1score: 0.7951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 58%|█████▊    | 56/96 [3:34:16<2:25:53, 218.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 5.6923 - acc: 0.4822 - f1score: 0.4822\n",
            "Epoch 00001: val_acc improved from -inf to 0.56760, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.66.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 5.6488 - acc: 0.4815 - f1score: 0.4809 - val_loss: 1.6617 - val_acc: 0.5676 - val_f1score: 0.5672\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.56760, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.66.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 5.6488 - acc: 0.4815 - f1score: 0.4809 - val_loss: 1.6617 - val_acc: 0.5676 - val_f1score: 0.5672\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.5746 - acc: 0.6676 - f1score: 0.6676\n",
            "Epoch 00002: val_acc improved from 0.56760 to 0.79077, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.01.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.5361 - acc: 0.6698 - f1score: 0.6718 - val_loss: 2.0063 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.56760 to 0.79077, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.01.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.5361 - acc: 0.6698 - f1score: 0.6718 - val_loss: 2.0063 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.6354 - acc: 0.7645 - f1score: 0.7645\n",
            "Epoch 00003: val_acc did not improve from 0.79077\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.6362 - acc: 0.7640 - f1score: 0.7636 - val_loss: 1.3772 - val_acc: 0.7833 - val_f1score: 0.7847\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.79077\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.6362 - acc: 0.7640 - f1score: 0.7636 - val_loss: 1.3772 - val_acc: 0.7833 - val_f1score: 0.7847\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.0092 - acc: 0.7193 - f1score: 0.7193\n",
            "Epoch 00004: val_acc did not improve from 0.79077\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0013 - acc: 0.7190 - f1score: 0.7188 - val_loss: 0.6525 - val_acc: 0.7811 - val_f1score: 0.7810\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.79077\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0013 - acc: 0.7190 - f1score: 0.7188 - val_loss: 0.6525 - val_acc: 0.7811 - val_f1score: 0.7810\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6666 - acc: 0.7317 - f1score: 0.7317\n",
            "Epoch 00005: val_acc improved from 0.79077 to 0.79721, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.49.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6628 - acc: 0.7328 - f1score: 0.7338 - val_loss: 0.4910 - val_acc: 0.7972 - val_f1score: 0.7926\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.79077 to 0.79721, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.49.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6628 - acc: 0.7328 - f1score: 0.7338 - val_loss: 0.4910 - val_acc: 0.7972 - val_f1score: 0.7926\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5626 - acc: 0.7408 - f1score: 0.7408\n",
            "Epoch 00006: val_acc improved from 0.79721 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.50.h5\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.79721 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.06-0.50.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5653 - acc: 0.7402 - f1score: 0.7397 - val_loss: 0.4952 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5653 - acc: 0.7402 - f1score: 0.7397 - val_loss: 0.4952 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5432 - acc: 0.7478 - f1score: 0.7478\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5470 - acc: 0.7466 - f1score: 0.7455 - val_loss: 0.4973 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5470 - acc: 0.7466 - f1score: 0.7455 - val_loss: 0.4973 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5329 - acc: 0.7635 - f1score: 0.7635\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5329 - acc: 0.7635 - f1score: 0.7635 - val_loss: 0.4863 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5329 - acc: 0.7635 - f1score: 0.7635 - val_loss: 0.4863 - val_acc: 0.8004 - val_f1score: 0.8038\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5243 - acc: 0.7678 - f1score: 0.7678\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5259 - acc: 0.7661 - f1score: 0.7647 - val_loss: 0.4893 - val_acc: 0.7961 - val_f1score: 0.7948\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5259 - acc: 0.7661 - f1score: 0.7647 - val_loss: 0.4893 - val_acc: 0.7961 - val_f1score: 0.7948\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5260 - acc: 0.7721 - f1score: 0.7721\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5262 - acc: 0.7704 - f1score: 0.7689 - val_loss: 0.5175 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5262 - acc: 0.7704 - f1score: 0.7689 - val_loss: 0.5175 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5143 - acc: 0.7764 - f1score: 0.7764\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5130 - acc: 0.7757 - f1score: 0.7750 - val_loss: 0.4825 - val_acc: 0.8004 - val_f1score: 0.7957\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5130 - acc: 0.7757 - f1score: 0.7750 - val_loss: 0.4825 - val_acc: 0.8004 - val_f1score: 0.7957\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5003 - acc: 0.7829 - f1score: 0.7829\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4960 - acc: 0.7862 - f1score: 0.7891 - val_loss: 0.4817 - val_acc: 0.7886 - val_f1score: 0.7899\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4960 - acc: 0.7862 - f1score: 0.7891 - val_loss: 0.4817 - val_acc: 0.7886 - val_f1score: 0.7899\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4899 - acc: 0.7845 - f1score: 0.7845\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4891 - acc: 0.7847 - f1score: 0.7848 - val_loss: 0.4844 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4891 - acc: 0.7847 - f1score: 0.7848 - val_loss: 0.4844 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4959 - acc: 0.7904 - f1score: 0.7904\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5007 - acc: 0.7889 - f1score: 0.7876 - val_loss: 0.4814 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5007 - acc: 0.7889 - f1score: 0.7876 - val_loss: 0.4814 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4872 - acc: 0.7883 - f1score: 0.7883\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4853 - acc: 0.7889 - f1score: 0.7894 - val_loss: 0.4845 - val_acc: 0.8004 - val_f1score: 0.7973\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4853 - acc: 0.7889 - f1score: 0.7894 - val_loss: 0.4845 - val_acc: 0.8004 - val_f1score: 0.7973\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4845 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4849 - acc: 0.7974 - f1score: 0.7982 - val_loss: 0.4785 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4849 - acc: 0.7974 - f1score: 0.7982 - val_loss: 0.4785 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4757 - acc: 0.7926 - f1score: 0.7926\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4764 - acc: 0.7931 - f1score: 0.7936 - val_loss: 0.4786 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4764 - acc: 0.7931 - f1score: 0.7936 - val_loss: 0.4786 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4879 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4879 - acc: 0.7968 - f1score: 0.7963 - val_loss: 0.4767 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4879 - acc: 0.7968 - f1score: 0.7963 - val_loss: 0.4767 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4894 - acc: 0.7958 - f1score: 0.7958\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4861 - acc: 0.7968 - f1score: 0.7977 - val_loss: 0.4820 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4861 - acc: 0.7968 - f1score: 0.7977 - val_loss: 0.4820 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4958 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4928 - acc: 0.7974 - f1score: 0.7978 - val_loss: 0.4794 - val_acc: 0.7897 - val_f1score: 0.7934\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4928 - acc: 0.7974 - f1score: 0.7978 - val_loss: 0.4794 - val_acc: 0.7897 - val_f1score: 0.7934\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4821 - acc: 0.8055 - f1score: 0.8055\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4807 - acc: 0.8058 - f1score: 0.8061 - val_loss: 0.4746 - val_acc: 0.7843 - val_f1score: 0.7858\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4807 - acc: 0.8058 - f1score: 0.8061 - val_loss: 0.4746 - val_acc: 0.7843 - val_f1score: 0.7858\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4892 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4948 - acc: 0.7910 - f1score: 0.7883 - val_loss: 0.4768 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4948 - acc: 0.7910 - f1score: 0.7883 - val_loss: 0.4768 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4717 - acc: 0.8033 - f1score: 0.8033\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4727 - acc: 0.8026 - f1score: 0.8021 - val_loss: 0.4785 - val_acc: 0.7918 - val_f1score: 0.7947\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4727 - acc: 0.8026 - f1score: 0.8021 - val_loss: 0.4785 - val_acc: 0.7918 - val_f1score: 0.7947\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4876 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4869 - acc: 0.7984 - f1score: 0.7993 - val_loss: 0.4758 - val_acc: 0.7951 - val_f1score: 0.7946\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4869 - acc: 0.7984 - f1score: 0.7993 - val_loss: 0.4758 - val_acc: 0.7951 - val_f1score: 0.7946\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4806 - acc: 0.7926 - f1score: 0.7926\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4793 - acc: 0.7937 - f1score: 0.7946 - val_loss: 0.4774 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4793 - acc: 0.7937 - f1score: 0.7946 - val_loss: 0.4774 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4820 - acc: 0.7931 - f1score: 0.7931\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4794 - acc: 0.7931 - f1score: 0.7931 - val_loss: 0.4749 - val_acc: 0.7940 - val_f1score: 0.7976\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4794 - acc: 0.7931 - f1score: 0.7931 - val_loss: 0.4749 - val_acc: 0.7940 - val_f1score: 0.7976\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4676 - acc: 0.8044 - f1score: 0.8044\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4654 - acc: 0.8053 - f1score: 0.8060 - val_loss: 0.4775 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4654 - acc: 0.8053 - f1score: 0.8060 - val_loss: 0.4775 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4621 - acc: 0.8033 - f1score: 0.8033\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4654 - acc: 0.8016 - f1score: 0.8001 - val_loss: 0.4755 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4654 - acc: 0.8016 - f1score: 0.8001 - val_loss: 0.4755 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4782 - acc: 0.8023 - f1score: 0.8023\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4750 - acc: 0.8032 - f1score: 0.8040 - val_loss: 0.4748 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4750 - acc: 0.8032 - f1score: 0.8040 - val_loss: 0.4748 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4691 - acc: 0.8028 - f1score: 0.8028\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4698 - acc: 0.8032 - f1score: 0.8035 - val_loss: 0.4729 - val_acc: 0.7843 - val_f1score: 0.7825\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4698 - acc: 0.8032 - f1score: 0.8035 - val_loss: 0.4729 - val_acc: 0.7843 - val_f1score: 0.7825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 59%|█████▉    | 57/96 [3:38:14<2:25:57, 224.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 5.7439 - acc: 0.4731 - f1score: 0.4731\n",
            "Epoch 00001: val_acc improved from -inf to 0.73927, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.93.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 5.6867 - acc: 0.4751 - f1score: 0.4769 - val_loss: 0.9335 - val_acc: 0.7393 - val_f1score: 0.7436\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.73927, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.93.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 5.6867 - acc: 0.4751 - f1score: 0.4769 - val_loss: 0.9335 - val_acc: 0.7393 - val_f1score: 0.7436\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.6737 - acc: 0.7150 - f1score: 0.7150\n",
            "Epoch 00002: val_acc improved from 0.73927 to 0.76609, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.58.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.73927 to 0.76609, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.58.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.6593 - acc: 0.7138 - f1score: 0.7127 - val_loss: 0.5831 - val_acc: 0.7661 - val_f1score: 0.7689\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.6593 - acc: 0.7138 - f1score: 0.7127 - val_loss: 0.5831 - val_acc: 0.7661 - val_f1score: 0.7689\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.8224 - acc: 0.7683 - f1score: 0.7683\n",
            "Epoch 00003: val_acc improved from 0.76609 to 0.78326, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.53.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.8189 - acc: 0.7683 - f1score: 0.7682 - val_loss: 0.5301 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.76609 to 0.78326, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.53.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.8189 - acc: 0.7683 - f1score: 0.7682 - val_loss: 0.5301 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5853 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00004: val_acc improved from 0.78326 to 0.78433, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.51.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5860 - acc: 0.7963 - f1score: 0.7963 - val_loss: 0.5068 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.78326 to 0.78433, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.51.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5860 - acc: 0.7963 - f1score: 0.7963 - val_loss: 0.5068 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5336 - acc: 0.7791 - f1score: 0.7791\n",
            "Epoch 00005: val_acc improved from 0.78433 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.50.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5286 - acc: 0.7804 - f1score: 0.7816 - val_loss: 0.5001 - val_acc: 0.7929 - val_f1score: 0.7909\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.78433 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.50.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5286 - acc: 0.7804 - f1score: 0.7816 - val_loss: 0.5001 - val_acc: 0.7929 - val_f1score: 0.7909\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5374 - acc: 0.7786 - f1score: 0.7786\n",
            "Epoch 00006: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5392 - acc: 0.7772 - f1score: 0.7761 - val_loss: 0.4921 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5392 - acc: 0.7772 - f1score: 0.7761 - val_loss: 0.4921 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5295 - acc: 0.7645 - f1score: 0.7645\n",
            "Epoch 00007: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5302 - acc: 0.7646 - f1score: 0.7646 - val_loss: 0.4948 - val_acc: 0.7929 - val_f1score: 0.7957\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5302 - acc: 0.7646 - f1score: 0.7646 - val_loss: 0.4948 - val_acc: 0.7929 - val_f1score: 0.7957\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5213 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00008: val_acc improved from 0.79292 to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.48.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5214 - acc: 0.7937 - f1score: 0.7932 - val_loss: 0.4841 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.79292 to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.48.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5214 - acc: 0.7937 - f1score: 0.7932 - val_loss: 0.4841 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5254 - acc: 0.7856 - f1score: 0.7856\n",
            "Epoch 00009: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5234 - acc: 0.7857 - f1score: 0.7858 - val_loss: 0.4858 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5234 - acc: 0.7857 - f1score: 0.7858 - val_loss: 0.4858 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5080 - acc: 0.7877 - f1score: 0.7877\n",
            "Epoch 00010: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5067 - acc: 0.7889 - f1score: 0.7899 - val_loss: 0.4879 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5067 - acc: 0.7889 - f1score: 0.7899 - val_loss: 0.4879 - val_acc: 0.7843 - val_f1score: 0.7850\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5100 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00011: val_acc improved from 0.79399 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.11-0.49.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5079 - acc: 0.7947 - f1score: 0.7952 - val_loss: 0.4865 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.79399 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.11-0.49.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5079 - acc: 0.7947 - f1score: 0.7952 - val_loss: 0.4865 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5144 - acc: 0.7775 - f1score: 0.7775\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5155 - acc: 0.7767 - f1score: 0.7761 - val_loss: 0.4872 - val_acc: 0.7876 - val_f1score: 0.7889\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5155 - acc: 0.7767 - f1score: 0.7761 - val_loss: 0.4872 - val_acc: 0.7876 - val_f1score: 0.7889\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5007 - acc: 0.7856 - f1score: 0.7856\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4984 - acc: 0.7868 - f1score: 0.7878 - val_loss: 0.4890 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4984 - acc: 0.7868 - f1score: 0.7878 - val_loss: 0.4890 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4978 - acc: 0.7861 - f1score: 0.7861\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5023 - acc: 0.7857 - f1score: 0.7854 - val_loss: 0.4888 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5023 - acc: 0.7857 - f1score: 0.7854 - val_loss: 0.4888 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5067 - acc: 0.7915 - f1score: 0.7915\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5064 - acc: 0.7905 - f1score: 0.7896 - val_loss: 0.4900 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5064 - acc: 0.7905 - f1score: 0.7896 - val_loss: 0.4900 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5039 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5001 - acc: 0.7979 - f1score: 0.7992 - val_loss: 0.4896 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5001 - acc: 0.7979 - f1score: 0.7992 - val_loss: 0.4896 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4924 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4914 - acc: 0.7947 - f1score: 0.7952 - val_loss: 0.4847 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4914 - acc: 0.7947 - f1score: 0.7952 - val_loss: 0.4847 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4992 - acc: 0.7872 - f1score: 0.7872\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4994 - acc: 0.7862 - f1score: 0.7854 - val_loss: 0.4829 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4994 - acc: 0.7862 - f1score: 0.7854 - val_loss: 0.4829 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5089 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00019: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5084 - acc: 0.7974 - f1score: 0.7968 - val_loss: 0.4862 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5084 - acc: 0.7974 - f1score: 0.7968 - val_loss: 0.4862 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4888 - acc: 0.7909 - f1score: 0.7909\n",
            "Epoch 00020: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4863 - acc: 0.7921 - f1score: 0.7930 - val_loss: 0.4833 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4863 - acc: 0.7921 - f1score: 0.7930 - val_loss: 0.4833 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4887 - acc: 0.7996 - f1score: 0.7996\n",
            "Epoch 00021: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4878 - acc: 0.7995 - f1score: 0.7994 - val_loss: 0.4802 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4878 - acc: 0.7995 - f1score: 0.7994 - val_loss: 0.4802 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4856 - acc: 0.8033 - f1score: 0.8033\n",
            "Epoch 00022: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4867 - acc: 0.8032 - f1score: 0.8030 - val_loss: 0.4806 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4867 - acc: 0.8032 - f1score: 0.8030 - val_loss: 0.4806 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4710 - acc: 0.8066 - f1score: 0.8066\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4719 - acc: 0.8053 - f1score: 0.8042 - val_loss: 0.4817 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4719 - acc: 0.8053 - f1score: 0.8042 - val_loss: 0.4817 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4895 - acc: 0.8012 - f1score: 0.8012\n",
            "Epoch 00024: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4885 - acc: 0.8016 - f1score: 0.8019 - val_loss: 0.4789 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4885 - acc: 0.8016 - f1score: 0.8019 - val_loss: 0.4789 - val_acc: 0.7897 - val_f1score: 0.7877\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4872 - acc: 0.8017 - f1score: 0.8017\n",
            "Epoch 00025: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4861 - acc: 0.8026 - f1score: 0.8034 - val_loss: 0.4820 - val_acc: 0.7876 - val_f1score: 0.7881\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4861 - acc: 0.8026 - f1score: 0.8034 - val_loss: 0.4820 - val_acc: 0.7876 - val_f1score: 0.7881\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4771 - acc: 0.8055 - f1score: 0.8055\n",
            "Epoch 00026: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4770 - acc: 0.8063 - f1score: 0.8071 - val_loss: 0.4808 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4770 - acc: 0.8063 - f1score: 0.8071 - val_loss: 0.4808 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4709 - acc: 0.8012 - f1score: 0.8012\n",
            "Epoch 00027: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4681 - acc: 0.8037 - f1score: 0.8059 - val_loss: 0.4799 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4681 - acc: 0.8037 - f1score: 0.8059 - val_loss: 0.4799 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4797 - acc: 0.8050 - f1score: 0.8050\n",
            "Epoch 00028: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4798 - acc: 0.8048 - f1score: 0.8046 - val_loss: 0.4816 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4798 - acc: 0.8048 - f1score: 0.8046 - val_loss: 0.4816 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4789 - acc: 0.8077 - f1score: 0.8077\n",
            "Epoch 00029: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4801 - acc: 0.8058 - f1score: 0.8043 - val_loss: 0.4800 - val_acc: 0.7983 - val_f1score: 0.7953\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4801 - acc: 0.8058 - f1score: 0.8043 - val_loss: 0.4800 - val_acc: 0.7983 - val_f1score: 0.7953\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4806 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00030: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4819 - acc: 0.8074 - f1score: 0.8063 - val_loss: 0.4787 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4819 - acc: 0.8074 - f1score: 0.8063 - val_loss: 0.4787 - val_acc: 0.7908 - val_f1score: 0.7904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 60%|██████    | 58/96 [3:43:21<2:38:01, 249.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 74)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           750         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,615,352\n",
            "Trainable params: 94,352\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 3.8659 - acc: 0.5183 - f1score: 0.5183\n",
            "Epoch 00001: val_acc improved from -inf to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.67.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 3.8540 - acc: 0.5217 - f1score: 0.5246 - val_loss: 0.6658 - val_acc: 0.8026 - val_f1score: 0.8051\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.67.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 3.8540 - acc: 0.5217 - f1score: 0.5246 - val_loss: 0.6658 - val_acc: 0.8026 - val_f1score: 0.8051\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.7838 - acc: 0.6994 - f1score: 0.6994\n",
            "Epoch 00002: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.53.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.7857 - acc: 0.6984 - f1score: 0.6976 - val_loss: 0.5251 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.53.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.7857 - acc: 0.6984 - f1score: 0.6976 - val_loss: 0.5251 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.6972 - acc: 0.6837 - f1score: 0.6837\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.6886 - acc: 0.6841 - f1score: 0.6845 - val_loss: 0.5067 - val_acc: 0.8026 - val_f1score: 0.8019\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.6886 - acc: 0.6841 - f1score: 0.6845 - val_loss: 0.5067 - val_acc: 0.8026 - val_f1score: 0.8019\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.4480 - acc: 0.6934 - f1score: 0.6934\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.4095 - acc: 0.6963 - f1score: 0.6987 - val_loss: 0.4918 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.4095 - acc: 0.6963 - f1score: 0.6987 - val_loss: 0.4918 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.2529 - acc: 0.7139 - f1score: 0.7139\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.2618 - acc: 0.7127 - f1score: 0.7117 - val_loss: 0.5555 - val_acc: 0.8015 - val_f1score: 0.8041\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.2618 - acc: 0.7127 - f1score: 0.7117 - val_loss: 0.5555 - val_acc: 0.8015 - val_f1score: 0.8041\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.0317 - acc: 0.7392 - f1score: 0.7392\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0262 - acc: 0.7376 - f1score: 0.7362 - val_loss: 0.5103 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0262 - acc: 0.7376 - f1score: 0.7362 - val_loss: 0.5103 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5316 - acc: 0.7635 - f1score: 0.7635\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5311 - acc: 0.7646 - f1score: 0.7655 - val_loss: 0.4853 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5311 - acc: 0.7646 - f1score: 0.7655 - val_loss: 0.4853 - val_acc: 0.7929 - val_f1score: 0.7900\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5084 - acc: 0.7866 - f1score: 0.7866\n",
            "Epoch 00008: val_acc improved from 0.80365 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5076 - acc: 0.7862 - f1score: 0.7859 - val_loss: 0.4804 - val_acc: 0.8058 - val_f1score: 0.8090\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80365 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5076 - acc: 0.7862 - f1score: 0.7859 - val_loss: 0.4804 - val_acc: 0.8058 - val_f1score: 0.8090\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4897 - acc: 0.8055 - f1score: 0.8055\n",
            "Epoch 00009: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4953 - acc: 0.8021 - f1score: 0.7992 - val_loss: 0.4811 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4953 - acc: 0.8021 - f1score: 0.7992 - val_loss: 0.4811 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4775 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00010: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4762 - acc: 0.7974 - f1score: 0.7978 - val_loss: 0.5009 - val_acc: 0.7790 - val_f1score: 0.7814\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4762 - acc: 0.7974 - f1score: 0.7978 - val_loss: 0.5009 - val_acc: 0.7790 - val_f1score: 0.7814\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4831 - acc: 0.8028 - f1score: 0.8028\n",
            "Epoch 00011: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4817 - acc: 0.8042 - f1score: 0.8055 - val_loss: 0.4861 - val_acc: 0.7865 - val_f1score: 0.7870\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4817 - acc: 0.8042 - f1score: 0.8055 - val_loss: 0.4861 - val_acc: 0.7865 - val_f1score: 0.7870\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4776 - acc: 0.8012 - f1score: 0.8012\n",
            "Epoch 00012: val_acc improved from 0.80579 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.12-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4820 - acc: 0.7995 - f1score: 0.7980 - val_loss: 0.4806 - val_acc: 0.8069 - val_f1score: 0.8076\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.80579 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.12-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4820 - acc: 0.7995 - f1score: 0.7980 - val_loss: 0.4806 - val_acc: 0.8069 - val_f1score: 0.8076\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4693 - acc: 0.8055 - f1score: 0.8055\n",
            "Epoch 00013: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4671 - acc: 0.8063 - f1score: 0.8071 - val_loss: 0.4809 - val_acc: 0.7800 - val_f1score: 0.7759\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4671 - acc: 0.8063 - f1score: 0.8071 - val_loss: 0.4809 - val_acc: 0.7800 - val_f1score: 0.7759\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4692 - acc: 0.8044 - f1score: 0.8044\n",
            "Epoch 00014: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4720 - acc: 0.8026 - f1score: 0.8011 - val_loss: 0.4827 - val_acc: 0.7865 - val_f1score: 0.7838\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4720 - acc: 0.8026 - f1score: 0.8011 - val_loss: 0.4827 - val_acc: 0.7865 - val_f1score: 0.7838\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4678 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00015: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4667 - acc: 0.8116 - f1score: 0.8114 - val_loss: 0.4751 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4667 - acc: 0.8116 - f1score: 0.8114 - val_loss: 0.4751 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4708 - acc: 0.8077 - f1score: 0.8077\n",
            "Epoch 00016: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4743 - acc: 0.8058 - f1score: 0.8043 - val_loss: 0.4838 - val_acc: 0.7886 - val_f1score: 0.7859\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4743 - acc: 0.8058 - f1score: 0.8043 - val_loss: 0.4838 - val_acc: 0.7886 - val_f1score: 0.7859\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4814 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00017: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4783 - acc: 0.7963 - f1score: 0.7972 - val_loss: 0.4754 - val_acc: 0.7951 - val_f1score: 0.7962\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4783 - acc: 0.7963 - f1score: 0.7972 - val_loss: 0.4754 - val_acc: 0.7951 - val_f1score: 0.7962\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4881 - acc: 0.8082 - f1score: 0.8082\n",
            "Epoch 00018: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4880 - acc: 0.8090 - f1score: 0.8097 - val_loss: 0.4807 - val_acc: 0.7951 - val_f1score: 0.7962\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4880 - acc: 0.8090 - f1score: 0.8097 - val_loss: 0.4807 - val_acc: 0.7951 - val_f1score: 0.7962\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4672 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00019: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4693 - acc: 0.8122 - f1score: 0.8114 - val_loss: 0.4787 - val_acc: 0.7918 - val_f1score: 0.7882\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4693 - acc: 0.8122 - f1score: 0.8114 - val_loss: 0.4787 - val_acc: 0.7918 - val_f1score: 0.7882\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4622 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00020: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4625 - acc: 0.8111 - f1score: 0.8113 - val_loss: 0.4762 - val_acc: 0.7908 - val_f1score: 0.7863\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4625 - acc: 0.8111 - f1score: 0.8113 - val_loss: 0.4762 - val_acc: 0.7908 - val_f1score: 0.7863\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4706 - acc: 0.7990 - f1score: 0.7990\n",
            "Epoch 00021: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4718 - acc: 0.7979 - f1score: 0.7969 - val_loss: 0.4732 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4718 - acc: 0.7979 - f1score: 0.7969 - val_loss: 0.4732 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4751 - acc: 0.8039 - f1score: 0.8039\n",
            "Epoch 00022: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4730 - acc: 0.8053 - f1score: 0.8065 - val_loss: 0.4718 - val_acc: 0.7961 - val_f1score: 0.7956\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4730 - acc: 0.8053 - f1score: 0.8065 - val_loss: 0.4718 - val_acc: 0.7961 - val_f1score: 0.7956\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00023: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4635 - acc: 0.8127 - f1score: 0.8142 - val_loss: 0.4732 - val_acc: 0.8058 - val_f1score: 0.8050\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4635 - acc: 0.8127 - f1score: 0.8142 - val_loss: 0.4732 - val_acc: 0.8058 - val_f1score: 0.8050\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4836 - acc: 0.8033 - f1score: 0.8033\n",
            "Epoch 00024: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4845 - acc: 0.8032 - f1score: 0.8030 - val_loss: 0.4711 - val_acc: 0.8026 - val_f1score: 0.7994\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4845 - acc: 0.8032 - f1score: 0.8030 - val_loss: 0.4711 - val_acc: 0.8026 - val_f1score: 0.7994\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4715 - acc: 0.8060 - f1score: 0.8060\n",
            "Epoch 00025: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4708 - acc: 0.8058 - f1score: 0.8056 - val_loss: 0.4735 - val_acc: 0.8047 - val_f1score: 0.8096\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4708 - acc: 0.8058 - f1score: 0.8056 - val_loss: 0.4735 - val_acc: 0.8047 - val_f1score: 0.8096\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4694 - acc: 0.8066 - f1score: 0.8066\n",
            "Epoch 00026: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4671 - acc: 0.8079 - f1score: 0.8091 - val_loss: 0.4761 - val_acc: 0.7951 - val_f1score: 0.7897\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4671 - acc: 0.8079 - f1score: 0.8091 - val_loss: 0.4761 - val_acc: 0.7951 - val_f1score: 0.7897\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4676 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00027: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4669 - acc: 0.8116 - f1score: 0.8123 - val_loss: 0.4703 - val_acc: 0.8004 - val_f1score: 0.7973\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4669 - acc: 0.8116 - f1score: 0.8123 - val_loss: 0.4703 - val_acc: 0.8004 - val_f1score: 0.7973\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00028: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4670 - acc: 0.8122 - f1score: 0.8110 - val_loss: 0.4719 - val_acc: 0.7994 - val_f1score: 0.7947\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4670 - acc: 0.8122 - f1score: 0.8110 - val_loss: 0.4719 - val_acc: 0.7994 - val_f1score: 0.7947\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4636 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00029: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4636 - acc: 0.8138 - f1score: 0.8139 - val_loss: 0.4729 - val_acc: 0.7961 - val_f1score: 0.7924\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4636 - acc: 0.8138 - f1score: 0.8139 - val_loss: 0.4729 - val_acc: 0.7961 - val_f1score: 0.7924\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4726 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00030: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4716 - acc: 0.8090 - f1score: 0.8106 - val_loss: 0.4728 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4716 - acc: 0.8090 - f1score: 0.8106 - val_loss: 0.4728 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4581 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00031: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4576 - acc: 0.8185 - f1score: 0.8177 - val_loss: 0.4805 - val_acc: 0.7854 - val_f1score: 0.7876\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4576 - acc: 0.8185 - f1score: 0.8177 - val_loss: 0.4805 - val_acc: 0.7854 - val_f1score: 0.7876\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4761 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00032: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4748 - acc: 0.8153 - f1score: 0.8164 - val_loss: 0.4798 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4748 - acc: 0.8153 - f1score: 0.8164 - val_loss: 0.4798 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4642 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00033: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4651 - acc: 0.8127 - f1score: 0.8124 - val_loss: 0.4695 - val_acc: 0.8047 - val_f1score: 0.8023\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4651 - acc: 0.8127 - f1score: 0.8124 - val_loss: 0.4695 - val_acc: 0.8047 - val_f1score: 0.8023\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4538 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00034: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4559 - acc: 0.8190 - f1score: 0.8182 - val_loss: 0.4715 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4559 - acc: 0.8190 - f1score: 0.8182 - val_loss: 0.4715 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4636 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00035: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4620 - acc: 0.8106 - f1score: 0.8112 - val_loss: 0.4759 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4620 - acc: 0.8106 - f1score: 0.8112 - val_loss: 0.4759 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00036: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4642 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.4696 - val_acc: 0.8058 - val_f1score: 0.8058\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4642 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.4696 - val_acc: 0.8058 - val_f1score: 0.8058\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4731 - acc: 0.8082 - f1score: 0.8082\n",
            "Epoch 00037: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4734 - acc: 0.8079 - f1score: 0.8077 - val_loss: 0.4693 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4734 - acc: 0.8079 - f1score: 0.8077 - val_loss: 0.4693 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4535 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00038: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4541 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4713 - val_acc: 0.8058 - val_f1score: 0.8050\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4541 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4713 - val_acc: 0.8058 - val_f1score: 0.8050\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4752 - acc: 0.8077 - f1score: 0.8077\n",
            "Epoch 00039: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4718 - acc: 0.8101 - f1score: 0.8121 - val_loss: 0.4762 - val_acc: 0.7886 - val_f1score: 0.7907\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4718 - acc: 0.8101 - f1score: 0.8121 - val_loss: 0.4762 - val_acc: 0.7886 - val_f1score: 0.7907\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4775 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00040: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4758 - acc: 0.8159 - f1score: 0.8155 - val_loss: 0.4695 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4758 - acc: 0.8159 - f1score: 0.8155 - val_loss: 0.4695 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4629 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00041: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4606 - acc: 0.8159 - f1score: 0.8174 - val_loss: 0.4687 - val_acc: 0.7972 - val_f1score: 0.7934\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4606 - acc: 0.8159 - f1score: 0.8174 - val_loss: 0.4687 - val_acc: 0.7972 - val_f1score: 0.7934\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00042: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4656 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4705 - val_acc: 0.8058 - val_f1score: 0.8082\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4656 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4705 - val_acc: 0.8058 - val_f1score: 0.8082\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4554 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00043: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4582 - acc: 0.8101 - f1score: 0.8093 - val_loss: 0.4722 - val_acc: 0.8058 - val_f1score: 0.8090\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4582 - acc: 0.8101 - f1score: 0.8093 - val_loss: 0.4722 - val_acc: 0.8058 - val_f1score: 0.8090\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4760 - acc: 0.8023 - f1score: 0.8023\n",
            "Epoch 00044: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4708 - acc: 0.8053 - f1score: 0.8079 - val_loss: 0.4696 - val_acc: 0.7961 - val_f1score: 0.7948\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4708 - acc: 0.8053 - f1score: 0.8079 - val_loss: 0.4696 - val_acc: 0.7961 - val_f1score: 0.7948\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4602 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00045: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4599 - acc: 0.8138 - f1score: 0.8134 - val_loss: 0.4680 - val_acc: 0.7983 - val_f1score: 0.7953\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4599 - acc: 0.8138 - f1score: 0.8134 - val_loss: 0.4680 - val_acc: 0.7983 - val_f1score: 0.7953\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4661 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00046: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4655 - acc: 0.8122 - f1score: 0.8128 - val_loss: 0.4705 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4655 - acc: 0.8122 - f1score: 0.8128 - val_loss: 0.4705 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4608 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00047: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4590 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4701 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4590 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4701 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4572 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00048: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4588 - acc: 0.8138 - f1score: 0.8134 - val_loss: 0.4692 - val_acc: 0.7994 - val_f1score: 0.7979\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4588 - acc: 0.8138 - f1score: 0.8134 - val_loss: 0.4692 - val_acc: 0.7994 - val_f1score: 0.7979\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4623 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00049: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4621 - acc: 0.8116 - f1score: 0.8114 - val_loss: 0.4721 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4621 - acc: 0.8116 - f1score: 0.8114 - val_loss: 0.4721 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4535 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00050: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4571 - acc: 0.8148 - f1score: 0.8131 - val_loss: 0.4695 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4571 - acc: 0.8148 - f1score: 0.8131 - val_loss: 0.4695 - val_acc: 0.8015 - val_f1score: 0.8024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 61%|██████▏   | 59/96 [3:49:53<3:00:08, 292.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           30          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 138)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           1390        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            22          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,742,200\n",
            "Trainable params: 221,200\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 3.4363 - acc: 0.6363 - f1score: 0.6363\n",
            "Epoch 00001: val_acc improved from -inf to 0.78112, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.77.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 3.4076 - acc: 0.6392 - f1score: 0.6416 - val_loss: 0.7718 - val_acc: 0.7811 - val_f1score: 0.7794\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78112, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.77.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 3.4076 - acc: 0.6392 - f1score: 0.6416 - val_loss: 0.7718 - val_acc: 0.7811 - val_f1score: 0.7794\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.5051 - acc: 0.7123 - f1score: 0.7123\n",
            "Epoch 00002: val_acc improved from 0.78112 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.72.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.78112 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.72.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.4993 - acc: 0.7101 - f1score: 0.7081 - val_loss: 0.7154 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.4993 - acc: 0.7101 - f1score: 0.7081 - val_loss: 0.7154 - val_acc: 0.8015 - val_f1score: 0.8008\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.2559 - acc: 0.7403 - f1score: 0.7403\n",
            "Epoch 00003: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.2405 - acc: 0.7413 - f1score: 0.7421 - val_loss: 0.6311 - val_acc: 0.7929 - val_f1score: 0.7949\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.2405 - acc: 0.7413 - f1score: 0.7421 - val_loss: 0.6311 - val_acc: 0.7929 - val_f1score: 0.7949\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6084 - acc: 0.7780 - f1score: 0.7780\n",
            "Epoch 00004: val_acc improved from 0.80150 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.49.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.6062 - acc: 0.7772 - f1score: 0.7766 - val_loss: 0.4882 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.80150 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.49.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.6062 - acc: 0.7772 - f1score: 0.7766 - val_loss: 0.4882 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5448 - acc: 0.7823 - f1score: 0.7823\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5406 - acc: 0.7841 - f1score: 0.7857 - val_loss: 0.5206 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5406 - acc: 0.7841 - f1score: 0.7857 - val_loss: 0.5206 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5479 - acc: 0.7678 - f1score: 0.7678\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5474 - acc: 0.7667 - f1score: 0.7657 - val_loss: 0.4967 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5474 - acc: 0.7667 - f1score: 0.7657 - val_loss: 0.4967 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5260 - acc: 0.7856 - f1score: 0.7856\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5295 - acc: 0.7847 - f1score: 0.7839 - val_loss: 0.5042 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5295 - acc: 0.7847 - f1score: 0.7839 - val_loss: 0.5042 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5226 - acc: 0.7872 - f1score: 0.7872\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5198 - acc: 0.7878 - f1score: 0.7884 - val_loss: 0.4967 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5198 - acc: 0.7878 - f1score: 0.7884 - val_loss: 0.4967 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5072 - acc: 0.7947 - f1score: 0.7947\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5066 - acc: 0.7952 - f1score: 0.7957 - val_loss: 0.5288 - val_acc: 0.7929 - val_f1score: 0.7909\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5066 - acc: 0.7952 - f1score: 0.7957 - val_loss: 0.5288 - val_acc: 0.7929 - val_f1score: 0.7909\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5020 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5015 - acc: 0.7952 - f1score: 0.7952 - val_loss: 0.4904 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5015 - acc: 0.7952 - f1score: 0.7952 - val_loss: 0.4904 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5132 - acc: 0.7764 - f1score: 0.7764\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5095 - acc: 0.7783 - f1score: 0.7799 - val_loss: 0.4950 - val_acc: 0.7897 - val_f1score: 0.7934\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5095 - acc: 0.7783 - f1score: 0.7799 - val_loss: 0.4950 - val_acc: 0.7897 - val_f1score: 0.7934\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5099 - acc: 0.7915 - f1score: 0.7915\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5114 - acc: 0.7915 - f1score: 0.7916 - val_loss: 0.5002 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5114 - acc: 0.7915 - f1score: 0.7916 - val_loss: 0.5002 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5100 - acc: 0.7845 - f1score: 0.7845\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5085 - acc: 0.7857 - f1score: 0.7868 - val_loss: 0.4953 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5085 - acc: 0.7857 - f1score: 0.7868 - val_loss: 0.4953 - val_acc: 0.8036 - val_f1score: 0.8029\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5095 - acc: 0.7931 - f1score: 0.7931\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5103 - acc: 0.7926 - f1score: 0.7922 - val_loss: 0.5279 - val_acc: 0.7854 - val_f1score: 0.7868\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5103 - acc: 0.7926 - f1score: 0.7922 - val_loss: 0.5279 - val_acc: 0.7854 - val_f1score: 0.7868\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5012 - acc: 0.8028 - f1score: 0.8028\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4998 - acc: 0.8032 - f1score: 0.8035 - val_loss: 0.4921 - val_acc: 0.7951 - val_f1score: 0.7921\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4998 - acc: 0.8032 - f1score: 0.8035 - val_loss: 0.4921 - val_acc: 0.7951 - val_f1score: 0.7921\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5053 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5107 - acc: 0.7958 - f1score: 0.7934 - val_loss: 0.4954 - val_acc: 0.7682 - val_f1score: 0.7701\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5107 - acc: 0.7958 - f1score: 0.7934 - val_loss: 0.4954 - val_acc: 0.7682 - val_f1score: 0.7701\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5017 - acc: 0.7883 - f1score: 0.7883\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4993 - acc: 0.7894 - f1score: 0.7904 - val_loss: 0.4734 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4993 - acc: 0.7894 - f1score: 0.7904 - val_loss: 0.4734 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5086 - acc: 0.7936 - f1score: 0.7936\n",
            "Epoch 00018: val_acc improved from 0.80365 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.18-0.48.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5067 - acc: 0.7942 - f1score: 0.7946 - val_loss: 0.4754 - val_acc: 0.8058 - val_f1score: 0.8066\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.80365 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.18-0.48.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5067 - acc: 0.7942 - f1score: 0.7946 - val_loss: 0.4754 - val_acc: 0.8058 - val_f1score: 0.8066\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4912 - acc: 0.7936 - f1score: 0.7936\n",
            "Epoch 00019: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4896 - acc: 0.7947 - f1score: 0.7956 - val_loss: 0.4756 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4896 - acc: 0.7947 - f1score: 0.7956 - val_loss: 0.4756 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4860 - acc: 0.8044 - f1score: 0.8044\n",
            "Epoch 00020: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4851 - acc: 0.8048 - f1score: 0.8051 - val_loss: 0.4800 - val_acc: 0.8036 - val_f1score: 0.7980\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4851 - acc: 0.8048 - f1score: 0.8051 - val_loss: 0.4800 - val_acc: 0.8036 - val_f1score: 0.7980\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4869 - acc: 0.7958 - f1score: 0.7958\n",
            "Epoch 00021: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4856 - acc: 0.7968 - f1score: 0.7977 - val_loss: 0.4743 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4856 - acc: 0.7968 - f1score: 0.7977 - val_loss: 0.4743 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4894 - acc: 0.7936 - f1score: 0.7936\n",
            "Epoch 00022: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4912 - acc: 0.7931 - f1score: 0.7927 - val_loss: 0.4933 - val_acc: 0.7800 - val_f1score: 0.7792\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4912 - acc: 0.7931 - f1score: 0.7927 - val_loss: 0.4933 - val_acc: 0.7800 - val_f1score: 0.7792\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4995 - acc: 0.7829 - f1score: 0.7829\n",
            "Epoch 00023: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4966 - acc: 0.7847 - f1score: 0.7862 - val_loss: 0.4775 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4966 - acc: 0.7847 - f1score: 0.7862 - val_loss: 0.4775 - val_acc: 0.8026 - val_f1score: 0.8035\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4974 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00024: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4937 - acc: 0.8005 - f1score: 0.8023 - val_loss: 0.4828 - val_acc: 0.7865 - val_f1score: 0.7846\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4937 - acc: 0.8005 - f1score: 0.8023 - val_loss: 0.4828 - val_acc: 0.7865 - val_f1score: 0.7846\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4876 - acc: 0.7861 - f1score: 0.7861\n",
            "Epoch 00025: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4868 - acc: 0.7873 - f1score: 0.7883 - val_loss: 0.4777 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4868 - acc: 0.7873 - f1score: 0.7883 - val_loss: 0.4777 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4784 - acc: 0.8012 - f1score: 0.8012\n",
            "Epoch 00026: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4785 - acc: 0.8016 - f1score: 0.8019 - val_loss: 0.4740 - val_acc: 0.7800 - val_f1score: 0.7808\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4785 - acc: 0.8016 - f1score: 0.8019 - val_loss: 0.4740 - val_acc: 0.7800 - val_f1score: 0.7808\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4879 - acc: 0.7990 - f1score: 0.7990\n",
            "Epoch 00027: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4856 - acc: 0.8005 - f1score: 0.8018 - val_loss: 0.4818 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4856 - acc: 0.8005 - f1score: 0.8018 - val_loss: 0.4818 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4795 - acc: 0.8050 - f1score: 0.8050\n",
            "Epoch 00028: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4836 - acc: 0.8032 - f1score: 0.8017 - val_loss: 0.4814 - val_acc: 0.7951 - val_f1score: 0.7937\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4836 - acc: 0.8032 - f1score: 0.8017 - val_loss: 0.4814 - val_acc: 0.7951 - val_f1score: 0.7937\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4892 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00029: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4879 - acc: 0.7984 - f1score: 0.7988 - val_loss: 0.4775 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4879 - acc: 0.7984 - f1score: 0.7988 - val_loss: 0.4775 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4724 - acc: 0.7920 - f1score: 0.7920\n",
            "Epoch 00030: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4726 - acc: 0.7926 - f1score: 0.7931 - val_loss: 0.4905 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4726 - acc: 0.7926 - f1score: 0.7931 - val_loss: 0.4905 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4672 - acc: 0.8001 - f1score: 0.8001\n",
            "Epoch 00031: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4652 - acc: 0.8021 - f1score: 0.8038 - val_loss: 0.4737 - val_acc: 0.7983 - val_f1score: 0.8001\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4652 - acc: 0.8021 - f1score: 0.8038 - val_loss: 0.4737 - val_acc: 0.7983 - val_f1score: 0.8001\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5024 - acc: 0.7947 - f1score: 0.7947\n",
            "Epoch 00032: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5022 - acc: 0.7947 - f1score: 0.7947 - val_loss: 0.4948 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5022 - acc: 0.7947 - f1score: 0.7947 - val_loss: 0.4948 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4811 - acc: 0.7942 - f1score: 0.7942\n",
            "Epoch 00033: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4813 - acc: 0.7937 - f1score: 0.7932 - val_loss: 0.4809 - val_acc: 0.7811 - val_f1score: 0.7794\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4813 - acc: 0.7937 - f1score: 0.7932 - val_loss: 0.4809 - val_acc: 0.7811 - val_f1score: 0.7794\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4696 - acc: 0.8033 - f1score: 0.8033\n",
            "Epoch 00034: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4725 - acc: 0.8032 - f1score: 0.8030 - val_loss: 0.4781 - val_acc: 0.7983 - val_f1score: 0.7944\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4725 - acc: 0.8032 - f1score: 0.8030 - val_loss: 0.4781 - val_acc: 0.7983 - val_f1score: 0.7944\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4727 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00035: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4731 - acc: 0.8074 - f1score: 0.8063 - val_loss: 0.4822 - val_acc: 0.8058 - val_f1score: 0.8090\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4731 - acc: 0.8074 - f1score: 0.8063 - val_loss: 0.4822 - val_acc: 0.8058 - val_f1score: 0.8090\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4772 - acc: 0.8028 - f1score: 0.8028\n",
            "Epoch 00036: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4829 - acc: 0.8000 - f1score: 0.7976 - val_loss: 0.4756 - val_acc: 0.7940 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4829 - acc: 0.8000 - f1score: 0.7976 - val_loss: 0.4756 - val_acc: 0.7940 - val_f1score: 0.7984\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4633 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00037: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4647 - acc: 0.8095 - f1score: 0.8088 - val_loss: 0.4776 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4647 - acc: 0.8095 - f1score: 0.8088 - val_loss: 0.4776 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4697 - acc: 0.8082 - f1score: 0.8082\n",
            "Epoch 00038: val_acc improved from 0.80579 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.38-0.48.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4725 - acc: 0.8063 - f1score: 0.8048 - val_loss: 0.4793 - val_acc: 0.8069 - val_f1score: 0.8052\n",
            "\n",
            "Epoch 00038: val_acc improved from 0.80579 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.38-0.48.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4725 - acc: 0.8063 - f1score: 0.8048 - val_loss: 0.4793 - val_acc: 0.8069 - val_f1score: 0.8052\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4698 - acc: 0.8001 - f1score: 0.8001\n",
            "Epoch 00039: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4734 - acc: 0.7984 - f1score: 0.7970 - val_loss: 0.4740 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4734 - acc: 0.7984 - f1score: 0.7970 - val_loss: 0.4740 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4613 - acc: 0.8055 - f1score: 0.8055\n",
            "Epoch 00040: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4660 - acc: 0.8037 - f1score: 0.8022 - val_loss: 0.4744 - val_acc: 0.8036 - val_f1score: 0.8069\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4660 - acc: 0.8037 - f1score: 0.8022 - val_loss: 0.4744 - val_acc: 0.8036 - val_f1score: 0.8069\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4521 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00041: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4504 - acc: 0.8153 - f1score: 0.8155 - val_loss: 0.4772 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4504 - acc: 0.8153 - f1score: 0.8155 - val_loss: 0.4772 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00042: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4647 - acc: 0.8143 - f1score: 0.8140 - val_loss: 0.4764 - val_acc: 0.7876 - val_f1score: 0.7840\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4647 - acc: 0.8143 - f1score: 0.8140 - val_loss: 0.4764 - val_acc: 0.7876 - val_f1score: 0.7840\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4624 - acc: 0.8060 - f1score: 0.8060\n",
            "Epoch 00043: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4592 - acc: 0.8085 - f1score: 0.8105 - val_loss: 0.4816 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4592 - acc: 0.8085 - f1score: 0.8105 - val_loss: 0.4816 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4748 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00044: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4763 - acc: 0.8069 - f1score: 0.8067 - val_loss: 0.4714 - val_acc: 0.7951 - val_f1score: 0.7954\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4763 - acc: 0.8069 - f1score: 0.8067 - val_loss: 0.4714 - val_acc: 0.7951 - val_f1score: 0.7954\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00045: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4653 - acc: 0.8132 - f1score: 0.8125 - val_loss: 0.4719 - val_acc: 0.7951 - val_f1score: 0.7962\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4653 - acc: 0.8132 - f1score: 0.8125 - val_loss: 0.4719 - val_acc: 0.7951 - val_f1score: 0.7962\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8093 - f1score: 0.8093\n",
            "Epoch 00046: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4626 - acc: 0.8106 - f1score: 0.8117 - val_loss: 0.4770 - val_acc: 0.7886 - val_f1score: 0.7891\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4626 - acc: 0.8106 - f1score: 0.8117 - val_loss: 0.4770 - val_acc: 0.7886 - val_f1score: 0.7891\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4726 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00047: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4717 - acc: 0.8085 - f1score: 0.8082 - val_loss: 0.4745 - val_acc: 0.7865 - val_f1score: 0.7862\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4717 - acc: 0.8085 - f1score: 0.8082 - val_loss: 0.4745 - val_acc: 0.7865 - val_f1score: 0.7862\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4488 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00048: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4469 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4843 - val_acc: 0.7865 - val_f1score: 0.7854\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4469 - acc: 0.8132 - f1score: 0.8138 - val_loss: 0.4843 - val_acc: 0.7865 - val_f1score: 0.7854\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4697 - acc: 0.8093 - f1score: 0.8093\n",
            "Epoch 00049: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4658 - acc: 0.8111 - f1score: 0.8127 - val_loss: 0.4727 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4658 - acc: 0.8111 - f1score: 0.8127 - val_loss: 0.4727 - val_acc: 0.7929 - val_f1score: 0.7933\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8093 - f1score: 0.8093\n",
            "Epoch 00050: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4604 - acc: 0.8085 - f1score: 0.8078 - val_loss: 0.4847 - val_acc: 0.8026 - val_f1score: 0.8051\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4604 - acc: 0.8085 - f1score: 0.8078 - val_loss: 0.4847 - val_acc: 0.8026 - val_f1score: 0.8051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 62%|██████▎   | 60/96 [3:58:18<3:33:37, 356.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.3440 - acc: 0.7425 - f1score: 0.7425\n",
            "Epoch 00001: val_acc improved from -inf to 0.77682, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.71.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.3349 - acc: 0.7429 - f1score: 0.7432 - val_loss: 0.7118 - val_acc: 0.7768 - val_f1score: 0.7769\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77682, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.71.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.3349 - acc: 0.7429 - f1score: 0.7432 - val_loss: 0.7118 - val_acc: 0.7768 - val_f1score: 0.7769\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.7717 - acc: 0.7505 - f1score: 0.7505\n",
            "Epoch 00002: val_acc improved from 0.77682 to 0.79185, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.53.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.77682 to 0.79185, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.53.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7716 - acc: 0.7503 - f1score: 0.7500 - val_loss: 0.5279 - val_acc: 0.7918 - val_f1score: 0.7890\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7716 - acc: 0.7503 - f1score: 0.7500 - val_loss: 0.5279 - val_acc: 0.7918 - val_f1score: 0.7890\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5686 - acc: 0.7877 - f1score: 0.7877\n",
            "Epoch 00003: val_acc improved from 0.79185 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.50.h5\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.79185 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.50.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5719 - acc: 0.7862 - f1score: 0.7850 - val_loss: 0.5003 - val_acc: 0.8004 - val_f1score: 0.7973\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5719 - acc: 0.7862 - f1score: 0.7850 - val_loss: 0.5003 - val_acc: 0.8004 - val_f1score: 0.7973\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4919 - acc: 0.7947 - f1score: 0.7947\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4928 - acc: 0.7947 - f1score: 0.7947 - val_loss: 0.4859 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4928 - acc: 0.7947 - f1score: 0.7947 - val_loss: 0.4859 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4867 - acc: 0.8050 - f1score: 0.8050\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4875 - acc: 0.8053 - f1score: 0.8056 - val_loss: 0.4912 - val_acc: 0.7951 - val_f1score: 0.7970\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4875 - acc: 0.8053 - f1score: 0.8056 - val_loss: 0.4912 - val_acc: 0.7951 - val_f1score: 0.7970\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4796 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4801 - acc: 0.7952 - f1score: 0.7952 - val_loss: 0.4847 - val_acc: 0.7800 - val_f1score: 0.7792\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4801 - acc: 0.7952 - f1score: 0.7952 - val_loss: 0.4847 - val_acc: 0.7800 - val_f1score: 0.7792\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4622 - acc: 0.8055 - f1score: 0.8055\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4653 - acc: 0.8042 - f1score: 0.8032 - val_loss: 0.4880 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4653 - acc: 0.8042 - f1score: 0.8032 - val_loss: 0.4880 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4620 - acc: 0.8050 - f1score: 0.8050\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4627 - acc: 0.8048 - f1score: 0.8046 - val_loss: 0.4845 - val_acc: 0.7961 - val_f1score: 0.7980\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4627 - acc: 0.8048 - f1score: 0.8046 - val_loss: 0.4845 - val_acc: 0.7961 - val_f1score: 0.7980\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4668 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4667 - acc: 0.8101 - f1score: 0.8103 - val_loss: 0.4902 - val_acc: 0.7811 - val_f1score: 0.7851\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4667 - acc: 0.8101 - f1score: 0.8103 - val_loss: 0.4902 - val_acc: 0.7811 - val_f1score: 0.7851\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4648 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4632 - acc: 0.8079 - f1score: 0.8086 - val_loss: 0.4892 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4632 - acc: 0.8079 - f1score: 0.8086 - val_loss: 0.4892 - val_acc: 0.7897 - val_f1score: 0.7885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 64%|██████▎   | 61/96 [3:59:43<2:40:14, 274.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.7174 - acc: 0.5770 - f1score: 0.5770\n",
            "Epoch 00001: val_acc improved from -inf to 0.71781, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.57.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.6807 - acc: 0.5794 - f1score: 0.5813 - val_loss: 0.5727 - val_acc: 0.7178 - val_f1score: 0.7163\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.71781, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.57.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.6807 - acc: 0.5794 - f1score: 0.5813 - val_loss: 0.5727 - val_acc: 0.7178 - val_f1score: 0.7163\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.3908 - acc: 0.7430 - f1score: 0.7430\n",
            "Epoch 00002: val_acc improved from 0.71781 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.49.h5\n",
            "1890/1890 [==============================] - 14s 7ms/sample - loss: 1.3796 - acc: 0.7418 - f1score: 0.7408 - val_loss: 0.4888 - val_acc: 0.8047 - val_f1score: 0.8039\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.71781 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.49.h5\n",
            "1890/1890 [==============================] - 14s 7ms/sample - loss: 1.3796 - acc: 0.7418 - f1score: 0.7408 - val_loss: 0.4888 - val_acc: 0.8047 - val_f1score: 0.8039\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.2912 - acc: 0.7500 - f1score: 0.7500\n",
            "Epoch 00003: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.2917 - acc: 0.7471 - f1score: 0.7446 - val_loss: 0.5248 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.2917 - acc: 0.7471 - f1score: 0.7446 - val_loss: 0.5248 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.7250 - acc: 0.7737 - f1score: 0.7737\n",
            "Epoch 00004: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.7261 - acc: 0.7735 - f1score: 0.7734 - val_loss: 0.5239 - val_acc: 0.8026 - val_f1score: 0.8051\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.7261 - acc: 0.7735 - f1score: 0.7734 - val_loss: 0.5239 - val_acc: 0.8026 - val_f1score: 0.8051\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5326 - acc: 0.7866 - f1score: 0.7866\n",
            "Epoch 00005: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5299 - acc: 0.7884 - f1score: 0.7898 - val_loss: 0.5135 - val_acc: 0.8036 - val_f1score: 0.8045\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5299 - acc: 0.7884 - f1score: 0.7898 - val_loss: 0.5135 - val_acc: 0.8036 - val_f1score: 0.8045\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4909 - acc: 0.8066 - f1score: 0.8066\n",
            "Epoch 00006: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4941 - acc: 0.8037 - f1score: 0.8013 - val_loss: 0.4954 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4941 - acc: 0.8037 - f1score: 0.8013 - val_loss: 0.4954 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4722 - acc: 0.8077 - f1score: 0.8077\n",
            "Epoch 00007: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4708 - acc: 0.8079 - f1score: 0.8082 - val_loss: 0.4861 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4708 - acc: 0.8079 - f1score: 0.8082 - val_loss: 0.4861 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4770 - acc: 0.8050 - f1score: 0.8050\n",
            "Epoch 00008: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4732 - acc: 0.8074 - f1score: 0.8095 - val_loss: 0.4816 - val_acc: 0.8026 - val_f1score: 0.8010\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4732 - acc: 0.8074 - f1score: 0.8095 - val_loss: 0.4816 - val_acc: 0.8026 - val_f1score: 0.8010\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4748 - acc: 0.8039 - f1score: 0.8039\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4739 - acc: 0.8037 - f1score: 0.8036 - val_loss: 0.5063 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4739 - acc: 0.8037 - f1score: 0.8036 - val_loss: 0.5063 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4659 - acc: 0.8082 - f1score: 0.8082\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4657 - acc: 0.8074 - f1score: 0.8067 - val_loss: 0.4879 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4657 - acc: 0.8074 - f1score: 0.8067 - val_loss: 0.4879 - val_acc: 0.8004 - val_f1score: 0.8006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 65%|██████▍   | 62/96 [4:01:31<2:07:23, 224.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.2874 - acc: 0.7435 - f1score: 0.7435\n",
            "Epoch 00001: val_acc improved from -inf to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.09.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.2760 - acc: 0.7439 - f1score: 0.7442 - val_loss: 1.0926 - val_acc: 0.8026 - val_f1score: 0.8002\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.09.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.2760 - acc: 0.7439 - f1score: 0.7442 - val_loss: 1.0926 - val_acc: 0.8026 - val_f1score: 0.8002\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.8033 - acc: 0.7683 - f1score: 0.7683\n",
            "Epoch 00002: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.57.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.57.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.8078 - acc: 0.7677 - f1score: 0.7672 - val_loss: 0.5707 - val_acc: 0.8036 - val_f1score: 0.8005\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.8078 - acc: 0.7677 - f1score: 0.7672 - val_loss: 0.5707 - val_acc: 0.8036 - val_f1score: 0.8005\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5495 - acc: 0.7861 - f1score: 0.7861\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5468 - acc: 0.7847 - f1score: 0.7834 - val_loss: 0.4944 - val_acc: 0.8026 - val_f1score: 0.8043\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5468 - acc: 0.7847 - f1score: 0.7834 - val_loss: 0.4944 - val_acc: 0.8026 - val_f1score: 0.8043\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5128 - acc: 0.7899 - f1score: 0.7899\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5144 - acc: 0.7894 - f1score: 0.7890 - val_loss: 0.4776 - val_acc: 0.7854 - val_f1score: 0.7868\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5144 - acc: 0.7894 - f1score: 0.7890 - val_loss: 0.4776 - val_acc: 0.7854 - val_f1score: 0.7868\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4928 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4927 - acc: 0.7958 - f1score: 0.7962 - val_loss: 0.4887 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4927 - acc: 0.7958 - f1score: 0.7962 - val_loss: 0.4887 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4715 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4708 - acc: 0.8143 - f1score: 0.8135 - val_loss: 0.4817 - val_acc: 0.7822 - val_f1score: 0.7780\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4708 - acc: 0.8143 - f1score: 0.8135 - val_loss: 0.4817 - val_acc: 0.7822 - val_f1score: 0.7780\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4564 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4618 - acc: 0.8138 - f1score: 0.8107 - val_loss: 0.4741 - val_acc: 0.7918 - val_f1score: 0.7922\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4618 - acc: 0.8138 - f1score: 0.8107 - val_loss: 0.4741 - val_acc: 0.7918 - val_f1score: 0.7922\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4510 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4501 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4830 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4501 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4830 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4468 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4481 - acc: 0.8196 - f1score: 0.8187 - val_loss: 0.4751 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4481 - acc: 0.8196 - f1score: 0.8187 - val_loss: 0.4751 - val_acc: 0.7854 - val_f1score: 0.7860\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4484 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4505 - acc: 0.8143 - f1score: 0.8135 - val_loss: 0.4745 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4505 - acc: 0.8143 - f1score: 0.8135 - val_loss: 0.4745 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4390 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4396 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4824 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4396 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4824 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4437 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4435 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4743 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4435 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4743 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4393 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4389 - acc: 0.8233 - f1score: 0.8242 - val_loss: 0.4758 - val_acc: 0.7940 - val_f1score: 0.7903\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4389 - acc: 0.8233 - f1score: 0.8242 - val_loss: 0.4758 - val_acc: 0.7940 - val_f1score: 0.7903\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4543 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4533 - acc: 0.8159 - f1score: 0.8165 - val_loss: 0.4801 - val_acc: 0.7811 - val_f1score: 0.7770\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4533 - acc: 0.8159 - f1score: 0.8165 - val_loss: 0.4801 - val_acc: 0.7811 - val_f1score: 0.7770\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4471 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4467 - acc: 0.8180 - f1score: 0.8172 - val_loss: 0.4732 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4467 - acc: 0.8180 - f1score: 0.8172 - val_loss: 0.4732 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4357 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4363 - acc: 0.8217 - f1score: 0.8213 - val_loss: 0.4733 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4363 - acc: 0.8217 - f1score: 0.8213 - val_loss: 0.4733 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4421 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4429 - acc: 0.8212 - f1score: 0.8212 - val_loss: 0.4697 - val_acc: 0.7994 - val_f1score: 0.8012\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4429 - acc: 0.8212 - f1score: 0.8212 - val_loss: 0.4697 - val_acc: 0.7994 - val_f1score: 0.8012\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4432 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4416 - acc: 0.8222 - f1score: 0.8232 - val_loss: 0.4699 - val_acc: 0.7983 - val_f1score: 0.8001\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4416 - acc: 0.8222 - f1score: 0.8232 - val_loss: 0.4699 - val_acc: 0.7983 - val_f1score: 0.8001\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4432 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4446 - acc: 0.8180 - f1score: 0.8167 - val_loss: 0.4735 - val_acc: 0.7908 - val_f1score: 0.7872\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4446 - acc: 0.8180 - f1score: 0.8167 - val_loss: 0.4735 - val_acc: 0.7908 - val_f1score: 0.7872\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4412 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4456 - acc: 0.8206 - f1score: 0.8188 - val_loss: 0.4720 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4456 - acc: 0.8206 - f1score: 0.8188 - val_loss: 0.4720 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4460 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4442 - acc: 0.8222 - f1score: 0.8232 - val_loss: 0.4672 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4442 - acc: 0.8222 - f1score: 0.8232 - val_loss: 0.4672 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4455 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4461 - acc: 0.8233 - f1score: 0.8237 - val_loss: 0.4698 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4461 - acc: 0.8233 - f1score: 0.8237 - val_loss: 0.4698 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4454 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4452 - acc: 0.8217 - f1score: 0.8217 - val_loss: 0.4701 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4452 - acc: 0.8217 - f1score: 0.8217 - val_loss: 0.4701 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4455 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4436 - acc: 0.8233 - f1score: 0.8233 - val_loss: 0.4695 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4436 - acc: 0.8233 - f1score: 0.8233 - val_loss: 0.4695 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4453 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4676 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4453 - acc: 0.8159 - f1score: 0.8160 - val_loss: 0.4676 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4470 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4434 - acc: 0.8185 - f1score: 0.8200 - val_loss: 0.4699 - val_acc: 0.7940 - val_f1score: 0.7911\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4434 - acc: 0.8185 - f1score: 0.8200 - val_loss: 0.4699 - val_acc: 0.7940 - val_f1score: 0.7911\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4446 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00027: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.27-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4442 - acc: 0.8185 - f1score: 0.8181 - val_loss: 0.4666 - val_acc: 0.8047 - val_f1score: 0.8080\n",
            "\n",
            "Epoch 00027: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.27-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4442 - acc: 0.8185 - f1score: 0.8181 - val_loss: 0.4666 - val_acc: 0.8047 - val_f1score: 0.8080\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4389 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4424 - acc: 0.8217 - f1score: 0.8203 - val_loss: 0.4711 - val_acc: 0.7865 - val_f1score: 0.7854\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4424 - acc: 0.8217 - f1score: 0.8203 - val_loss: 0.4711 - val_acc: 0.7865 - val_f1score: 0.7854\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4367 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4375 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4668 - val_acc: 0.8026 - val_f1score: 0.8051\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4375 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4668 - val_acc: 0.8026 - val_f1score: 0.8051\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4417 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4400 - acc: 0.8238 - f1score: 0.8247 - val_loss: 0.4669 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4400 - acc: 0.8238 - f1score: 0.8247 - val_loss: 0.4669 - val_acc: 0.7940 - val_f1score: 0.7951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 66%|██████▌   | 63/96 [4:05:26<2:05:11, 227.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 4.2771 - acc: 0.6374 - f1score: 0.6374\n",
            "Epoch 00001: val_acc improved from -inf to 0.78219, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.40.h5\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78219, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.40.h5\n",
            "1890/1890 [==============================] - 15s 8ms/sample - loss: 4.2235 - acc: 0.6423 - f1score: 0.6465 - val_loss: 2.4020 - val_acc: 0.7822 - val_f1score: 0.7788\n",
            "1890/1890 [==============================] - 15s 8ms/sample - loss: 4.2235 - acc: 0.6423 - f1score: 0.6465 - val_loss: 2.4020 - val_acc: 0.7822 - val_f1score: 0.7788\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.8066 - acc: 0.7877 - f1score: 0.7877\n",
            "Epoch 00002: val_acc improved from 0.78219 to 0.78541, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.68.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.7943 - acc: 0.7873 - f1score: 0.7869 - val_loss: 1.6775 - val_acc: 0.7854 - val_f1score: 0.7828\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.78219 to 0.78541, saving model to /content/drive/My Drive/LSTM_Model/model.02-1.68.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.7943 - acc: 0.7873 - f1score: 0.7869 - val_loss: 1.6775 - val_acc: 0.7854 - val_f1score: 0.7828\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.2959 - acc: 0.7640 - f1score: 0.7640\n",
            "Epoch 00003: val_acc improved from 0.78541 to 0.79936, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.74.h5\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.78541 to 0.79936, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.74.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.3080 - acc: 0.7614 - f1score: 0.7591 - val_loss: 0.7361 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.3080 - acc: 0.7614 - f1score: 0.7591 - val_loss: 0.7361 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.7647 - acc: 0.7689 - f1score: 0.7689\n",
            "Epoch 00004: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.7585 - acc: 0.7698 - f1score: 0.7707 - val_loss: 0.5761 - val_acc: 0.7157 - val_f1score: 0.7175\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.7585 - acc: 0.7698 - f1score: 0.7707 - val_loss: 0.5761 - val_acc: 0.7157 - val_f1score: 0.7175\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5219 - acc: 0.7936 - f1score: 0.7936\n",
            "Epoch 00005: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5219 - acc: 0.7937 - f1score: 0.7937 - val_loss: 0.5138 - val_acc: 0.7918 - val_f1score: 0.7890\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5219 - acc: 0.7937 - f1score: 0.7937 - val_loss: 0.5138 - val_acc: 0.7918 - val_f1score: 0.7890\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4914 - acc: 0.7931 - f1score: 0.7931\n",
            "Epoch 00006: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4894 - acc: 0.7931 - f1score: 0.7931 - val_loss: 0.4861 - val_acc: 0.7886 - val_f1score: 0.7875\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4894 - acc: 0.7931 - f1score: 0.7931 - val_loss: 0.4861 - val_acc: 0.7886 - val_f1score: 0.7875\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4684 - acc: 0.8077 - f1score: 0.8077\n",
            "Epoch 00007: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4673 - acc: 0.8090 - f1score: 0.8101 - val_loss: 0.5079 - val_acc: 0.7983 - val_f1score: 0.7993\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4673 - acc: 0.8090 - f1score: 0.8101 - val_loss: 0.5079 - val_acc: 0.7983 - val_f1score: 0.7993\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4665 - acc: 0.8087 - f1score: 0.8087\n",
            "Epoch 00008: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4657 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.4918 - val_acc: 0.7876 - val_f1score: 0.7889\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4657 - acc: 0.8090 - f1score: 0.8092 - val_loss: 0.4918 - val_acc: 0.7876 - val_f1score: 0.7889\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4777 - acc: 0.8044 - f1score: 0.8044\n",
            "Epoch 00009: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4784 - acc: 0.8042 - f1score: 0.8041 - val_loss: 0.4842 - val_acc: 0.7811 - val_f1score: 0.7770\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4784 - acc: 0.8042 - f1score: 0.8041 - val_loss: 0.4842 - val_acc: 0.7811 - val_f1score: 0.7770\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4687 - acc: 0.7974 - f1score: 0.7974\n",
            "Epoch 00010: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4686 - acc: 0.7989 - f1score: 0.8002 - val_loss: 0.4865 - val_acc: 0.7854 - val_f1score: 0.7844\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4686 - acc: 0.7989 - f1score: 0.8002 - val_loss: 0.4865 - val_acc: 0.7854 - val_f1score: 0.7844\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4519 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00011: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4539 - acc: 0.8143 - f1score: 0.8140 - val_loss: 0.4844 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4539 - acc: 0.8143 - f1score: 0.8140 - val_loss: 0.4844 - val_acc: 0.7833 - val_f1score: 0.7831\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4548 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00012: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4534 - acc: 0.8127 - f1score: 0.8142 - val_loss: 0.4837 - val_acc: 0.7790 - val_f1score: 0.7765\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4534 - acc: 0.8127 - f1score: 0.8142 - val_loss: 0.4837 - val_acc: 0.7790 - val_f1score: 0.7765\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4541 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00013: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4535 - acc: 0.8106 - f1score: 0.8112 - val_loss: 0.4868 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4535 - acc: 0.8106 - f1score: 0.8112 - val_loss: 0.4868 - val_acc: 0.7897 - val_f1score: 0.7861\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4500 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00014: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4504 - acc: 0.8132 - f1score: 0.8125 - val_loss: 0.4834 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4504 - acc: 0.8132 - f1score: 0.8125 - val_loss: 0.4834 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8077 - f1score: 0.8077\n",
            "Epoch 00015: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4586 - acc: 0.8079 - f1score: 0.8082 - val_loss: 0.4821 - val_acc: 0.7833 - val_f1score: 0.7855\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4586 - acc: 0.8079 - f1score: 0.8082 - val_loss: 0.4821 - val_acc: 0.7833 - val_f1score: 0.7855\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00016: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4490 - acc: 0.8143 - f1score: 0.8140 - val_loss: 0.4854 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4490 - acc: 0.8143 - f1score: 0.8140 - val_loss: 0.4854 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4526 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00017: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4538 - acc: 0.8169 - f1score: 0.8157 - val_loss: 0.4832 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4538 - acc: 0.8169 - f1score: 0.8157 - val_loss: 0.4832 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4611 - acc: 0.8093 - f1score: 0.8093\n",
            "Epoch 00018: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4570 - acc: 0.8106 - f1score: 0.8117 - val_loss: 0.4820 - val_acc: 0.7918 - val_f1score: 0.7939\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4570 - acc: 0.8106 - f1score: 0.8117 - val_loss: 0.4820 - val_acc: 0.7918 - val_f1score: 0.7939\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4583 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00019: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4585 - acc: 0.8101 - f1score: 0.8098 - val_loss: 0.4833 - val_acc: 0.7918 - val_f1score: 0.7882\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4585 - acc: 0.8101 - f1score: 0.8098 - val_loss: 0.4833 - val_acc: 0.7918 - val_f1score: 0.7882\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4542 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00020: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4514 - acc: 0.8127 - f1score: 0.8142 - val_loss: 0.4825 - val_acc: 0.7994 - val_f1score: 0.7971\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4514 - acc: 0.8127 - f1score: 0.8142 - val_loss: 0.4825 - val_acc: 0.7994 - val_f1score: 0.7971\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4477 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00021: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4529 - acc: 0.8127 - f1score: 0.8110 - val_loss: 0.4807 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4529 - acc: 0.8127 - f1score: 0.8110 - val_loss: 0.4807 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4565 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00022: val_acc improved from 0.79936 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.22-0.49.h5\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.79936 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.22-0.49.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4547 - acc: 0.8159 - f1score: 0.8165 - val_loss: 0.4874 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4547 - acc: 0.8159 - f1score: 0.8165 - val_loss: 0.4874 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4585 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4557 - acc: 0.8127 - f1score: 0.8142 - val_loss: 0.4785 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4557 - acc: 0.8127 - f1score: 0.8142 - val_loss: 0.4785 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4561 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00024: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4544 - acc: 0.8159 - f1score: 0.8165 - val_loss: 0.4774 - val_acc: 0.7800 - val_f1score: 0.7792\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4544 - acc: 0.8159 - f1score: 0.8165 - val_loss: 0.4774 - val_acc: 0.7800 - val_f1score: 0.7792\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4559 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00025: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4550 - acc: 0.8132 - f1score: 0.8125 - val_loss: 0.4837 - val_acc: 0.7758 - val_f1score: 0.7774\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4550 - acc: 0.8132 - f1score: 0.8125 - val_loss: 0.4837 - val_acc: 0.7758 - val_f1score: 0.7774\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4630 - acc: 0.8103 - f1score: 0.8103\n",
            "Epoch 00026: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4597 - acc: 0.8116 - f1score: 0.8127 - val_loss: 0.4777 - val_acc: 0.7929 - val_f1score: 0.7949\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4597 - acc: 0.8116 - f1score: 0.8127 - val_loss: 0.4777 - val_acc: 0.7929 - val_f1score: 0.7949\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4567 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00027: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4538 - acc: 0.8153 - f1score: 0.8169 - val_loss: 0.4776 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4538 - acc: 0.8153 - f1score: 0.8169 - val_loss: 0.4776 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4490 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00028: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4477 - acc: 0.8127 - f1score: 0.8133 - val_loss: 0.4821 - val_acc: 0.7994 - val_f1score: 0.8003\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4477 - acc: 0.8127 - f1score: 0.8133 - val_loss: 0.4821 - val_acc: 0.7994 - val_f1score: 0.8003\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4577 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00029: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4557 - acc: 0.8138 - f1score: 0.8148 - val_loss: 0.4834 - val_acc: 0.7983 - val_f1score: 0.7969\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4557 - acc: 0.8138 - f1score: 0.8148 - val_loss: 0.4834 - val_acc: 0.7983 - val_f1score: 0.7969\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4469 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00030: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4495 - acc: 0.8111 - f1score: 0.8095 - val_loss: 0.4783 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4495 - acc: 0.8111 - f1score: 0.8095 - val_loss: 0.4783 - val_acc: 0.7908 - val_f1score: 0.7920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 67%|██████▋   | 64/96 [4:10:33<2:14:10, 251.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.2349 - acc: 0.6762 - f1score: 0.6762\n",
            "Epoch 00001: val_acc improved from -inf to 0.77790, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.71.h5\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.77790, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.71.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.2327 - acc: 0.6778 - f1score: 0.6791 - val_loss: 0.7143 - val_acc: 0.7779 - val_f1score: 0.7803\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.2327 - acc: 0.6778 - f1score: 0.6791 - val_loss: 0.7143 - val_acc: 0.7779 - val_f1score: 0.7803\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.7737 - acc: 0.7408 - f1score: 0.7408\n",
            "Epoch 00002: val_acc improved from 0.77790 to 0.78541, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.52.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.77790 to 0.78541, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.52.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.7691 - acc: 0.7402 - f1score: 0.7397 - val_loss: 0.5162 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.7691 - acc: 0.7402 - f1score: 0.7397 - val_loss: 0.5162 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5052 - acc: 0.7926 - f1score: 0.7926\n",
            "Epoch 00003: val_acc improved from 0.78541 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.48.h5\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.78541 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.48.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5045 - acc: 0.7926 - f1score: 0.7926 - val_loss: 0.4849 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5045 - acc: 0.7926 - f1score: 0.7926 - val_loss: 0.4849 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4479 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00004: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4493 - acc: 0.8095 - f1score: 0.8084 - val_loss: 0.4806 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.80043 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.48.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4493 - acc: 0.8095 - f1score: 0.8084 - val_loss: 0.4806 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4442 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4418 - acc: 0.8148 - f1score: 0.8159 - val_loss: 0.4786 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4418 - acc: 0.8148 - f1score: 0.8159 - val_loss: 0.4786 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4358 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4370 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4758 - val_acc: 0.7886 - val_f1score: 0.7899\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4370 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4758 - val_acc: 0.7886 - val_f1score: 0.7899\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4418 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4386 - acc: 0.8212 - f1score: 0.8221 - val_loss: 0.4754 - val_acc: 0.7918 - val_f1score: 0.7898\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4386 - acc: 0.8212 - f1score: 0.8221 - val_loss: 0.4754 - val_acc: 0.7918 - val_f1score: 0.7898\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4445 - acc: 0.8228 - f1score: 0.8241 - val_loss: 0.4750 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4445 - acc: 0.8228 - f1score: 0.8241 - val_loss: 0.4750 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4423 - acc: 0.8249 - f1score: 0.8249\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4418 - acc: 0.8259 - f1score: 0.8268 - val_loss: 0.4743 - val_acc: 0.7994 - val_f1score: 0.8012\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4418 - acc: 0.8259 - f1score: 0.8268 - val_loss: 0.4743 - val_acc: 0.7994 - val_f1score: 0.8012\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4337 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4376 - acc: 0.8228 - f1score: 0.8200 - val_loss: 0.4726 - val_acc: 0.7951 - val_f1score: 0.7946\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4376 - acc: 0.8228 - f1score: 0.8200 - val_loss: 0.4726 - val_acc: 0.7951 - val_f1score: 0.7946\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4357 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4360 - acc: 0.8212 - f1score: 0.8217 - val_loss: 0.4723 - val_acc: 0.8026 - val_f1score: 0.7978\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4360 - acc: 0.8212 - f1score: 0.8217 - val_loss: 0.4723 - val_acc: 0.8026 - val_f1score: 0.7978\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4379 - acc: 0.8265 - f1score: 0.8265\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4470 - acc: 0.8201 - f1score: 0.8146 - val_loss: 0.8372 - val_acc: 0.6910 - val_f1score: 0.6911\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4470 - acc: 0.8201 - f1score: 0.8146 - val_loss: 0.8372 - val_acc: 0.6910 - val_f1score: 0.6911\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4633 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4621 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4794 - val_acc: 0.7876 - val_f1score: 0.7873\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4621 - acc: 0.8169 - f1score: 0.8180 - val_loss: 0.4794 - val_acc: 0.7876 - val_f1score: 0.7873\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4416 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4420 - acc: 0.8228 - f1score: 0.8228 - val_loss: 0.4763 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4420 - acc: 0.8228 - f1score: 0.8228 - val_loss: 0.4763 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4363 - acc: 0.8254 - f1score: 0.8254\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4382 - acc: 0.8243 - f1score: 0.8234 - val_loss: 0.4758 - val_acc: 0.7886 - val_f1score: 0.7916\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4382 - acc: 0.8243 - f1score: 0.8234 - val_loss: 0.4758 - val_acc: 0.7886 - val_f1score: 0.7916\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4345 - acc: 0.8249 - f1score: 0.8249\n",
            "Epoch 00016: val_acc improved from 0.80365 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.16-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4367 - acc: 0.8238 - f1score: 0.8229 - val_loss: 0.4715 - val_acc: 0.8058 - val_f1score: 0.8066\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.80365 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.16-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4367 - acc: 0.8238 - f1score: 0.8229 - val_loss: 0.4715 - val_acc: 0.8058 - val_f1score: 0.8066\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4333 - acc: 0.8292 - f1score: 0.8292\n",
            "Epoch 00017: val_acc improved from 0.80579 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.17-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4375 - acc: 0.8270 - f1score: 0.8251 - val_loss: 0.4708 - val_acc: 0.8069 - val_f1score: 0.8052\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.80579 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.17-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4375 - acc: 0.8270 - f1score: 0.8251 - val_loss: 0.4708 - val_acc: 0.8069 - val_f1score: 0.8052\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4284 - acc: 0.8265 - f1score: 0.8265\n",
            "Epoch 00018: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4308 - acc: 0.8243 - f1score: 0.8225 - val_loss: 0.4735 - val_acc: 0.7951 - val_f1score: 0.7978\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4308 - acc: 0.8243 - f1score: 0.8225 - val_loss: 0.4735 - val_acc: 0.7951 - val_f1score: 0.7978\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4309 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00019: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4336 - acc: 0.8222 - f1score: 0.8213 - val_loss: 0.4714 - val_acc: 0.7961 - val_f1score: 0.7956\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4336 - acc: 0.8222 - f1score: 0.8213 - val_loss: 0.4714 - val_acc: 0.7961 - val_f1score: 0.7956\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4350 - acc: 0.8238 - f1score: 0.8238\n",
            "Epoch 00020: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4335 - acc: 0.8254 - f1score: 0.8267 - val_loss: 0.4705 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4335 - acc: 0.8254 - f1score: 0.8267 - val_loss: 0.4705 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4355 - acc: 0.8238 - f1score: 0.8238\n",
            "Epoch 00021: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4348 - acc: 0.8243 - f1score: 0.8248 - val_loss: 0.4758 - val_acc: 0.7886 - val_f1score: 0.7883\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4348 - acc: 0.8243 - f1score: 0.8248 - val_loss: 0.4758 - val_acc: 0.7886 - val_f1score: 0.7883\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4352 - acc: 0.8254 - f1score: 0.8254\n",
            "Epoch 00022: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4341 - acc: 0.8265 - f1score: 0.8273 - val_loss: 0.4714 - val_acc: 0.7961 - val_f1score: 0.7948\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4341 - acc: 0.8265 - f1score: 0.8273 - val_loss: 0.4714 - val_acc: 0.7961 - val_f1score: 0.7948\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4383 - acc: 0.8249 - f1score: 0.8249\n",
            "Epoch 00023: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4359 - acc: 0.8259 - f1score: 0.8268 - val_loss: 0.4696 - val_acc: 0.8058 - val_f1score: 0.8066\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4359 - acc: 0.8259 - f1score: 0.8268 - val_loss: 0.4696 - val_acc: 0.8058 - val_f1score: 0.8066\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4350 - acc: 0.8265 - f1score: 0.8265\n",
            "Epoch 00024: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4363 - acc: 0.8259 - f1score: 0.8254 - val_loss: 0.4696 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4363 - acc: 0.8259 - f1score: 0.8254 - val_loss: 0.4696 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4322 - acc: 0.8297 - f1score: 0.8297\n",
            "Epoch 00025: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4337 - acc: 0.8275 - f1score: 0.8256 - val_loss: 0.4717 - val_acc: 0.7918 - val_f1score: 0.7939\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4337 - acc: 0.8275 - f1score: 0.8256 - val_loss: 0.4717 - val_acc: 0.7918 - val_f1score: 0.7939\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4325 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00026: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4335 - acc: 0.8249 - f1score: 0.8239 - val_loss: 0.4708 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4335 - acc: 0.8249 - f1score: 0.8239 - val_loss: 0.4708 - val_acc: 0.8004 - val_f1score: 0.8014\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4343 - acc: 0.8254 - f1score: 0.8254\n",
            "Epoch 00027: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4318 - acc: 0.8275 - f1score: 0.8293 - val_loss: 0.4780 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4318 - acc: 0.8275 - f1score: 0.8293 - val_loss: 0.4780 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4331 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00028: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4364 - acc: 0.8233 - f1score: 0.8210 - val_loss: 0.4717 - val_acc: 0.7983 - val_f1score: 0.7961\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4364 - acc: 0.8233 - f1score: 0.8210 - val_loss: 0.4717 - val_acc: 0.7983 - val_f1score: 0.7961\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4356 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00029: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4333 - acc: 0.8217 - f1score: 0.8231 - val_loss: 0.4696 - val_acc: 0.7972 - val_f1score: 0.7958\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4333 - acc: 0.8217 - f1score: 0.8231 - val_loss: 0.4696 - val_acc: 0.7972 - val_f1score: 0.7958\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4272 - acc: 0.8244 - f1score: 0.8244\n",
            "Epoch 00030: val_acc improved from 0.80687 to 0.81009, saving model to /content/drive/My Drive/LSTM_Model/model.30-0.47.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.4314 - acc: 0.8222 - f1score: 0.8204 - val_loss: 0.4708 - val_acc: 0.8101 - val_f1score: 0.8116\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.80687 to 0.81009, saving model to /content/drive/My Drive/LSTM_Model/model.30-0.47.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.4314 - acc: 0.8222 - f1score: 0.8204 - val_loss: 0.4708 - val_acc: 0.8101 - val_f1score: 0.8116\n",
            "Epoch 31/50\n",
            "  64/1890 [>.............................] - ETA: 5s - loss: 0.3876 - acc: 0.8594 - f1score: 0.8594Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4311 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00031: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4341 - acc: 0.8238 - f1score: 0.8220 - val_loss: 0.4686 - val_acc: 0.7994 - val_f1score: 0.7979\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4341 - acc: 0.8238 - f1score: 0.8220 - val_loss: 0.4686 - val_acc: 0.7994 - val_f1score: 0.7979\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4319 - acc: 0.8244 - f1score: 0.8244\n",
            "Epoch 00032: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4329 - acc: 0.8233 - f1score: 0.8224 - val_loss: 0.4735 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4329 - acc: 0.8233 - f1score: 0.8224 - val_loss: 0.4735 - val_acc: 0.7897 - val_f1score: 0.7902\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4317 - acc: 0.8249 - f1score: 0.8249\n",
            "Epoch 00033: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4309 - acc: 0.8254 - f1score: 0.8258 - val_loss: 0.4673 - val_acc: 0.8069 - val_f1score: 0.8084\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4309 - acc: 0.8254 - f1score: 0.8258 - val_loss: 0.4673 - val_acc: 0.8069 - val_f1score: 0.8084\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4310 - acc: 0.8254 - f1score: 0.8254\n",
            "Epoch 00034: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4301 - acc: 0.8254 - f1score: 0.8254 - val_loss: 0.4688 - val_acc: 0.7972 - val_f1score: 0.7991\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4301 - acc: 0.8254 - f1score: 0.8254 - val_loss: 0.4688 - val_acc: 0.7972 - val_f1score: 0.7991\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4326 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00035: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4313 - acc: 0.8228 - f1score: 0.8232 - val_loss: 0.4707 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4313 - acc: 0.8228 - f1score: 0.8232 - val_loss: 0.4707 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4324 - acc: 0.8249 - f1score: 0.8249\n",
            "Epoch 00036: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4316 - acc: 0.8249 - f1score: 0.8248 - val_loss: 0.4689 - val_acc: 0.7983 - val_f1score: 0.8001\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.4316 - acc: 0.8249 - f1score: 0.8248 - val_loss: 0.4689 - val_acc: 0.7983 - val_f1score: 0.8001\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4369 - acc: 0.8244 - f1score: 0.8244\n",
            "Epoch 00037: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4349 - acc: 0.8259 - f1score: 0.8273 - val_loss: 0.4666 - val_acc: 0.8015 - val_f1score: 0.8049\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4349 - acc: 0.8259 - f1score: 0.8273 - val_loss: 0.4666 - val_acc: 0.8015 - val_f1score: 0.8049\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4237 - acc: 0.8297 - f1score: 0.8297\n",
            "Epoch 00038: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4280 - acc: 0.8275 - f1score: 0.8256 - val_loss: 0.4701 - val_acc: 0.7983 - val_f1score: 0.8009\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4280 - acc: 0.8275 - f1score: 0.8256 - val_loss: 0.4701 - val_acc: 0.7983 - val_f1score: 0.8009\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4287 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00039: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4299 - acc: 0.8249 - f1score: 0.8239 - val_loss: 0.4783 - val_acc: 0.7811 - val_f1score: 0.7778\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4299 - acc: 0.8249 - f1score: 0.8239 - val_loss: 0.4783 - val_acc: 0.7811 - val_f1score: 0.7778\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4366 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00040: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4346 - acc: 0.8228 - f1score: 0.8237 - val_loss: 0.4717 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4346 - acc: 0.8228 - f1score: 0.8237 - val_loss: 0.4717 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4322 - acc: 0.8276 - f1score: 0.8276\n",
            "Epoch 00041: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4342 - acc: 0.8265 - f1score: 0.8255 - val_loss: 0.4686 - val_acc: 0.7983 - val_f1score: 0.7977\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4342 - acc: 0.8265 - f1score: 0.8255 - val_loss: 0.4686 - val_acc: 0.7983 - val_f1score: 0.7977\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4334 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00042: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4321 - acc: 0.8238 - f1score: 0.8247 - val_loss: 0.4686 - val_acc: 0.7951 - val_f1score: 0.7962\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4321 - acc: 0.8238 - f1score: 0.8247 - val_loss: 0.4686 - val_acc: 0.7951 - val_f1score: 0.7962\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4275 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00043: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4281 - acc: 0.8265 - f1score: 0.8269 - val_loss: 0.4683 - val_acc: 0.8079 - val_f1score: 0.8071\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4281 - acc: 0.8265 - f1score: 0.8269 - val_loss: 0.4683 - val_acc: 0.8079 - val_f1score: 0.8071\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4378 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00044: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4371 - acc: 0.8233 - f1score: 0.8233 - val_loss: 0.4669 - val_acc: 0.8047 - val_f1score: 0.8064\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4371 - acc: 0.8233 - f1score: 0.8233 - val_loss: 0.4669 - val_acc: 0.8047 - val_f1score: 0.8064\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4319 - acc: 0.8276 - f1score: 0.8276\n",
            "Epoch 00045: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4318 - acc: 0.8275 - f1score: 0.8275 - val_loss: 0.4694 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4318 - acc: 0.8275 - f1score: 0.8275 - val_loss: 0.4694 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4302 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00046: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4306 - acc: 0.8265 - f1score: 0.8269 - val_loss: 0.4666 - val_acc: 0.7994 - val_f1score: 0.7979\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4306 - acc: 0.8265 - f1score: 0.8269 - val_loss: 0.4666 - val_acc: 0.7994 - val_f1score: 0.7979\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4318 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00047: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4307 - acc: 0.8238 - f1score: 0.8252 - val_loss: 0.4671 - val_acc: 0.7994 - val_f1score: 0.7947\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4307 - acc: 0.8238 - f1score: 0.8252 - val_loss: 0.4671 - val_acc: 0.7994 - val_f1score: 0.7947\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4302 - acc: 0.8254 - f1score: 0.8254\n",
            "Epoch 00048: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4303 - acc: 0.8254 - f1score: 0.8254 - val_loss: 0.4663 - val_acc: 0.7972 - val_f1score: 0.7999\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4303 - acc: 0.8254 - f1score: 0.8254 - val_loss: 0.4663 - val_acc: 0.7972 - val_f1score: 0.7999\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4317 - acc: 0.8254 - f1score: 0.8254\n",
            "Epoch 00049: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4286 - acc: 0.8275 - f1score: 0.8293 - val_loss: 0.4658 - val_acc: 0.7994 - val_f1score: 0.8003\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4286 - acc: 0.8275 - f1score: 0.8293 - val_loss: 0.4658 - val_acc: 0.7994 - val_f1score: 0.8003\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4299 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00050: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4284 - acc: 0.8270 - f1score: 0.8278 - val_loss: 0.4649 - val_acc: 0.8036 - val_f1score: 0.8045\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.81009\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4284 - acc: 0.8270 - f1score: 0.8278 - val_loss: 0.4649 - val_acc: 0.8036 - val_f1score: 0.8045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 68%|██████▊   | 65/96 [4:17:07<2:32:06, 294.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.1870 - acc: 0.6466 - f1score: 0.6466\n",
            "Epoch 00001: val_acc improved from -inf to 0.78433, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.57.h5\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78433, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.57.h5\n",
            "1890/1890 [==============================] - 13s 7ms/sample - loss: 2.1707 - acc: 0.6466 - f1score: 0.6466 - val_loss: 0.5743 - val_acc: 0.7843 - val_f1score: 0.7866\n",
            "1890/1890 [==============================] - 13s 7ms/sample - loss: 2.1707 - acc: 0.6466 - f1score: 0.6466 - val_loss: 0.5743 - val_acc: 0.7843 - val_f1score: 0.7866\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.0883 - acc: 0.7381 - f1score: 0.7381\n",
            "Epoch 00002: val_acc improved from 0.78433 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.70.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.0793 - acc: 0.7397 - f1score: 0.7410 - val_loss: 0.6986 - val_acc: 0.7929 - val_f1score: 0.7949\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.78433 to 0.79292, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.70.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.0793 - acc: 0.7397 - f1score: 0.7410 - val_loss: 0.6986 - val_acc: 0.7929 - val_f1score: 0.7949\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5244 - acc: 0.7904 - f1score: 0.7904\n",
            "Epoch 00003: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5259 - acc: 0.7905 - f1score: 0.7905 - val_loss: 0.4864 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5259 - acc: 0.7905 - f1score: 0.7905 - val_loss: 0.4864 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4544 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00004: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4528 - acc: 0.8111 - f1score: 0.8122 - val_loss: 0.4824 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4528 - acc: 0.8111 - f1score: 0.8122 - val_loss: 0.4824 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00005: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4605 - acc: 0.8122 - f1score: 0.8114 - val_loss: 0.4813 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4605 - acc: 0.8122 - f1score: 0.8114 - val_loss: 0.4813 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4513 - acc: 0.8184 - f1score: 0.8184\n",
            "Epoch 00006: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4503 - acc: 0.8196 - f1score: 0.8206 - val_loss: 0.4771 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4503 - acc: 0.8196 - f1score: 0.8206 - val_loss: 0.4771 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4461 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00007: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4483 - acc: 0.8185 - f1score: 0.8181 - val_loss: 0.4791 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4483 - acc: 0.8185 - f1score: 0.8181 - val_loss: 0.4791 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4564 - acc: 0.8093 - f1score: 0.8093\n",
            "Epoch 00008: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4556 - acc: 0.8101 - f1score: 0.8107 - val_loss: 0.5141 - val_acc: 0.7865 - val_f1score: 0.7870\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4556 - acc: 0.8101 - f1score: 0.8107 - val_loss: 0.5141 - val_acc: 0.7865 - val_f1score: 0.7870\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4727 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00009: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4717 - acc: 0.8101 - f1score: 0.8103 - val_loss: 0.4818 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4717 - acc: 0.8101 - f1score: 0.8103 - val_loss: 0.4818 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4573 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00010: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4560 - acc: 0.8122 - f1score: 0.8123 - val_loss: 0.4861 - val_acc: 0.7800 - val_f1score: 0.7767\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4560 - acc: 0.8122 - f1score: 0.8123 - val_loss: 0.4861 - val_acc: 0.7800 - val_f1score: 0.7767\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4504 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00011: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4517 - acc: 0.8132 - f1score: 0.8120 - val_loss: 0.4754 - val_acc: 0.7908 - val_f1score: 0.7953\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4517 - acc: 0.8132 - f1score: 0.8120 - val_loss: 0.4754 - val_acc: 0.7908 - val_f1score: 0.7953\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4539 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00012: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4516 - acc: 0.8169 - f1score: 0.8184 - val_loss: 0.4794 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4516 - acc: 0.8169 - f1score: 0.8184 - val_loss: 0.4794 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4482 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00013: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4502 - acc: 0.8190 - f1score: 0.8177 - val_loss: 0.4756 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4502 - acc: 0.8190 - f1score: 0.8177 - val_loss: 0.4756 - val_acc: 0.7843 - val_f1score: 0.7833\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4474 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00014: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4471 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4932 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4471 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4932 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4459 - acc: 0.8157 - f1score: 0.8157\n",
            "Epoch 00015: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4497 - acc: 0.8138 - f1score: 0.8121 - val_loss: 0.4789 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4497 - acc: 0.8138 - f1score: 0.8121 - val_loss: 0.4789 - val_acc: 0.7822 - val_f1score: 0.7829\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00016: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4553 - acc: 0.8169 - f1score: 0.8189 - val_loss: 0.4770 - val_acc: 0.7929 - val_f1score: 0.7909\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4553 - acc: 0.8169 - f1score: 0.8189 - val_loss: 0.4770 - val_acc: 0.7929 - val_f1score: 0.7909\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4497 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00017: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4487 - acc: 0.8190 - f1score: 0.8205 - val_loss: 0.4741 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4487 - acc: 0.8190 - f1score: 0.8205 - val_loss: 0.4741 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4430 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00018: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4437 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4730 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4437 - acc: 0.8175 - f1score: 0.8176 - val_loss: 0.4730 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4473 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00019: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4439 - acc: 0.8148 - f1score: 0.8159 - val_loss: 0.4767 - val_acc: 0.7811 - val_f1score: 0.7843\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4439 - acc: 0.8148 - f1score: 0.8159 - val_loss: 0.4767 - val_acc: 0.7811 - val_f1score: 0.7843\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4445 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00020: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4448 - acc: 0.8206 - f1score: 0.8211 - val_loss: 0.4778 - val_acc: 0.7843 - val_f1score: 0.7858\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4448 - acc: 0.8206 - f1score: 0.8211 - val_loss: 0.4778 - val_acc: 0.7843 - val_f1score: 0.7858\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00021: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4484 - acc: 0.8196 - f1score: 0.8210 - val_loss: 0.4742 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4484 - acc: 0.8196 - f1score: 0.8210 - val_loss: 0.4742 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4362 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00022: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4366 - acc: 0.8164 - f1score: 0.8161 - val_loss: 0.4794 - val_acc: 0.7811 - val_f1score: 0.7810\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.79292\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4366 - acc: 0.8164 - f1score: 0.8161 - val_loss: 0.4794 - val_acc: 0.7811 - val_f1score: 0.7810\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4448 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00023: val_acc improved from 0.79292 to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.23-0.47.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4438 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4731 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.79292 to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.23-0.47.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4438 - acc: 0.8196 - f1score: 0.8201 - val_loss: 0.4731 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4434 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00024: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4422 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4723 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.79399\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4422 - acc: 0.8190 - f1score: 0.8187 - val_loss: 0.4723 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4473 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00025: val_acc improved from 0.79399 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.25-0.47.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4450 - acc: 0.8185 - f1score: 0.8195 - val_loss: 0.4706 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.79399 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.25-0.47.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4450 - acc: 0.8185 - f1score: 0.8195 - val_loss: 0.4706 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00026: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4414 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4751 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4414 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4751 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4416 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00027: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4376 - acc: 0.8201 - f1score: 0.8220 - val_loss: 0.4755 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4376 - acc: 0.8201 - f1score: 0.8220 - val_loss: 0.4755 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4418 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00028: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4465 - acc: 0.8175 - f1score: 0.8153 - val_loss: 0.4725 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4465 - acc: 0.8175 - f1score: 0.8153 - val_loss: 0.4725 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4432 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00029: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4430 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4727 - val_acc: 0.7876 - val_f1score: 0.7873\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4430 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4727 - val_acc: 0.7876 - val_f1score: 0.7873\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4384 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00030: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4381 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4727 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4381 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4727 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4461 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00031: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4472 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4724 - val_acc: 0.7865 - val_f1score: 0.7846\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4472 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4724 - val_acc: 0.7865 - val_f1score: 0.7846\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4478 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00032: val_acc improved from 0.80150 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.32-0.47.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4483 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4684 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "\n",
            "Epoch 00032: val_acc improved from 0.80150 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.32-0.47.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4483 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4684 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4407 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4407 - acc: 0.8196 - f1score: 0.8187 - val_loss: 0.4669 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4407 - acc: 0.8196 - f1score: 0.8187 - val_loss: 0.4669 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4471 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4715 - val_acc: 0.7843 - val_f1score: 0.7825\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4471 - acc: 0.8164 - f1score: 0.8165 - val_loss: 0.4715 - val_acc: 0.7843 - val_f1score: 0.7825\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4455 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4437 - acc: 0.8206 - f1score: 0.8216 - val_loss: 0.4700 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4437 - acc: 0.8206 - f1score: 0.8216 - val_loss: 0.4700 - val_acc: 0.7918 - val_f1score: 0.7931\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4443 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4429 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4696 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4429 - acc: 0.8138 - f1score: 0.8144 - val_loss: 0.4696 - val_acc: 0.8004 - val_f1score: 0.8006\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4431 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4444 - acc: 0.8206 - f1score: 0.8207 - val_loss: 0.4670 - val_acc: 0.7961 - val_f1score: 0.7980\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4444 - acc: 0.8206 - f1score: 0.8207 - val_loss: 0.4670 - val_acc: 0.7961 - val_f1score: 0.7980\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4391 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4410 - acc: 0.8217 - f1score: 0.8203 - val_loss: 0.4696 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4410 - acc: 0.8217 - f1score: 0.8203 - val_loss: 0.4696 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4418 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4418 - acc: 0.8201 - f1score: 0.8197 - val_loss: 0.4676 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4418 - acc: 0.8201 - f1score: 0.8197 - val_loss: 0.4676 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4462 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4443 - acc: 0.8201 - f1score: 0.8211 - val_loss: 0.4703 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4443 - acc: 0.8201 - f1score: 0.8211 - val_loss: 0.4703 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4406 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4402 - acc: 0.8212 - f1score: 0.8221 - val_loss: 0.4686 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4402 - acc: 0.8212 - f1score: 0.8221 - val_loss: 0.4686 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4399 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4391 - acc: 0.8238 - f1score: 0.8247 - val_loss: 0.4679 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4391 - acc: 0.8238 - f1score: 0.8247 - val_loss: 0.4679 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4419 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4418 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4671 - val_acc: 0.7961 - val_f1score: 0.7972\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4418 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4671 - val_acc: 0.7961 - val_f1score: 0.7972\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4368 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4383 - acc: 0.8196 - f1score: 0.8178 - val_loss: 0.4687 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4383 - acc: 0.8196 - f1score: 0.8178 - val_loss: 0.4687 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4373 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4388 - acc: 0.8217 - f1score: 0.8203 - val_loss: 0.4703 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4388 - acc: 0.8217 - f1score: 0.8203 - val_loss: 0.4703 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4408 - acc: 0.8244 - f1score: 0.8244\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4439 - acc: 0.8217 - f1score: 0.8194 - val_loss: 0.4673 - val_acc: 0.7940 - val_f1score: 0.7976\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4439 - acc: 0.8217 - f1score: 0.8194 - val_loss: 0.4673 - val_acc: 0.7940 - val_f1score: 0.7976\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4418 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00047: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4411 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4689 - val_acc: 0.7940 - val_f1score: 0.7895\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4411 - acc: 0.8196 - f1score: 0.8196 - val_loss: 0.4689 - val_acc: 0.7940 - val_f1score: 0.7895\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4392 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00048: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4407 - acc: 0.8180 - f1score: 0.8167 - val_loss: 0.4667 - val_acc: 0.7994 - val_f1score: 0.8028\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4407 - acc: 0.8180 - f1score: 0.8167 - val_loss: 0.4667 - val_acc: 0.7994 - val_f1score: 0.8028\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4337 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00049: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4346 - acc: 0.8217 - f1score: 0.8217 - val_loss: 0.4670 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4346 - acc: 0.8217 - f1score: 0.8217 - val_loss: 0.4670 - val_acc: 0.7940 - val_f1score: 0.7919\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4446 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00050: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4417 - acc: 0.8185 - f1score: 0.8204 - val_loss: 0.4703 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4417 - acc: 0.8185 - f1score: 0.8204 - val_loss: 0.4703 - val_acc: 0.7854 - val_f1score: 0.7852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 69%|██████▉   | 66/96 [4:25:33<2:58:50, 357.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.9069 - acc: 0.6530 - f1score: 0.6530\n",
            "Epoch 00001: val_acc improved from -inf to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.43.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.8759 - acc: 0.6556 - f1score: 0.6577 - val_loss: 2.4310 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.79399, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.43.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.8759 - acc: 0.6556 - f1score: 0.6577 - val_loss: 2.4310 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.2390 - acc: 0.7996 - f1score: 0.7996\n",
            "Epoch 00002: val_acc improved from 0.79399 to 0.79721, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.40.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.79399 to 0.79721, saving model to /content/drive/My Drive/LSTM_Model/model.02-2.40.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.2272 - acc: 0.8000 - f1score: 0.8004 - val_loss: 2.3985 - val_acc: 0.7972 - val_f1score: 0.7942\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.2272 - acc: 0.8000 - f1score: 0.8004 - val_loss: 2.3985 - val_acc: 0.7972 - val_f1score: 0.7942\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.9413 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00003: val_acc did not improve from 0.79721\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.9649 - acc: 0.7963 - f1score: 0.7944 - val_loss: 1.8263 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.79721\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.9649 - acc: 0.7963 - f1score: 0.7944 - val_loss: 1.8263 - val_acc: 0.7897 - val_f1score: 0.7885\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.9368 - acc: 0.7328 - f1score: 0.7328\n",
            "Epoch 00004: val_acc improved from 0.79721 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.56.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.9305 - acc: 0.7349 - f1score: 0.7368 - val_loss: 0.5611 - val_acc: 0.8004 - val_f1score: 0.7973\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.79721 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.56.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.9305 - acc: 0.7349 - f1score: 0.7368 - val_loss: 0.5611 - val_acc: 0.8004 - val_f1score: 0.7973\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5714 - acc: 0.7602 - f1score: 0.7602\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5681 - acc: 0.7624 - f1score: 0.7643 - val_loss: 0.4935 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5681 - acc: 0.7624 - f1score: 0.7643 - val_loss: 0.4935 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5249 - acc: 0.7786 - f1score: 0.7786\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5232 - acc: 0.7799 - f1score: 0.7810 - val_loss: 0.4997 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5232 - acc: 0.7799 - f1score: 0.7810 - val_loss: 0.4997 - val_acc: 0.7833 - val_f1score: 0.7839\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5084 - acc: 0.7839 - f1score: 0.7839\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5061 - acc: 0.7862 - f1score: 0.7882 - val_loss: 0.4862 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5061 - acc: 0.7862 - f1score: 0.7882 - val_loss: 0.4862 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5193 - acc: 0.7726 - f1score: 0.7726\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5174 - acc: 0.7735 - f1score: 0.7743 - val_loss: 0.5288 - val_acc: 0.7951 - val_f1score: 0.7954\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5174 - acc: 0.7735 - f1score: 0.7743 - val_loss: 0.5288 - val_acc: 0.7951 - val_f1score: 0.7954\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5221 - acc: 0.7812 - f1score: 0.7812\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5230 - acc: 0.7799 - f1score: 0.7787 - val_loss: 0.5441 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5230 - acc: 0.7799 - f1score: 0.7787 - val_loss: 0.5441 - val_acc: 0.7843 - val_f1score: 0.7841\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5189 - acc: 0.7823 - f1score: 0.7823\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5173 - acc: 0.7831 - f1score: 0.7837 - val_loss: 0.4827 - val_acc: 0.7929 - val_f1score: 0.7909\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5173 - acc: 0.7831 - f1score: 0.7837 - val_loss: 0.4827 - val_acc: 0.7929 - val_f1score: 0.7909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 70%|██████▉   | 67/96 [4:26:55<2:12:54, 274.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.3368 - acc: 0.7554 - f1score: 0.7554\n",
            "Epoch 00001: val_acc improved from -inf to 0.79936, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.10.h5\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.79936, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.10.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.3423 - acc: 0.7561 - f1score: 0.7567 - val_loss: 2.1014 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.3423 - acc: 0.7561 - f1score: 0.7567 - val_loss: 2.1014 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "Epoch 2/10\n",
            "Epoch 2/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.6411 - acc: 0.7678 - f1score: 0.7678\n",
            "Epoch 00002: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.6365 - acc: 0.7688 - f1score: 0.7696 - val_loss: 1.3609 - val_acc: 0.7983 - val_f1score: 0.7961\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.6365 - acc: 0.7688 - f1score: 0.7696 - val_loss: 1.3609 - val_acc: 0.7983 - val_f1score: 0.7961\n",
            "Epoch 3/10\n",
            "Epoch 3/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.9320 - acc: 0.7398 - f1score: 0.7398\n",
            "Epoch 00003: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9239 - acc: 0.7413 - f1score: 0.7426 - val_loss: 0.5534 - val_acc: 0.7457 - val_f1score: 0.7442\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.79936\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9239 - acc: 0.7413 - f1score: 0.7426 - val_loss: 0.5534 - val_acc: 0.7457 - val_f1score: 0.7442\n",
            "Epoch 4/10\n",
            "Epoch 4/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6005 - acc: 0.7381 - f1score: 0.7381\n",
            "Epoch 00004: val_acc improved from 0.79936 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.48.h5\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.79936 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.48.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5976 - acc: 0.7386 - f1score: 0.7390 - val_loss: 0.4788 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5976 - acc: 0.7386 - f1score: 0.7390 - val_loss: 0.4788 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "Epoch 5/10\n",
            "Epoch 5/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5291 - acc: 0.7662 - f1score: 0.7662\n",
            "Epoch 00005: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.48.h5\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.05-0.48.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5289 - acc: 0.7672 - f1score: 0.7681 - val_loss: 0.4829 - val_acc: 0.8047 - val_f1score: 0.8056\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5289 - acc: 0.7672 - f1score: 0.7681 - val_loss: 0.4829 - val_acc: 0.8047 - val_f1score: 0.8056\n",
            "Epoch 6/10\n",
            "Epoch 6/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5219 - acc: 0.7780 - f1score: 0.7780\n",
            "Epoch 00006: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5213 - acc: 0.7788 - f1score: 0.7795 - val_loss: 0.4815 - val_acc: 0.8015 - val_f1score: 0.8041\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5213 - acc: 0.7788 - f1score: 0.7795 - val_loss: 0.4815 - val_acc: 0.8015 - val_f1score: 0.8041\n",
            "Epoch 7/10\n",
            "Epoch 7/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5112 - acc: 0.7834 - f1score: 0.7834\n",
            "Epoch 00007: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5073 - acc: 0.7857 - f1score: 0.7877 - val_loss: 0.4805 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5073 - acc: 0.7857 - f1score: 0.7877 - val_loss: 0.4805 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "Epoch 8/10\n",
            "Epoch 8/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5213 - acc: 0.7662 - f1score: 0.7662\n",
            "Epoch 00008: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5237 - acc: 0.7656 - f1score: 0.7651 - val_loss: 0.5101 - val_acc: 0.7833 - val_f1score: 0.7855\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5237 - acc: 0.7656 - f1score: 0.7651 - val_loss: 0.5101 - val_acc: 0.7833 - val_f1score: 0.7855\n",
            "Epoch 9/10\n",
            "Epoch 9/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5230 - acc: 0.7791 - f1score: 0.7791\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5227 - acc: 0.7783 - f1score: 0.7776 - val_loss: 0.5106 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5227 - acc: 0.7783 - f1score: 0.7776 - val_loss: 0.5106 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 10/10\n",
            "Epoch 10/10\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5219 - acc: 0.7861 - f1score: 0.7861\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5190 - acc: 0.7884 - f1score: 0.7903 - val_loss: 0.5016 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5190 - acc: 0.7884 - f1score: 0.7903 - val_loss: 0.5016 - val_acc: 0.8036 - val_f1score: 0.8037\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 71%|███████   | 68/96 [4:28:41<1:44:46, 224.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.4525 - acc: 0.7134 - f1score: 0.7134\n",
            "Epoch 00001: val_acc improved from -inf to 0.78541, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.33.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.4215 - acc: 0.7164 - f1score: 0.7190 - val_loss: 2.3330 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.78541, saving model to /content/drive/My Drive/LSTM_Model/model.01-2.33.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 2.4215 - acc: 0.7164 - f1score: 0.7190 - val_loss: 2.3330 - val_acc: 0.7854 - val_f1score: 0.7852\n",
            "Epoch 2/30\n",
            "  64/1890 [>.............................] - ETA: 5s - loss: 2.5674 - acc: 0.7344 - f1score: 0.7344Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.8576 - acc: 0.7710 - f1score: 0.7710\n",
            "Epoch 00002: val_acc did not improve from 0.78541\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.8328 - acc: 0.7735 - f1score: 0.7757 - val_loss: 1.3171 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.78541\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.8328 - acc: 0.7735 - f1score: 0.7757 - val_loss: 1.3171 - val_acc: 0.7833 - val_f1score: 0.7823\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.0175 - acc: 0.7268 - f1score: 0.7268\n",
            "Epoch 00003: val_acc improved from 0.78541 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.78.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0123 - acc: 0.7280 - f1score: 0.7291 - val_loss: 0.7826 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.78541 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.03-0.78.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0123 - acc: 0.7280 - f1score: 0.7291 - val_loss: 0.7826 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6246 - acc: 0.7543 - f1score: 0.7543\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6251 - acc: 0.7540 - f1score: 0.7537 - val_loss: 0.5495 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6251 - acc: 0.7540 - f1score: 0.7537 - val_loss: 0.5495 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5153 - acc: 0.7872 - f1score: 0.7872\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5180 - acc: 0.7857 - f1score: 0.7845 - val_loss: 0.4762 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5180 - acc: 0.7857 - f1score: 0.7845 - val_loss: 0.4762 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5004 - acc: 0.7791 - f1score: 0.7791\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4994 - acc: 0.7788 - f1score: 0.7786 - val_loss: 0.4909 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4994 - acc: 0.7788 - f1score: 0.7786 - val_loss: 0.4909 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5043 - acc: 0.7926 - f1score: 0.7926\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5016 - acc: 0.7926 - f1score: 0.7926 - val_loss: 0.4872 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5016 - acc: 0.7926 - f1score: 0.7926 - val_loss: 0.4872 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5040 - acc: 0.7769 - f1score: 0.7769\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5036 - acc: 0.7772 - f1score: 0.7775 - val_loss: 0.4723 - val_acc: 0.7940 - val_f1score: 0.7984\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5036 - acc: 0.7772 - f1score: 0.7775 - val_loss: 0.4723 - val_acc: 0.7940 - val_f1score: 0.7984\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4963 - acc: 0.7888 - f1score: 0.7888\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4929 - acc: 0.7905 - f1score: 0.7919 - val_loss: 0.4800 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4929 - acc: 0.7905 - f1score: 0.7919 - val_loss: 0.4800 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4846 - acc: 0.7936 - f1score: 0.7936\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4890 - acc: 0.7921 - f1score: 0.7907 - val_loss: 0.4815 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4890 - acc: 0.7921 - f1score: 0.7907 - val_loss: 0.4815 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4652 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4646 - acc: 0.8079 - f1score: 0.8086 - val_loss: 0.4809 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4646 - acc: 0.8079 - f1score: 0.8086 - val_loss: 0.4809 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4954 - acc: 0.7915 - f1score: 0.7915\n",
            "Epoch 00012: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.12-0.47.h5\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.80043 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.12-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4933 - acc: 0.7921 - f1score: 0.7926 - val_loss: 0.4727 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4933 - acc: 0.7921 - f1score: 0.7926 - val_loss: 0.4727 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4767 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00013: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4764 - acc: 0.7984 - f1score: 0.7983 - val_loss: 0.4723 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4764 - acc: 0.7984 - f1score: 0.7983 - val_loss: 0.4723 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4748 - acc: 0.7990 - f1score: 0.7990\n",
            "Epoch 00014: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.14-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4775 - acc: 0.7979 - f1score: 0.7969 - val_loss: 0.4710 - val_acc: 0.8026 - val_f1score: 0.8010\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.80150 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.14-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4775 - acc: 0.7979 - f1score: 0.7969 - val_loss: 0.4710 - val_acc: 0.8026 - val_f1score: 0.8010\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4812 - acc: 0.8023 - f1score: 0.8023\n",
            "Epoch 00015: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.15-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4833 - acc: 0.8011 - f1score: 0.8000 - val_loss: 0.4712 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.15-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4833 - acc: 0.8011 - f1score: 0.8000 - val_loss: 0.4712 - val_acc: 0.8036 - val_f1score: 0.8053\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4665 - acc: 0.8012 - f1score: 0.8012\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4685 - acc: 0.8016 - f1score: 0.8019 - val_loss: 0.4684 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4685 - acc: 0.8016 - f1score: 0.8019 - val_loss: 0.4684 - val_acc: 0.8036 - val_f1score: 0.8013\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4683 - acc: 0.7990 - f1score: 0.7990\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4695 - acc: 0.7979 - f1score: 0.7969 - val_loss: 0.4766 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4695 - acc: 0.7979 - f1score: 0.7969 - val_loss: 0.4766 - val_acc: 0.8036 - val_f1score: 0.8037\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4681 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4649 - acc: 0.8085 - f1score: 0.8096 - val_loss: 0.5155 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4649 - acc: 0.8085 - f1score: 0.8096 - val_loss: 0.5155 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4704 - acc: 0.8001 - f1score: 0.8001\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4707 - acc: 0.8011 - f1score: 0.8019 - val_loss: 0.4811 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4707 - acc: 0.8011 - f1score: 0.8019 - val_loss: 0.4811 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4623 - acc: 0.8050 - f1score: 0.8050\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4605 - acc: 0.8069 - f1score: 0.8085 - val_loss: 0.4707 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4605 - acc: 0.8069 - f1score: 0.8085 - val_loss: 0.4707 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00021: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.21-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4536 - acc: 0.8127 - f1score: 0.8110 - val_loss: 0.4692 - val_acc: 0.8047 - val_f1score: 0.7999\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.80365 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.21-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4536 - acc: 0.8127 - f1score: 0.8110 - val_loss: 0.4692 - val_acc: 0.8047 - val_f1score: 0.7999\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4864 - acc: 0.7915 - f1score: 0.7915\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4886 - acc: 0.7910 - f1score: 0.7906 - val_loss: 0.5053 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4886 - acc: 0.7910 - f1score: 0.7906 - val_loss: 0.5053 - val_acc: 0.7822 - val_f1score: 0.7837\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4509 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4531 - acc: 0.8111 - f1score: 0.8099 - val_loss: 0.4782 - val_acc: 0.8026 - val_f1score: 0.8010\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4531 - acc: 0.8111 - f1score: 0.8099 - val_loss: 0.4782 - val_acc: 0.8026 - val_f1score: 0.8010\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4714 - acc: 0.7963 - f1score: 0.7963\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4680 - acc: 0.7984 - f1score: 0.8002 - val_loss: 0.4705 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4680 - acc: 0.7984 - f1score: 0.8002 - val_loss: 0.4705 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4516 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4557 - acc: 0.8095 - f1score: 0.8079 - val_loss: 0.4719 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4557 - acc: 0.8095 - f1score: 0.8079 - val_loss: 0.4719 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4606 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4611 - acc: 0.8169 - f1score: 0.8166 - val_loss: 0.4675 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4611 - acc: 0.8169 - f1score: 0.8166 - val_loss: 0.4675 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4426 - acc: 0.8254 - f1score: 0.8254\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4466 - acc: 0.8233 - f1score: 0.8214 - val_loss: 0.4782 - val_acc: 0.7961 - val_f1score: 0.7940\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4466 - acc: 0.8233 - f1score: 0.8214 - val_loss: 0.4782 - val_acc: 0.7961 - val_f1score: 0.7940\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4624 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4616 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4670 - val_acc: 0.7994 - val_f1score: 0.8012\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4616 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4670 - val_acc: 0.7994 - val_f1score: 0.8012\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4515 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4549 - acc: 0.8127 - f1score: 0.8110 - val_loss: 0.4680 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4549 - acc: 0.8127 - f1score: 0.8110 - val_loss: 0.4680 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4549 - acc: 0.8164 - f1score: 0.8184 - val_loss: 0.4665 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4549 - acc: 0.8164 - f1score: 0.8184 - val_loss: 0.4665 - val_acc: 0.7908 - val_f1score: 0.7888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 72%|███████▏  | 69/96 [4:32:36<1:42:23, 227.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.1112 - acc: 0.7333 - f1score: 0.7333\n",
            "Epoch 00001: val_acc improved from -inf to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.62.h5\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.62.h5\n",
            "1890/1890 [==============================] - 13s 7ms/sample - loss: 2.0902 - acc: 0.7360 - f1score: 0.7383 - val_loss: 1.6170 - val_acc: 0.8026 - val_f1score: 0.8019\n",
            "1890/1890 [==============================] - 13s 7ms/sample - loss: 2.0902 - acc: 0.7360 - f1score: 0.7383 - val_loss: 1.6170 - val_acc: 0.8026 - val_f1score: 0.8019\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 1.2279 - acc: 0.7344 - f1score: 0.7344\n",
            "Epoch 00002: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.2259 - acc: 0.7354 - f1score: 0.7364 - val_loss: 0.5666 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.2259 - acc: 0.7354 - f1score: 0.7364 - val_loss: 0.5666 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.6170 - acc: 0.7629 - f1score: 0.7629\n",
            "Epoch 00003: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6124 - acc: 0.7640 - f1score: 0.7650 - val_loss: 0.5419 - val_acc: 0.7876 - val_f1score: 0.7865\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6124 - acc: 0.7640 - f1score: 0.7650 - val_loss: 0.5419 - val_acc: 0.7876 - val_f1score: 0.7865\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5153 - acc: 0.7936 - f1score: 0.7936\n",
            "Epoch 00004: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5137 - acc: 0.7942 - f1score: 0.7946 - val_loss: 0.5186 - val_acc: 0.7886 - val_f1score: 0.7851\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5137 - acc: 0.7942 - f1score: 0.7946 - val_loss: 0.5186 - val_acc: 0.7886 - val_f1score: 0.7851\n",
            "Epoch 5/30\n",
            "Epoch 5/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4984 - acc: 0.7931 - f1score: 0.7931\n",
            "Epoch 00005: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4960 - acc: 0.7937 - f1score: 0.7941 - val_loss: 0.4809 - val_acc: 0.7865 - val_f1score: 0.7862\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4960 - acc: 0.7937 - f1score: 0.7941 - val_loss: 0.4809 - val_acc: 0.7865 - val_f1score: 0.7862\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4758 - acc: 0.8044 - f1score: 0.8044\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4738 - acc: 0.8058 - f1score: 0.8070 - val_loss: 0.5021 - val_acc: 0.7897 - val_f1score: 0.7869\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4738 - acc: 0.8058 - f1score: 0.8070 - val_loss: 0.5021 - val_acc: 0.7897 - val_f1score: 0.7869\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4843 - acc: 0.8012 - f1score: 0.8012\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4809 - acc: 0.8032 - f1score: 0.8049 - val_loss: 0.4873 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4809 - acc: 0.8032 - f1score: 0.8049 - val_loss: 0.4873 - val_acc: 0.7811 - val_f1score: 0.7834\n",
            "Epoch 8/30\n",
            "Epoch 8/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4694 - acc: 0.8066 - f1score: 0.8066\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4696 - acc: 0.8063 - f1score: 0.8062 - val_loss: 0.5035 - val_acc: 0.7822 - val_f1score: 0.7788\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4696 - acc: 0.8063 - f1score: 0.8062 - val_loss: 0.5035 - val_acc: 0.7822 - val_f1score: 0.7788\n",
            "Epoch 9/30\n",
            "Epoch 9/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4895 - acc: 0.8006 - f1score: 0.8006\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4867 - acc: 0.8026 - f1score: 0.8044 - val_loss: 0.4822 - val_acc: 0.8026 - val_f1score: 0.8010\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4867 - acc: 0.8026 - f1score: 0.8044 - val_loss: 0.4822 - val_acc: 0.8026 - val_f1score: 0.8010\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4862 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4861 - acc: 0.7958 - f1score: 0.7962 - val_loss: 0.4885 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4861 - acc: 0.7958 - f1score: 0.7962 - val_loss: 0.4885 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "Epoch 11/30\n",
            "Epoch 11/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4804 - acc: 0.8055 - f1score: 0.8055\n",
            "Epoch 00011: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4800 - acc: 0.8058 - f1score: 0.8061 - val_loss: 0.4932 - val_acc: 0.7854 - val_f1score: 0.7884\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4800 - acc: 0.8058 - f1score: 0.8061 - val_loss: 0.4932 - val_acc: 0.7854 - val_f1score: 0.7884\n",
            "Epoch 12/30\n",
            "Epoch 12/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4759 - acc: 0.8039 - f1score: 0.8039\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4801 - acc: 0.8021 - f1score: 0.8006 - val_loss: 0.4800 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4801 - acc: 0.8021 - f1score: 0.8006 - val_loss: 0.4800 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 13/30\n",
            "Epoch 13/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4729 - acc: 0.8017 - f1score: 0.8017\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4689 - acc: 0.8037 - f1score: 0.8054 - val_loss: 0.4954 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4689 - acc: 0.8037 - f1score: 0.8054 - val_loss: 0.4954 - val_acc: 0.7929 - val_f1score: 0.7917\n",
            "Epoch 14/30\n",
            "Epoch 14/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4652 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00014: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4671 - acc: 0.8148 - f1score: 0.8145 - val_loss: 0.4739 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4671 - acc: 0.8148 - f1score: 0.8145 - val_loss: 0.4739 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 15/30\n",
            "Epoch 15/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4642 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00015: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4627 - acc: 0.8143 - f1score: 0.8149 - val_loss: 0.5166 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4627 - acc: 0.8143 - f1score: 0.8149 - val_loss: 0.5166 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4690 - acc: 0.8093 - f1score: 0.8093\n",
            "Epoch 00016: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4694 - acc: 0.8090 - f1score: 0.8088 - val_loss: 0.4734 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4694 - acc: 0.8090 - f1score: 0.8088 - val_loss: 0.4734 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 17/30\n",
            "Epoch 17/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4669 - acc: 0.8050 - f1score: 0.8050\n",
            "Epoch 00017: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4696 - acc: 0.8037 - f1score: 0.8026 - val_loss: 0.4834 - val_acc: 0.7886 - val_f1score: 0.7891\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4696 - acc: 0.8037 - f1score: 0.8026 - val_loss: 0.4834 - val_acc: 0.7886 - val_f1score: 0.7891\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4552 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00018: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4558 - acc: 0.8164 - f1score: 0.8161 - val_loss: 0.4716 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4558 - acc: 0.8164 - f1score: 0.8161 - val_loss: 0.4716 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4518 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00019: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4529 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4748 - val_acc: 0.7940 - val_f1score: 0.7911\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4529 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4748 - val_acc: 0.7940 - val_f1score: 0.7911\n",
            "Epoch 20/30\n",
            "Epoch 20/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4680 - acc: 0.8050 - f1score: 0.8050\n",
            "Epoch 00020: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.20-0.47.h5\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.80258 to 0.80365, saving model to /content/drive/My Drive/LSTM_Model/model.20-0.47.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4679 - acc: 0.8058 - f1score: 0.8066 - val_loss: 0.4698 - val_acc: 0.8036 - val_f1score: 0.8045\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4679 - acc: 0.8058 - f1score: 0.8066 - val_loss: 0.4698 - val_acc: 0.8036 - val_f1score: 0.8045\n",
            "Epoch 21/30\n",
            "Epoch 21/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4634 - acc: 0.8125 - f1score: 0.8125\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4635 - acc: 0.8122 - f1score: 0.8119 - val_loss: 0.4707 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4635 - acc: 0.8122 - f1score: 0.8119 - val_loss: 0.4707 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 22/30\n",
            "Epoch 22/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4595 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4588 - acc: 0.8122 - f1score: 0.8123 - val_loss: 0.4722 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4588 - acc: 0.8122 - f1score: 0.8123 - val_loss: 0.4722 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 23/30\n",
            "Epoch 23/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4601 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4622 - acc: 0.8138 - f1score: 0.8130 - val_loss: 0.4708 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4622 - acc: 0.8138 - f1score: 0.8130 - val_loss: 0.4708 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 24/30\n",
            "Epoch 24/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4535 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4537 - acc: 0.8116 - f1score: 0.8118 - val_loss: 0.4918 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4537 - acc: 0.8116 - f1score: 0.8118 - val_loss: 0.4918 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 25/30\n",
            "Epoch 25/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4683 - acc: 0.8033 - f1score: 0.8033\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4715 - acc: 0.8016 - f1score: 0.8001 - val_loss: 0.4687 - val_acc: 0.7940 - val_f1score: 0.7976\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4715 - acc: 0.8016 - f1score: 0.8001 - val_loss: 0.4687 - val_acc: 0.7940 - val_f1score: 0.7976\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4643 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4664 - acc: 0.8085 - f1score: 0.8073 - val_loss: 0.4711 - val_acc: 0.7961 - val_f1score: 0.7972\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4664 - acc: 0.8085 - f1score: 0.8073 - val_loss: 0.4711 - val_acc: 0.7961 - val_f1score: 0.7972\n",
            "Epoch 27/30\n",
            "Epoch 27/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4528 - acc: 0.8163 - f1score: 0.8163\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4515 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4701 - val_acc: 0.7951 - val_f1score: 0.7897\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4515 - acc: 0.8169 - f1score: 0.8175 - val_loss: 0.4701 - val_acc: 0.7951 - val_f1score: 0.7897\n",
            "Epoch 28/30\n",
            "Epoch 28/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4463 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4440 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4685 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4440 - acc: 0.8190 - f1score: 0.8200 - val_loss: 0.4685 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "Epoch 29/30\n",
            "Epoch 29/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4644 - acc: 0.8093 - f1score: 0.8093\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4609 - acc: 0.8116 - f1score: 0.8137 - val_loss: 0.4725 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4609 - acc: 0.8116 - f1score: 0.8137 - val_loss: 0.4725 - val_acc: 0.7908 - val_f1score: 0.7888\n",
            "Epoch 30/30\n",
            "Epoch 30/30\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4578 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4577 - acc: 0.8185 - f1score: 0.8177 - val_loss: 0.4874 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80365\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4577 - acc: 0.8185 - f1score: 0.8177 - val_loss: 0.4874 - val_acc: 0.7908 - val_f1score: 0.7920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 73%|███████▎  | 70/96 [4:37:42<1:48:43, 250.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           1700        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,616,662\n",
            "Trainable params: 95,662\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.9500 - acc: 0.7198 - f1score: 0.7198\n",
            "Epoch 00001: val_acc improved from -inf to 0.76502, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.56.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.9446 - acc: 0.7180 - f1score: 0.7164 - val_loss: 0.5603 - val_acc: 0.7650 - val_f1score: 0.7638\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.76502, saving model to /content/drive/My Drive/LSTM_Model/model.01-0.56.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.9446 - acc: 0.7180 - f1score: 0.7164 - val_loss: 0.5603 - val_acc: 0.7650 - val_f1score: 0.7638\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5863 - acc: 0.7570 - f1score: 0.7570\n",
            "Epoch 00002: val_acc improved from 0.76502 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.49.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.5865 - acc: 0.7561 - f1score: 0.7553 - val_loss: 0.4932 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.76502 to 0.80150, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.49.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.5865 - acc: 0.7561 - f1score: 0.7553 - val_loss: 0.4932 - val_acc: 0.8015 - val_f1score: 0.8024\n",
            "Epoch 3/50\n",
            "  64/1890 [>.............................] - ETA: 5s - loss: 0.5635 - acc: 0.7188 - f1score: 0.7187Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5311 - acc: 0.7592 - f1score: 0.7592\n",
            "Epoch 00003: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5311 - acc: 0.7608 - f1score: 0.7623 - val_loss: 0.4811 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80150\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5311 - acc: 0.7608 - f1score: 0.7623 - val_loss: 0.4811 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5048 - acc: 0.7861 - f1score: 0.7861\n",
            "Epoch 00004: val_acc improved from 0.80150 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.50.h5\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.80150 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.04-0.50.h5\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.5019 - acc: 0.7878 - f1score: 0.7893 - val_loss: 0.4953 - val_acc: 0.8047 - val_f1score: 0.8023\n",
            "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.5019 - acc: 0.7878 - f1score: 0.7893 - val_loss: 0.4953 - val_acc: 0.8047 - val_f1score: 0.8023\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4961 - acc: 0.7834 - f1score: 0.7834\n",
            "Epoch 00005: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4952 - acc: 0.7841 - f1score: 0.7847 - val_loss: 0.5418 - val_acc: 0.7800 - val_f1score: 0.7824\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4952 - acc: 0.7841 - f1score: 0.7847 - val_loss: 0.5418 - val_acc: 0.7800 - val_f1score: 0.7824\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4962 - acc: 0.7839 - f1score: 0.7839\n",
            "Epoch 00006: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4950 - acc: 0.7836 - f1score: 0.7833 - val_loss: 0.4880 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4950 - acc: 0.7836 - f1score: 0.7833 - val_loss: 0.4880 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4840 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00007: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4822 - acc: 0.7989 - f1score: 0.7998 - val_loss: 0.4827 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4822 - acc: 0.7989 - f1score: 0.7998 - val_loss: 0.4827 - val_acc: 0.7822 - val_f1score: 0.7845\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4909 - acc: 0.7883 - f1score: 0.7883\n",
            "Epoch 00008: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4878 - acc: 0.7889 - f1score: 0.7894 - val_loss: 0.4938 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4878 - acc: 0.7889 - f1score: 0.7894 - val_loss: 0.4938 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4874 - acc: 0.7985 - f1score: 0.7985\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4862 - acc: 0.7989 - f1score: 0.7993 - val_loss: 0.4843 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4862 - acc: 0.7989 - f1score: 0.7993 - val_loss: 0.4843 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4801 - acc: 0.8006 - f1score: 0.8006\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4775 - acc: 0.8011 - f1score: 0.8014 - val_loss: 0.4828 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4775 - acc: 0.8011 - f1score: 0.8014 - val_loss: 0.4828 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4680 - acc: 0.8055 - f1score: 0.8055\n",
            "Epoch 00011: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4687 - acc: 0.8048 - f1score: 0.8041 - val_loss: 0.4785 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4687 - acc: 0.8048 - f1score: 0.8041 - val_loss: 0.4785 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4767 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00012: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4766 - acc: 0.8111 - f1score: 0.8108 - val_loss: 0.4800 - val_acc: 0.8036 - val_f1score: 0.8021\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4766 - acc: 0.8111 - f1score: 0.8108 - val_loss: 0.4800 - val_acc: 0.8036 - val_f1score: 0.8021\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4803 - acc: 0.7953 - f1score: 0.7953\n",
            "Epoch 00013: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4786 - acc: 0.7968 - f1score: 0.7982 - val_loss: 0.4766 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4786 - acc: 0.7968 - f1score: 0.7982 - val_loss: 0.4766 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4599 - acc: 0.8147 - f1score: 0.8147\n",
            "Epoch 00014: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4602 - acc: 0.8159 - f1score: 0.8169 - val_loss: 0.4917 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4602 - acc: 0.8159 - f1score: 0.8169 - val_loss: 0.4917 - val_acc: 0.7897 - val_f1score: 0.7894\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4748 - acc: 0.8033 - f1score: 0.8033\n",
            "Epoch 00015: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4771 - acc: 0.8016 - f1score: 0.8001 - val_loss: 0.4746 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4771 - acc: 0.8016 - f1score: 0.8001 - val_loss: 0.4746 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4827 - acc: 0.8012 - f1score: 0.8012\n",
            "Epoch 00016: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4775 - acc: 0.8037 - f1score: 0.8059 - val_loss: 0.4753 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4775 - acc: 0.8037 - f1score: 0.8059 - val_loss: 0.4753 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4618 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00017: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4632 - acc: 0.8190 - f1score: 0.8182 - val_loss: 0.4737 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4632 - acc: 0.8190 - f1score: 0.8182 - val_loss: 0.4737 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4646 - acc: 0.8114 - f1score: 0.8114\n",
            "Epoch 00018: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4649 - acc: 0.8111 - f1score: 0.8108 - val_loss: 0.4781 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4649 - acc: 0.8111 - f1score: 0.8108 - val_loss: 0.4781 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4601 - acc: 0.8130 - f1score: 0.8130\n",
            "Epoch 00019: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4610 - acc: 0.8122 - f1score: 0.8114 - val_loss: 0.4806 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4610 - acc: 0.8122 - f1score: 0.8114 - val_loss: 0.4806 - val_acc: 0.7908 - val_f1score: 0.7896\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00020: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4642 - acc: 0.8222 - f1score: 0.8227 - val_loss: 0.4739 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4642 - acc: 0.8222 - f1score: 0.8227 - val_loss: 0.4739 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4583 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00021: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4594 - acc: 0.8143 - f1score: 0.8149 - val_loss: 0.4708 - val_acc: 0.7994 - val_f1score: 0.8003\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4594 - acc: 0.8143 - f1score: 0.8149 - val_loss: 0.4708 - val_acc: 0.7994 - val_f1score: 0.8003\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4533 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4533 - acc: 0.8217 - f1score: 0.8213 - val_loss: 0.4725 - val_acc: 0.7865 - val_f1score: 0.7870\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4533 - acc: 0.8217 - f1score: 0.8213 - val_loss: 0.4725 - val_acc: 0.7865 - val_f1score: 0.7870\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4621 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4616 - acc: 0.8175 - f1score: 0.8180 - val_loss: 0.4781 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4616 - acc: 0.8175 - f1score: 0.8180 - val_loss: 0.4781 - val_acc: 0.7940 - val_f1score: 0.7968\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4525 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4533 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4716 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4533 - acc: 0.8201 - f1score: 0.8202 - val_loss: 0.4716 - val_acc: 0.7908 - val_f1score: 0.7880\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4415 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4433 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4761 - val_acc: 0.7994 - val_f1score: 0.8020\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4433 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4761 - val_acc: 0.7994 - val_f1score: 0.8020\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4583 - acc: 0.8173 - f1score: 0.8173\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4560 - acc: 0.8180 - f1score: 0.8185 - val_loss: 0.4804 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4560 - acc: 0.8180 - f1score: 0.8185 - val_loss: 0.4804 - val_acc: 0.7908 - val_f1score: 0.7936\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4540 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4526 - acc: 0.8270 - f1score: 0.8278 - val_loss: 0.4731 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4526 - acc: 0.8270 - f1score: 0.8278 - val_loss: 0.4731 - val_acc: 0.7908 - val_f1score: 0.7928\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4434 - acc: 0.8217 - f1score: 0.8217\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4456 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4719 - val_acc: 0.8026 - val_f1score: 0.8043\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4456 - acc: 0.8212 - f1score: 0.8207 - val_loss: 0.4719 - val_acc: 0.8026 - val_f1score: 0.8043\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4444 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4423 - acc: 0.8228 - f1score: 0.8246 - val_loss: 0.4706 - val_acc: 0.7951 - val_f1score: 0.7921\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4423 - acc: 0.8228 - f1score: 0.8246 - val_loss: 0.4706 - val_acc: 0.7951 - val_f1score: 0.7921\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4492 - acc: 0.8222 - f1score: 0.8222\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4507 - acc: 0.8217 - f1score: 0.8213 - val_loss: 0.4725 - val_acc: 0.7886 - val_f1score: 0.7891\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4507 - acc: 0.8217 - f1score: 0.8213 - val_loss: 0.4725 - val_acc: 0.7886 - val_f1score: 0.7891\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.8254 - f1score: 0.8254\n",
            "Epoch 00031: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4497 - acc: 0.8243 - f1score: 0.8234 - val_loss: 0.4705 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4497 - acc: 0.8243 - f1score: 0.8234 - val_loss: 0.4705 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4407 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00032: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4408 - acc: 0.8228 - f1score: 0.8228 - val_loss: 0.4685 - val_acc: 0.7951 - val_f1score: 0.7978\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4408 - acc: 0.8228 - f1score: 0.8228 - val_loss: 0.4685 - val_acc: 0.7951 - val_f1score: 0.7978\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.8195 - f1score: 0.8195\n",
            "Epoch 00033: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4441 - acc: 0.8217 - f1score: 0.8236 - val_loss: 0.4797 - val_acc: 0.7833 - val_f1score: 0.7815\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4441 - acc: 0.8217 - f1score: 0.8236 - val_loss: 0.4797 - val_acc: 0.7833 - val_f1score: 0.7815\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4407 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00034: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4448 - acc: 0.8212 - f1score: 0.8198 - val_loss: 0.4690 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4448 - acc: 0.8212 - f1score: 0.8198 - val_loss: 0.4690 - val_acc: 0.7994 - val_f1score: 0.7987\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4457 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00035: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4468 - acc: 0.8254 - f1score: 0.8249 - val_loss: 0.4695 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4468 - acc: 0.8254 - f1score: 0.8249 - val_loss: 0.4695 - val_acc: 0.7940 - val_f1score: 0.7935\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4412 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00036: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4411 - acc: 0.8217 - f1score: 0.8222 - val_loss: 0.4758 - val_acc: 0.7822 - val_f1score: 0.7812\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4411 - acc: 0.8217 - f1score: 0.8222 - val_loss: 0.4758 - val_acc: 0.7822 - val_f1score: 0.7812\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4428 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00037: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4439 - acc: 0.8217 - f1score: 0.8203 - val_loss: 0.4689 - val_acc: 0.7994 - val_f1score: 0.8012\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4439 - acc: 0.8217 - f1score: 0.8203 - val_loss: 0.4689 - val_acc: 0.7994 - val_f1score: 0.8012\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4383 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00038: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4420 - acc: 0.8222 - f1score: 0.8218 - val_loss: 0.4806 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4420 - acc: 0.8222 - f1score: 0.8218 - val_loss: 0.4806 - val_acc: 0.7908 - val_f1score: 0.7904\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4402 - acc: 0.8249 - f1score: 0.8249\n",
            "Epoch 00039: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4430 - acc: 0.8233 - f1score: 0.8219 - val_loss: 0.4707 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4430 - acc: 0.8233 - f1score: 0.8219 - val_loss: 0.4707 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4431 - acc: 0.8265 - f1score: 0.8265\n",
            "Epoch 00040: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4430 - acc: 0.8259 - f1score: 0.8254 - val_loss: 0.4719 - val_acc: 0.7886 - val_f1score: 0.7867\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4430 - acc: 0.8259 - f1score: 0.8254 - val_loss: 0.4719 - val_acc: 0.7886 - val_f1score: 0.7867\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4412 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00041: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4402 - acc: 0.8217 - f1score: 0.8222 - val_loss: 0.4711 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4402 - acc: 0.8217 - f1score: 0.8222 - val_loss: 0.4711 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4408 - acc: 0.8238 - f1score: 0.8238\n",
            "Epoch 00042: val_acc improved from 0.80472 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.42-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4417 - acc: 0.8238 - f1score: 0.8238 - val_loss: 0.4665 - val_acc: 0.8058 - val_f1score: 0.8058\n",
            "\n",
            "Epoch 00042: val_acc improved from 0.80472 to 0.80579, saving model to /content/drive/My Drive/LSTM_Model/model.42-0.47.h5\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4417 - acc: 0.8238 - f1score: 0.8238 - val_loss: 0.4665 - val_acc: 0.8058 - val_f1score: 0.8058\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4353 - acc: 0.8227 - f1score: 0.8227\n",
            "Epoch 00043: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4380 - acc: 0.8217 - f1score: 0.8208 - val_loss: 0.4667 - val_acc: 0.7961 - val_f1score: 0.7948\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4380 - acc: 0.8217 - f1score: 0.8208 - val_loss: 0.4667 - val_acc: 0.7961 - val_f1score: 0.7948\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4353 - acc: 0.8211 - f1score: 0.8211\n",
            "Epoch 00044: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4345 - acc: 0.8212 - f1score: 0.8212 - val_loss: 0.4658 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4345 - acc: 0.8212 - f1score: 0.8212 - val_loss: 0.4658 - val_acc: 0.8004 - val_f1score: 0.7998\n",
            "Epoch 45/50\n",
            "Epoch 45/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4364 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00045: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4356 - acc: 0.8259 - f1score: 0.8259 - val_loss: 0.4685 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4356 - acc: 0.8259 - f1score: 0.8259 - val_loss: 0.4685 - val_acc: 0.7897 - val_f1score: 0.7926\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4422 - acc: 0.8260 - f1score: 0.8260\n",
            "Epoch 00046: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4400 - acc: 0.8270 - f1score: 0.8278 - val_loss: 0.4659 - val_acc: 0.8047 - val_f1score: 0.8064\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4400 - acc: 0.8270 - f1score: 0.8278 - val_loss: 0.4659 - val_acc: 0.8047 - val_f1score: 0.8064\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4381 - acc: 0.8233 - f1score: 0.8233\n",
            "Epoch 00047: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4402 - acc: 0.8217 - f1score: 0.8203 - val_loss: 0.4671 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4402 - acc: 0.8217 - f1score: 0.8203 - val_loss: 0.4671 - val_acc: 0.7918 - val_f1score: 0.7906\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4413 - acc: 0.8244 - f1score: 0.8244\n",
            "Epoch 00048: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4417 - acc: 0.8233 - f1score: 0.8224 - val_loss: 0.4668 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4417 - acc: 0.8233 - f1score: 0.8224 - val_loss: 0.4668 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4405 - acc: 0.8238 - f1score: 0.8238\n",
            "Epoch 00049: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4396 - acc: 0.8243 - f1score: 0.8248 - val_loss: 0.4671 - val_acc: 0.7972 - val_f1score: 0.7991\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4396 - acc: 0.8243 - f1score: 0.8248 - val_loss: 0.4671 - val_acc: 0.7972 - val_f1score: 0.7991\n",
            "Epoch 50/50\n",
            "Epoch 50/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4331 - acc: 0.8249 - f1score: 0.8249\n",
            "Epoch 00050: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4316 - acc: 0.8259 - f1score: 0.8268 - val_loss: 0.4701 - val_acc: 0.7886 - val_f1score: 0.7891\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.80579\n",
            "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4316 - acc: 0.8259 - f1score: 0.8268 - val_loss: 0.4701 - val_acc: 0.7886 - val_f1score: 0.7891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            " 74%|███████▍  | 71/96 [4:44:10<2:01:42, 292.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function standard_lstm at 0x7f74e15dd620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f74e15dd620>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function cudnn_lstm at 0x7f74e15dd6a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f74e15dd6a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1500, 300)    7521000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20)           60          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20)           420         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20)           2980        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 20)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            42          dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,744,150\n",
            "Trainable params: 223,150\n",
            "Non-trainable params: 7,521,000\n",
            "__________________________________________________________________________________________________\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "Train on 1890 samples, validate on 932 samples\n",
            "Epoch 1/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 2.1178 - acc: 0.6643 - f1score: 0.6643\n",
            "Epoch 00001: val_acc improved from -inf to 0.79721, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.27.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.1018 - acc: 0.6640 - f1score: 0.6638 - val_loss: 1.2743 - val_acc: 0.7972 - val_f1score: 0.7950\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.79721, saving model to /content/drive/My Drive/LSTM_Model/model.01-1.27.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 2.1018 - acc: 0.6640 - f1score: 0.6638 - val_loss: 1.2743 - val_acc: 0.7972 - val_f1score: 0.7950\n",
            "Epoch 2/50\n",
            "Epoch 2/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.9151 - acc: 0.7425 - f1score: 0.7425\n",
            "Epoch 00002: val_acc improved from 0.79721 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.50.h5\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.79721 to 0.80043, saving model to /content/drive/My Drive/LSTM_Model/model.02-0.50.h5\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9114 - acc: 0.7418 - f1score: 0.7412 - val_loss: 0.5039 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9114 - acc: 0.7418 - f1score: 0.7412 - val_loss: 0.5039 - val_acc: 0.8004 - val_f1score: 0.8022\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5255 - acc: 0.7742 - f1score: 0.7742\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5251 - acc: 0.7735 - f1score: 0.7729 - val_loss: 0.5065 - val_acc: 0.7725 - val_f1score: 0.7743\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5251 - acc: 0.7735 - f1score: 0.7729 - val_loss: 0.5065 - val_acc: 0.7725 - val_f1score: 0.7743\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5139 - acc: 0.7737 - f1score: 0.7737\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5135 - acc: 0.7746 - f1score: 0.7754 - val_loss: 0.4810 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5135 - acc: 0.7746 - f1score: 0.7754 - val_loss: 0.4810 - val_acc: 0.7908 - val_f1score: 0.7912\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4920 - acc: 0.7866 - f1score: 0.7866\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4944 - acc: 0.7862 - f1score: 0.7859 - val_loss: 0.4771 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4944 - acc: 0.7862 - f1score: 0.7859 - val_loss: 0.4771 - val_acc: 0.7929 - val_f1score: 0.7941\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4866 - acc: 0.7920 - f1score: 0.7920\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4868 - acc: 0.7921 - f1score: 0.7921 - val_loss: 0.4835 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4868 - acc: 0.7921 - f1score: 0.7921 - val_loss: 0.4835 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5068 - acc: 0.7866 - f1score: 0.7866\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5074 - acc: 0.7868 - f1score: 0.7869 - val_loss: 0.4869 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.80043\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5074 - acc: 0.7868 - f1score: 0.7869 - val_loss: 0.4869 - val_acc: 0.7811 - val_f1score: 0.7818\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4985 - acc: 0.7904 - f1score: 0.7904\n",
            "Epoch 00008: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.50.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.4967 - acc: 0.7921 - f1score: 0.7935 - val_loss: 0.5047 - val_acc: 0.8026 - val_f1score: 0.8002\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.80043 to 0.80258, saving model to /content/drive/My Drive/LSTM_Model/model.08-0.50.h5\n",
            "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.4967 - acc: 0.7921 - f1score: 0.7935 - val_loss: 0.5047 - val_acc: 0.8026 - val_f1score: 0.8002\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4963 - acc: 0.7780 - f1score: 0.7780\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4950 - acc: 0.7794 - f1score: 0.7805 - val_loss: 0.4751 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4950 - acc: 0.7794 - f1score: 0.7805 - val_loss: 0.4751 - val_acc: 0.7811 - val_f1score: 0.7802\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.5178 - acc: 0.7742 - f1score: 0.7742\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5153 - acc: 0.7746 - f1score: 0.7749 - val_loss: 0.4813 - val_acc: 0.7747 - val_f1score: 0.7788\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5153 - acc: 0.7746 - f1score: 0.7749 - val_loss: 0.4813 - val_acc: 0.7747 - val_f1score: 0.7788\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4973 - acc: 0.7888 - f1score: 0.7888\n",
            "Epoch 00011: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4964 - acc: 0.7894 - f1score: 0.7900 - val_loss: 0.4801 - val_acc: 0.8026 - val_f1score: 0.8027\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4964 - acc: 0.7894 - f1score: 0.7900 - val_loss: 0.4801 - val_acc: 0.8026 - val_f1score: 0.8027\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4820 - acc: 0.7883 - f1score: 0.7883\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4827 - acc: 0.7884 - f1score: 0.7884 - val_loss: 0.4859 - val_acc: 0.7822 - val_f1score: 0.7821\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4827 - acc: 0.7884 - f1score: 0.7884 - val_loss: 0.4859 - val_acc: 0.7822 - val_f1score: 0.7821\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4949 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4950 - acc: 0.7974 - f1score: 0.7968 - val_loss: 0.4815 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4950 - acc: 0.7974 - f1score: 0.7968 - val_loss: 0.4815 - val_acc: 0.7811 - val_f1score: 0.7826\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4786 - acc: 0.7980 - f1score: 0.7980\n",
            "Epoch 00014: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4785 - acc: 0.7984 - f1score: 0.7988 - val_loss: 0.4770 - val_acc: 0.8026 - val_f1score: 0.8002\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4785 - acc: 0.7984 - f1score: 0.7988 - val_loss: 0.4770 - val_acc: 0.8026 - val_f1score: 0.8002\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4866 - acc: 0.7899 - f1score: 0.7899\n",
            "Epoch 00015: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4858 - acc: 0.7905 - f1score: 0.7910 - val_loss: 0.4769 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4858 - acc: 0.7905 - f1score: 0.7910 - val_loss: 0.4769 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4859 - acc: 0.7969 - f1score: 0.7969\n",
            "Epoch 00016: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4876 - acc: 0.7958 - f1score: 0.7948 - val_loss: 0.4795 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4876 - acc: 0.7958 - f1score: 0.7948 - val_loss: 0.4795 - val_acc: 0.7908 - val_f1score: 0.7920\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4791 - acc: 0.7931 - f1score: 0.7931\n",
            "Epoch 00017: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4778 - acc: 0.7931 - f1score: 0.7931 - val_loss: 0.4880 - val_acc: 0.7811 - val_f1score: 0.7810\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4778 - acc: 0.7931 - f1score: 0.7931 - val_loss: 0.4880 - val_acc: 0.7811 - val_f1score: 0.7810\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4794 - acc: 0.8033 - f1score: 0.8033\n",
            "Epoch 00018: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4803 - acc: 0.8021 - f1score: 0.8011 - val_loss: 0.4742 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4803 - acc: 0.8021 - f1score: 0.8011 - val_loss: 0.4742 - val_acc: 0.7929 - val_f1score: 0.7925\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4845 - acc: 0.8033 - f1score: 0.8033\n",
            "Epoch 00019: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4856 - acc: 0.8011 - f1score: 0.7991 - val_loss: 0.4721 - val_acc: 0.7961 - val_f1score: 0.7972\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4856 - acc: 0.8011 - f1score: 0.7991 - val_loss: 0.4721 - val_acc: 0.7961 - val_f1score: 0.7972\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.8033 - f1score: 0.8033\n",
            "Epoch 00020: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4681 - acc: 0.8042 - f1score: 0.8050 - val_loss: 0.4735 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4681 - acc: 0.8042 - f1score: 0.8050 - val_loss: 0.4735 - val_acc: 0.7940 - val_f1score: 0.7951\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4777 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00021: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4777 - acc: 0.8153 - f1score: 0.8155 - val_loss: 0.4784 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80258\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4777 - acc: 0.8153 - f1score: 0.8155 - val_loss: 0.4784 - val_acc: 0.7822 - val_f1score: 0.7804\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8017 - f1score: 0.8017\n",
            "Epoch 00022: val_acc improved from 0.80258 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.22-0.48.h5\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.80258 to 0.80472, saving model to /content/drive/My Drive/LSTM_Model/model.22-0.48.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4653 - acc: 0.8011 - f1score: 0.8005 - val_loss: 0.4760 - val_acc: 0.8047 - val_f1score: 0.8023\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4653 - acc: 0.8011 - f1score: 0.8005 - val_loss: 0.4760 - val_acc: 0.8047 - val_f1score: 0.8023\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4763 - acc: 0.8098 - f1score: 0.8098\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4751 - acc: 0.8090 - f1score: 0.8083 - val_loss: 0.4722 - val_acc: 0.8015 - val_f1score: 0.8049\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4751 - acc: 0.8090 - f1score: 0.8083 - val_loss: 0.4722 - val_acc: 0.8015 - val_f1score: 0.8049\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4724 - acc: 0.8071 - f1score: 0.8071\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4716 - acc: 0.8079 - f1score: 0.8086 - val_loss: 0.4860 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4716 - acc: 0.8079 - f1score: 0.8086 - val_loss: 0.4860 - val_acc: 0.8004 - val_f1score: 0.7990\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4704 - acc: 0.8060 - f1score: 0.8060\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4708 - acc: 0.8063 - f1score: 0.8066 - val_loss: 0.4716 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4708 - acc: 0.8063 - f1score: 0.8066 - val_loss: 0.4716 - val_acc: 0.8015 - val_f1score: 0.8032\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4644 - acc: 0.8033 - f1score: 0.8033\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4651 - acc: 0.8032 - f1score: 0.8030 - val_loss: 0.4744 - val_acc: 0.7994 - val_f1score: 0.8003\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4651 - acc: 0.8032 - f1score: 0.8030 - val_loss: 0.4744 - val_acc: 0.7994 - val_f1score: 0.8003\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4672 - acc: 0.8136 - f1score: 0.8136\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4683 - acc: 0.8122 - f1score: 0.8110 - val_loss: 0.4746 - val_acc: 0.7811 - val_f1score: 0.7843\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4683 - acc: 0.8122 - f1score: 0.8110 - val_loss: 0.4746 - val_acc: 0.7811 - val_f1score: 0.7843\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4613 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4648 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4899 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4648 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.4899 - val_acc: 0.7897 - val_f1score: 0.7910\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4615 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4620 - acc: 0.8111 - f1score: 0.8113 - val_loss: 0.4708 - val_acc: 0.7865 - val_f1score: 0.7846\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4620 - acc: 0.8111 - f1score: 0.8113 - val_loss: 0.4708 - val_acc: 0.7865 - val_f1score: 0.7846\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4538 - acc: 0.8190 - f1score: 0.8190\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4518 - acc: 0.8206 - f1score: 0.8221 - val_loss: 0.4678 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4518 - acc: 0.8206 - f1score: 0.8221 - val_loss: 0.4678 - val_acc: 0.8015 - val_f1score: 0.8000\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4583 - acc: 0.8109 - f1score: 0.8109\n",
            "Epoch 00031: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4574 - acc: 0.8111 - f1score: 0.8113 - val_loss: 0.4703 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4574 - acc: 0.8111 - f1score: 0.8113 - val_loss: 0.4703 - val_acc: 0.7940 - val_f1score: 0.7927\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4495 - acc: 0.8060 - f1score: 0.8060\n",
            "Epoch 00032: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4474 - acc: 0.8079 - f1score: 0.8096 - val_loss: 0.4741 - val_acc: 0.7833 - val_f1score: 0.7815\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4474 - acc: 0.8079 - f1score: 0.8096 - val_loss: 0.4741 - val_acc: 0.7833 - val_f1score: 0.7815\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4520 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00033: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4512 - acc: 0.8169 - f1score: 0.8184 - val_loss: 0.4702 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4512 - acc: 0.8169 - f1score: 0.8184 - val_loss: 0.4702 - val_acc: 0.7994 - val_f1score: 0.7995\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.8120 - f1score: 0.8120\n",
            "Epoch 00034: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4614 - acc: 0.8111 - f1score: 0.8104 - val_loss: 0.4882 - val_acc: 0.7886 - val_f1score: 0.7899\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4614 - acc: 0.8111 - f1score: 0.8104 - val_loss: 0.4882 - val_acc: 0.7886 - val_f1score: 0.7899\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4550 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00035: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4533 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4729 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4533 - acc: 0.8180 - f1score: 0.8181 - val_loss: 0.4729 - val_acc: 0.7940 - val_f1score: 0.7943\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4574 - acc: 0.8206 - f1score: 0.8206\n",
            "Epoch 00036: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4566 - acc: 0.8212 - f1score: 0.8217 - val_loss: 0.4719 - val_acc: 0.7833 - val_f1score: 0.7815\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.80472\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4566 - acc: 0.8212 - f1score: 0.8217 - val_loss: 0.4719 - val_acc: 0.7833 - val_f1score: 0.7815\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4585 - acc: 0.8152 - f1score: 0.8152\n",
            "Epoch 00037: val_acc improved from 0.80472 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.37-0.47.h5\n",
            "\n",
            "Epoch 00037: val_acc improved from 0.80472 to 0.80687, saving model to /content/drive/My Drive/LSTM_Model/model.37-0.47.h5\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4573 - acc: 0.8159 - f1score: 0.8165 - val_loss: 0.4694 - val_acc: 0.8069 - val_f1score: 0.8020\n",
            "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4573 - acc: 0.8159 - f1score: 0.8165 - val_loss: 0.4694 - val_acc: 0.8069 - val_f1score: 0.8020\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4529 - acc: 0.8141 - f1score: 0.8141\n",
            "Epoch 00038: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4564 - acc: 0.8122 - f1score: 0.8105 - val_loss: 0.4697 - val_acc: 0.7951 - val_f1score: 0.7978\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4564 - acc: 0.8122 - f1score: 0.8105 - val_loss: 0.4697 - val_acc: 0.7951 - val_f1score: 0.7978\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4493 - acc: 0.8168 - f1score: 0.8168\n",
            "Epoch 00039: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4481 - acc: 0.8180 - f1score: 0.8190 - val_loss: 0.4694 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4481 - acc: 0.8180 - f1score: 0.8190 - val_loss: 0.4694 - val_acc: 0.8004 - val_f1score: 0.7981\n",
            "Epoch 40/50\n",
            "Epoch 40/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4504 - acc: 0.8179 - f1score: 0.8179\n",
            "Epoch 00040: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4501 - acc: 0.8164 - f1score: 0.8151 - val_loss: 0.4693 - val_acc: 0.8047 - val_f1score: 0.8056\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4501 - acc: 0.8164 - f1score: 0.8151 - val_loss: 0.4693 - val_acc: 0.8047 - val_f1score: 0.8056\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "1856/1890 [============================>.] - ETA: 0s - loss: 0.4545 - acc: 0.8200 - f1score: 0.8200\n",
            "Epoch 00041: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4557 - acc: 0.8185 - f1score: 0.8172 - val_loss: 0.4691 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.80687\n",
            "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4557 - acc: 0.8185 - f1score: 0.8172 - val_loss: 0.4691 - val_acc: 0.7940 - val_f1score: 0.7959\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "1216/1890 [==================>...........] - ETA: 2s - loss: 0.4491 - acc: 0.8158 - f1score: 0.8158Buffered data was truncated after reaching the output size limit.Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwMu_45OqkVX"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import reimport tensorflow as tf\n",
    "\n",
    "\n",
    "tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "from time import time\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, LSTM, Embedding, Reshape, Input, Concatenate\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import os, sys\n",
    "import string\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from collections import Counter\n",
    "import datetime \n",
    "import calendar \n",
    "\n",
    "from python_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RhfJVPMqrobO"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DataSets/26_5_Final-Merged-File.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "id": "AC4-bWl6WKug",
    "outputId": "e52da69c-9d64-4bc8-8670-0990f26e7f82"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>label</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A video shows a fortune teller predicting the...</td>\n",
       "      <td>Circulating on social networks a video that sh...</td>\n",
       "      <td>08-04-2020</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>https://observador.pt/factchecks/fact-check-um...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title   \\\n",
       "0   A video shows a fortune teller predicting the...   \n",
       "\n",
       "                                                text        date    country  \\\n",
       "0  Circulating on social networks a video that sh...  08-04-2020   Portugal   \n",
       "\n",
       "   label                                                URL  \n",
       "0  FALSE  https://observador.pt/factchecks/fact-check-um...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fSyTNpgUr5Ys"
   },
   "outputs": [],
   "source": [
    "#dataframe with spatial and temporal information\n",
    "df_nc = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Qiy65OlVOtwJ",
    "outputId": "f0b53aca-67a6-418e-e994-a11452eed410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n"
     ]
    }
   ],
   "source": [
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "\n",
    "cleanedDates = []\n",
    "\n",
    "colm_list = [\"title \",\"text\",\"date\",\"country\",\"label\",\"URL\"]\n",
    "x = 0\n",
    "start = 1803\n",
    "mid = 2168\n",
    "while x<2901:\n",
    "\tif x >= mid:\n",
    "\t\tstre = df['date'][x]\n",
    "\t\tsd= parser.parse(stre)\n",
    "\t\tcleanedDates.append(sd.strftime(\"%d-%m-%Y\"))\n",
    "\t\tprint(x)\n",
    "\tif x >= start and x < mid:\n",
    "\t\tstre = df['date'][x]\n",
    "\t\tfor i in stre.splitlines():\n",
    "\t\t\tif i[0].isdigit():\n",
    "\t\t\t\td = parser.parse(i)\n",
    "\t\t\t\tcleanedDates.append(d.strftime(\"%d-%m-%Y\"))\n",
    "\t\t\t\tprint(x)\n",
    "\tif x < start:\n",
    "\t\tcleanedDates.append(df['date'][x])\n",
    "\t\tprint(x)\n",
    "\tx = x + 1 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "MbnFIxANUOQP",
    "outputId": "2c1d9ca1-e33d-4bbc-dfdf-b6ab6986b4cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-->08-04-2020\n",
      "***\n",
      "1-->17-04-2020\n",
      "***\n",
      "2-->09-04-2020\n",
      "***\n",
      "3-->11-04-2020\n",
      "***\n",
      "4-->11-04-2020\n",
      "***\n",
      "5-->08-04-2020\n",
      "***\n",
      "6-->19-04-2020\n",
      "***\n",
      "7-->07-04-2020\n",
      "***\n",
      "8-->18-04-2020\n",
      "***\n",
      "9-->12-04-2020\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  print(\"{}-->{}\".format(i,cleanedDates[i]))\n",
    "  df['date'][i]\n",
    "  print('***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "fafamK3DsAw4",
    "outputId": "206f2354-1f68-4324-a2f2-e990670c3c1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>label</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A video shows a fortune teller predicting the...</td>\n",
       "      <td>Circulating on social networks a video that sh...</td>\n",
       "      <td>08-04-2020</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>https://observador.pt/factchecks/fact-check-um...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Internet sensation and the worlds cutest ba...</td>\n",
       "      <td>Internet sensation and the worlds cutest baby...</td>\n",
       "      <td>17-04-2020</td>\n",
       "      <td>India</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>https://www.newschecker.in/article/news-detail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A video has been viewed hundreds of thousands ...</td>\n",
       "      <td>A video has been viewed hundreds of thousands ...</td>\n",
       "      <td>09-04-2020</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>https://factcheck.afp.com/video-shows-us-presi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Treasury is depositing Kshs 45, 000 to the mob...</td>\n",
       "      <td>A Facebook post claiming that the National Tre...</td>\n",
       "      <td>11-04-2020</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>https://pesacheck.org/false-treasury-is-not-se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hunagrian authorities are capturing men 50 or ...</td>\n",
       "      <td>Moves on Facebook and Twitter a video showing ...</td>\n",
       "      <td>11-04-2020</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>https://www.animalpolitico.com/elsabueso/hungr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title   \\\n",
       "0   A video shows a fortune teller predicting the...   \n",
       "1  Internet sensation and the worlds cutest ba...   \n",
       "2  A video has been viewed hundreds of thousands ...   \n",
       "3  Treasury is depositing Kshs 45, 000 to the mob...   \n",
       "4  Hunagrian authorities are capturing men 50 or ...   \n",
       "\n",
       "                                                text        date     country  \\\n",
       "0  Circulating on social networks a video that sh...  08-04-2020    Portugal   \n",
       "1  Internet sensation and the worlds cutest baby...  17-04-2020       India   \n",
       "2  A video has been viewed hundreds of thousands ...  09-04-2020   Indonesia   \n",
       "3  A Facebook post claiming that the National Tre...  11-04-2020       Kenya   \n",
       "4  Moves on Facebook and Twitter a video showing ...  11-04-2020      Mexico   \n",
       "\n",
       "   label                                                URL  \n",
       "0  FALSE  https://observador.pt/factchecks/fact-check-um...  \n",
       "1  FALSE  https://www.newschecker.in/article/news-detail...  \n",
       "2  FALSE  https://factcheck.afp.com/video-shows-us-presi...  \n",
       "3  FALSE  https://pesacheck.org/false-treasury-is-not-se...  \n",
       "4  FALSE  https://www.animalpolitico.com/elsabueso/hungr...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_nc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "vBMYj5aAsDJV",
    "outputId": "cc4fa979-d1a9-4c8d-a783-5bb392f14035"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title ', 'text', 'date', 'country', 'label', 'URL'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df_nc.columns\n",
    "#needed are title, text, label, URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "t1LCHHDRsJmj",
    "outputId": "1800e08e-e212-4425-facc-ae39a8b38d5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title      2901\n",
       "text       2894\n",
       "date       2901\n",
       "country    2901\n",
       "label      2901\n",
       "URL        2901\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xn4NRbvYBy5"
   },
   "outputs": [],
   "source": [
    "def findDay(date):\n",
    "    if date == '00-01-1900':\n",
    "      return 1 \n",
    "    born = datetime.datetime.strptime(date, '%d-%m-%Y').weekday() \n",
    "    if (calendar.day_name[born]) == 'Monday':\n",
    "        return 1\n",
    "    elif (calendar.day_name[born]) == 'Tuesday':\n",
    "        return 2\n",
    "    elif (calendar.day_name[born]) == 'Wednesday':\n",
    "        return 3\n",
    "    elif (calendar.day_name[born]) == 'Thursday':\n",
    "        return 4\n",
    "    elif (calendar.day_name[born]) == 'Friday':\n",
    "        return 5\n",
    "    elif (calendar.day_name[born]) == 'Saturday':\n",
    "        return 6\n",
    "    elif (calendar.day_name[born]) == 'Sunday':\n",
    "        return 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "eoX7V8iPsQWZ",
    "outputId": "71dab9fa-f0ee-498b-f784-805db73b9b2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FALSE', 'Pants on Fire!', 'misleading', 'Explanatory',\n",
       "       'Partly false', 'Mostly False', 'PARTLY FALSE', 'MISLEADING',\n",
       "       'Misleading', 'No Evidence', 'Mainly false', 'Mostly false',\n",
       "       'No evidence', 'Partially false', 'Misleading/False',\n",
       "       'MOSTLY TRUE', 'Partly true', 'false and misleading', 'HALF TRUE',\n",
       "       'Mostly True', \"(Org. doesn't apply rating)\", 'Fake', 'Correct',\n",
       "       'Unlikely', 'Conspiracy theory', 'Partially true', 'Not true',\n",
       "       'Half True', 'MOSTLY FALSE', 'PARTLY TRUE', 'TRUE', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nc.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnaauIrdsTIF"
   },
   "outputs": [],
   "source": [
    "#converting our problem into a binary classification problem\n",
    "df_nc['label'] = df_nc['label'].replace({\n",
    "                                        'FALSE' : 'False',\n",
    "                                        'Pants on Fire!' : 'False', \n",
    "                                        'misleading': 'False',\n",
    "                                        'Partly false' : 'False',\n",
    "                                        'Mostly False' : 'False',\n",
    "                                        'PARTLY FALSE' : 'False',\n",
    "                                        'MISLEADING' : 'False',\n",
    "                                        'Misleading' : 'False',\n",
    "                                        'Mainly false' : 'False',\n",
    "                                        'Mostly false' : 'False',\n",
    "                                        'Partially false' : 'False',\n",
    "                                        'Misleading/False' : 'False',\n",
    "                                        'false and misleading' : 'False',\n",
    "                                        'Fake' : 'False',\n",
    "                                        'Unlikely' : 'False',\n",
    "                                        'Not true' : 'False',\n",
    "                                        'MOSTLY FALSE' : 'False',\n",
    "                                        'Conspiracy theory' : 'False',\n",
    "                                        'MOSTLY TRUE' : 'True',\n",
    "                                        'Partly true' : 'True',\n",
    "                                        'Mostly True' : 'True',\n",
    "                                        'Correct' : 'True',\n",
    "                                        'Half True' : 'True',\n",
    "                                        'HALF TRUE' : 'True',\n",
    "                                        'Partially true' : 'True',\n",
    "                                        'PARTLY TRUE' : 'True',\n",
    "                                        'TRUE' : 'True',\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "z4vRdyoQsXCf",
    "outputId": "57bd6b02-2137-42ac-d189-86be64add22f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False                          1635\n",
       "True                           1236\n",
       "Explanatory                    13  \n",
       "No evidence                    11  \n",
       "(Org. doesn't apply rating)    5   \n",
       "No Evidence                    1   \n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nc.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A0jKwH6Gj-R8"
   },
   "outputs": [],
   "source": [
    "#removing anything except 'True' or 'False'\n",
    "df_nc = df_nc[df_nc['label'].isin(['False', 'True'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "2pTlz0I8j-R_",
    "outputId": "e9b97ed6-b8f1-40c0-dabd-36ce71f2fca6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1635\n",
       "True     1236\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nc.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMosL1vvseRA"
   },
   "outputs": [],
   "source": [
    "#converting to a text array first\n",
    "all_text = []\n",
    "\n",
    "all_text.extend(list(df_nc.text.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Sm6dhIRsj1Y"
   },
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    \n",
    "    #removing numbers and punctuations\n",
    "    text = re.sub(r\"[^a-zA-Z]\", ' ', txt)\n",
    "    \n",
    "    #removing multiple spaces\n",
    "    text = re.sub(r\"\\s+\", ' ', text)\n",
    "    \n",
    "    #single character removal\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "    \n",
    "    #converting to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "corpus = [clean_text(str(x)) for x in all_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9P3Nb-OZsmsI"
   },
   "outputs": [],
   "source": [
    "def avg_wl(txt):\n",
    "    words = txt.split()\n",
    "    mean = sum(len(word) for word in words)/len(words)\n",
    "    \n",
    "    return mean\n",
    "\n",
    "avg_word_len = [avg_wl(sentence) for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "PROncx4DsqKE",
    "outputId": "2e8a97d2-d7fa-4950-8117-e9b913a518da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marouf/anaconda3/envs/FakeNews/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_nc['avg_word_len'] = avg_word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "colab_type": "code",
    "id": "ogyxJP71ssRi",
    "outputId": "fcc4252a-8b70-4159-a0e0-c81521dce27f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marouf/anaconda3/envs/FakeNews/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>label</th>\n",
       "      <th>URL</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>len_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A video shows a fortune teller predicting the coronavirus pandemic in December on Spanish TV.</td>\n",
       "      <td>Circulating on social networks a video that shows an excerpt from a Spanish television show, supposedly issued December 24, 2019, in which it appears a woman (who claims to be psychic) ??to make \"predictions\". In this video, the woman describes a set of events that have been interpreted as a detailed forecast of Covid-19 pandemic that has hit the world. It is, however, a fake video, at least as regards the date of issue. The video has been being disseminated on the Internet with a date and not tampered with the real.</td>\n",
       "      <td>08-04-2020</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>False</td>\n",
       "      <td>https://observador.pt/factchecks/fact-check-uma-vidente-previu-a-pandemia-da-covid-19-na-televisao-espanhola-em-dezembro/</td>\n",
       "      <td>4.795181</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           title   \\\n",
       "0   A video shows a fortune teller predicting the coronavirus pandemic in December on Spanish TV.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text  \\\n",
       "0  Circulating on social networks a video that shows an excerpt from a Spanish television show, supposedly issued December 24, 2019, in which it appears a woman (who claims to be psychic) ??to make \"predictions\". In this video, the woman describes a set of events that have been interpreted as a detailed forecast of Covid-19 pandemic that has hit the world. It is, however, a fake video, at least as regards the date of issue. The video has been being disseminated on the Internet with a date and not tampered with the real.   \n",
       "\n",
       "         date    country  label  \\\n",
       "0  08-04-2020   Portugal  False   \n",
       "\n",
       "                                                                                                                         URL  \\\n",
       "0  https://observador.pt/factchecks/fact-check-uma-vidente-previu-a-pandemia-da-covid-19-na-televisao-espanhola-em-dezembro/   \n",
       "\n",
       "   avg_word_len  len_sentences  \n",
       "0  4.795181      83             "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_sentences = [len(s.split()) for s in corpus]\n",
    "df_nc['len_sentences'] = len_sentences\n",
    "df_nc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6rX1_4fsyri"
   },
   "outputs": [],
   "source": [
    "#cleaning the URL feature to only have relevanant domain names in the data available for training\n",
    "##getting the URL into an array first\n",
    "\n",
    "all_url = []\n",
    "all_url.extend(list(df_nc.URL.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "V4cXOYO2tHYO",
    "outputId": "820932f3-4632-45ff-b6c7-1e658417c3fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://observador.pt/factchecks/fact-check-uma-vidente-previu-a-pandemia-da-covid-19-na-televisao-espanhola-em-dezembro/']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_url[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "berVY8IStJ_y"
   },
   "outputs": [],
   "source": [
    "def clean_url(url_long):    \n",
    "    domain_name = []\n",
    "    regexp = re.compile(r\"(https?:\\/\\/)?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b\")\n",
    "    url = regexp.search(url_long) \n",
    "    return url.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KXHnBlHytdhL"
   },
   "outputs": [],
   "source": [
    "cleanedList = [x for x in all_url if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJdJAdTLtgmJ"
   },
   "outputs": [],
   "source": [
    "all_url = cleanedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wqf0C9Biuexy",
    "outputId": "d12d5ee5-3e29-4f33-f5f8-c555a914fd74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2871"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dkgdE9bouiPY",
    "outputId": "7ebff76e-61f8-4964-b440-2b3975f5c3bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2871"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EFiQdPVrujoH"
   },
   "outputs": [],
   "source": [
    "domain_name_list = [clean_url(u) for u in all_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "hHcVuil9utqL",
    "outputId": "b5932ce1-682e-4797-ab72-4b03fcdbea7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://observador.pt',\n",
       " 'https://www.newschecker.in',\n",
       " 'https://factcheck.afp.com',\n",
       " 'https://pesacheck.org',\n",
       " 'https://www.animalpolitico.com']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#contains the domain names that are present in the list of urls\n",
    "domain_name_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "oB5DuSsuuwTG",
    "outputId": "5b3d4c90-89b5-4025-d368-9df455dbdcd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['https://observador.pt', 'https://www.newschecker.in', 'https://factcheck.afp.com', 'https://pesacheck.org', 'https://www.animalpolitico.com', 'https://dubawa.org', 'https://www.politifact.com', 'https://www.newtral.es', 'https://aosfatos.org', 'https://lasillavacia.com', 'https://piaui.folha.uol.com.br', 'https://correctiv.org', 'https://teyit.org', 'https://africacheck.org', 'https://leadstories.com', 'https://factuel.afp.com', 'https://maldita.es', 'https://politica.estadao.com.br', 'https://srilanka.factcrescendo.com', 'https://www.rappler.com', 'https://faktograf.hr', 'https://ici.radio-canada.ca', 'https://efectococuyo.com', 'https://www.factcheck.org', 'https://english.factcrescendo.com', 'https://ghana.dubawa.org', 'https://www.francetvinfo.fr', 'https://vistinomer.mk', 'https://analysis.leadstories.com', 'http://u.afp.com', 'https://www.15min.lt', 'https://observers.france24.com', 'http://factuel.afp.com', 'https://s.id', 'https://www.lemonde.fr', 'https://factly.in', 'https://hoax-alert.leadstories.com', 'https://www.boomlive.in', 'https://www.buzzfeed.com', 'https://pagellapolitica.it', 'https://colombiacheck.com', 'http://www.aaj.tv', 'https://www.afghanistannews.net', 'https://www.adelaidenow.com.au', 'http://www.adelaidenow.com.au', 'https://www.snopes.com'])\n",
      "dict_values([25, 60, 204, 34, 27, 24, 178, 107, 35, 24, 55, 32, 79, 19, 59, 36, 132, 47, 20, 27, 31, 28, 22, 22, 32, 13, 30, 18, 1, 26, 25, 22, 2, 28, 2, 65, 31, 19, 9, 4, 1, 118, 365, 554, 2, 177])\n"
     ]
    }
   ],
   "source": [
    "#this shows where the data is coming from and domains that contibute to fake news or not.\n",
    "\n",
    "print(Counter(domain_name_list).keys())\n",
    "print(Counter(domain_name_list).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "O1j4y4Rku2Au",
    "outputId": "4ad7764b-575f-469e-de34-5691b5ac0f22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marouf/anaconda3/envs/FakeNews/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_nc['source'] = domain_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 777
    },
    "colab_type": "code",
    "id": "U_ccGVtT6ScT",
    "outputId": "195e6364-12e3-444b-f40e-9de931da8737"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>label</th>\n",
       "      <th>URL</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>len_sentences</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A video shows a fortune teller predicting the coronavirus pandemic in December on Spanish TV.</td>\n",
       "      <td>Circulating on social networks a video that shows an excerpt from a Spanish television show, supposedly issued December 24, 2019, in which it appears a woman (who claims to be psychic) ??to make \"predictions\". In this video, the woman describes a set of events that have been interpreted as a detailed forecast of Covid-19 pandemic that has hit the world. It is, however, a fake video, at least as regards the date of issue. The video has been being disseminated on the Internet with a date and not tampered with the real.</td>\n",
       "      <td>08-04-2020</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>False</td>\n",
       "      <td>https://observador.pt/factchecks/fact-check-uma-vidente-previu-a-pandemia-da-covid-19-na-televisao-espanhola-em-dezembro/</td>\n",
       "      <td>4.795181</td>\n",
       "      <td>83</td>\n",
       "      <td>https://observador.pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           title   \\\n",
       "0   A video shows a fortune teller predicting the coronavirus pandemic in December on Spanish TV.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         text  \\\n",
       "0  Circulating on social networks a video that shows an excerpt from a Spanish television show, supposedly issued December 24, 2019, in which it appears a woman (who claims to be psychic) ??to make \"predictions\". In this video, the woman describes a set of events that have been interpreted as a detailed forecast of Covid-19 pandemic that has hit the world. It is, however, a fake video, at least as regards the date of issue. The video has been being disseminated on the Internet with a date and not tampered with the real.   \n",
       "\n",
       "         date    country  label  \\\n",
       "0  08-04-2020   Portugal  False   \n",
       "\n",
       "                                                                                                                         URL  \\\n",
       "0  https://observador.pt/factchecks/fact-check-uma-vidente-previu-a-pandemia-da-covid-19-na-televisao-espanhola-em-dezembro/   \n",
       "\n",
       "   avg_word_len  len_sentences                 source  \n",
       "0  4.795181      83             https://observador.pt  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "OnKAlviNu9Vj",
    "outputId": "cdde6204-dcd3-44f2-9fc6-7fadfbc358ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marouf/anaconda3/envs/FakeNews/lib/python3.7/site-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_nc.drop('URL', axis=1, inplace=True)\n",
    "df_nc.drop('text', axis=1, inplace=True)\n",
    "df_nc.drop('date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "K1o3zDL9XEiq",
    "outputId": "fdcbf0ee-787d-4048-89d7-23ff84f2ec5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2871\n",
      "2901\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus))\n",
    "print(len(cleanedDates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eU1JZl48XPRn"
   },
   "outputs": [],
   "source": [
    "cleanedDates = cleanedDates[:2871]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "kWZtXBRFu_9P",
    "outputId": "abcb0f82-c8b7-4fad-9aff-fcc7f6e15894"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marouf/anaconda3/envs/FakeNews/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/marouf/anaconda3/envs/FakeNews/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_nc['text'] = corpus\n",
    "df_nc['date'] = cleanedDates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "5bQhu0CZZRXo",
    "outputId": "d2816270-cebb-429d-f68f-36b4755c4a45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marouf/anaconda3/envs/FakeNews/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_nc['date'] = df_nc['date'].apply(findDay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "Xas3f35VvBui",
    "outputId": "15bfe6dc-f714-4396-953f-7f2e21de9092"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "l = ['avg_word_len', 'len_sentences']\n",
    "number_of_columns = 2\n",
    "number_of_rows = len(l)-1/number_of_columns\n",
    "plt.figure(figsize=(2*number_of_columns,6*number_of_rows))\n",
    "for i in range(0,len(l)):\n",
    "    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.boxplot(df_nc[l[i]],color='green',orient='v')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BU3Wyr8-vDqt",
    "outputId": "b538c97f-48b0-4df7-c7dc-4f962aaa2415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of articles that have a word count of more than 1500 is 1.95%\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for x in range(1500, 4000, 1000 ):\n",
    "    results = df_nc[df_nc['len_sentences'] > x]\n",
    "    sum = sum + results['title '].size\n",
    "    \n",
    "amt = (sum/df_nc['title '].size)*100\n",
    "print('Percentage of articles that have a word count of more than 1500 is {percent:.2f}%'.format(percent = amt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "K54aMHnNvJcM",
    "outputId": "82e32b47-b56a-4d8f-d8fa-dcc5d446e9b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marouf/anaconda3/envs/FakeNews/lib/python3.7/site-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4c85a050>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#articles of word count more than 1900 are thus being dropped\n",
    "result_df = df_nc[df_nc['len_sentences']>=1500]\n",
    "\n",
    "df_nc.drop(df_nc[df_nc['len_sentences'] >= 1500].index, inplace = True) \n",
    "sns.boxplot(df_nc['len_sentences'],color='green',orient='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "zYuO9U4xvMmX",
    "outputId": "f87ca23b-ed27-4955-b81c-a56e4562300b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            2822\n",
       "country          2822\n",
       "label            2822\n",
       "avg_word_len     2822\n",
       "len_sentences    2822\n",
       "source           2822\n",
       "text             2822\n",
       "date             2822\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "MYVFdi-iv3C-",
    "outputId": "1fff6221-cc67-46e0-dfa2-b3345fd18375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            2822\n",
       "country          2822\n",
       "label            2822\n",
       "avg_word_len     2822\n",
       "len_sentences    2822\n",
       "source           2822\n",
       "text             2822\n",
       "date             2822\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_CSwozTBwBkn"
   },
   "outputs": [],
   "source": [
    "X = df_nc.drop('label', axis=1)\n",
    "y = df_nc['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "QDerFdVOj-TZ",
    "outputId": "636ba5d5-d28f-4b03-fe2d-fb2f1da79aa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "2896    True \n",
       "2897    True \n",
       "2898    True \n",
       "2899    True \n",
       "2900    True \n",
       "Name: label, Length: 2822, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nc['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "eVVxXllQj-Tc",
    "outputId": "5c46831b-1e59-4e16-edb9-98b31535ca61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "2896    True \n",
       "2897    True \n",
       "2898    True \n",
       "2899    True \n",
       "2900    True \n",
       "Name: label, Length: 2822, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jSZJzdLKr00T"
   },
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZ2UzubDtCJQ"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lz8g39sktEDl"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j88VbqqKtFpS"
   },
   "outputs": [],
   "source": [
    "X1_train = list(X_train['text'])\n",
    "X1_val = list(X_val['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MzOAC-2r4LLN"
   },
   "outputs": [],
   "source": [
    "X2_train = list(X_train['country'])\n",
    "X2_val = list(X_val['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-PJJxVAqTgid"
   },
   "outputs": [],
   "source": [
    "def CreateEmbeddings(XN_train, XN_val, maxlength):\n",
    "  tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(XN_train)\n",
    "\n",
    "  X1_train = tokenizer.texts_to_sequences(XN_train)\n",
    "  X1_val = tokenizer.texts_to_sequences(XN_val)\n",
    "\n",
    "  vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "  maxlen = maxlength\n",
    "\n",
    "  X1_train = pad_sequences(X1_train, padding='post', maxlen=maxlen)\n",
    "  X1_val = pad_sequences(X1_val, padding='post', maxlen=maxlen)\n",
    "\n",
    "  #prepare embeddings by GloVe\n",
    "  embedding_index = {}\n",
    "  f = open('../glove.6B/glove.6B.300d.txt')\n",
    "  for line in f:\n",
    "      values = line.split()\n",
    "      word = values[0]\n",
    "      coefs = np.asarray(values[1:], dtype='float32')\n",
    "      embedding_index[word] = coefs\n",
    "\n",
    "  f.close()\n",
    "  print('Found %s word vectors.' % len(embedding_index))\n",
    "\n",
    "  embedding_matrix = np.zeros((vocab_size, 300))\n",
    "\n",
    "  for word, i in tokenizer.word_index.items():\n",
    "      embedding_vector = embedding_index.get(word)\n",
    "      if embedding_vector is not None:\n",
    "          #words not found in embedding index will be all-zero\n",
    "          embedding_matrix[i] = embedding_vector\n",
    "\n",
    "  return embedding_matrix, vocab_size, X1_train, X1_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "A_lsuBm-UCHw",
    "outputId": "9aec9fba-39b4-4ca4-af4f-f9120ebd9933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n",
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix, vocab_size, X1_train, X1_val = CreateEmbeddings(X1_train, X1_val, 1500)\n",
    "embedding_matrix2, vocab_size2, X2_train, X2_val = CreateEmbeddings(X2_train, X2_val, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "qA8cEMRDR_vy",
    "outputId": "8e004ea1-ed62-4cc0-ea9a-fe9b20900e90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24762\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)\n",
    "print(vocab_size2)\n",
    "maxlen = 1500\n",
    "maxlen2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGU0g5K4QTLE"
   },
   "outputs": [],
   "source": [
    "X3_train = X_train[['avg_word_len', 'len_sentences']]\n",
    "X3_val = X_val[['avg_word_len', 'len_sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sWcDs9NPHJz4"
   },
   "outputs": [],
   "source": [
    "X4_train = X_train['date']\n",
    "X4_val = X_val['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XQRMvfqgUAS2"
   },
   "outputs": [],
   "source": [
    "X3_train = np.asarray(X3_train)\n",
    "X3_val = np.asarray(X3_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ggD4nZdWeO44"
   },
   "outputs": [],
   "source": [
    "X4_train = np.asarray(X4_train)\n",
    "X4_val = np.asarray(X4_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJedq8YoQr3r",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7428600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       60000       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,574,288\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,488,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#input 1\n",
    "input_1 = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], trainable=False)(input_1)\n",
    "LSTM_Layer_1 = LSTM(32)(embedding_layer)\n",
    "  \n",
    "\n",
    "#input 2\n",
    "input_2 = Input(shape=(maxlen2,))\n",
    "embedding_layer2 = Embedding(vocab_size2, 300, weights=[embedding_matrix2], trainable=False)(input_2)\n",
    "LSTM_Layer_2 = LSTM(32)(embedding_layer2)\n",
    "  \n",
    "#input 3\n",
    "input_3 = Input(shape=(2,))\n",
    "dense_layer_1 = Dense(10, activation='relu')(input_3)\n",
    "dense_layer_2 = Dense(10, activation='relu')(dense_layer_1)\n",
    "dense_layer_3 = Dropout(0.0)(dense_layer_2)\n",
    "\n",
    "#input 4\n",
    "input_4 = Input(shape=(1,))\n",
    "dense_layer_4 = Dense(10, activation='relu')(input_4)\n",
    "dense_layer_5 = Dense(10, activation='relu')(dense_layer_4)\n",
    "dense_layer_6 = Dropout(0.0)(dense_layer_5)\n",
    "\n",
    "#concatenation\n",
    "concat_layer = Concatenate()([LSTM_Layer_1, LSTM_Layer_2, dense_layer_3, dense_layer_6])\n",
    "\n",
    "#output layer\n",
    "output = Dense(2, activation='sigmoid')(concat_layer)\n",
    "\n",
    "model = Model(inputs=[input_1, input_2, input_3, input_4], outputs=output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  out = model.fit(x=x_train,\n",
    "                      y=y_train, \n",
    "                      validation_data=[x_val, y_val],\n",
    "                      batch_size=params['batch_size'],\n",
    "                      epochs=params['epochs'],\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lXaKHc_zESkz"
   },
   "outputs": [],
   "source": [
    "p = { 'neurons' : [32, 64, 128],\n",
    "      'dense' : [10, 20, 30],\n",
    "     'activation':['relu', 'elu'],\n",
    "     'last_activation':['softmax', 'sigmoid'],\n",
    "     'dropout' : [0, 0.1, 0.3],\n",
    "     'batch_size' : [64, 128],\n",
    "     'epochs' : [10, 30, 50],\n",
    "     'optimizer':['nadam', 'adam']\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "InBWZzA9ek3e",
    "outputId": "2ed600f5-c0f0-45bf-f642-967106ae6f16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1296 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           30          input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           20          input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1500, 300)    7503300     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 5, 300)       58800       input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10)           110         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           110         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 32)           42624       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 32)           42624       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 10)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 10)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 84)           0           lstm_4[0][0]                     \n",
      "                                                                 lstm_5[0][0]                     \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            170         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5773 - acc: 0.7667 - f1score: 0.7667\n",
      "Epoch 00001: val_acc improved from -inf to 0.89378, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.42.h5\n",
      "1890/1890 [==============================] - 16s 8ms/sample - loss: 0.5744 - acc: 0.7693 - f1score: 0.7715 - val_loss: 0.4208 - val_acc: 0.8938 - val_f1score: 0.8944\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2804 - acc: 0.9235 - f1score: 0.9235\n",
      "Epoch 00002: val_acc improved from 0.89378 to 0.93348, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.20.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2770 - acc: 0.9243 - f1score: 0.9251 - val_loss: 0.1953 - val_acc: 0.9335 - val_f1score: 0.9354\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1741 - acc: 0.9450 - f1score: 0.9450\n",
      "Epoch 00003: val_acc did not improve from 0.93348\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1768 - acc: 0.9444 - f1score: 0.9439 - val_loss: 0.4374 - val_acc: 0.8423 - val_f1score: 0.8388\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1823 - acc: 0.9450 - f1score: 0.9450\n",
      "Epoch 00004: val_acc improved from 0.93348 to 0.93562, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.23.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1810 - acc: 0.9450 - f1score: 0.9449 - val_loss: 0.2272 - val_acc: 0.9356 - val_f1score: 0.9359\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00005: val_acc did not improve from 0.93562\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1455 - acc: 0.9603 - f1score: 0.9605 - val_loss: 0.3527 - val_acc: 0.8294 - val_f1score: 0.8287\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1569 - acc: 0.9580 - f1score: 0.9580\n",
      "Epoch 00006: val_acc improved from 0.93562 to 0.94528, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.16.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1614 - acc: 0.9566 - f1score: 0.9555 - val_loss: 0.1592 - val_acc: 0.9453 - val_f1score: 0.9453\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1410 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00007: val_acc improved from 0.94528 to 0.95172, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.16.h5\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1393 - acc: 0.9598 - f1score: 0.9604 - val_loss: 0.1558 - val_acc: 0.9517 - val_f1score: 0.9499\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1356 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00008: val_acc improved from 0.95172 to 0.96137, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.15.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1339 - acc: 0.9598 - f1score: 0.9604 - val_loss: 0.1485 - val_acc: 0.9614 - val_f1score: 0.9625\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9558 - f1score: 0.9558\n",
      "Epoch 00009: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1471 - acc: 0.9566 - f1score: 0.9573 - val_loss: 0.1596 - val_acc: 0.9560 - val_f1score: 0.9557\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9650 - f1score: 0.9650\n",
      "Epoch 00010: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1229 - acc: 0.9646 - f1score: 0.9642 - val_loss: 0.1887 - val_acc: 0.9431 - val_f1score: 0.9424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 1/1296 [01:28<31:51:56, 88.58s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.0264 - acc: 0.4758 - f1score: 0.4758\n",
      "Epoch 00001: val_acc improved from -inf to 0.65773, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.59.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.0218 - acc: 0.4767 - f1score: 0.4775 - val_loss: 0.5857 - val_acc: 0.6577 - val_f1score: 0.6547\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3625 - acc: 0.8664 - f1score: 0.8664\n",
      "Epoch 00002: val_acc improved from 0.65773 to 0.89914, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.27.h5\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.3604 - acc: 0.8677 - f1score: 0.8689 - val_loss: 0.2685 - val_acc: 0.8991 - val_f1score: 0.9013\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9305 - f1score: 0.9305\n",
      "Epoch 00003: val_acc improved from 0.89914 to 0.92704, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.20.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2058 - acc: 0.9307 - f1score: 0.9309 - val_loss: 0.1969 - val_acc: 0.9270 - val_f1score: 0.9243\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1656 - acc: 0.9467 - f1score: 0.9467\n",
      "Epoch 00004: val_acc improved from 0.92704 to 0.94313, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.17.h5\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1643 - acc: 0.9471 - f1score: 0.9475 - val_loss: 0.1677 - val_acc: 0.9431 - val_f1score: 0.9416\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9526 - f1score: 0.9526\n",
      "Epoch 00005: val_acc improved from 0.94313 to 0.94528, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.16.h5\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1479 - acc: 0.9524 - f1score: 0.9522 - val_loss: 0.1565 - val_acc: 0.9453 - val_f1score: 0.9453\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9607 - f1score: 0.9607\n",
      "Epoch 00006: val_acc improved from 0.94528 to 0.95708, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.15.h5\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1353 - acc: 0.9603 - f1score: 0.9600 - val_loss: 0.1487 - val_acc: 0.9571 - val_f1score: 0.9559\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00007: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1302 - acc: 0.9667 - f1score: 0.9672 - val_loss: 0.1414 - val_acc: 0.9464 - val_f1score: 0.9455\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00008: val_acc improved from 0.95708 to 0.96567, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.14.h5\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1213 - acc: 0.9640 - f1score: 0.9646 - val_loss: 0.1356 - val_acc: 0.9657 - val_f1score: 0.9650\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00009: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1167 - acc: 0.9656 - f1score: 0.9652 - val_loss: 0.1243 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00010: val_acc improved from 0.96567 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.13.h5\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1119 - acc: 0.9677 - f1score: 0.9678 - val_loss: 0.1277 - val_acc: 0.9678 - val_f1score: 0.9671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 2/1296 [02:48<30:55:02, 86.01s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 3.0127 - acc: 0.7053 - f1score: 0.7053\n",
      "Epoch 00001: val_acc improved from -inf to 0.80901, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-2.40.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 2.9997 - acc: 0.7063 - f1score: 0.7073 - val_loss: 2.3953 - val_acc: 0.8090 - val_f1score: 0.8081\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.1340 - acc: 0.8341 - f1score: 0.8341\n",
      "Epoch 00002: val_acc improved from 0.80901 to 0.83369, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-2.25.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.1282 - acc: 0.8349 - f1score: 0.8357 - val_loss: 2.2511 - val_acc: 0.8337 - val_f1score: 0.8304\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.0364 - acc: 0.8459 - f1score: 0.8459\n",
      "Epoch 00003: val_acc improved from 0.83369 to 0.83691, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-2.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.0342 - acc: 0.8460 - f1score: 0.8461 - val_loss: 2.1149 - val_acc: 0.8369 - val_f1score: 0.8368\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.4133 - acc: 0.8524 - f1score: 0.8524\n",
      "Epoch 00004: val_acc did not improve from 0.83691\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.4024 - acc: 0.8519 - f1score: 0.8514 - val_loss: 1.3768 - val_acc: 0.7833 - val_f1score: 0.7839\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7842 - acc: 0.8788 - f1score: 0.8788\n",
      "Epoch 00005: val_acc improved from 0.83691 to 0.91202, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.36.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7745 - acc: 0.8794 - f1score: 0.8799 - val_loss: 0.3628 - val_acc: 0.9120 - val_f1score: 0.9097\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2282 - acc: 0.9327 - f1score: 0.9327\n",
      "Epoch 00006: val_acc improved from 0.91202 to 0.94635, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.19.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2259 - acc: 0.9328 - f1score: 0.9329 - val_loss: 0.1867 - val_acc: 0.9464 - val_f1score: 0.9471\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1817 - acc: 0.9467 - f1score: 0.9467\n",
      "Epoch 00007: val_acc improved from 0.94635 to 0.94850, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.16.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1791 - acc: 0.9476 - f1score: 0.9484 - val_loss: 0.1603 - val_acc: 0.9485 - val_f1score: 0.9476\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9542 - f1score: 0.9542\n",
      "Epoch 00008: val_acc did not improve from 0.94850\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1545 - acc: 0.9545 - f1score: 0.9547 - val_loss: 0.1572 - val_acc: 0.9453 - val_f1score: 0.9461\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2000 - acc: 0.9375 - f1score: 0.9375\n",
      "Epoch 00009: val_acc improved from 0.94850 to 0.95064, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.19.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1966 - acc: 0.9386 - f1score: 0.9396 - val_loss: 0.1858 - val_acc: 0.9506 - val_f1score: 0.9513\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00010: val_acc did not improve from 0.95064\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1413 - acc: 0.9630 - f1score: 0.9626 - val_loss: 0.1753 - val_acc: 0.9474 - val_f1score: 0.9473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 3/1296 [04:17<31:13:46, 86.95s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.0658 - acc: 0.7053 - f1score: 0.7053\n",
      "Epoch 00001: val_acc improved from -inf to 0.67811, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-1.06.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.0429 - acc: 0.7053 - f1score: 0.7053 - val_loss: 1.0614 - val_acc: 0.6781 - val_f1score: 0.6818\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4771 - acc: 0.8394 - f1score: 0.8394\n",
      "Epoch 00002: val_acc improved from 0.67811 to 0.89592, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.28.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4740 - acc: 0.8418 - f1score: 0.8438 - val_loss: 0.2838 - val_acc: 0.8959 - val_f1score: 0.8949\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2125 - acc: 0.9256 - f1score: 0.9256\n",
      "Epoch 00003: val_acc improved from 0.89592 to 0.93455, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.21.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2113 - acc: 0.9254 - f1score: 0.9252 - val_loss: 0.2063 - val_acc: 0.9345 - val_f1score: 0.9356\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9407 - f1score: 0.9407\n",
      "Epoch 00004: val_acc improved from 0.93455 to 0.93884, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.17.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1742 - acc: 0.9413 - f1score: 0.9417 - val_loss: 0.1667 - val_acc: 0.9388 - val_f1score: 0.9398\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9515 - f1score: 0.9515\n",
      "Epoch 00005: val_acc improved from 0.93884 to 0.94421, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.17.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1512 - acc: 0.9519 - f1score: 0.9521 - val_loss: 0.1702 - val_acc: 0.9442 - val_f1score: 0.9434\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00006: val_acc improved from 0.94421 to 0.95172, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.17.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1538 - acc: 0.9603 - f1score: 0.9605 - val_loss: 0.1697 - val_acc: 0.9517 - val_f1score: 0.9515\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9574 - f1score: 0.9574\n",
      "Epoch 00007: val_acc did not improve from 0.95172\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1458 - acc: 0.9566 - f1score: 0.9559 - val_loss: 0.1727 - val_acc: 0.9496 - val_f1score: 0.9486\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1625 - acc: 0.9531 - f1score: 0.9531\n",
      "Epoch 00008: val_acc did not improve from 0.95172\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1612 - acc: 0.9534 - f1score: 0.9537 - val_loss: 0.3071 - val_acc: 0.9303 - val_f1score: 0.9299\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2089 - acc: 0.9494 - f1score: 0.9494\n",
      "Epoch 00009: val_acc did not improve from 0.95172\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2151 - acc: 0.9481 - f1score: 0.9471 - val_loss: 0.1905 - val_acc: 0.9453 - val_f1score: 0.9469\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1630 - acc: 0.9547 - f1score: 0.9547\n",
      "Epoch 00010: val_acc did not improve from 0.95172\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1622 - acc: 0.9545 - f1score: 0.9543 - val_loss: 0.1558 - val_acc: 0.9464 - val_f1score: 0.9471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 4/1296 [05:44<31:13:44, 87.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 3.5002 - acc: 0.5981 - f1score: 0.5981\n",
      "Epoch 00001: val_acc improved from -inf to 0.90665, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.27.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 3.4423 - acc: 0.6037 - f1score: 0.6085 - val_loss: 0.2731 - val_acc: 0.9067 - val_f1score: 0.9086\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2278 - acc: 0.9246 - f1score: 0.9246\n",
      "Epoch 00002: val_acc improved from 0.90665 to 0.92811, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.23.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2252 - acc: 0.9254 - f1score: 0.9261 - val_loss: 0.2306 - val_acc: 0.9281 - val_f1score: 0.9286\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1712 - acc: 0.9461 - f1score: 0.9461\n",
      "Epoch 00003: val_acc did not improve from 0.92811\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1744 - acc: 0.9455 - f1score: 0.9450 - val_loss: 0.3324 - val_acc: 0.8433 - val_f1score: 0.8431\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9450 - f1score: 0.9450\n",
      "Epoch 00004: val_acc improved from 0.92811 to 0.94742, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.16.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1669 - acc: 0.9455 - f1score: 0.9459 - val_loss: 0.1594 - val_acc: 0.9474 - val_f1score: 0.9473\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9553 - f1score: 0.9553\n",
      "Epoch 00005: val_acc improved from 0.94742 to 0.95279, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.18.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1429 - acc: 0.9550 - f1score: 0.9548 - val_loss: 0.1802 - val_acc: 0.9528 - val_f1score: 0.9525\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9537 - f1score: 0.9537\n",
      "Epoch 00006: val_acc improved from 0.95279 to 0.95386, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.18.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1374 - acc: 0.9529 - f1score: 0.9523 - val_loss: 0.1753 - val_acc: 0.9539 - val_f1score: 0.9552\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1322 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00007: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1310 - acc: 0.9593 - f1score: 0.9599 - val_loss: 0.1488 - val_acc: 0.9506 - val_f1score: 0.9513\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9537 - f1score: 0.9537\n",
      "Epoch 00008: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1334 - acc: 0.9545 - f1score: 0.9552 - val_loss: 0.1495 - val_acc: 0.9496 - val_f1score: 0.9486\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00009: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1280 - acc: 0.9630 - f1score: 0.9631 - val_loss: 0.1747 - val_acc: 0.9453 - val_f1score: 0.9453\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1322 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00010: val_acc improved from 0.95386 to 0.95494, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.15.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1311 - acc: 0.9598 - f1score: 0.9595 - val_loss: 0.1478 - val_acc: 0.9549 - val_f1score: 0.9562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 5/1296 [07:37<33:59:45, 94.80s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.2954 - acc: 0.7446 - f1score: 0.7446\n",
      "Epoch 00001: val_acc improved from -inf to 0.87876, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.41.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 1.2779 - acc: 0.7476 - f1score: 0.7502 - val_loss: 0.4070 - val_acc: 0.8788 - val_f1score: 0.8782\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2505 - acc: 0.9143 - f1score: 0.9143\n",
      "Epoch 00002: val_acc improved from 0.87876 to 0.93884, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.19.h5\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.2485 - acc: 0.9148 - f1score: 0.9152 - val_loss: 0.1884 - val_acc: 0.9388 - val_f1score: 0.9398\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1736 - acc: 0.9413 - f1score: 0.9413\n",
      "Epoch 00003: val_acc improved from 0.93884 to 0.94313, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1717 - acc: 0.9418 - f1score: 0.9422 - val_loss: 0.1730 - val_acc: 0.9431 - val_f1score: 0.9407\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9537 - f1score: 0.9537\n",
      "Epoch 00004: val_acc improved from 0.94313 to 0.95064, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.18.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1460 - acc: 0.9540 - f1score: 0.9542 - val_loss: 0.1826 - val_acc: 0.9506 - val_f1score: 0.9497\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9558 - f1score: 0.9558\n",
      "Epoch 00005: val_acc did not improve from 0.95064\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1443 - acc: 0.9545 - f1score: 0.9534 - val_loss: 0.1766 - val_acc: 0.9506 - val_f1score: 0.9513\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00006: val_acc improved from 0.95064 to 0.95708, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1371 - acc: 0.9624 - f1score: 0.9621 - val_loss: 0.1656 - val_acc: 0.9571 - val_f1score: 0.9543\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1584 - acc: 0.9569 - f1score: 0.9569\n",
      "Epoch 00007: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1564 - acc: 0.9577 - f1score: 0.9583 - val_loss: 0.1538 - val_acc: 0.9453 - val_f1score: 0.9461\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1391 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00008: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1374 - acc: 0.9603 - f1score: 0.9609 - val_loss: 0.1670 - val_acc: 0.9442 - val_f1score: 0.9434\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1536 - acc: 0.9558 - f1score: 0.9558\n",
      "Epoch 00009: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1518 - acc: 0.9561 - f1score: 0.9563 - val_loss: 0.1473 - val_acc: 0.9474 - val_f1score: 0.9481\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00010: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1293 - acc: 0.9587 - f1score: 0.9585 - val_loss: 0.2459 - val_acc: 0.9399 - val_f1score: 0.9392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 6/1296 [09:28<35:39:38, 99.52s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 4.9486 - acc: 0.5622 - f1score: 0.2782\n",
      "Epoch 00001: val_acc improved from -inf to 0.61856, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-4.31.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 4.9311 - acc: 0.5635 - f1score: 0.2852 - val_loss: 4.3112 - val_acc: 0.6186 - val_f1score: 0.4787\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 4.3827 - acc: 0.6517 - f1score: 0.5076\n",
      "Epoch 00002: val_acc improved from 0.61856 to 0.67543, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-4.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 4.3623 - acc: 0.6532 - f1score: 0.5120 - val_loss: 4.1399 - val_acc: 0.6754 - val_f1score: 0.5353\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 4.1812 - acc: 0.6805 - f1score: 0.5449\n",
      "Epoch 00003: val_acc improved from 0.67543 to 0.69957, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-3.89.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 4.1651 - acc: 0.6812 - f1score: 0.5477 - val_loss: 3.8890 - val_acc: 0.6996 - val_f1score: 0.5879\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.6254 - acc: 0.7621 - f1score: 0.6840\n",
      "Epoch 00004: val_acc improved from 0.69957 to 0.80418, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.50.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.5815 - acc: 0.7659 - f1score: 0.6936 - val_loss: 0.4962 - val_acc: 0.8042 - val_f1score: 0.8102\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9394 - f1score: 0.9396\n",
      "Epoch 00005: val_acc improved from 0.80418 to 0.93509, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.22.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2166 - acc: 0.9405 - f1score: 0.9416 - val_loss: 0.2177 - val_acc: 0.9351 - val_f1score: 0.9360\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9518 - f1score: 0.9517\n",
      "Epoch 00006: val_acc improved from 0.93509 to 0.94582, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.19.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1708 - acc: 0.9511 - f1score: 0.9502 - val_loss: 0.1900 - val_acc: 0.9458 - val_f1score: 0.9466\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9558 - f1score: 0.9557\n",
      "Epoch 00007: val_acc did not improve from 0.94582\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1544 - acc: 0.9556 - f1score: 0.9552 - val_loss: 0.1711 - val_acc: 0.9447 - val_f1score: 0.9433\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9582 - f1score: 0.9579\n",
      "Epoch 00008: val_acc improved from 0.94582 to 0.95118, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.18.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1450 - acc: 0.9574 - f1score: 0.9564 - val_loss: 0.1752 - val_acc: 0.9512 - val_f1score: 0.9513\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9547 - f1score: 0.9545\n",
      "Epoch 00009: val_acc did not improve from 0.95118\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1420 - acc: 0.9545 - f1score: 0.9541 - val_loss: 0.1745 - val_acc: 0.9512 - val_f1score: 0.9505\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9574 - f1score: 0.9572\n",
      "Epoch 00010: val_acc improved from 0.95118 to 0.95655, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.16.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1351 - acc: 0.9566 - f1score: 0.9557 - val_loss: 0.1649 - val_acc: 0.9565 - val_f1score: 0.9576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 7/1296 [10:52<33:59:13, 94.92s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.7787 - acc: 0.6253 - f1score: 0.6284\n",
      "Epoch 00001: val_acc improved from -inf to 0.78702, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-2.48.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.7622 - acc: 0.6278 - f1score: 0.6329 - val_loss: 2.4762 - val_acc: 0.7870 - val_f1score: 0.7902\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.1061 - acc: 0.8117 - f1score: 0.8133\n",
      "Epoch 00002: val_acc improved from 0.78702 to 0.81706, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-2.16.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.1176 - acc: 0.8106 - f1score: 0.8113 - val_loss: 2.1603 - val_acc: 0.8171 - val_f1score: 0.8185\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.2837 - acc: 0.7966 - f1score: 0.7892\n",
      "Epoch 00003: val_acc did not improve from 0.81706\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 1.2767 - acc: 0.7952 - f1score: 0.7876 - val_loss: 0.7436 - val_acc: 0.7758 - val_f1score: 0.7970\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4615 - acc: 0.8324 - f1score: 0.8371\n",
      "Epoch 00004: val_acc improved from 0.81706 to 0.88627, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.34.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4617 - acc: 0.8336 - f1score: 0.8391 - val_loss: 0.3395 - val_acc: 0.8863 - val_f1score: 0.8894\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2744 - acc: 0.9178 - f1score: 0.9186\n",
      "Epoch 00005: val_acc improved from 0.88627 to 0.91738, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.27.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2742 - acc: 0.9183 - f1score: 0.9193 - val_loss: 0.2668 - val_acc: 0.9174 - val_f1score: 0.9173\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2185 - acc: 0.9372 - f1score: 0.9371\n",
      "Epoch 00006: val_acc improved from 0.91738 to 0.93455, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.21.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2188 - acc: 0.9365 - f1score: 0.9357 - val_loss: 0.2113 - val_acc: 0.9345 - val_f1score: 0.9338\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1861 - acc: 0.9426 - f1score: 0.9426\n",
      "Epoch 00007: val_acc did not improve from 0.93455\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1856 - acc: 0.9426 - f1score: 0.9425 - val_loss: 0.1966 - val_acc: 0.9324 - val_f1score: 0.9328\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9421 - f1score: 0.9420\n",
      "Epoch 00008: val_acc improved from 0.93455 to 0.95064, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.17.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1690 - acc: 0.9421 - f1score: 0.9420 - val_loss: 0.1652 - val_acc: 0.9506 - val_f1score: 0.9514\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9564 - f1score: 0.9564\n",
      "Epoch 00009: val_acc did not improve from 0.95064\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1491 - acc: 0.9561 - f1score: 0.9558 - val_loss: 0.1643 - val_acc: 0.9437 - val_f1score: 0.9444\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00010: val_acc did not improve from 0.95064\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1371 - acc: 0.9587 - f1score: 0.9589 - val_loss: 0.1459 - val_acc: 0.9485 - val_f1score: 0.9492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 8/1296 [12:13<32:26:02, 90.65s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.5614 - acc: 0.6703 - f1score: 0.7000\n",
      "Epoch 00001: val_acc improved from -inf to 0.83047, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.46.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 2.5237 - acc: 0.6733 - f1score: 0.7038 - val_loss: 0.4622 - val_acc: 0.8305 - val_f1score: 0.8184\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2681 - acc: 0.9127 - f1score: 0.9108\n",
      "Epoch 00002: val_acc improved from 0.83047 to 0.93509, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.19.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.2662 - acc: 0.9132 - f1score: 0.9119 - val_loss: 0.1940 - val_acc: 0.9351 - val_f1score: 0.9369\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1718 - acc: 0.9418 - f1score: 0.9419\n",
      "Epoch 00003: val_acc improved from 0.93509 to 0.94474, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.17.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1718 - acc: 0.9413 - f1score: 0.9409 - val_loss: 0.1732 - val_acc: 0.9447 - val_f1score: 0.9448\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1698 - acc: 0.9488 - f1score: 0.9491\n",
      "Epoch 00004: val_acc did not improve from 0.94474\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1695 - acc: 0.9481 - f1score: 0.9478 - val_loss: 0.1765 - val_acc: 0.9442 - val_f1score: 0.9445\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9566 - f1score: 0.9567\n",
      "Epoch 00005: val_acc improved from 0.94474 to 0.95386, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.16.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1456 - acc: 0.9563 - f1score: 0.9562 - val_loss: 0.1563 - val_acc: 0.9539 - val_f1score: 0.9522\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9569 - f1score: 0.9570\n",
      "Epoch 00006: val_acc improved from 0.95386 to 0.95976, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.15.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1370 - acc: 0.9571 - f1score: 0.9574 - val_loss: 0.1478 - val_acc: 0.9598 - val_f1score: 0.9603\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9585 - f1score: 0.9586\n",
      "Epoch 00007: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1379 - acc: 0.9587 - f1score: 0.9590 - val_loss: 0.1500 - val_acc: 0.9474 - val_f1score: 0.9465\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00008: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1321 - acc: 0.9593 - f1score: 0.9595 - val_loss: 0.1429 - val_acc: 0.9496 - val_f1score: 0.9508\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9577 - f1score: 0.9578\n",
      "Epoch 00009: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1277 - acc: 0.9585 - f1score: 0.9592 - val_loss: 0.1399 - val_acc: 0.9549 - val_f1score: 0.9539\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9636 - f1score: 0.9636\n",
      "Epoch 00010: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1272 - acc: 0.9632 - f1score: 0.9629 - val_loss: 0.1408 - val_acc: 0.9464 - val_f1score: 0.9456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 9/1296 [13:43<32:22:09, 90.54s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 6.9432 - acc: 0.3718 - f1score: 0.4312\n",
      "Epoch 00001: val_acc improved from -inf to 0.39646, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-5.14.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 6.9251 - acc: 0.3714 - f1score: 0.4323 - val_loss: 5.1438 - val_acc: 0.3965 - val_f1score: 0.5250\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 4.1370 - acc: 0.5110 - f1score: 0.6227\n",
      "Epoch 00002: val_acc improved from 0.39646 to 0.61481, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-2.55.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 4.1212 - acc: 0.5119 - f1score: 0.6228 - val_loss: 2.5510 - val_acc: 0.6148 - val_f1score: 0.6557\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.2293 - acc: 0.6983 - f1score: 0.6761\n",
      "Epoch 00003: val_acc improved from 0.61481 to 0.88519, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.49.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.2109 - acc: 0.7026 - f1score: 0.6849 - val_loss: 0.4929 - val_acc: 0.8852 - val_f1score: 0.8828\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3661 - acc: 0.9289 - f1score: 0.9287\n",
      "Epoch 00004: val_acc improved from 0.88519 to 0.93240, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.36.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.3665 - acc: 0.9286 - f1score: 0.9282 - val_loss: 0.3615 - val_acc: 0.9324 - val_f1score: 0.9319\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2883 - acc: 0.9423 - f1score: 0.9423\n",
      "Epoch 00005: val_acc did not improve from 0.93240\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2896 - acc: 0.9423 - f1score: 0.9423 - val_loss: 0.3077 - val_acc: 0.9313 - val_f1score: 0.9315\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2250 - acc: 0.9426 - f1score: 0.9424\n",
      "Epoch 00006: val_acc improved from 0.93240 to 0.94260, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.22.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2247 - acc: 0.9426 - f1score: 0.9423 - val_loss: 0.2191 - val_acc: 0.9426 - val_f1score: 0.9432\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1741 - acc: 0.9550 - f1score: 0.9549\n",
      "Epoch 00007: val_acc improved from 0.94260 to 0.95064, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.17.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1741 - acc: 0.9550 - f1score: 0.9549 - val_loss: 0.1652 - val_acc: 0.9506 - val_f1score: 0.9502\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9596 - f1score: 0.9595\n",
      "Epoch 00008: val_acc improved from 0.95064 to 0.95172, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.16.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1477 - acc: 0.9593 - f1score: 0.9589 - val_loss: 0.1597 - val_acc: 0.9517 - val_f1score: 0.9515\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9599 - f1score: 0.9598\n",
      "Epoch 00009: val_acc improved from 0.95172 to 0.95547, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.15.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1400 - acc: 0.9606 - f1score: 0.9612 - val_loss: 0.1455 - val_acc: 0.9555 - val_f1score: 0.9552\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9588 - f1score: 0.9588\n",
      "Epoch 00010: val_acc improved from 0.95547 to 0.95601, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.16.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1363 - acc: 0.9590 - f1score: 0.9592 - val_loss: 0.1619 - val_acc: 0.9560 - val_f1score: 0.9557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 10/1296 [15:11<32:03:54, 89.76s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 4.0552 - acc: 0.6277 - f1score: 0.4317\n",
      "Epoch 00001: val_acc improved from -inf to 0.84496, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-1.12.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 4.0045 - acc: 0.6323 - f1score: 0.4463 - val_loss: 1.1228 - val_acc: 0.8450 - val_f1score: 0.8421\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5309 - acc: 0.8906 - f1score: 0.8914\n",
      "Epoch 00002: val_acc improved from 0.84496 to 0.90933, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.31.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5245 - acc: 0.8913 - f1score: 0.8925 - val_loss: 0.3063 - val_acc: 0.9093 - val_f1score: 0.9086\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2149 - acc: 0.9386 - f1score: 0.9385\n",
      "Epoch 00003: val_acc improved from 0.90933 to 0.92436, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.22.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2183 - acc: 0.9376 - f1score: 0.9366 - val_loss: 0.2178 - val_acc: 0.9244 - val_f1score: 0.9240\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1784 - acc: 0.9467 - f1score: 0.9465\n",
      "Epoch 00004: val_acc improved from 0.92436 to 0.93240, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.20.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1797 - acc: 0.9460 - f1score: 0.9454 - val_loss: 0.2004 - val_acc: 0.9324 - val_f1score: 0.9332\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9475 - f1score: 0.9473\n",
      "Epoch 00005: val_acc improved from 0.93240 to 0.93884, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1712 - acc: 0.9468 - f1score: 0.9461 - val_loss: 0.1730 - val_acc: 0.9388 - val_f1score: 0.9397\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9504 - f1score: 0.9503\n",
      "Epoch 00006: val_acc improved from 0.93884 to 0.94421, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.19.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1471 - acc: 0.9505 - f1score: 0.9505 - val_loss: 0.1907 - val_acc: 0.9442 - val_f1score: 0.9434\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9561 - f1score: 0.9559\n",
      "Epoch 00007: val_acc improved from 0.94421 to 0.94903, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.15.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1460 - acc: 0.9553 - f1score: 0.9545 - val_loss: 0.1482 - val_acc: 0.9490 - val_f1score: 0.9466\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9545 - f1score: 0.9544\n",
      "Epoch 00008: val_acc improved from 0.94903 to 0.95440, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.14.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1339 - acc: 0.9542 - f1score: 0.9539 - val_loss: 0.1437 - val_acc: 0.9544 - val_f1score: 0.9549\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9582 - f1score: 0.9581\n",
      "Epoch 00009: val_acc did not improve from 0.95440\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1305 - acc: 0.9585 - f1score: 0.9585 - val_loss: 0.1413 - val_acc: 0.9512 - val_f1score: 0.9517\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9607 - f1score: 0.9606\n",
      "Epoch 00010: val_acc did not improve from 0.95440\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1263 - acc: 0.9608 - f1score: 0.9610 - val_loss: 0.1707 - val_acc: 0.9453 - val_f1score: 0.9461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 11/1296 [17:09<35:01:41, 98.13s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.6689 - acc: 0.8077 - f1score: 0.7999\n",
      "Epoch 00001: val_acc improved from -inf to 0.89914, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.29.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.6616 - acc: 0.8101 - f1score: 0.8046 - val_loss: 0.2866 - val_acc: 0.8991 - val_f1score: 0.9022\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2235 - acc: 0.9262 - f1score: 0.9262\n",
      "Epoch 00002: val_acc improved from 0.89914 to 0.94206, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.19.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2201 - acc: 0.9275 - f1score: 0.9286 - val_loss: 0.1918 - val_acc: 0.9421 - val_f1score: 0.9437\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1731 - acc: 0.9477 - f1score: 0.9477\n",
      "Epoch 00003: val_acc did not improve from 0.94206\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1733 - acc: 0.9474 - f1score: 0.9470 - val_loss: 0.1686 - val_acc: 0.9378 - val_f1score: 0.9388\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1575 - acc: 0.9547 - f1score: 0.9547\n",
      "Epoch 00004: val_acc improved from 0.94206 to 0.95279, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1551 - acc: 0.9556 - f1score: 0.9562 - val_loss: 0.1699 - val_acc: 0.9528 - val_f1score: 0.9533\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1399 - acc: 0.9561 - f1score: 0.9561\n",
      "Epoch 00005: val_acc did not improve from 0.95279\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1402 - acc: 0.9558 - f1score: 0.9556 - val_loss: 0.1498 - val_acc: 0.9464 - val_f1score: 0.9463\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9607 - f1score: 0.9607\n",
      "Epoch 00006: val_acc improved from 0.95279 to 0.95923, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.16.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1483 - acc: 0.9603 - f1score: 0.9600 - val_loss: 0.1610 - val_acc: 0.9592 - val_f1score: 0.9596\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00007: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1336 - acc: 0.9619 - f1score: 0.9620 - val_loss: 0.1444 - val_acc: 0.9464 - val_f1score: 0.9479\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9623 - f1score: 0.9623\n",
      "Epoch 00008: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1265 - acc: 0.9624 - f1score: 0.9626 - val_loss: 0.1564 - val_acc: 0.9528 - val_f1score: 0.9525\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9685 - f1score: 0.9686\n",
      "Epoch 00009: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1113 - acc: 0.9680 - f1score: 0.9676 - val_loss: 0.1256 - val_acc: 0.9533 - val_f1score: 0.9530\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9717 - f1score: 0.9717\n",
      "Epoch 00010: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1070 - acc: 0.9712 - f1score: 0.9707 - val_loss: 0.1199 - val_acc: 0.9592 - val_f1score: 0.9589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 12/1296 [19:01<36:28:41, 102.28s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.5919 - acc: 0.5954 - f1score: 0.5954\n",
      "Epoch 00001: val_acc improved from -inf to 0.82833, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.44.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.5712 - acc: 0.6000 - f1score: 0.6040 - val_loss: 0.4426 - val_acc: 0.8283 - val_f1score: 0.8301\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2854 - acc: 0.9014 - f1score: 0.9014\n",
      "Epoch 00002: val_acc improved from 0.82833 to 0.92489, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.20.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.2837 - acc: 0.9021 - f1score: 0.9027 - val_loss: 0.2022 - val_acc: 0.9249 - val_f1score: 0.9247\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1665 - acc: 0.9456 - f1score: 0.9456\n",
      "Epoch 00003: val_acc improved from 0.92489 to 0.94421, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.16.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1660 - acc: 0.9455 - f1score: 0.9454 - val_loss: 0.1629 - val_acc: 0.9442 - val_f1score: 0.9442\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9564 - f1score: 0.9564\n",
      "Epoch 00004: val_acc improved from 0.94421 to 0.95279, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.17.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1472 - acc: 0.9556 - f1score: 0.9549 - val_loss: 0.1658 - val_acc: 0.9528 - val_f1score: 0.9534\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00005: val_acc did not improve from 0.95279\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1354 - acc: 0.9593 - f1score: 0.9590 - val_loss: 0.1418 - val_acc: 0.9506 - val_f1score: 0.9521\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00006: val_acc did not improve from 0.95279\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1309 - acc: 0.9635 - f1score: 0.9636 - val_loss: 0.1399 - val_acc: 0.9496 - val_f1score: 0.9494\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00007: val_acc improved from 0.95279 to 0.96352, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1228 - acc: 0.9624 - f1score: 0.9630 - val_loss: 0.1443 - val_acc: 0.9635 - val_f1score: 0.9646\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00008: val_acc did not improve from 0.96352\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1207 - acc: 0.9651 - f1score: 0.9642 - val_loss: 0.1804 - val_acc: 0.9474 - val_f1score: 0.9473\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00009: val_acc did not improve from 0.96352\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1148 - acc: 0.9709 - f1score: 0.9700 - val_loss: 0.1451 - val_acc: 0.9464 - val_f1score: 0.9455\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9688 - f1score: 0.9687\n",
      "Epoch 00010: val_acc improved from 0.96352 to 0.96459, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.13.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1124 - acc: 0.9693 - f1score: 0.9698 - val_loss: 0.1301 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00011: val_acc improved from 0.96459 to 0.96674, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.11-0.13.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1097 - acc: 0.9677 - f1score: 0.9673 - val_loss: 0.1269 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00012: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1081 - acc: 0.9698 - f1score: 0.9699 - val_loss: 0.1507 - val_acc: 0.9506 - val_f1score: 0.9521\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00013: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1056 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1595 - val_acc: 0.9421 - val_f1score: 0.9429\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00014: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1046 - acc: 0.9683 - f1score: 0.9683 - val_loss: 0.1221 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00015: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1022 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1175 - val_acc: 0.9624 - val_f1score: 0.9627\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00016: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1050 - acc: 0.9688 - f1score: 0.9693 - val_loss: 0.1213 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00017: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1016 - acc: 0.9693 - f1score: 0.9684 - val_loss: 0.1252 - val_acc: 0.9571 - val_f1score: 0.9583\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00018: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1007 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1443 - val_acc: 0.9506 - val_f1score: 0.9497\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00019: val_acc improved from 0.96674 to 0.97103, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.19-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1009 - acc: 0.9704 - f1score: 0.9699 - val_loss: 0.1130 - val_acc: 0.9710 - val_f1score: 0.9703\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00020: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0987 - acc: 0.9730 - f1score: 0.9725 - val_loss: 0.1154 - val_acc: 0.9635 - val_f1score: 0.9638\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00021: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0953 - acc: 0.9730 - f1score: 0.9730 - val_loss: 0.1095 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00022: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0949 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1122 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00023: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0990 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1167 - val_acc: 0.9678 - val_f1score: 0.9663\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00024: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0952 - acc: 0.9714 - f1score: 0.9710 - val_loss: 0.1096 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00025: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0987 - acc: 0.9714 - f1score: 0.9705 - val_loss: 0.1067 - val_acc: 0.9678 - val_f1score: 0.9655\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00026: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0910 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1090 - val_acc: 0.9667 - val_f1score: 0.9653\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00027: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0924 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1130 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00028: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0967 - acc: 0.9709 - f1score: 0.9704 - val_loss: 0.1085 - val_acc: 0.9646 - val_f1score: 0.9624\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9747 - f1score: 0.9747\n",
      "Epoch 00029: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0942 - acc: 0.9746 - f1score: 0.9745 - val_loss: 0.1131 - val_acc: 0.9657 - val_f1score: 0.9667\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00030: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0937 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1127 - val_acc: 0.9678 - val_f1score: 0.9687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 13/1296 [22:58<50:56:14, 142.93s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.0770 - acc: 0.7209 - f1score: 0.7209\n",
      "Epoch 00001: val_acc improved from -inf to 0.82296, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.62.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.0627 - acc: 0.7233 - f1score: 0.7253 - val_loss: 0.6174 - val_acc: 0.8230 - val_f1score: 0.8241\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3652 - acc: 0.8788 - f1score: 0.8788\n",
      "Epoch 00002: val_acc improved from 0.82296 to 0.90880, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.28.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.3629 - acc: 0.8799 - f1score: 0.8809 - val_loss: 0.2824 - val_acc: 0.9088 - val_f1score: 0.9098\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2180 - acc: 0.9283 - f1score: 0.9283\n",
      "Epoch 00003: val_acc improved from 0.90880 to 0.94528, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.19.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2159 - acc: 0.9296 - f1score: 0.9307 - val_loss: 0.1869 - val_acc: 0.9453 - val_f1score: 0.9461\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9483 - f1score: 0.9483\n",
      "Epoch 00004: val_acc improved from 0.94528 to 0.95708, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.16.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1597 - acc: 0.9481 - f1score: 0.9480 - val_loss: 0.1625 - val_acc: 0.9571 - val_f1score: 0.9559\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1411 - acc: 0.9537 - f1score: 0.9537\n",
      "Epoch 00005: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1417 - acc: 0.9534 - f1score: 0.9532 - val_loss: 0.1493 - val_acc: 0.9549 - val_f1score: 0.9546\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00006: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1308 - acc: 0.9619 - f1score: 0.9620 - val_loss: 0.1334 - val_acc: 0.9539 - val_f1score: 0.9552\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00007: val_acc improved from 0.95708 to 0.95815, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.13.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1225 - acc: 0.9667 - f1score: 0.9667 - val_loss: 0.1300 - val_acc: 0.9582 - val_f1score: 0.9569\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00008: val_acc improved from 0.95815 to 0.96352, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.12.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1164 - acc: 0.9683 - f1score: 0.9687 - val_loss: 0.1227 - val_acc: 0.9635 - val_f1score: 0.9613\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00009: val_acc improved from 0.96352 to 0.96567, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1128 - acc: 0.9698 - f1score: 0.9689 - val_loss: 0.1149 - val_acc: 0.9657 - val_f1score: 0.9667\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00010: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1098 - acc: 0.9709 - f1score: 0.9714 - val_loss: 0.1214 - val_acc: 0.9657 - val_f1score: 0.9659\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00011: val_acc improved from 0.96567 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.11-0.12.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1063 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1178 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9688 - f1score: 0.9687\n",
      "Epoch 00012: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1078 - acc: 0.9693 - f1score: 0.9698 - val_loss: 0.1287 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00013: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1051 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1075 - val_acc: 0.9678 - val_f1score: 0.9688\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00014: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1090 - acc: 0.9730 - f1score: 0.9730 - val_loss: 0.1179 - val_acc: 0.9603 - val_f1score: 0.9615\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00015: val_acc improved from 0.96781 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.15-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1113 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1123 - val_acc: 0.9689 - val_f1score: 0.9674\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00016: val_acc improved from 0.96888 to 0.96996, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.16-0.12.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1010 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1190 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00017: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0970 - acc: 0.9730 - f1score: 0.9730 - val_loss: 0.1178 - val_acc: 0.9689 - val_f1score: 0.9666\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00018: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0953 - acc: 0.9725 - f1score: 0.9720 - val_loss: 0.1066 - val_acc: 0.9667 - val_f1score: 0.9653\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00019: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0991 - acc: 0.9698 - f1score: 0.9694 - val_loss: 0.1268 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00020: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0981 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1268 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00021: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1134 - acc: 0.9693 - f1score: 0.9693 - val_loss: 0.1180 - val_acc: 0.9592 - val_f1score: 0.9596\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00022: val_acc improved from 0.96996 to 0.97103, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.22-0.10.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1004 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1043 - val_acc: 0.9710 - val_f1score: 0.9703\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00023: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1001 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1139 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00024: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0984 - acc: 0.9735 - f1score: 0.9730 - val_loss: 0.1084 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00025: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0964 - acc: 0.9714 - f1score: 0.9696 - val_loss: 0.1082 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00026: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1055 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1145 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00027: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1125 - acc: 0.9735 - f1score: 0.9735 - val_loss: 0.1356 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00028: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0942 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1164 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9752 - f1score: 0.9752\n",
      "Epoch 00029: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0924 - acc: 0.9757 - f1score: 0.9760 - val_loss: 0.1052 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00030: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0926 - acc: 0.9730 - f1score: 0.9730 - val_loss: 0.1065 - val_acc: 0.9700 - val_f1score: 0.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 14/1296 [26:54<60:47:37, 170.72s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 4.5642 - acc: 0.5248 - f1score: 0.5248\n",
      "Epoch 00001: val_acc improved from -inf to 0.84227, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.37.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 4.4879 - acc: 0.5307 - f1score: 0.5357 - val_loss: 0.3656 - val_acc: 0.8423 - val_f1score: 0.8436\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2641 - acc: 0.9084 - f1score: 0.9084\n",
      "Epoch 00002: val_acc improved from 0.84227 to 0.93884, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.21.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2629 - acc: 0.9090 - f1score: 0.9095 - val_loss: 0.2078 - val_acc: 0.9388 - val_f1score: 0.9398\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1841 - acc: 0.9423 - f1score: 0.9423\n",
      "Epoch 00003: val_acc improved from 0.93884 to 0.94528, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.17.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1820 - acc: 0.9429 - f1score: 0.9433 - val_loss: 0.1746 - val_acc: 0.9453 - val_f1score: 0.9444\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1641 - acc: 0.9515 - f1score: 0.9515\n",
      "Epoch 00004: val_acc did not improve from 0.94528\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1638 - acc: 0.9519 - f1score: 0.9521 - val_loss: 0.1844 - val_acc: 0.9442 - val_f1score: 0.9450\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9569 - f1score: 0.9569\n",
      "Epoch 00005: val_acc improved from 0.94528 to 0.94635, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.17.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1515 - acc: 0.9566 - f1score: 0.9564 - val_loss: 0.1650 - val_acc: 0.9464 - val_f1score: 0.9463\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9537 - f1score: 0.9537\n",
      "Epoch 00006: val_acc did not improve from 0.94635\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1544 - acc: 0.9545 - f1score: 0.9552 - val_loss: 0.1754 - val_acc: 0.9442 - val_f1score: 0.9442\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9553 - f1score: 0.9553\n",
      "Epoch 00007: val_acc improved from 0.94635 to 0.94850, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.15.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1461 - acc: 0.9550 - f1score: 0.9548 - val_loss: 0.1542 - val_acc: 0.9485 - val_f1score: 0.9484\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.9537 - f1score: 0.9537\n",
      "Epoch 00008: val_acc did not improve from 0.94850\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1464 - acc: 0.9534 - f1score: 0.9532 - val_loss: 0.2548 - val_acc: 0.8948 - val_f1score: 0.8955\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00009: val_acc did not improve from 0.94850\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1390 - acc: 0.9603 - f1score: 0.9609 - val_loss: 0.1481 - val_acc: 0.9485 - val_f1score: 0.9484\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9564 - f1score: 0.9564\n",
      "Epoch 00010: val_acc did not improve from 0.94850\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1366 - acc: 0.9561 - f1score: 0.9559 - val_loss: 0.1655 - val_acc: 0.9442 - val_f1score: 0.9442\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9547 - f1score: 0.9547\n",
      "Epoch 00011: val_acc improved from 0.94850 to 0.95494, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.11-0.15.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1399 - acc: 0.9545 - f1score: 0.9543 - val_loss: 0.1523 - val_acc: 0.9549 - val_f1score: 0.9522\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00012: val_acc did not improve from 0.95494\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1394 - acc: 0.9577 - f1score: 0.9570 - val_loss: 0.1676 - val_acc: 0.9464 - val_f1score: 0.9463\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00013: val_acc did not improve from 0.95494\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1321 - acc: 0.9635 - f1score: 0.9636 - val_loss: 0.2287 - val_acc: 0.9453 - val_f1score: 0.9444\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9564 - f1score: 0.9564\n",
      "Epoch 00014: val_acc did not improve from 0.95494\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1359 - acc: 0.9571 - f1score: 0.9578 - val_loss: 0.1405 - val_acc: 0.9528 - val_f1score: 0.9517\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00015: val_acc did not improve from 0.95494\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1254 - acc: 0.9587 - f1score: 0.9585 - val_loss: 0.1821 - val_acc: 0.9442 - val_f1score: 0.9442\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00016: val_acc did not improve from 0.95494\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1310 - acc: 0.9582 - f1score: 0.9575 - val_loss: 0.1548 - val_acc: 0.9453 - val_f1score: 0.9453\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9607 - f1score: 0.9607\n",
      "Epoch 00017: val_acc did not improve from 0.95494\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1266 - acc: 0.9608 - f1score: 0.9610 - val_loss: 0.1420 - val_acc: 0.9506 - val_f1score: 0.9497\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1541 - acc: 0.9504 - f1score: 0.9504\n",
      "Epoch 00018: val_acc did not improve from 0.95494\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1524 - acc: 0.9513 - f1score: 0.9521 - val_loss: 0.1976 - val_acc: 0.9517 - val_f1score: 0.9523\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00019: val_acc did not improve from 0.95494\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1294 - acc: 0.9614 - f1score: 0.9615 - val_loss: 0.1369 - val_acc: 0.9528 - val_f1score: 0.9534\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00020: val_acc improved from 0.95494 to 0.95708, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.20-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1375 - acc: 0.9587 - f1score: 0.9589 - val_loss: 0.1388 - val_acc: 0.9571 - val_f1score: 0.9575\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00021: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1248 - acc: 0.9603 - f1score: 0.9596 - val_loss: 0.1568 - val_acc: 0.9485 - val_f1score: 0.9476\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00022: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1257 - acc: 0.9614 - f1score: 0.9615 - val_loss: 0.1456 - val_acc: 0.9549 - val_f1score: 0.9546\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00023: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1273 - acc: 0.9619 - f1score: 0.9607 - val_loss: 0.1353 - val_acc: 0.9549 - val_f1score: 0.9546\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00024: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1228 - acc: 0.9582 - f1score: 0.9566 - val_loss: 0.1377 - val_acc: 0.9464 - val_f1score: 0.9479\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00025: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1237 - acc: 0.9624 - f1score: 0.9630 - val_loss: 0.1372 - val_acc: 0.9560 - val_f1score: 0.9549\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00026: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1198 - acc: 0.9593 - f1score: 0.9594 - val_loss: 0.1637 - val_acc: 0.9474 - val_f1score: 0.9473\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00027: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1270 - acc: 0.9630 - f1score: 0.9617 - val_loss: 0.1465 - val_acc: 0.9539 - val_f1score: 0.9536\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00028: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1261 - acc: 0.9593 - f1score: 0.9594 - val_loss: 0.1473 - val_acc: 0.9571 - val_f1score: 0.9575\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00029: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1169 - acc: 0.9635 - f1score: 0.9636 - val_loss: 0.1466 - val_acc: 0.9453 - val_f1score: 0.9461\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00030: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1262 - acc: 0.9577 - f1score: 0.9570 - val_loss: 0.1465 - val_acc: 0.9442 - val_f1score: 0.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 15/1296 [31:05<69:21:19, 194.91s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.4366 - acc: 0.6945 - f1score: 0.6945\n",
      "Epoch 00001: val_acc improved from -inf to 0.79185, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-2.00.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.4241 - acc: 0.6947 - f1score: 0.6949 - val_loss: 1.9964 - val_acc: 0.7918 - val_f1score: 0.7931\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.9182 - acc: 0.8039 - f1score: 0.8039\n",
      "Epoch 00002: val_acc improved from 0.79185 to 0.88841, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.36.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.9121 - acc: 0.8042 - f1score: 0.8045 - val_loss: 0.3551 - val_acc: 0.8884 - val_f1score: 0.8892\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2421 - acc: 0.9100 - f1score: 0.9100\n",
      "Epoch 00003: val_acc improved from 0.88841 to 0.93026, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.25.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2490 - acc: 0.9085 - f1score: 0.9071 - val_loss: 0.2540 - val_acc: 0.9303 - val_f1score: 0.9291\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1911 - acc: 0.9402 - f1score: 0.9402\n",
      "Epoch 00004: val_acc improved from 0.93026 to 0.94635, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.17.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1941 - acc: 0.9386 - f1score: 0.9373 - val_loss: 0.1700 - val_acc: 0.9464 - val_f1score: 0.9455\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1553 - acc: 0.9531 - f1score: 0.9531\n",
      "Epoch 00005: val_acc improved from 0.94635 to 0.94957, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.16.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1558 - acc: 0.9534 - f1score: 0.9537 - val_loss: 0.1579 - val_acc: 0.9496 - val_f1score: 0.9502\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9569 - f1score: 0.9569\n",
      "Epoch 00006: val_acc did not improve from 0.94957\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1470 - acc: 0.9556 - f1score: 0.9544 - val_loss: 0.2202 - val_acc: 0.9442 - val_f1score: 0.9434\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9574 - f1score: 0.9574\n",
      "Epoch 00007: val_acc did not improve from 0.94957\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1640 - acc: 0.9577 - f1score: 0.9579 - val_loss: 0.1472 - val_acc: 0.9474 - val_f1score: 0.9490\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9564 - f1score: 0.9564\n",
      "Epoch 00008: val_acc improved from 0.94957 to 0.95386, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.14.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1363 - acc: 0.9566 - f1score: 0.9568 - val_loss: 0.1414 - val_acc: 0.9539 - val_f1score: 0.9552\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00009: val_acc improved from 0.95386 to 0.95923, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.15.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1228 - acc: 0.9587 - f1score: 0.9589 - val_loss: 0.1491 - val_acc: 0.9592 - val_f1score: 0.9604\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00010: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1191 - acc: 0.9677 - f1score: 0.9678 - val_loss: 0.1892 - val_acc: 0.9453 - val_f1score: 0.9428\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00011: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1308 - acc: 0.9593 - f1score: 0.9599 - val_loss: 0.1596 - val_acc: 0.9528 - val_f1score: 0.9517\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00012: val_acc improved from 0.95923 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.12-0.13.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1186 - acc: 0.9661 - f1score: 0.9667 - val_loss: 0.1255 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9650 - f1score: 0.9650\n",
      "Epoch 00013: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1193 - acc: 0.9651 - f1score: 0.9652 - val_loss: 0.1387 - val_acc: 0.9464 - val_f1score: 0.9463\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00014: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1171 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1301 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00015: val_acc improved from 0.96781 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.15-0.11.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1050 - acc: 0.9667 - f1score: 0.9667 - val_loss: 0.1120 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9688 - f1score: 0.9687\n",
      "Epoch 00016: val_acc improved from 0.96888 to 0.96996, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.16-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1069 - acc: 0.9683 - f1score: 0.9678 - val_loss: 0.1113 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00017: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1209 - acc: 0.9635 - f1score: 0.9636 - val_loss: 0.1290 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00018: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1053 - acc: 0.9698 - f1score: 0.9689 - val_loss: 0.1077 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00019: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0999 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1149 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00020: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1008 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1107 - val_acc: 0.9635 - val_f1score: 0.9646\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00021: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0990 - acc: 0.9693 - f1score: 0.9693 - val_loss: 0.1068 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00022: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0946 - acc: 0.9725 - f1score: 0.9720 - val_loss: 0.1114 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00023: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0928 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1101 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00024: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0951 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1173 - val_acc: 0.9678 - val_f1score: 0.9655\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00025: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1034 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1165 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9688 - f1score: 0.9688\n",
      "Epoch 00026: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1055 - acc: 0.9683 - f1score: 0.9678 - val_loss: 0.1084 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00027: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0930 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1041 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00028: val_acc improved from 0.96996 to 0.97103, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.28-0.12.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0964 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1208 - val_acc: 0.9710 - val_f1score: 0.9711\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00029: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0971 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1196 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00030: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0985 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1137 - val_acc: 0.9689 - val_f1score: 0.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 16/1296 [35:15<75:10:12, 211.42s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8844 - acc: 0.7759 - f1score: 0.7759\n",
      "Epoch 00001: val_acc improved from -inf to 0.91953, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.26.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.8733 - acc: 0.7783 - f1score: 0.7804 - val_loss: 0.2562 - val_acc: 0.9195 - val_f1score: 0.9219\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1975 - acc: 0.9294 - f1score: 0.9294\n",
      "Epoch 00002: val_acc improved from 0.91953 to 0.93562, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.19.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1963 - acc: 0.9291 - f1score: 0.9288 - val_loss: 0.1936 - val_acc: 0.9356 - val_f1score: 0.9367\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1800 - acc: 0.9434 - f1score: 0.9434\n",
      "Epoch 00003: val_acc improved from 0.93562 to 0.94099, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.18.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1777 - acc: 0.9444 - f1score: 0.9453 - val_loss: 0.1786 - val_acc: 0.9410 - val_f1score: 0.9403\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9547 - f1score: 0.9547\n",
      "Epoch 00004: val_acc did not improve from 0.94099\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1525 - acc: 0.9556 - f1score: 0.9562 - val_loss: 0.1772 - val_acc: 0.9399 - val_f1score: 0.9384\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9504 - f1score: 0.9504\n",
      "Epoch 00005: val_acc improved from 0.94099 to 0.94742, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.16.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1574 - acc: 0.9513 - f1score: 0.9521 - val_loss: 0.1575 - val_acc: 0.9474 - val_f1score: 0.9490\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00006: val_acc improved from 0.94742 to 0.95386, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.15.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1394 - acc: 0.9598 - f1score: 0.9604 - val_loss: 0.1467 - val_acc: 0.9539 - val_f1score: 0.9536\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1593 - acc: 0.9542 - f1score: 0.9542\n",
      "Epoch 00007: val_acc improved from 0.95386 to 0.96137, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1572 - acc: 0.9550 - f1score: 0.9557 - val_loss: 0.1724 - val_acc: 0.9614 - val_f1score: 0.9625\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00008: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1371 - acc: 0.9603 - f1score: 0.9605 - val_loss: 0.1592 - val_acc: 0.9421 - val_f1score: 0.9413\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1398 - acc: 0.9553 - f1score: 0.9553\n",
      "Epoch 00009: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1382 - acc: 0.9561 - f1score: 0.9568 - val_loss: 0.1528 - val_acc: 0.9442 - val_f1score: 0.9410\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9580 - f1score: 0.9580\n",
      "Epoch 00010: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1315 - acc: 0.9577 - f1score: 0.9574 - val_loss: 0.1433 - val_acc: 0.9464 - val_f1score: 0.9471\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00011: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1290 - acc: 0.9603 - f1score: 0.9605 - val_loss: 0.1578 - val_acc: 0.9506 - val_f1score: 0.9505\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9553 - f1score: 0.9553\n",
      "Epoch 00012: val_acc improved from 0.96137 to 0.96352, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.12-0.14.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1452 - acc: 0.9556 - f1score: 0.9558 - val_loss: 0.1397 - val_acc: 0.9635 - val_f1score: 0.9638\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9650 - f1score: 0.9650\n",
      "Epoch 00013: val_acc did not improve from 0.96352\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1260 - acc: 0.9656 - f1score: 0.9661 - val_loss: 0.1817 - val_acc: 0.9485 - val_f1score: 0.9459\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00014: val_acc did not improve from 0.96352\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1223 - acc: 0.9646 - f1score: 0.9651 - val_loss: 0.1784 - val_acc: 0.9453 - val_f1score: 0.9461\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00015: val_acc did not improve from 0.96352\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1129 - acc: 0.9667 - f1score: 0.9667 - val_loss: 0.1459 - val_acc: 0.9453 - val_f1score: 0.9453\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9650 - f1score: 0.9650\n",
      "Epoch 00016: val_acc did not improve from 0.96352\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1129 - acc: 0.9646 - f1score: 0.9642 - val_loss: 0.1312 - val_acc: 0.9453 - val_f1score: 0.9444\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00017: val_acc did not improve from 0.96352\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1139 - acc: 0.9688 - f1score: 0.9679 - val_loss: 0.3436 - val_acc: 0.8122 - val_f1score: 0.8120\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9564 - f1score: 0.9564\n",
      "Epoch 00018: val_acc improved from 0.96352 to 0.96459, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.18-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1311 - acc: 0.9571 - f1score: 0.9578 - val_loss: 0.1277 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00019: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1087 - acc: 0.9661 - f1score: 0.9657 - val_loss: 0.1624 - val_acc: 0.9485 - val_f1score: 0.9492\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9650 - f1score: 0.9650\n",
      "Epoch 00020: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1178 - acc: 0.9640 - f1score: 0.9632 - val_loss: 0.1653 - val_acc: 0.9496 - val_f1score: 0.9494\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00021: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1120 - acc: 0.9683 - f1score: 0.9683 - val_loss: 0.1437 - val_acc: 0.9582 - val_f1score: 0.9594\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00022: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1143 - acc: 0.9677 - f1score: 0.9682 - val_loss: 0.1205 - val_acc: 0.9635 - val_f1score: 0.9638\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1443 - acc: 0.9607 - f1score: 0.9607\n",
      "Epoch 00023: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1420 - acc: 0.9614 - f1score: 0.9620 - val_loss: 0.1780 - val_acc: 0.9474 - val_f1score: 0.9465\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00024: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1133 - acc: 0.9683 - f1score: 0.9688 - val_loss: 0.1298 - val_acc: 0.9603 - val_f1score: 0.9598\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00025: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1215 - acc: 0.9667 - f1score: 0.9672 - val_loss: 0.1454 - val_acc: 0.9549 - val_f1score: 0.9546\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00026: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1058 - acc: 0.9677 - f1score: 0.9682 - val_loss: 0.1186 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00027: val_acc improved from 0.96459 to 0.96567, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.27-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1236 - acc: 0.9619 - f1score: 0.9625 - val_loss: 0.1243 - val_acc: 0.9657 - val_f1score: 0.9650\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00028: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1127 - acc: 0.9672 - f1score: 0.9668 - val_loss: 0.1406 - val_acc: 0.9453 - val_f1score: 0.9436\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00029: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1042 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1335 - val_acc: 0.9582 - val_f1score: 0.9594\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00030: val_acc improved from 0.96567 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.30-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1050 - acc: 0.9720 - f1score: 0.9706 - val_loss: 0.1200 - val_acc: 0.9678 - val_f1score: 0.9671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|         | 17/1296 [40:40<87:11:52, 245.44s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 3.1755 - acc: 0.5140 - f1score: 0.5140\n",
      "Epoch 00001: val_acc improved from -inf to 0.87768, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.40.h5\n",
      "1890/1890 [==============================] - 12s 7ms/sample - loss: 3.1261 - acc: 0.5190 - f1score: 0.5233 - val_loss: 0.4047 - val_acc: 0.8777 - val_f1score: 0.8796\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2572 - acc: 0.9100 - f1score: 0.9100\n",
      "Epoch 00002: val_acc improved from 0.87768 to 0.91845, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.22.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2594 - acc: 0.9095 - f1score: 0.9091 - val_loss: 0.2232 - val_acc: 0.9185 - val_f1score: 0.9192\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9397 - f1score: 0.9397\n",
      "Epoch 00003: val_acc improved from 0.91845 to 0.94099, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1777 - acc: 0.9386 - f1score: 0.9377 - val_loss: 0.1689 - val_acc: 0.9410 - val_f1score: 0.9419\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9510 - f1score: 0.9510\n",
      "Epoch 00004: val_acc improved from 0.94099 to 0.95064, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.14.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1433 - acc: 0.9513 - f1score: 0.9516 - val_loss: 0.1427 - val_acc: 0.9506 - val_f1score: 0.9513\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9564 - f1score: 0.9564\n",
      "Epoch 00005: val_acc improved from 0.95064 to 0.95601, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1287 - acc: 0.9566 - f1score: 0.9568 - val_loss: 0.1320 - val_acc: 0.9560 - val_f1score: 0.9565\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00006: val_acc improved from 0.95601 to 0.96567, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1195 - acc: 0.9667 - f1score: 0.9667 - val_loss: 0.1324 - val_acc: 0.9657 - val_f1score: 0.9659\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00007: val_acc improved from 0.96567 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1167 - acc: 0.9667 - f1score: 0.9658 - val_loss: 0.1294 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00008: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1133 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1232 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00009: val_acc improved from 0.96781 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.12.h5\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1059 - acc: 0.9693 - f1score: 0.9689 - val_loss: 0.1240 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00010: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1033 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1125 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00011: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1025 - acc: 0.9725 - f1score: 0.9720 - val_loss: 0.1128 - val_acc: 0.9624 - val_f1score: 0.9619\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00012: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1048 - acc: 0.9693 - f1score: 0.9689 - val_loss: 0.1224 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00013: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0993 - acc: 0.9693 - f1score: 0.9693 - val_loss: 0.1075 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00014: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0983 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1059 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00015: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0967 - acc: 0.9720 - f1score: 0.9710 - val_loss: 0.1137 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00016: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0995 - acc: 0.9735 - f1score: 0.9735 - val_loss: 0.1142 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00017: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0937 - acc: 0.9683 - f1score: 0.9683 - val_loss: 0.1053 - val_acc: 0.9678 - val_f1score: 0.9688\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00018: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0948 - acc: 0.9735 - f1score: 0.9735 - val_loss: 0.1097 - val_acc: 0.9657 - val_f1score: 0.9667\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00019: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0941 - acc: 0.9714 - f1score: 0.9719 - val_loss: 0.1027 - val_acc: 0.9689 - val_f1score: 0.9674\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00020: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0960 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1090 - val_acc: 0.9678 - val_f1score: 0.9663\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00021: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0962 - acc: 0.9730 - f1score: 0.9730 - val_loss: 0.1260 - val_acc: 0.9485 - val_f1score: 0.9476\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00022: val_acc improved from 0.96888 to 0.96996, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.22-0.11.h5\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1040 - acc: 0.9683 - f1score: 0.9683 - val_loss: 0.1088 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00023: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0941 - acc: 0.9741 - f1score: 0.9740 - val_loss: 0.1060 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00024: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0945 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1065 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00025: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0942 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1054 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00026: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0921 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1076 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9747 - f1score: 0.9747\n",
      "Epoch 00027: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0924 - acc: 0.9730 - f1score: 0.9716 - val_loss: 0.1049 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9747 - f1score: 0.9747\n",
      "Epoch 00028: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0963 - acc: 0.9741 - f1score: 0.9736 - val_loss: 0.1147 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00029: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0971 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1052 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00030: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0910 - acc: 0.9704 - f1score: 0.9699 - val_loss: 0.1108 - val_acc: 0.9678 - val_f1score: 0.9679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|         | 18/1296 [45:58<94:50:21, 267.15s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.5277 - acc: 0.7188 - f1score: 0.7595\n",
      "Epoch 00001: val_acc improved from -inf to 0.61695, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.75.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 1.5119 - acc: 0.7188 - f1score: 0.7580 - val_loss: 0.7456 - val_acc: 0.6170 - val_f1score: 0.5323\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3937 - acc: 0.8502 - f1score: 0.8434\n",
      "Epoch 00002: val_acc improved from 0.61695 to 0.89378, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.38.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.3933 - acc: 0.8503 - f1score: 0.8435 - val_loss: 0.3805 - val_acc: 0.8938 - val_f1score: 0.8931\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2382 - acc: 0.9256 - f1score: 0.9260\n",
      "Epoch 00003: val_acc improved from 0.89378 to 0.93240, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.29.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2396 - acc: 0.9254 - f1score: 0.9256 - val_loss: 0.2940 - val_acc: 0.9324 - val_f1score: 0.9346\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1851 - acc: 0.9423 - f1score: 0.9425\n",
      "Epoch 00004: val_acc improved from 0.93240 to 0.94313, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.19.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1839 - acc: 0.9423 - f1score: 0.9424 - val_loss: 0.1927 - val_acc: 0.9431 - val_f1score: 0.9441\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9418 - f1score: 0.9419\n",
      "Epoch 00005: val_acc did not improve from 0.94313\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1785 - acc: 0.9402 - f1score: 0.9390 - val_loss: 0.3514 - val_acc: 0.8922 - val_f1score: 0.8926\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1642 - acc: 0.9477 - f1score: 0.9479\n",
      "Epoch 00006: val_acc improved from 0.94313 to 0.94796, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.17.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1622 - acc: 0.9487 - f1score: 0.9496 - val_loss: 0.1708 - val_acc: 0.9480 - val_f1score: 0.9490\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1552 - acc: 0.9534 - f1score: 0.9534\n",
      "Epoch 00007: val_acc did not improve from 0.94796\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1534 - acc: 0.9542 - f1score: 0.9550 - val_loss: 0.1771 - val_acc: 0.9480 - val_f1score: 0.9481\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9566 - f1score: 0.9567\n",
      "Epoch 00008: val_acc improved from 0.94796 to 0.95386, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.17.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1478 - acc: 0.9574 - f1score: 0.9581 - val_loss: 0.1749 - val_acc: 0.9539 - val_f1score: 0.9548\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9547 - f1score: 0.9548\n",
      "Epoch 00009: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1535 - acc: 0.9545 - f1score: 0.9544 - val_loss: 0.1650 - val_acc: 0.9496 - val_f1score: 0.9503\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9604 - f1score: 0.9605\n",
      "Epoch 00010: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1421 - acc: 0.9601 - f1score: 0.9598 - val_loss: 0.3058 - val_acc: 0.9045 - val_f1score: 0.9047\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1471 - acc: 0.9566 - f1score: 0.9567\n",
      "Epoch 00011: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1454 - acc: 0.9569 - f1score: 0.9572 - val_loss: 0.1520 - val_acc: 0.9474 - val_f1score: 0.9492\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9615 - f1score: 0.9616\n",
      "Epoch 00012: val_acc improved from 0.95386 to 0.95547, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.12-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1297 - acc: 0.9622 - f1score: 0.9629 - val_loss: 0.1441 - val_acc: 0.9555 - val_f1score: 0.9562\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1322 - acc: 0.9609 - f1score: 0.9611\n",
      "Epoch 00013: val_acc did not improve from 0.95547\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1303 - acc: 0.9616 - f1score: 0.9624 - val_loss: 0.1386 - val_acc: 0.9555 - val_f1score: 0.9555\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9617 - f1score: 0.9619\n",
      "Epoch 00014: val_acc improved from 0.95547 to 0.95655, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.14-0.15.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1288 - acc: 0.9624 - f1score: 0.9631 - val_loss: 0.1471 - val_acc: 0.9565 - val_f1score: 0.9569\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00015: val_acc did not improve from 0.95655\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1315 - acc: 0.9595 - f1score: 0.9595 - val_loss: 0.2494 - val_acc: 0.9303 - val_f1score: 0.9321\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9558 - f1score: 0.9560\n",
      "Epoch 00016: val_acc did not improve from 0.95655\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1352 - acc: 0.9556 - f1score: 0.9555 - val_loss: 0.1438 - val_acc: 0.9533 - val_f1score: 0.9529\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00017: val_acc improved from 0.95655 to 0.96406, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.17-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1217 - acc: 0.9640 - f1score: 0.9646 - val_loss: 0.1366 - val_acc: 0.9641 - val_f1score: 0.9651\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00018: val_acc did not improve from 0.96406\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1261 - acc: 0.9646 - f1score: 0.9652 - val_loss: 0.1483 - val_acc: 0.9587 - val_f1score: 0.9575\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9650 - f1score: 0.9651\n",
      "Epoch 00019: val_acc did not improve from 0.96406\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1161 - acc: 0.9651 - f1score: 0.9652 - val_loss: 0.1319 - val_acc: 0.9630 - val_f1score: 0.9632\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1268 - acc: 0.9690 - f1score: 0.9691\n",
      "Epoch 00020: val_acc did not improve from 0.96406\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1265 - acc: 0.9690 - f1score: 0.9691 - val_loss: 0.1309 - val_acc: 0.9517 - val_f1score: 0.9530\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9617 - f1score: 0.9619\n",
      "Epoch 00021: val_acc did not improve from 0.96406\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1189 - acc: 0.9624 - f1score: 0.9632 - val_loss: 0.1652 - val_acc: 0.9480 - val_f1score: 0.9475\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9623 - f1score: 0.9624\n",
      "Epoch 00022: val_acc did not improve from 0.96406\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1428 - acc: 0.9619 - f1score: 0.9617 - val_loss: 0.2134 - val_acc: 0.9426 - val_f1score: 0.9427\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9628 - f1score: 0.9629\n",
      "Epoch 00023: val_acc did not improve from 0.96406\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1342 - acc: 0.9627 - f1score: 0.9626 - val_loss: 0.1294 - val_acc: 0.9603 - val_f1score: 0.9597\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00024: val_acc improved from 0.96406 to 0.96567, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.24-0.13.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1225 - acc: 0.9651 - f1score: 0.9656 - val_loss: 0.1306 - val_acc: 0.9657 - val_f1score: 0.9658\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9642 - f1score: 0.9641\n",
      "Epoch 00025: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1183 - acc: 0.9643 - f1score: 0.9643 - val_loss: 0.1757 - val_acc: 0.9523 - val_f1score: 0.9529\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00026: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1182 - acc: 0.9667 - f1score: 0.9667 - val_loss: 0.1251 - val_acc: 0.9614 - val_f1score: 0.9616\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9620 - f1score: 0.9620\n",
      "Epoch 00027: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1277 - acc: 0.9622 - f1score: 0.9623 - val_loss: 0.1304 - val_acc: 0.9464 - val_f1score: 0.9473\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9679 - f1score: 0.9679\n",
      "Epoch 00028: val_acc improved from 0.96567 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.28-0.12.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1122 - acc: 0.9680 - f1score: 0.9680 - val_loss: 0.1237 - val_acc: 0.9678 - val_f1score: 0.9670\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9679 - f1score: 0.9679\n",
      "Epoch 00029: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1152 - acc: 0.9685 - f1score: 0.9690 - val_loss: 0.1425 - val_acc: 0.9592 - val_f1score: 0.9591\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00030: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1112 - acc: 0.9677 - f1score: 0.9673 - val_loss: 0.1398 - val_acc: 0.9453 - val_f1score: 0.9428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|         | 19/1296 [49:57<91:46:12, 258.71s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.9619 - acc: 0.7117 - f1score: 0.7418\n",
      "Epoch 00001: val_acc improved from -inf to 0.78326, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-1.54.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.9463 - acc: 0.7135 - f1score: 0.7446 - val_loss: 1.5371 - val_acc: 0.7833 - val_f1score: 0.7951\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.2227 - acc: 0.7934 - f1score: 0.8118\n",
      "Epoch 00002: val_acc improved from 0.78326 to 0.81921, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-1.19.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.2177 - acc: 0.7937 - f1score: 0.8118 - val_loss: 1.1885 - val_acc: 0.8192 - val_f1score: 0.8243\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7830 - acc: 0.8483 - f1score: 0.8539\n",
      "Epoch 00003: val_acc improved from 0.81921 to 0.85891, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.69.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7792 - acc: 0.8484 - f1score: 0.8539 - val_loss: 0.6945 - val_acc: 0.8589 - val_f1score: 0.8610\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4562 - acc: 0.8831 - f1score: 0.8805\n",
      "Epoch 00004: val_acc improved from 0.85891 to 0.87661, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.40.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4513 - acc: 0.8839 - f1score: 0.8820 - val_loss: 0.3988 - val_acc: 0.8766 - val_f1score: 0.8747\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2934 - acc: 0.9178 - f1score: 0.9173\n",
      "Epoch 00005: val_acc improved from 0.87661 to 0.90987, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.28.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2986 - acc: 0.9156 - f1score: 0.9132 - val_loss: 0.2750 - val_acc: 0.9099 - val_f1score: 0.9118\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2213 - acc: 0.9386 - f1score: 0.9383\n",
      "Epoch 00006: val_acc improved from 0.90987 to 0.92811, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.22.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.2193 - acc: 0.9392 - f1score: 0.9394 - val_loss: 0.2189 - val_acc: 0.9281 - val_f1score: 0.9256\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1859 - acc: 0.9461 - f1score: 0.9460\n",
      "Epoch 00007: val_acc improved from 0.92811 to 0.94045, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.20.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1836 - acc: 0.9471 - f1score: 0.9478 - val_loss: 0.2004 - val_acc: 0.9405 - val_f1score: 0.9401\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9464 - f1score: 0.9461\n",
      "Epoch 00008: val_acc improved from 0.94045 to 0.94957, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.18.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1656 - acc: 0.9471 - f1score: 0.9474 - val_loss: 0.1762 - val_acc: 0.9496 - val_f1score: 0.9491\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9591 - f1score: 0.9589\n",
      "Epoch 00009: val_acc did not improve from 0.94957\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1471 - acc: 0.9577 - f1score: 0.9563 - val_loss: 0.1647 - val_acc: 0.9464 - val_f1score: 0.9456\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9577 - f1score: 0.9574\n",
      "Epoch 00010: val_acc did not improve from 0.94957\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1410 - acc: 0.9585 - f1score: 0.9588 - val_loss: 0.1609 - val_acc: 0.9442 - val_f1score: 0.9438\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9599 - f1score: 0.9599\n",
      "Epoch 00011: val_acc did not improve from 0.94957\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1358 - acc: 0.9601 - f1score: 0.9602 - val_loss: 0.1531 - val_acc: 0.9469 - val_f1score: 0.9466\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9604 - f1score: 0.9603\n",
      "Epoch 00012: val_acc did not improve from 0.94957\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1314 - acc: 0.9606 - f1score: 0.9606 - val_loss: 0.1512 - val_acc: 0.9490 - val_f1score: 0.9488\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9620 - f1score: 0.9620\n",
      "Epoch 00013: val_acc did not improve from 0.94957\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1286 - acc: 0.9622 - f1score: 0.9622 - val_loss: 0.1524 - val_acc: 0.9437 - val_f1score: 0.9444\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9599 - f1score: 0.9599\n",
      "Epoch 00014: val_acc improved from 0.94957 to 0.95976, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.14-0.15.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1278 - acc: 0.9606 - f1score: 0.9612 - val_loss: 0.1488 - val_acc: 0.9598 - val_f1score: 0.9596\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00015: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1314 - acc: 0.9611 - f1score: 0.9606 - val_loss: 0.1501 - val_acc: 0.9533 - val_f1score: 0.9543\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9628 - f1score: 0.9627\n",
      "Epoch 00016: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1240 - acc: 0.9622 - f1score: 0.9616 - val_loss: 0.1452 - val_acc: 0.9464 - val_f1score: 0.9446\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9626 - f1score: 0.9626\n",
      "Epoch 00017: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1244 - acc: 0.9627 - f1score: 0.9628 - val_loss: 0.1410 - val_acc: 0.9485 - val_f1score: 0.9500\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9620 - f1score: 0.9619\n",
      "Epoch 00018: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1208 - acc: 0.9616 - f1score: 0.9612 - val_loss: 0.1397 - val_acc: 0.9544 - val_f1score: 0.9543\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9626 - f1score: 0.9625\n",
      "Epoch 00019: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1189 - acc: 0.9627 - f1score: 0.9628 - val_loss: 0.1368 - val_acc: 0.9598 - val_f1score: 0.9600\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9647 - f1score: 0.9647\n",
      "Epoch 00020: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1187 - acc: 0.9651 - f1score: 0.9653 - val_loss: 0.1368 - val_acc: 0.9582 - val_f1score: 0.9580\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9615 - f1score: 0.9613\n",
      "Epoch 00021: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1179 - acc: 0.9616 - f1score: 0.9616 - val_loss: 0.1344 - val_acc: 0.9592 - val_f1score: 0.9594\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9650 - f1score: 0.9649\n",
      "Epoch 00022: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1164 - acc: 0.9651 - f1score: 0.9651 - val_loss: 0.1345 - val_acc: 0.9539 - val_f1score: 0.9551\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9636 - f1score: 0.9635\n",
      "Epoch 00023: val_acc improved from 0.95976 to 0.96191, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.23-0.13.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1158 - acc: 0.9638 - f1score: 0.9638 - val_loss: 0.1341 - val_acc: 0.9619 - val_f1score: 0.9617\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9663 - f1score: 0.9663\n",
      "Epoch 00024: val_acc did not improve from 0.96191\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1145 - acc: 0.9669 - f1score: 0.9674 - val_loss: 0.1316 - val_acc: 0.9555 - val_f1score: 0.9558\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9631 - f1score: 0.9630\n",
      "Epoch 00025: val_acc did not improve from 0.96191\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1174 - acc: 0.9632 - f1score: 0.9632 - val_loss: 0.1331 - val_acc: 0.9523 - val_f1score: 0.9514\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9636 - f1score: 0.9635\n",
      "Epoch 00026: val_acc did not improve from 0.96191\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1157 - acc: 0.9638 - f1score: 0.9638 - val_loss: 0.1325 - val_acc: 0.9480 - val_f1score: 0.9478\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9658 - f1score: 0.9657\n",
      "Epoch 00027: val_acc improved from 0.96191 to 0.96245, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.27-0.13.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1103 - acc: 0.9661 - f1score: 0.9664 - val_loss: 0.1328 - val_acc: 0.9624 - val_f1score: 0.9630\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9658 - f1score: 0.9659\n",
      "Epoch 00028: val_acc did not improve from 0.96245\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1099 - acc: 0.9646 - f1score: 0.9635 - val_loss: 0.1270 - val_acc: 0.9565 - val_f1score: 0.9567\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9677 - f1score: 0.9676\n",
      "Epoch 00029: val_acc did not improve from 0.96245\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1118 - acc: 0.9667 - f1score: 0.9657 - val_loss: 0.1282 - val_acc: 0.9533 - val_f1score: 0.9535\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9671 - f1score: 0.9670\n",
      "Epoch 00030: val_acc did not improve from 0.96245\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1096 - acc: 0.9672 - f1score: 0.9672 - val_loss: 0.1256 - val_acc: 0.9614 - val_f1score: 0.9623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|         | 20/1296 [53:52<89:11:40, 251.65s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 4.9407 - acc: 0.3152 - f1score: 0.3352\n",
      "Epoch 00001: val_acc improved from -inf to 0.49517, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-1.62.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 4.8882 - acc: 0.3169 - f1score: 0.3378 - val_loss: 1.6194 - val_acc: 0.4952 - val_f1score: 0.4957\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7557 - acc: 0.7619 - f1score: 0.7555\n",
      "Epoch 00002: val_acc improved from 0.49517 to 0.92811, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.34.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7483 - acc: 0.7648 - f1score: 0.7612 - val_loss: 0.3429 - val_acc: 0.9281 - val_f1score: 0.9283\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2855 - acc: 0.9378 - f1score: 0.9376\n",
      "Epoch 00003: val_acc improved from 0.92811 to 0.93187, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.28.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2826 - acc: 0.9384 - f1score: 0.9387 - val_loss: 0.2802 - val_acc: 0.9319 - val_f1score: 0.9329\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2265 - acc: 0.9450 - f1score: 0.9450\n",
      "Epoch 00004: val_acc improved from 0.93187 to 0.93670, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.24.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2267 - acc: 0.9450 - f1score: 0.9449 - val_loss: 0.2404 - val_acc: 0.9367 - val_f1score: 0.9383\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1869 - acc: 0.9485 - f1score: 0.9485\n",
      "Epoch 00005: val_acc improved from 0.93670 to 0.94421, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.20.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1888 - acc: 0.9476 - f1score: 0.9467 - val_loss: 0.2034 - val_acc: 0.9442 - val_f1score: 0.9434\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9515 - f1score: 0.9514\n",
      "Epoch 00006: val_acc improved from 0.94421 to 0.94528, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.19.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1642 - acc: 0.9513 - f1score: 0.9511 - val_loss: 0.1869 - val_acc: 0.9453 - val_f1score: 0.9461\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1573 - acc: 0.9555 - f1score: 0.9555\n",
      "Epoch 00007: val_acc did not improve from 0.94528\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1577 - acc: 0.9553 - f1score: 0.9550 - val_loss: 0.1928 - val_acc: 0.9442 - val_f1score: 0.9450\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9564 - f1score: 0.9563\n",
      "Epoch 00008: val_acc improved from 0.94528 to 0.95118, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.18.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1529 - acc: 0.9566 - f1score: 0.9568 - val_loss: 0.1792 - val_acc: 0.9512 - val_f1score: 0.9510\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1511 - acc: 0.9542 - f1score: 0.9542\n",
      "Epoch 00009: val_acc improved from 0.95118 to 0.95172, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.17.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1523 - acc: 0.9540 - f1score: 0.9537 - val_loss: 0.1748 - val_acc: 0.9517 - val_f1score: 0.9523\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9547 - f1score: 0.9547\n",
      "Epoch 00010: val_acc improved from 0.95172 to 0.95333, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.16.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1490 - acc: 0.9550 - f1score: 0.9552 - val_loss: 0.1619 - val_acc: 0.9533 - val_f1score: 0.9538\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9561 - f1score: 0.9561\n",
      "Epoch 00011: val_acc improved from 0.95333 to 0.95494, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.11-0.15.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1434 - acc: 0.9553 - f1score: 0.9546 - val_loss: 0.1528 - val_acc: 0.9549 - val_f1score: 0.9562\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1327 - acc: 0.9585 - f1score: 0.9584\n",
      "Epoch 00012: val_acc did not improve from 0.95494\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1344 - acc: 0.9571 - f1score: 0.9559 - val_loss: 0.1694 - val_acc: 0.9437 - val_f1score: 0.9445\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9555 - f1score: 0.9555\n",
      "Epoch 00013: val_acc did not improve from 0.95494\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1341 - acc: 0.9558 - f1score: 0.9560 - val_loss: 0.1508 - val_acc: 0.9485 - val_f1score: 0.9491\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00014: val_acc improved from 0.95494 to 0.95547, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.14-0.16.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1292 - acc: 0.9603 - f1score: 0.9604 - val_loss: 0.1578 - val_acc: 0.9555 - val_f1score: 0.9538\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9558 - f1score: 0.9557\n",
      "Epoch 00015: val_acc did not improve from 0.95547\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1324 - acc: 0.9561 - f1score: 0.9562 - val_loss: 0.1478 - val_acc: 0.9517 - val_f1score: 0.9498\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9566 - f1score: 0.9566\n",
      "Epoch 00016: val_acc improved from 0.95547 to 0.95655, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.16-0.15.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1292 - acc: 0.9569 - f1score: 0.9571 - val_loss: 0.1455 - val_acc: 0.9565 - val_f1score: 0.9545\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9572 - f1score: 0.9571\n",
      "Epoch 00017: val_acc improved from 0.95655 to 0.95923, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.17-0.14.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1264 - acc: 0.9579 - f1score: 0.9585 - val_loss: 0.1436 - val_acc: 0.9592 - val_f1score: 0.9591\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9566 - f1score: 0.9566\n",
      "Epoch 00018: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1276 - acc: 0.9569 - f1score: 0.9570 - val_loss: 0.1414 - val_acc: 0.9582 - val_f1score: 0.9593\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9588 - f1score: 0.9587\n",
      "Epoch 00019: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1245 - acc: 0.9590 - f1score: 0.9591 - val_loss: 0.1406 - val_acc: 0.9549 - val_f1score: 0.9532\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9569 - f1score: 0.9568\n",
      "Epoch 00020: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1255 - acc: 0.9571 - f1score: 0.9573 - val_loss: 0.1389 - val_acc: 0.9576 - val_f1score: 0.9572\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9609 - f1score: 0.9609\n",
      "Epoch 00021: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1239 - acc: 0.9590 - f1score: 0.9573 - val_loss: 0.1367 - val_acc: 0.9565 - val_f1score: 0.9570\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00022: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1205 - acc: 0.9593 - f1score: 0.9598 - val_loss: 0.1432 - val_acc: 0.9576 - val_f1score: 0.9579\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9564 - f1score: 0.9563\n",
      "Epoch 00023: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1222 - acc: 0.9566 - f1score: 0.9568 - val_loss: 0.1436 - val_acc: 0.9571 - val_f1score: 0.9553\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9569 - f1score: 0.9569\n",
      "Epoch 00024: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1203 - acc: 0.9571 - f1score: 0.9573 - val_loss: 0.1383 - val_acc: 0.9587 - val_f1score: 0.9590\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9615 - f1score: 0.9614\n",
      "Epoch 00025: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1193 - acc: 0.9606 - f1score: 0.9598 - val_loss: 0.1378 - val_acc: 0.9555 - val_f1score: 0.9559\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9626 - f1score: 0.9625\n",
      "Epoch 00026: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1165 - acc: 0.9627 - f1score: 0.9628 - val_loss: 0.1467 - val_acc: 0.9571 - val_f1score: 0.9567\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9580 - f1score: 0.9579\n",
      "Epoch 00027: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1191 - acc: 0.9577 - f1score: 0.9573 - val_loss: 0.1353 - val_acc: 0.9523 - val_f1score: 0.9521\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00028: val_acc improved from 0.95923 to 0.95976, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.28-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1167 - acc: 0.9603 - f1score: 0.9609 - val_loss: 0.1413 - val_acc: 0.9598 - val_f1score: 0.9576\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9593 - f1score: 0.9593\n",
      "Epoch 00029: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1175 - acc: 0.9595 - f1score: 0.9597 - val_loss: 0.1351 - val_acc: 0.9544 - val_f1score: 0.9533\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00030: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1152 - acc: 0.9603 - f1score: 0.9605 - val_loss: 0.1350 - val_acc: 0.9576 - val_f1score: 0.9571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|         | 21/1296 [58:10<89:45:54, 253.45s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7971 - acc: 0.6999 - f1score: 0.6558\n",
      "Epoch 00001: val_acc improved from -inf to 0.82082, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.52.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.7936 - acc: 0.7016 - f1score: 0.6604 - val_loss: 0.5184 - val_acc: 0.8208 - val_f1score: 0.8210\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3415 - acc: 0.8850 - f1score: 0.8849\n",
      "Epoch 00002: val_acc improved from 0.82082 to 0.91470, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.26.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.3385 - acc: 0.8860 - f1score: 0.8867 - val_loss: 0.2607 - val_acc: 0.9147 - val_f1score: 0.9123\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9332 - f1score: 0.9330\n",
      "Epoch 00003: val_acc improved from 0.91470 to 0.92597, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.20.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.2046 - acc: 0.9328 - f1score: 0.9323 - val_loss: 0.2040 - val_acc: 0.9260 - val_f1score: 0.9278\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1658 - acc: 0.9477 - f1score: 0.9476\n",
      "Epoch 00004: val_acc improved from 0.92597 to 0.93938, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1670 - acc: 0.9466 - f1score: 0.9455 - val_loss: 0.1713 - val_acc: 0.9394 - val_f1score: 0.9360\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9526 - f1score: 0.9524\n",
      "Epoch 00005: val_acc improved from 0.93938 to 0.94796, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.16.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1465 - acc: 0.9529 - f1score: 0.9530 - val_loss: 0.1625 - val_acc: 0.9480 - val_f1score: 0.9468\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9582 - f1score: 0.9581\n",
      "Epoch 00006: val_acc improved from 0.94796 to 0.95225, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.16.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1408 - acc: 0.9582 - f1score: 0.9580 - val_loss: 0.1582 - val_acc: 0.9523 - val_f1score: 0.9536\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9601 - f1score: 0.9600\n",
      "Epoch 00007: val_acc did not improve from 0.95225\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1305 - acc: 0.9598 - f1score: 0.9594 - val_loss: 0.1471 - val_acc: 0.9480 - val_f1score: 0.9476\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9564 - f1score: 0.9562\n",
      "Epoch 00008: val_acc did not improve from 0.95225\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1309 - acc: 0.9571 - f1score: 0.9577 - val_loss: 0.1472 - val_acc: 0.9464 - val_f1score: 0.9446\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1307 - acc: 0.9547 - f1score: 0.9547\n",
      "Epoch 00009: val_acc did not improve from 0.95225\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1292 - acc: 0.9556 - f1score: 0.9562 - val_loss: 0.1437 - val_acc: 0.9496 - val_f1score: 0.9493\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00010: val_acc did not improve from 0.95225\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1258 - acc: 0.9646 - f1score: 0.9646 - val_loss: 0.1516 - val_acc: 0.9453 - val_f1score: 0.9459\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9599 - f1score: 0.9598\n",
      "Epoch 00011: val_acc did not improve from 0.95225\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1241 - acc: 0.9595 - f1score: 0.9592 - val_loss: 0.1424 - val_acc: 0.9458 - val_f1score: 0.9457\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9609 - f1score: 0.9609\n",
      "Epoch 00012: val_acc improved from 0.95225 to 0.95386, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.12-0.14.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1224 - acc: 0.9616 - f1score: 0.9622 - val_loss: 0.1407 - val_acc: 0.9539 - val_f1score: 0.9536\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00013: val_acc improved from 0.95386 to 0.95762, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1218 - acc: 0.9585 - f1score: 0.9584 - val_loss: 0.1410 - val_acc: 0.9576 - val_f1score: 0.9588\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00014: val_acc did not improve from 0.95762\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1246 - acc: 0.9598 - f1score: 0.9599 - val_loss: 0.1363 - val_acc: 0.9555 - val_f1score: 0.9550\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9609 - f1score: 0.9609\n",
      "Epoch 00015: val_acc did not improve from 0.95762\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1218 - acc: 0.9601 - f1score: 0.9592 - val_loss: 0.1368 - val_acc: 0.9496 - val_f1score: 0.9501\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9620 - f1score: 0.9620\n",
      "Epoch 00016: val_acc did not improve from 0.95762\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1214 - acc: 0.9627 - f1score: 0.9633 - val_loss: 0.1376 - val_acc: 0.9571 - val_f1score: 0.9567\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9642 - f1score: 0.9642\n",
      "Epoch 00017: val_acc did not improve from 0.95762\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1183 - acc: 0.9630 - f1score: 0.9619 - val_loss: 0.1408 - val_acc: 0.9447 - val_f1score: 0.9431\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9636 - f1score: 0.9636\n",
      "Epoch 00018: val_acc did not improve from 0.95762\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1167 - acc: 0.9638 - f1score: 0.9639 - val_loss: 0.1394 - val_acc: 0.9442 - val_f1score: 0.9434\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00019: val_acc did not improve from 0.95762\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1193 - acc: 0.9603 - f1score: 0.9596 - val_loss: 0.1352 - val_acc: 0.9496 - val_f1score: 0.9493\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9572 - f1score: 0.9572\n",
      "Epoch 00020: val_acc did not improve from 0.95762\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1217 - acc: 0.9574 - f1score: 0.9576 - val_loss: 0.1397 - val_acc: 0.9480 - val_f1score: 0.9486\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9609 - f1score: 0.9609\n",
      "Epoch 00021: val_acc improved from 0.95762 to 0.96030, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.21-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1180 - acc: 0.9611 - f1score: 0.9613 - val_loss: 0.1448 - val_acc: 0.9603 - val_f1score: 0.9599\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9609 - f1score: 0.9609\n",
      "Epoch 00022: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1182 - acc: 0.9606 - f1score: 0.9602 - val_loss: 0.1376 - val_acc: 0.9523 - val_f1score: 0.9504\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9623 - f1score: 0.9623\n",
      "Epoch 00023: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1175 - acc: 0.9630 - f1score: 0.9635 - val_loss: 0.1370 - val_acc: 0.9474 - val_f1score: 0.9488\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9620 - f1score: 0.9620\n",
      "Epoch 00024: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1187 - acc: 0.9611 - f1score: 0.9603 - val_loss: 0.1338 - val_acc: 0.9555 - val_f1score: 0.9555\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00025: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1158 - acc: 0.9603 - f1score: 0.9604 - val_loss: 0.1408 - val_acc: 0.9560 - val_f1score: 0.9565\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9620 - f1score: 0.9620\n",
      "Epoch 00026: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1161 - acc: 0.9627 - f1score: 0.9633 - val_loss: 0.1373 - val_acc: 0.9539 - val_f1score: 0.9545\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9599 - f1score: 0.9598\n",
      "Epoch 00027: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1149 - acc: 0.9590 - f1score: 0.9582 - val_loss: 0.1355 - val_acc: 0.9549 - val_f1score: 0.9562\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9593 - f1score: 0.9594\n",
      "Epoch 00028: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1139 - acc: 0.9595 - f1score: 0.9598 - val_loss: 0.1361 - val_acc: 0.9603 - val_f1score: 0.9610\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00029: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1189 - acc: 0.9619 - f1score: 0.9620 - val_loss: 0.1332 - val_acc: 0.9555 - val_f1score: 0.9543\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9609 - f1score: 0.9609\n",
      "Epoch 00030: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1133 - acc: 0.9606 - f1score: 0.9603 - val_loss: 0.1365 - val_acc: 0.9560 - val_f1score: 0.9565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|         | 22/1296 [1:02:24<89:48:59, 253.80s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 4.2742 - acc: 0.4523 - f1score: 0.3358\n",
      "Epoch 00001: val_acc improved from -inf to 0.61964, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-1.61.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 4.2205 - acc: 0.4563 - f1score: 0.3457 - val_loss: 1.6069 - val_acc: 0.6196 - val_f1score: 0.6118\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8333 - acc: 0.8112 - f1score: 0.8124\n",
      "Epoch 00002: val_acc improved from 0.61964 to 0.91255, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.45.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.8208 - acc: 0.8138 - f1score: 0.8172 - val_loss: 0.4467 - val_acc: 0.9126 - val_f1score: 0.9136\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3332 - acc: 0.9348 - f1score: 0.9342\n",
      "Epoch 00003: val_acc improved from 0.91255 to 0.92758, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.40.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.3364 - acc: 0.9349 - f1score: 0.9344 - val_loss: 0.4045 - val_acc: 0.9276 - val_f1score: 0.9272\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2926 - acc: 0.9442 - f1score: 0.9442\n",
      "Epoch 00004: val_acc improved from 0.92758 to 0.93240, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.33.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2891 - acc: 0.9447 - f1score: 0.9451 - val_loss: 0.3323 - val_acc: 0.9324 - val_f1score: 0.9329\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2362 - acc: 0.9512 - f1score: 0.9513\n",
      "Epoch 00005: val_acc improved from 0.93240 to 0.94313, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.24.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2372 - acc: 0.9511 - f1score: 0.9509 - val_loss: 0.2398 - val_acc: 0.9431 - val_f1score: 0.9444\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1927 - acc: 0.9520 - f1score: 0.9519\n",
      "Epoch 00006: val_acc improved from 0.94313 to 0.94903, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.20.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1922 - acc: 0.9519 - f1score: 0.9516 - val_loss: 0.2010 - val_acc: 0.9490 - val_f1score: 0.9487\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9577 - f1score: 0.9577\n",
      "Epoch 00007: val_acc did not improve from 0.94903\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1647 - acc: 0.9558 - f1score: 0.9542 - val_loss: 0.2126 - val_acc: 0.9297 - val_f1score: 0.9282\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9542 - f1score: 0.9540\n",
      "Epoch 00008: val_acc improved from 0.94903 to 0.95064, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.15.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1504 - acc: 0.9545 - f1score: 0.9545 - val_loss: 0.1504 - val_acc: 0.9506 - val_f1score: 0.9518\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9591 - f1score: 0.9590\n",
      "Epoch 00009: val_acc improved from 0.95064 to 0.95333, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.14.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1333 - acc: 0.9593 - f1score: 0.9594 - val_loss: 0.1385 - val_acc: 0.9533 - val_f1score: 0.9538\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9585 - f1score: 0.9584\n",
      "Epoch 00010: val_acc improved from 0.95333 to 0.96513, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.14.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1244 - acc: 0.9590 - f1score: 0.9593 - val_loss: 0.1380 - val_acc: 0.9651 - val_f1score: 0.9636\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9636 - f1score: 0.9635\n",
      "Epoch 00011: val_acc did not improve from 0.96513\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1198 - acc: 0.9643 - f1score: 0.9648 - val_loss: 0.1255 - val_acc: 0.9576 - val_f1score: 0.9578\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9688 - f1score: 0.9687\n",
      "Epoch 00012: val_acc did not improve from 0.96513\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1139 - acc: 0.9683 - f1score: 0.9678 - val_loss: 0.1261 - val_acc: 0.9496 - val_f1score: 0.9486\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00013: val_acc improved from 0.96513 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1137 - acc: 0.9646 - f1score: 0.9637 - val_loss: 0.1232 - val_acc: 0.9678 - val_f1score: 0.9674\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9663 - f1score: 0.9663\n",
      "Epoch 00014: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1105 - acc: 0.9659 - f1score: 0.9655 - val_loss: 0.1230 - val_acc: 0.9490 - val_f1score: 0.9480\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9669 - f1score: 0.9669\n",
      "Epoch 00015: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1078 - acc: 0.9675 - f1score: 0.9680 - val_loss: 0.1165 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9682 - f1score: 0.9683\n",
      "Epoch 00016: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1032 - acc: 0.9683 - f1score: 0.9683 - val_loss: 0.1221 - val_acc: 0.9635 - val_f1score: 0.9630\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00017: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1054 - acc: 0.9683 - f1score: 0.9674 - val_loss: 0.1167 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9706 - f1score: 0.9707\n",
      "Epoch 00018: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1033 - acc: 0.9712 - f1score: 0.9716 - val_loss: 0.1137 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9701 - f1score: 0.9701\n",
      "Epoch 00019: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1021 - acc: 0.9706 - f1score: 0.9711 - val_loss: 0.1127 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00020: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1010 - acc: 0.9714 - f1score: 0.9719 - val_loss: 0.1130 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00021: val_acc improved from 0.96781 to 0.96835, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.21-0.11.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1025 - acc: 0.9698 - f1score: 0.9699 - val_loss: 0.1084 - val_acc: 0.9683 - val_f1score: 0.9668\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00022: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0994 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1073 - val_acc: 0.9641 - val_f1score: 0.9635\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00023: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0987 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1080 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00024: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0983 - acc: 0.9714 - f1score: 0.9719 - val_loss: 0.1057 - val_acc: 0.9683 - val_f1score: 0.9676\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9712 - f1score: 0.9712\n",
      "Epoch 00025: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0974 - acc: 0.9709 - f1score: 0.9706 - val_loss: 0.1064 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00026: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0977 - acc: 0.9698 - f1score: 0.9689 - val_loss: 0.1101 - val_acc: 0.9651 - val_f1score: 0.9662\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00027: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0950 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1067 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00028: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0957 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1067 - val_acc: 0.9667 - val_f1score: 0.9676\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9717 - f1score: 0.9717\n",
      "Epoch 00029: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0955 - acc: 0.9722 - f1score: 0.9727 - val_loss: 0.1052 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9728 - f1score: 0.9728\n",
      "Epoch 00030: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0944 - acc: 0.9728 - f1score: 0.9727 - val_loss: 0.1083 - val_acc: 0.9678 - val_f1score: 0.9671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|         | 23/1296 [1:07:49<97:16:37, 275.10s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.7826 - acc: 0.7126 - f1score: 0.7273\n",
      "Epoch 00001: val_acc improved from -inf to 0.81223, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-1.27.h5\n",
      "1890/1890 [==============================] - 12s 7ms/sample - loss: 1.7707 - acc: 0.7159 - f1score: 0.7331 - val_loss: 1.2699 - val_acc: 0.8122 - val_f1score: 0.8249\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7159 - acc: 0.8672 - f1score: 0.8681\n",
      "Epoch 00002: val_acc improved from 0.81223 to 0.87768, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.41.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.7095 - acc: 0.8677 - f1score: 0.8690 - val_loss: 0.4080 - val_acc: 0.8777 - val_f1score: 0.8676\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2740 - acc: 0.9146 - f1score: 0.9097\n",
      "Epoch 00003: val_acc improved from 0.87768 to 0.93026, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.23.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2748 - acc: 0.9146 - f1score: 0.9098 - val_loss: 0.2320 - val_acc: 0.9303 - val_f1score: 0.9309\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9415 - f1score: 0.9416\n",
      "Epoch 00004: val_acc improved from 0.93026 to 0.94045, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.20.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1974 - acc: 0.9415 - f1score: 0.9416 - val_loss: 0.2012 - val_acc: 0.9405 - val_f1score: 0.9400\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1665 - acc: 0.9531 - f1score: 0.9533\n",
      "Epoch 00005: val_acc improved from 0.94045 to 0.94260, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.21.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1646 - acc: 0.9540 - f1score: 0.9548 - val_loss: 0.2072 - val_acc: 0.9426 - val_f1score: 0.9428\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9529 - f1score: 0.9530\n",
      "Epoch 00006: val_acc improved from 0.94260 to 0.95440, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.16.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1459 - acc: 0.9532 - f1score: 0.9536 - val_loss: 0.1587 - val_acc: 0.9544 - val_f1score: 0.9555\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.9601 - f1score: 0.9603\n",
      "Epoch 00007: val_acc did not improve from 0.95440\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1416 - acc: 0.9608 - f1score: 0.9616 - val_loss: 0.1457 - val_acc: 0.9523 - val_f1score: 0.9528\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9596 - f1score: 0.9597\n",
      "Epoch 00008: val_acc did not improve from 0.95440\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1354 - acc: 0.9587 - f1score: 0.9581 - val_loss: 0.2189 - val_acc: 0.9421 - val_f1score: 0.9430\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9566 - f1score: 0.9567\n",
      "Epoch 00009: val_acc did not improve from 0.95440\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1451 - acc: 0.9563 - f1score: 0.9561 - val_loss: 0.1402 - val_acc: 0.9512 - val_f1score: 0.9506\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9609 - f1score: 0.9610\n",
      "Epoch 00010: val_acc did not improve from 0.95440\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1237 - acc: 0.9611 - f1score: 0.9613 - val_loss: 0.1453 - val_acc: 0.9539 - val_f1score: 0.9543\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00011: val_acc improved from 0.95440 to 0.95708, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.11-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1320 - acc: 0.9598 - f1score: 0.9600 - val_loss: 0.1347 - val_acc: 0.9571 - val_f1score: 0.9574\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00012: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1293 - acc: 0.9646 - f1score: 0.9646 - val_loss: 0.1330 - val_acc: 0.9501 - val_f1score: 0.9509\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9636 - f1score: 0.9637\n",
      "Epoch 00013: val_acc improved from 0.95708 to 0.96352, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.14.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1190 - acc: 0.9638 - f1score: 0.9639 - val_loss: 0.1427 - val_acc: 0.9635 - val_f1score: 0.9638\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9604 - f1score: 0.9604\n",
      "Epoch 00014: val_acc did not improve from 0.96352\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1210 - acc: 0.9601 - f1score: 0.9597 - val_loss: 0.1576 - val_acc: 0.9496 - val_f1score: 0.9502\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00015: val_acc improved from 0.96352 to 0.96406, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.15-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1187 - acc: 0.9672 - f1score: 0.9668 - val_loss: 0.1283 - val_acc: 0.9641 - val_f1score: 0.9644\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00016: val_acc did not improve from 0.96406\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1097 - acc: 0.9669 - f1score: 0.9667 - val_loss: 0.1256 - val_acc: 0.9523 - val_f1score: 0.9526\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9642 - f1score: 0.9642\n",
      "Epoch 00017: val_acc did not improve from 0.96406\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1110 - acc: 0.9643 - f1score: 0.9644 - val_loss: 0.1383 - val_acc: 0.9598 - val_f1score: 0.9586\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9669 - f1score: 0.9668\n",
      "Epoch 00018: val_acc did not improve from 0.96406\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1067 - acc: 0.9669 - f1score: 0.9669 - val_loss: 0.1194 - val_acc: 0.9592 - val_f1score: 0.9570\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00019: val_acc did not improve from 0.96406\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1076 - acc: 0.9664 - f1score: 0.9662 - val_loss: 0.1656 - val_acc: 0.9506 - val_f1score: 0.9505\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9679 - f1score: 0.9679\n",
      "Epoch 00020: val_acc improved from 0.96406 to 0.96620, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.20-0.12.h5\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1060 - acc: 0.9685 - f1score: 0.9690 - val_loss: 0.1157 - val_acc: 0.9662 - val_f1score: 0.9664\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9688 - f1score: 0.9687\n",
      "Epoch 00021: val_acc improved from 0.96620 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.21-0.11.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1019 - acc: 0.9688 - f1score: 0.9688 - val_loss: 0.1142 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9679 - f1score: 0.9679\n",
      "Epoch 00022: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1026 - acc: 0.9680 - f1score: 0.9680 - val_loss: 0.1133 - val_acc: 0.9678 - val_f1score: 0.9680\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00023: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1015 - acc: 0.9730 - f1score: 0.9730 - val_loss: 0.1131 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9717 - f1score: 0.9717\n",
      "Epoch 00024: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0957 - acc: 0.9722 - f1score: 0.9726 - val_loss: 0.1108 - val_acc: 0.9673 - val_f1score: 0.9666\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9717 - f1score: 0.9717\n",
      "Epoch 00025: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0955 - acc: 0.9722 - f1score: 0.9727 - val_loss: 0.1072 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00026: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0945 - acc: 0.9720 - f1score: 0.9710 - val_loss: 0.1068 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00027: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0961 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1165 - val_acc: 0.9641 - val_f1score: 0.9643\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9733 - f1score: 0.9733\n",
      "Epoch 00028: val_acc improved from 0.96781 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.28-0.12.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1007 - acc: 0.9728 - f1score: 0.9723 - val_loss: 0.1170 - val_acc: 0.9689 - val_f1score: 0.9689\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9728 - f1score: 0.9728\n",
      "Epoch 00029: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0969 - acc: 0.9717 - f1score: 0.9708 - val_loss: 0.1073 - val_acc: 0.9657 - val_f1score: 0.9635\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9723 - f1score: 0.9723\n",
      "Epoch 00030: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0981 - acc: 0.9722 - f1score: 0.9722 - val_loss: 0.1079 - val_acc: 0.9678 - val_f1score: 0.9671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|         | 24/1296 [1:13:15<102:32:58, 290.23s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.9972 - acc: 0.7872 - f1score: 0.7872\n",
      "Epoch 00001: val_acc improved from -inf to 0.86051, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.41.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.9850 - acc: 0.7889 - f1score: 0.7903 - val_loss: 0.4052 - val_acc: 0.8605 - val_f1score: 0.8597\n",
      "Epoch 2/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2657 - acc: 0.9186 - f1score: 0.9186\n",
      "Epoch 00002: val_acc improved from 0.86051 to 0.93455, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.21.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.2636 - acc: 0.9196 - f1score: 0.9204 - val_loss: 0.2080 - val_acc: 0.9345 - val_f1score: 0.9340\n",
      "Epoch 3/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9434 - f1score: 0.9434\n",
      "Epoch 00003: val_acc improved from 0.93455 to 0.94313, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.18.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1714 - acc: 0.9429 - f1score: 0.9424 - val_loss: 0.1773 - val_acc: 0.9431 - val_f1score: 0.9440\n",
      "Epoch 4/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9531 - f1score: 0.9531\n",
      "Epoch 00004: val_acc improved from 0.94313 to 0.94742, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.18.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1542 - acc: 0.9529 - f1score: 0.9527 - val_loss: 0.1762 - val_acc: 0.9474 - val_f1score: 0.9465\n",
      "Epoch 5/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9580 - f1score: 0.9580\n",
      "Epoch 00005: val_acc did not improve from 0.94742\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1443 - acc: 0.9577 - f1score: 0.9574 - val_loss: 0.1540 - val_acc: 0.9453 - val_f1score: 0.9461\n",
      "Epoch 6/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9574 - f1score: 0.9574\n",
      "Epoch 00006: val_acc improved from 0.94742 to 0.95064, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.16.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1466 - acc: 0.9577 - f1score: 0.9579 - val_loss: 0.1570 - val_acc: 0.9506 - val_f1score: 0.9513\n",
      "Epoch 7/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9607 - f1score: 0.9607\n",
      "Epoch 00007: val_acc did not improve from 0.95064\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1322 - acc: 0.9608 - f1score: 0.9610 - val_loss: 0.1715 - val_acc: 0.9442 - val_f1score: 0.9450\n",
      "Epoch 8/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00008: val_acc did not improve from 0.95064\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1270 - acc: 0.9624 - f1score: 0.9621 - val_loss: 0.2030 - val_acc: 0.9324 - val_f1score: 0.9311\n",
      "Epoch 9/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00009: val_acc improved from 0.95064 to 0.96567, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1232 - acc: 0.9608 - f1score: 0.9601 - val_loss: 0.1396 - val_acc: 0.9657 - val_f1score: 0.9659\n",
      "Epoch 10/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00010: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1202 - acc: 0.9646 - f1score: 0.9637 - val_loss: 0.2529 - val_acc: 0.8873 - val_f1score: 0.8866\n",
      "Epoch 11/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00011: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1210 - acc: 0.9677 - f1score: 0.9673 - val_loss: 0.1751 - val_acc: 0.9464 - val_f1score: 0.9463\n",
      "Epoch 12/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00012: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1114 - acc: 0.9677 - f1score: 0.9682 - val_loss: 0.1224 - val_acc: 0.9657 - val_f1score: 0.9667\n",
      "Epoch 13/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00013: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1114 - acc: 0.9688 - f1score: 0.9674 - val_loss: 0.1667 - val_acc: 0.9399 - val_f1score: 0.9392\n",
      "Epoch 14/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00014: val_acc improved from 0.96567 to 0.96674, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.14-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1083 - acc: 0.9688 - f1score: 0.9693 - val_loss: 0.1134 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 15/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00015: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1026 - acc: 0.9683 - f1score: 0.9683 - val_loss: 0.1190 - val_acc: 0.9624 - val_f1score: 0.9619\n",
      "Epoch 16/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00016: val_acc improved from 0.96674 to 0.96996, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.16-0.12.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1027 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1194 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 17/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00017: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1111 - acc: 0.9683 - f1score: 0.9651 - val_loss: 0.6944 - val_acc: 0.8948 - val_f1score: 0.8939\n",
      "Epoch 18/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1531 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00018: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1552 - acc: 0.9608 - f1score: 0.9601 - val_loss: 0.1128 - val_acc: 0.9657 - val_f1score: 0.9659\n",
      "Epoch 19/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00019: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0999 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1087 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 20/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00020: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0981 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1117 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 21/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00021: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0972 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1160 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 22/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00022: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0944 - acc: 0.9698 - f1score: 0.9703 - val_loss: 0.1165 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 23/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00023: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0979 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1132 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 24/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00024: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0972 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1147 - val_acc: 0.9678 - val_f1score: 0.9688\n",
      "Epoch 25/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9747 - f1score: 0.9747\n",
      "Epoch 00025: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0928 - acc: 0.9741 - f1score: 0.9736 - val_loss: 0.1082 - val_acc: 0.9646 - val_f1score: 0.9640\n",
      "Epoch 26/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00026: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0959 - acc: 0.9730 - f1score: 0.9730 - val_loss: 0.1274 - val_acc: 0.9549 - val_f1score: 0.9562\n",
      "Epoch 27/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00027: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0926 - acc: 0.9735 - f1score: 0.9730 - val_loss: 0.1216 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 28/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00028: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0942 - acc: 0.9698 - f1score: 0.9694 - val_loss: 0.1337 - val_acc: 0.9549 - val_f1score: 0.9562\n",
      "Epoch 29/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00029: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0964 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1066 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 30/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00030: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0973 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1068 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 31/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00031: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0931 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1058 - val_acc: 0.9657 - val_f1score: 0.9650\n",
      "Epoch 32/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00032: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0890 - acc: 0.9730 - f1score: 0.9725 - val_loss: 0.1078 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 33/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9752 - f1score: 0.9752\n",
      "Epoch 00033: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0925 - acc: 0.9746 - f1score: 0.9741 - val_loss: 0.1062 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 34/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00034: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0937 - acc: 0.9714 - f1score: 0.9719 - val_loss: 0.1214 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 35/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00035: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0950 - acc: 0.9714 - f1score: 0.9710 - val_loss: 0.1184 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 36/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00036: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0910 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1151 - val_acc: 0.9689 - val_f1score: 0.9666\n",
      "Epoch 37/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00037: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0931 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1067 - val_acc: 0.9689 - val_f1score: 0.9674\n",
      "Epoch 38/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00038: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0928 - acc: 0.9741 - f1score: 0.9740 - val_loss: 0.1085 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 39/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00039: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0916 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1218 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 40/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00040: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0927 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1143 - val_acc: 0.9678 - val_f1score: 0.9663\n",
      "Epoch 41/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00041: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0944 - acc: 0.9730 - f1score: 0.9725 - val_loss: 0.1066 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 42/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9752 - f1score: 0.9752\n",
      "Epoch 00042: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0906 - acc: 0.9757 - f1score: 0.9760 - val_loss: 0.1077 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 43/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9758 - f1score: 0.9758\n",
      "Epoch 00043: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0901 - acc: 0.9762 - f1score: 0.9766 - val_loss: 0.1093 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 44/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00044: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0914 - acc: 0.9735 - f1score: 0.9740 - val_loss: 0.1172 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 45/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00045: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0914 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1111 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 46/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00046: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0906 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1110 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 47/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00047: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0931 - acc: 0.9735 - f1score: 0.9735 - val_loss: 0.1048 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 48/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00048: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0897 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1046 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 49/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00049: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0911 - acc: 0.9730 - f1score: 0.9730 - val_loss: 0.1065 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 50/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9747 - f1score: 0.9747\n",
      "Epoch 00050: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0900 - acc: 0.9751 - f1score: 0.9755 - val_loss: 0.1141 - val_acc: 0.9678 - val_f1score: 0.9679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|         | 25/1296 [1:19:50<113:33:04, 321.62s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8672 - acc: 0.7177 - f1score: 0.7177\n",
      "Epoch 00001: val_acc improved from -inf to 0.83691, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.51.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.8603 - acc: 0.7201 - f1score: 0.7222 - val_loss: 0.5080 - val_acc: 0.8369 - val_f1score: 0.8384\n",
      "Epoch 2/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3428 - acc: 0.8998 - f1score: 0.8998\n",
      "Epoch 00002: val_acc improved from 0.83691 to 0.91524, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.28.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.3399 - acc: 0.9000 - f1score: 0.9002 - val_loss: 0.2759 - val_acc: 0.9152 - val_f1score: 0.9153\n",
      "Epoch 3/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9364 - f1score: 0.9364\n",
      "Epoch 00003: val_acc improved from 0.91524 to 0.93884, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.18.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1974 - acc: 0.9354 - f1score: 0.9346 - val_loss: 0.1835 - val_acc: 0.9388 - val_f1score: 0.9398\n",
      "Epoch 4/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9494 - f1score: 0.9494\n",
      "Epoch 00004: val_acc did not improve from 0.93884\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1644 - acc: 0.9481 - f1score: 0.9471 - val_loss: 0.1822 - val_acc: 0.9345 - val_f1score: 0.9340\n",
      "Epoch 5/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9569 - f1score: 0.9569\n",
      "Epoch 00005: val_acc improved from 0.93884 to 0.94528, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.16.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1479 - acc: 0.9566 - f1score: 0.9564 - val_loss: 0.1586 - val_acc: 0.9453 - val_f1score: 0.9444\n",
      "Epoch 6/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00006: val_acc improved from 0.94528 to 0.95064, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1403 - acc: 0.9624 - f1score: 0.9630 - val_loss: 0.1428 - val_acc: 0.9506 - val_f1score: 0.9488\n",
      "Epoch 7/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00007: val_acc improved from 0.95064 to 0.96567, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.14.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1416 - acc: 0.9619 - f1score: 0.9611 - val_loss: 0.1448 - val_acc: 0.9657 - val_f1score: 0.9667\n",
      "Epoch 8/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1347 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00008: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1336 - acc: 0.9661 - f1score: 0.9662 - val_loss: 0.1554 - val_acc: 0.9582 - val_f1score: 0.9586\n",
      "Epoch 9/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00009: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1240 - acc: 0.9656 - f1score: 0.9652 - val_loss: 0.1285 - val_acc: 0.9571 - val_f1score: 0.9567\n",
      "Epoch 10/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00010: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1350 - acc: 0.9646 - f1score: 0.9651 - val_loss: 0.1420 - val_acc: 0.9635 - val_f1score: 0.9646\n",
      "Epoch 11/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00011: val_acc improved from 0.96567 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.11-0.12.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1185 - acc: 0.9677 - f1score: 0.9678 - val_loss: 0.1205 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 12/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9688 - f1score: 0.9687\n",
      "Epoch 00012: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1109 - acc: 0.9693 - f1score: 0.9698 - val_loss: 0.1271 - val_acc: 0.9657 - val_f1score: 0.9659\n",
      "Epoch 13/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00013: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1179 - acc: 0.9661 - f1score: 0.9662 - val_loss: 0.1186 - val_acc: 0.9635 - val_f1score: 0.9646\n",
      "Epoch 14/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00014: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1204 - acc: 0.9651 - f1score: 0.9656 - val_loss: 0.1148 - val_acc: 0.9614 - val_f1score: 0.9593\n",
      "Epoch 15/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00015: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1161 - acc: 0.9709 - f1score: 0.9714 - val_loss: 0.1615 - val_acc: 0.9421 - val_f1score: 0.9421\n",
      "Epoch 16/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00016: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1074 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1192 - val_acc: 0.9571 - val_f1score: 0.9567\n",
      "Epoch 17/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00017: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1056 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1130 - val_acc: 0.9614 - val_f1score: 0.9617\n",
      "Epoch 18/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00018: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1045 - acc: 0.9704 - f1score: 0.9695 - val_loss: 0.1144 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 19/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00019: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1044 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1243 - val_acc: 0.9517 - val_f1score: 0.9523\n",
      "Epoch 20/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00020: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1056 - acc: 0.9688 - f1score: 0.9693 - val_loss: 0.1090 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 21/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00021: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1026 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1202 - val_acc: 0.9657 - val_f1score: 0.9642\n",
      "Epoch 22/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0998 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00022: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1006 - acc: 0.9688 - f1score: 0.9684 - val_loss: 0.1102 - val_acc: 0.9667 - val_f1score: 0.9653\n",
      "Epoch 23/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00023: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0997 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1090 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 24/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00024: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0986 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1084 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 25/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00025: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1089 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1181 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 26/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00026: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1053 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1238 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 27/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00027: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1008 - acc: 0.9688 - f1score: 0.9693 - val_loss: 0.1377 - val_acc: 0.9592 - val_f1score: 0.9596\n",
      "Epoch 28/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00028: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1045 - acc: 0.9735 - f1score: 0.9735 - val_loss: 0.1070 - val_acc: 0.9657 - val_f1score: 0.9634\n",
      "Epoch 29/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00029: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1006 - acc: 0.9714 - f1score: 0.9710 - val_loss: 0.1065 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 30/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00030: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1028 - acc: 0.9698 - f1score: 0.9699 - val_loss: 0.1219 - val_acc: 0.9657 - val_f1score: 0.9667\n",
      "Epoch 31/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00031: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0947 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1090 - val_acc: 0.9678 - val_f1score: 0.9663\n",
      "Epoch 32/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9752 - f1score: 0.9752\n",
      "Epoch 00032: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0964 - acc: 0.9746 - f1score: 0.9741 - val_loss: 0.1109 - val_acc: 0.9624 - val_f1score: 0.9619\n",
      "Epoch 33/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00033: val_acc improved from 0.96781 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.33-0.12.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1006 - acc: 0.9714 - f1score: 0.9710 - val_loss: 0.1246 - val_acc: 0.9689 - val_f1score: 0.9674\n",
      "Epoch 34/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00034: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1023 - acc: 0.9688 - f1score: 0.9693 - val_loss: 0.1044 - val_acc: 0.9678 - val_f1score: 0.9663\n",
      "Epoch 35/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9752 - f1score: 0.9752\n",
      "Epoch 00035: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0959 - acc: 0.9746 - f1score: 0.9741 - val_loss: 0.1066 - val_acc: 0.9689 - val_f1score: 0.9674\n",
      "Epoch 36/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00036: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1019 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1088 - val_acc: 0.9657 - val_f1score: 0.9659\n",
      "Epoch 37/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00037: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0960 - acc: 0.9709 - f1score: 0.9714 - val_loss: 0.1059 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 38/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00038: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0969 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1292 - val_acc: 0.9549 - val_f1score: 0.9554\n",
      "Epoch 39/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9763 - f1score: 0.9763\n",
      "Epoch 00039: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0990 - acc: 0.9751 - f1score: 0.9741 - val_loss: 0.1662 - val_acc: 0.9517 - val_f1score: 0.9507\n",
      "Epoch 40/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00040: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1027 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1300 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 41/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00041: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0952 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1062 - val_acc: 0.9646 - val_f1score: 0.9640\n",
      "Epoch 42/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00042: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0941 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1061 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 43/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00043: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0938 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1101 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 44/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00044: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0911 - acc: 0.9746 - f1score: 0.9750 - val_loss: 0.1110 - val_acc: 0.9689 - val_f1score: 0.9666\n",
      "Epoch 45/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9747 - f1score: 0.9747\n",
      "Epoch 00045: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0959 - acc: 0.9751 - f1score: 0.9755 - val_loss: 0.1709 - val_acc: 0.9506 - val_f1score: 0.9505\n",
      "Epoch 46/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00046: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1058 - acc: 0.9693 - f1score: 0.9693 - val_loss: 0.1118 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 47/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00047: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0939 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1122 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 48/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00048: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0992 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1062 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 49/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9758 - f1score: 0.9758\n",
      "Epoch 00049: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0952 - acc: 0.9757 - f1score: 0.9756 - val_loss: 0.1095 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 50/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00050: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0942 - acc: 0.9709 - f1score: 0.9704 - val_loss: 0.1297 - val_acc: 0.9657 - val_f1score: 0.9659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|         | 26/1296 [1:26:19<120:39:54, 342.04s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.9962 - acc: 0.5119 - f1score: 0.5119\n",
      "Epoch 00001: val_acc improved from -inf to 0.89056, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.33.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 2.9465 - acc: 0.5196 - f1score: 0.5262 - val_loss: 0.3330 - val_acc: 0.8906 - val_f1score: 0.8897\n",
      "Epoch 2/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2316 - acc: 0.9300 - f1score: 0.9300\n",
      "Epoch 00002: val_acc improved from 0.89056 to 0.94313, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.20.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.2304 - acc: 0.9307 - f1score: 0.9313 - val_loss: 0.1982 - val_acc: 0.9431 - val_f1score: 0.9432\n",
      "Epoch 3/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9445 - f1score: 0.9445\n",
      "Epoch 00003: val_acc improved from 0.94313 to 0.94528, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1769 - acc: 0.9450 - f1score: 0.9454 - val_loss: 0.1735 - val_acc: 0.9453 - val_f1score: 0.9444\n",
      "Epoch 4/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9499 - f1score: 0.9499\n",
      "Epoch 00004: val_acc improved from 0.94528 to 0.94957, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.17.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1554 - acc: 0.9492 - f1score: 0.9486 - val_loss: 0.1678 - val_acc: 0.9496 - val_f1score: 0.9502\n",
      "Epoch 5/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9537 - f1score: 0.9537\n",
      "Epoch 00005: val_acc did not improve from 0.94957\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1454 - acc: 0.9534 - f1score: 0.9532 - val_loss: 0.1650 - val_acc: 0.9421 - val_f1score: 0.9397\n",
      "Epoch 6/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9569 - f1score: 0.9569\n",
      "Epoch 00006: val_acc improved from 0.94957 to 0.96030, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.15.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1389 - acc: 0.9556 - f1score: 0.9544 - val_loss: 0.1496 - val_acc: 0.9603 - val_f1score: 0.9582\n",
      "Epoch 7/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00007: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1335 - acc: 0.9598 - f1score: 0.9595 - val_loss: 0.1559 - val_acc: 0.9453 - val_f1score: 0.9436\n",
      "Epoch 8/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00008: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1326 - acc: 0.9587 - f1score: 0.9589 - val_loss: 0.1516 - val_acc: 0.9453 - val_f1score: 0.9461\n",
      "Epoch 9/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00009: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1280 - acc: 0.9603 - f1score: 0.9609 - val_loss: 0.1456 - val_acc: 0.9517 - val_f1score: 0.9523\n",
      "Epoch 10/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00010: val_acc improved from 0.96030 to 0.96137, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.15.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1236 - acc: 0.9614 - f1score: 0.9615 - val_loss: 0.1510 - val_acc: 0.9614 - val_f1score: 0.9609\n",
      "Epoch 11/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9580 - f1score: 0.9580\n",
      "Epoch 00011: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1259 - acc: 0.9582 - f1score: 0.9584 - val_loss: 0.1468 - val_acc: 0.9560 - val_f1score: 0.9565\n",
      "Epoch 12/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9623 - f1score: 0.9623\n",
      "Epoch 00012: val_acc improved from 0.96137 to 0.96352, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.12-0.14.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1226 - acc: 0.9630 - f1score: 0.9635 - val_loss: 0.1372 - val_acc: 0.9635 - val_f1score: 0.9630\n",
      "Epoch 13/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00013: val_acc improved from 0.96352 to 0.96567, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.14.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1214 - acc: 0.9593 - f1score: 0.9590 - val_loss: 0.1423 - val_acc: 0.9657 - val_f1score: 0.9650\n",
      "Epoch 14/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00014: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1213 - acc: 0.9608 - f1score: 0.9605 - val_loss: 0.1464 - val_acc: 0.9614 - val_f1score: 0.9617\n",
      "Epoch 15/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00015: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1191 - acc: 0.9619 - f1score: 0.9620 - val_loss: 0.1411 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 16/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00016: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1164 - acc: 0.9630 - f1score: 0.9626 - val_loss: 0.1405 - val_acc: 0.9582 - val_f1score: 0.9578\n",
      "Epoch 17/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00017: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1185 - acc: 0.9635 - f1score: 0.9641 - val_loss: 0.1333 - val_acc: 0.9582 - val_f1score: 0.9578\n",
      "Epoch 18/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00018: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1157 - acc: 0.9608 - f1score: 0.9615 - val_loss: 0.1329 - val_acc: 0.9560 - val_f1score: 0.9541\n",
      "Epoch 19/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9623 - f1score: 0.9623\n",
      "Epoch 00019: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1147 - acc: 0.9624 - f1score: 0.9626 - val_loss: 0.1505 - val_acc: 0.9582 - val_f1score: 0.9578\n",
      "Epoch 20/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9650 - f1score: 0.9650\n",
      "Epoch 00020: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1150 - acc: 0.9656 - f1score: 0.9661 - val_loss: 0.1327 - val_acc: 0.9528 - val_f1score: 0.9542\n",
      "Epoch 21/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00021: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1135 - acc: 0.9603 - f1score: 0.9609 - val_loss: 0.1392 - val_acc: 0.9539 - val_f1score: 0.9552\n",
      "Epoch 22/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9650 - f1score: 0.9650\n",
      "Epoch 00022: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1149 - acc: 0.9646 - f1score: 0.9642 - val_loss: 0.1284 - val_acc: 0.9635 - val_f1score: 0.9646\n",
      "Epoch 23/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9623 - f1score: 0.9623\n",
      "Epoch 00023: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1122 - acc: 0.9619 - f1score: 0.9616 - val_loss: 0.1271 - val_acc: 0.9592 - val_f1score: 0.9596\n",
      "Epoch 24/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00024: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1140 - acc: 0.9608 - f1score: 0.9605 - val_loss: 0.1297 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 25/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00025: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1101 - acc: 0.9656 - f1score: 0.9657 - val_loss: 0.1293 - val_acc: 0.9571 - val_f1score: 0.9559\n",
      "Epoch 26/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9650 - f1score: 0.9650\n",
      "Epoch 00026: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1101 - acc: 0.9656 - f1score: 0.9661 - val_loss: 0.1302 - val_acc: 0.9549 - val_f1score: 0.9554\n",
      "Epoch 27/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9623 - f1score: 0.9623\n",
      "Epoch 00027: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1108 - acc: 0.9619 - f1score: 0.9616 - val_loss: 0.1276 - val_acc: 0.9549 - val_f1score: 0.9554\n",
      "Epoch 28/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00028: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1091 - acc: 0.9635 - f1score: 0.9636 - val_loss: 0.1304 - val_acc: 0.9560 - val_f1score: 0.9557\n",
      "Epoch 29/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9607 - f1score: 0.9607\n",
      "Epoch 00029: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1096 - acc: 0.9608 - f1score: 0.9610 - val_loss: 0.1258 - val_acc: 0.9635 - val_f1score: 0.9646\n",
      "Epoch 30/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00030: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1082 - acc: 0.9672 - f1score: 0.9668 - val_loss: 0.1262 - val_acc: 0.9614 - val_f1score: 0.9625\n",
      "Epoch 31/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1094 - acc: 0.9650 - f1score: 0.9650\n",
      "Epoch 00031: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1085 - acc: 0.9651 - f1score: 0.9652 - val_loss: 0.1272 - val_acc: 0.9614 - val_f1score: 0.9609\n",
      "Epoch 32/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00032: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1091 - acc: 0.9677 - f1score: 0.9682 - val_loss: 0.1253 - val_acc: 0.9657 - val_f1score: 0.9659\n",
      "Epoch 33/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00033: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1095 - acc: 0.9667 - f1score: 0.9667 - val_loss: 0.1241 - val_acc: 0.9560 - val_f1score: 0.9557\n",
      "Epoch 34/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00034: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1069 - acc: 0.9661 - f1score: 0.9662 - val_loss: 0.1245 - val_acc: 0.9560 - val_f1score: 0.9573\n",
      "Epoch 35/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00035: val_acc improved from 0.96567 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.35-0.13.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1092 - acc: 0.9667 - f1score: 0.9658 - val_loss: 0.1252 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 36/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00036: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1080 - acc: 0.9661 - f1score: 0.9667 - val_loss: 0.1250 - val_acc: 0.9667 - val_f1score: 0.9653\n",
      "Epoch 37/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00037: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1067 - acc: 0.9667 - f1score: 0.9663 - val_loss: 0.1240 - val_acc: 0.9528 - val_f1score: 0.9542\n",
      "Epoch 38/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00038: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1060 - acc: 0.9640 - f1score: 0.9637 - val_loss: 0.1305 - val_acc: 0.9635 - val_f1score: 0.9646\n",
      "Epoch 39/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00039: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1032 - acc: 0.9672 - f1score: 0.9663 - val_loss: 0.1373 - val_acc: 0.9464 - val_f1score: 0.9463\n",
      "Epoch 40/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00040: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1093 - acc: 0.9640 - f1score: 0.9637 - val_loss: 0.1224 - val_acc: 0.9614 - val_f1score: 0.9617\n",
      "Epoch 41/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00041: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1058 - acc: 0.9693 - f1score: 0.9689 - val_loss: 0.1268 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 42/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00042: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1058 - acc: 0.9661 - f1score: 0.9662 - val_loss: 0.1228 - val_acc: 0.9549 - val_f1score: 0.9538\n",
      "Epoch 43/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00043: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1058 - acc: 0.9646 - f1score: 0.9637 - val_loss: 0.1211 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 44/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00044: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1038 - acc: 0.9672 - f1score: 0.9677 - val_loss: 0.1317 - val_acc: 0.9635 - val_f1score: 0.9646\n",
      "Epoch 45/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00045: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1056 - acc: 0.9672 - f1score: 0.9677 - val_loss: 0.1268 - val_acc: 0.9657 - val_f1score: 0.9650\n",
      "Epoch 46/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00046: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1042 - acc: 0.9683 - f1score: 0.9688 - val_loss: 0.1199 - val_acc: 0.9592 - val_f1score: 0.9580\n",
      "Epoch 47/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00047: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1038 - acc: 0.9677 - f1score: 0.9678 - val_loss: 0.1272 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 48/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00048: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1033 - acc: 0.9672 - f1score: 0.9668 - val_loss: 0.1253 - val_acc: 0.9539 - val_f1score: 0.9536\n",
      "Epoch 49/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00049: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1045 - acc: 0.9677 - f1score: 0.9682 - val_loss: 0.1207 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 50/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00050: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1036 - acc: 0.9704 - f1score: 0.9699 - val_loss: 0.1215 - val_acc: 0.9539 - val_f1score: 0.9552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|         | 27/1296 [1:33:22<129:07:35, 366.32s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7209 - acc: 0.7392 - f1score: 0.7392\n",
      "Epoch 00001: val_acc improved from -inf to 0.86910, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.40.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.7165 - acc: 0.7407 - f1score: 0.7420 - val_loss: 0.3991 - val_acc: 0.8691 - val_f1score: 0.8681\n",
      "Epoch 2/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2573 - acc: 0.9181 - f1score: 0.9181\n",
      "Epoch 00002: val_acc improved from 0.86910 to 0.94099, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.19.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.2543 - acc: 0.9196 - f1score: 0.9208 - val_loss: 0.1938 - val_acc: 0.9410 - val_f1score: 0.9403\n",
      "Epoch 3/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1713 - acc: 0.9440 - f1score: 0.9440\n",
      "Epoch 00003: val_acc improved from 0.94099 to 0.94742, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.17.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1728 - acc: 0.9423 - f1score: 0.9409 - val_loss: 0.1712 - val_acc: 0.9474 - val_f1score: 0.9481\n",
      "Epoch 4/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9520 - f1score: 0.9520\n",
      "Epoch 00004: val_acc did not improve from 0.94742\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1516 - acc: 0.9513 - f1score: 0.9507 - val_loss: 0.1584 - val_acc: 0.9474 - val_f1score: 0.9473\n",
      "Epoch 5/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9537 - f1score: 0.9537\n",
      "Epoch 00005: val_acc improved from 0.94742 to 0.94957, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.15.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1406 - acc: 0.9534 - f1score: 0.9532 - val_loss: 0.1507 - val_acc: 0.9496 - val_f1score: 0.9510\n",
      "Epoch 6/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00006: val_acc did not improve from 0.94957\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1272 - acc: 0.9619 - f1score: 0.9602 - val_loss: 0.1593 - val_acc: 0.9485 - val_f1score: 0.9492\n",
      "Epoch 7/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9607 - f1score: 0.9607\n",
      "Epoch 00007: val_acc improved from 0.94957 to 0.95064, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1302 - acc: 0.9608 - f1score: 0.9610 - val_loss: 0.1336 - val_acc: 0.9506 - val_f1score: 0.9497\n",
      "Epoch 8/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00008: val_acc improved from 0.95064 to 0.96567, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.12.h5\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1171 - acc: 0.9640 - f1score: 0.9646 - val_loss: 0.1231 - val_acc: 0.9657 - val_f1score: 0.9667\n",
      "Epoch 9/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00009: val_acc improved from 0.96567 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.12.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1125 - acc: 0.9667 - f1score: 0.9663 - val_loss: 0.1196 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 10/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00010: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1168 - acc: 0.9688 - f1score: 0.9693 - val_loss: 0.1401 - val_acc: 0.9657 - val_f1score: 0.9642\n",
      "Epoch 11/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00011: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1104 - acc: 0.9672 - f1score: 0.9668 - val_loss: 0.1123 - val_acc: 0.9678 - val_f1score: 0.9663\n",
      "Epoch 12/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00012: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0998 - acc: 0.9693 - f1score: 0.9689 - val_loss: 0.1206 - val_acc: 0.9614 - val_f1score: 0.9625\n",
      "Epoch 13/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00013: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1109 - acc: 0.9698 - f1score: 0.9703 - val_loss: 0.1180 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 14/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9688 - f1score: 0.9687\n",
      "Epoch 00014: val_acc improved from 0.96781 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.14-0.12.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0980 - acc: 0.9688 - f1score: 0.9688 - val_loss: 0.1214 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 15/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00015: val_acc improved from 0.96888 to 0.96996, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.15-0.11.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1067 - acc: 0.9677 - f1score: 0.9678 - val_loss: 0.1094 - val_acc: 0.9700 - val_f1score: 0.9692\n",
      "Epoch 16/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00016: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0968 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1088 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 17/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00017: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0978 - acc: 0.9704 - f1score: 0.9699 - val_loss: 0.1068 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 18/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00018: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0963 - acc: 0.9714 - f1score: 0.9705 - val_loss: 0.1067 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 19/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00019: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0927 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1068 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 20/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00020: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0925 - acc: 0.9725 - f1score: 0.9715 - val_loss: 0.1067 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 21/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00021: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1093 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1590 - val_acc: 0.9614 - val_f1score: 0.9609\n",
      "Epoch 22/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00022: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1421 - acc: 0.9619 - f1score: 0.9620 - val_loss: 0.1295 - val_acc: 0.9549 - val_f1score: 0.9538\n",
      "Epoch 23/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00023: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0965 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1109 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 24/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0879 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00024: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0897 - acc: 0.9725 - f1score: 0.9715 - val_loss: 0.1221 - val_acc: 0.9571 - val_f1score: 0.9575\n",
      "Epoch 25/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00025: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0989 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1301 - val_acc: 0.9689 - val_f1score: 0.9674\n",
      "Epoch 26/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00026: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0994 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1220 - val_acc: 0.9549 - val_f1score: 0.9538\n",
      "Epoch 27/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00027: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0938 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1076 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 28/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00028: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0906 - acc: 0.9709 - f1score: 0.9714 - val_loss: 0.1054 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 29/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00029: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0901 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1122 - val_acc: 0.9592 - val_f1score: 0.9604\n",
      "Epoch 30/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00030: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0942 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1280 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 31/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00031: val_acc improved from 0.96996 to 0.97103, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.31-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0932 - acc: 0.9730 - f1score: 0.9730 - val_loss: 0.1118 - val_acc: 0.9710 - val_f1score: 0.9694\n",
      "Epoch 32/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00032: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0901 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1071 - val_acc: 0.9700 - val_f1score: 0.9684\n",
      "Epoch 33/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00033: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0902 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1101 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 34/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00034: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0946 - acc: 0.9714 - f1score: 0.9710 - val_loss: 0.1072 - val_acc: 0.9710 - val_f1score: 0.9711\n",
      "Epoch 35/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00035: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0959 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1085 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 36/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00036: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1065 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1113 - val_acc: 0.9657 - val_f1score: 0.9659\n",
      "Epoch 37/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00037: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0974 - acc: 0.9725 - f1score: 0.9715 - val_loss: 0.1131 - val_acc: 0.9592 - val_f1score: 0.9604\n",
      "Epoch 38/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00038: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0942 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1110 - val_acc: 0.9624 - val_f1score: 0.9619\n",
      "Epoch 39/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00039: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0890 - acc: 0.9741 - f1score: 0.9745 - val_loss: 0.1078 - val_acc: 0.9678 - val_f1score: 0.9655\n",
      "Epoch 40/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00040: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0922 - acc: 0.9741 - f1score: 0.9745 - val_loss: 0.1168 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 41/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00041: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0907 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1084 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 42/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9747 - f1score: 0.9747\n",
      "Epoch 00042: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0884 - acc: 0.9746 - f1score: 0.9745 - val_loss: 0.1187 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 43/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00043: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0886 - acc: 0.9730 - f1score: 0.9730 - val_loss: 0.1108 - val_acc: 0.9700 - val_f1score: 0.9692\n",
      "Epoch 44/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9752 - f1score: 0.9752\n",
      "Epoch 00044: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0916 - acc: 0.9746 - f1score: 0.9741 - val_loss: 0.1098 - val_acc: 0.9700 - val_f1score: 0.9692\n",
      "Epoch 45/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00045: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0915 - acc: 0.9709 - f1score: 0.9714 - val_loss: 0.1116 - val_acc: 0.9624 - val_f1score: 0.9619\n",
      "Epoch 46/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00046: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0920 - acc: 0.9735 - f1score: 0.9735 - val_loss: 0.1108 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 47/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00047: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0922 - acc: 0.9746 - f1score: 0.9750 - val_loss: 0.1142 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 48/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00048: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0897 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1287 - val_acc: 0.9582 - val_f1score: 0.9578\n",
      "Epoch 49/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00049: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0950 - acc: 0.9730 - f1score: 0.9725 - val_loss: 0.1389 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 50/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00050: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0875 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1207 - val_acc: 0.9689 - val_f1score: 0.9698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|         | 28/1296 [1:40:24<134:52:37, 382.93s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 5.4044 - acc: 0.5496 - f1score: 0.5496\n",
      "Epoch 00001: val_acc improved from -inf to 0.89592, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.59.h5\n",
      "1890/1890 [==============================] - 14s 8ms/sample - loss: 5.3202 - acc: 0.5566 - f1score: 0.5626 - val_loss: 0.5933 - val_acc: 0.8959 - val_f1score: 0.8949\n",
      "Epoch 2/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3095 - acc: 0.9203 - f1score: 0.9203\n",
      "Epoch 00002: val_acc improved from 0.89592 to 0.91202, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.25.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.3070 - acc: 0.9206 - f1score: 0.9210 - val_loss: 0.2456 - val_acc: 0.9120 - val_f1score: 0.9105\n",
      "Epoch 3/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9429 - f1score: 0.9429\n",
      "Epoch 00003: val_acc improved from 0.91202 to 0.94099, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.20.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.2019 - acc: 0.9429 - f1score: 0.9428 - val_loss: 0.1961 - val_acc: 0.9410 - val_f1score: 0.9395\n",
      "Epoch 4/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1616 - acc: 0.9547 - f1score: 0.9547\n",
      "Epoch 00004: val_acc did not improve from 0.94099\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1653 - acc: 0.9540 - f1score: 0.9533 - val_loss: 0.2570 - val_acc: 0.8573 - val_f1score: 0.8574\n",
      "Epoch 5/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9504 - f1score: 0.9504\n",
      "Epoch 00005: val_acc did not improve from 0.94099\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1500 - acc: 0.9508 - f1score: 0.9511 - val_loss: 0.1570 - val_acc: 0.9410 - val_f1score: 0.9419\n",
      "Epoch 6/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9542 - f1score: 0.9542\n",
      "Epoch 00006: val_acc improved from 0.94099 to 0.95815, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.16.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1427 - acc: 0.9545 - f1score: 0.9547 - val_loss: 0.1575 - val_acc: 0.9582 - val_f1score: 0.9594\n",
      "Epoch 7/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9564 - f1score: 0.9564\n",
      "Epoch 00007: val_acc improved from 0.95815 to 0.95923, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.18.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1385 - acc: 0.9561 - f1score: 0.9559 - val_loss: 0.1761 - val_acc: 0.9592 - val_f1score: 0.9588\n",
      "Epoch 8/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1307 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00008: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1314 - acc: 0.9598 - f1score: 0.9595 - val_loss: 0.1380 - val_acc: 0.9528 - val_f1score: 0.9534\n",
      "Epoch 9/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00009: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1245 - acc: 0.9630 - f1score: 0.9622 - val_loss: 0.1429 - val_acc: 0.9453 - val_f1score: 0.9461\n",
      "Epoch 10/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00010: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1239 - acc: 0.9656 - f1score: 0.9657 - val_loss: 0.1324 - val_acc: 0.9496 - val_f1score: 0.9502\n",
      "Epoch 11/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00011: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1253 - acc: 0.9619 - f1score: 0.9625 - val_loss: 0.1303 - val_acc: 0.9528 - val_f1score: 0.9542\n",
      "Epoch 12/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00012: val_acc improved from 0.95923 to 0.96674, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.12-0.14.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1136 - acc: 0.9651 - f1score: 0.9656 - val_loss: 0.1411 - val_acc: 0.9667 - val_f1score: 0.9645\n",
      "Epoch 13/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00013: val_acc improved from 0.96674 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.12.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1141 - acc: 0.9651 - f1score: 0.9656 - val_loss: 0.1189 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 14/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00014: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1095 - acc: 0.9688 - f1score: 0.9693 - val_loss: 0.1243 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 15/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00015: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1051 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1198 - val_acc: 0.9624 - val_f1score: 0.9627\n",
      "Epoch 16/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00016: val_acc improved from 0.96781 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.16-0.11.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1078 - acc: 0.9677 - f1score: 0.9678 - val_loss: 0.1098 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 17/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00017: val_acc improved from 0.96888 to 0.96996, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.17-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1033 - acc: 0.9698 - f1score: 0.9694 - val_loss: 0.1170 - val_acc: 0.9700 - val_f1score: 0.9692\n",
      "Epoch 18/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00018: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0990 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1293 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 19/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00019: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1056 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1086 - val_acc: 0.9689 - val_f1score: 0.9674\n",
      "Epoch 20/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00020: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0983 - acc: 0.9730 - f1score: 0.9725 - val_loss: 0.1196 - val_acc: 0.9700 - val_f1score: 0.9692\n",
      "Epoch 21/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00021: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0971 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1087 - val_acc: 0.9657 - val_f1score: 0.9667\n",
      "Epoch 22/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9688 - f1score: 0.9688\n",
      "Epoch 00022: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0985 - acc: 0.9683 - f1score: 0.9678 - val_loss: 0.1815 - val_acc: 0.9474 - val_f1score: 0.9481\n",
      "Epoch 23/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00023: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1058 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1114 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 24/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00024: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1008 - acc: 0.9688 - f1score: 0.9684 - val_loss: 0.1202 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 25/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00025: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0976 - acc: 0.9704 - f1score: 0.9695 - val_loss: 0.1098 - val_acc: 0.9700 - val_f1score: 0.9692\n",
      "Epoch 26/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00026: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1011 - acc: 0.9698 - f1score: 0.9699 - val_loss: 0.1086 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 27/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00027: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0993 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1609 - val_acc: 0.9421 - val_f1score: 0.9429\n",
      "Epoch 28/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00028: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0988 - acc: 0.9693 - f1score: 0.9693 - val_loss: 0.1131 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 29/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00029: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0914 - acc: 0.9735 - f1score: 0.9740 - val_loss: 0.1111 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 30/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0983 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00030: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1000 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1117 - val_acc: 0.9700 - val_f1score: 0.9684\n",
      "Epoch 31/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00031: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0984 - acc: 0.9714 - f1score: 0.9705 - val_loss: 0.1053 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 32/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00032: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0948 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1267 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 33/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00033: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0930 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1860 - val_acc: 0.9496 - val_f1score: 0.9502\n",
      "Epoch 34/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00034: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0968 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1095 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 35/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00035: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0994 - acc: 0.9698 - f1score: 0.9699 - val_loss: 0.1326 - val_acc: 0.9549 - val_f1score: 0.9538\n",
      "Epoch 36/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00036: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0974 - acc: 0.9693 - f1score: 0.9689 - val_loss: 0.1386 - val_acc: 0.9592 - val_f1score: 0.9596\n",
      "Epoch 37/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00037: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1016 - acc: 0.9683 - f1score: 0.9688 - val_loss: 0.1219 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 38/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00038: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0930 - acc: 0.9741 - f1score: 0.9745 - val_loss: 0.1132 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 39/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00039: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0921 - acc: 0.9693 - f1score: 0.9693 - val_loss: 0.1045 - val_acc: 0.9689 - val_f1score: 0.9674\n",
      "Epoch 40/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00040: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0969 - acc: 0.9714 - f1score: 0.9710 - val_loss: 0.1120 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 41/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00041: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0950 - acc: 0.9693 - f1score: 0.9680 - val_loss: 0.1088 - val_acc: 0.9700 - val_f1score: 0.9692\n",
      "Epoch 42/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00042: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0957 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1020 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 43/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00043: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0925 - acc: 0.9735 - f1score: 0.9735 - val_loss: 0.1063 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 44/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00044: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0908 - acc: 0.9741 - f1score: 0.9740 - val_loss: 0.1170 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 45/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00045: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0928 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1041 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 46/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00046: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0927 - acc: 0.9746 - f1score: 0.9750 - val_loss: 0.1107 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 47/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00047: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0922 - acc: 0.9709 - f1score: 0.9714 - val_loss: 0.1035 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 48/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00048: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0935 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1034 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 49/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00049: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0928 - acc: 0.9714 - f1score: 0.9710 - val_loss: 0.1053 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 50/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00050: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0964 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1137 - val_acc: 0.9689 - val_f1score: 0.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|         | 29/1296 [1:49:22<151:11:26, 429.59s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5458 - acc: 0.7904 - f1score: 0.7904\n",
      "Epoch 00001: val_acc improved from -inf to 0.90343, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.26.h5\n",
      "1890/1890 [==============================] - 14s 7ms/sample - loss: 0.5374 - acc: 0.7942 - f1score: 0.7974 - val_loss: 0.2631 - val_acc: 0.9034 - val_f1score: 0.9030\n",
      "Epoch 2/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1799 - acc: 0.9391 - f1score: 0.9391\n",
      "Epoch 00002: val_acc improved from 0.90343 to 0.94206, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1797 - acc: 0.9392 - f1score: 0.9392 - val_loss: 0.1707 - val_acc: 0.9421 - val_f1score: 0.9421\n",
      "Epoch 3/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1486 - acc: 0.9504 - f1score: 0.9504\n",
      "Epoch 00003: val_acc improved from 0.94206 to 0.94635, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.16.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1484 - acc: 0.9508 - f1score: 0.9511 - val_loss: 0.1560 - val_acc: 0.9464 - val_f1score: 0.9479\n",
      "Epoch 4/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9580 - f1score: 0.9580\n",
      "Epoch 00004: val_acc improved from 0.94635 to 0.96030, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.15.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1368 - acc: 0.9587 - f1score: 0.9594 - val_loss: 0.1499 - val_acc: 0.9603 - val_f1score: 0.9615\n",
      "Epoch 5/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1418 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00005: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1409 - acc: 0.9587 - f1score: 0.9589 - val_loss: 0.1501 - val_acc: 0.9592 - val_f1score: 0.9604\n",
      "Epoch 6/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00006: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1395 - acc: 0.9677 - f1score: 0.9673 - val_loss: 0.1335 - val_acc: 0.9603 - val_f1score: 0.9615\n",
      "Epoch 7/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00007: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1259 - acc: 0.9630 - f1score: 0.9631 - val_loss: 0.1444 - val_acc: 0.9464 - val_f1score: 0.9455\n",
      "Epoch 8/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00008: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1183 - acc: 0.9624 - f1score: 0.9612 - val_loss: 0.1318 - val_acc: 0.9560 - val_f1score: 0.9573\n",
      "Epoch 9/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00009: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1197 - acc: 0.9656 - f1score: 0.9652 - val_loss: 0.1300 - val_acc: 0.9539 - val_f1score: 0.9552\n",
      "Epoch 10/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00010: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1174 - acc: 0.9683 - f1score: 0.9688 - val_loss: 0.1346 - val_acc: 0.9603 - val_f1score: 0.9582\n",
      "Epoch 11/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00011: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1144 - acc: 0.9661 - f1score: 0.9648 - val_loss: 0.1205 - val_acc: 0.9549 - val_f1score: 0.9554\n",
      "Epoch 12/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00012: val_acc improved from 0.96030 to 0.96245, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.12-0.14.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1122 - acc: 0.9698 - f1score: 0.9694 - val_loss: 0.1389 - val_acc: 0.9624 - val_f1score: 0.9587\n",
      "Epoch 13/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00013: val_acc improved from 0.96245 to 0.96567, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.11.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1073 - acc: 0.9693 - f1score: 0.9693 - val_loss: 0.1139 - val_acc: 0.9657 - val_f1score: 0.9659\n",
      "Epoch 14/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00014: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1102 - acc: 0.9698 - f1score: 0.9703 - val_loss: 0.1301 - val_acc: 0.9657 - val_f1score: 0.9650\n",
      "Epoch 15/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00015: val_acc improved from 0.96567 to 0.96674, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.15-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.0972 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1244 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 16/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00016: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0978 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1086 - val_acc: 0.9657 - val_f1score: 0.9659\n",
      "Epoch 17/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00017: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0997 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1176 - val_acc: 0.9635 - val_f1score: 0.9646\n",
      "Epoch 18/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00018: val_acc improved from 0.96674 to 0.97103, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.18-0.11.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.0965 - acc: 0.9730 - f1score: 0.9725 - val_loss: 0.1074 - val_acc: 0.9710 - val_f1score: 0.9711\n",
      "Epoch 19/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00019: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1054 - acc: 0.9698 - f1score: 0.9689 - val_loss: 0.1379 - val_acc: 0.9549 - val_f1score: 0.9530\n",
      "Epoch 20/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00020: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1071 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1091 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 21/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00021: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1103 - acc: 0.9714 - f1score: 0.9710 - val_loss: 0.1205 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 22/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00022: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0959 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1118 - val_acc: 0.9635 - val_f1score: 0.9638\n",
      "Epoch 23/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00023: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1048 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1550 - val_acc: 0.9549 - val_f1score: 0.9563\n",
      "Epoch 24/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00024: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1015 - acc: 0.9693 - f1score: 0.9693 - val_loss: 0.1444 - val_acc: 0.9549 - val_f1score: 0.9546\n",
      "Epoch 25/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00025: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0929 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1104 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 26/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00026: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0914 - acc: 0.9735 - f1score: 0.9735 - val_loss: 0.1088 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 27/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00027: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1039 - acc: 0.9688 - f1score: 0.9684 - val_loss: 0.1493 - val_acc: 0.9506 - val_f1score: 0.9488\n",
      "Epoch 28/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00028: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0974 - acc: 0.9714 - f1score: 0.9719 - val_loss: 0.1149 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 29/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00029: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0965 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1223 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 30/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00030: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0962 - acc: 0.9709 - f1score: 0.9704 - val_loss: 0.1116 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 31/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00031: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0929 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1250 - val_acc: 0.9635 - val_f1score: 0.9630\n",
      "Epoch 32/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00032: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0952 - acc: 0.9714 - f1score: 0.9710 - val_loss: 0.1068 - val_acc: 0.9657 - val_f1score: 0.9659\n",
      "Epoch 33/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00033: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0917 - acc: 0.9735 - f1score: 0.9735 - val_loss: 0.1180 - val_acc: 0.9657 - val_f1score: 0.9667\n",
      "Epoch 34/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00034: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0965 - acc: 0.9735 - f1score: 0.9740 - val_loss: 0.1101 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 35/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9688 - f1score: 0.9687\n",
      "Epoch 00035: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1018 - acc: 0.9693 - f1score: 0.9698 - val_loss: 0.1265 - val_acc: 0.9571 - val_f1score: 0.9559\n",
      "Epoch 36/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00036: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0939 - acc: 0.9698 - f1score: 0.9699 - val_loss: 0.1406 - val_acc: 0.9549 - val_f1score: 0.9546\n",
      "Epoch 37/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00037: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0980 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1158 - val_acc: 0.9700 - val_f1score: 0.9684\n",
      "Epoch 38/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00038: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0916 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1076 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 39/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00039: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0884 - acc: 0.9709 - f1score: 0.9704 - val_loss: 0.1317 - val_acc: 0.9549 - val_f1score: 0.9562\n",
      "Epoch 40/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1134 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00040: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1122 - acc: 0.9667 - f1score: 0.9667 - val_loss: 0.1117 - val_acc: 0.9635 - val_f1score: 0.9638\n",
      "Epoch 41/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00041: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0935 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1062 - val_acc: 0.9678 - val_f1score: 0.9688\n",
      "Epoch 42/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00042: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0895 - acc: 0.9735 - f1score: 0.9730 - val_loss: 0.1138 - val_acc: 0.9700 - val_f1score: 0.9692\n",
      "Epoch 43/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00043: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0954 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1078 - val_acc: 0.9689 - val_f1score: 0.9674\n",
      "Epoch 44/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00044: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0985 - acc: 0.9698 - f1score: 0.9694 - val_loss: 0.1129 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 45/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0983 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00045: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0968 - acc: 0.9709 - f1score: 0.9714 - val_loss: 0.1100 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 46/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00046: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0895 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1214 - val_acc: 0.9689 - val_f1score: 0.9674\n",
      "Epoch 47/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00047: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0935 - acc: 0.9714 - f1score: 0.9719 - val_loss: 0.1111 - val_acc: 0.9700 - val_f1score: 0.9692\n",
      "Epoch 48/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00048: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0946 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1327 - val_acc: 0.9549 - val_f1score: 0.9562\n",
      "Epoch 49/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9688 - f1score: 0.9687\n",
      "Epoch 00049: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1039 - acc: 0.9693 - f1score: 0.9698 - val_loss: 0.1351 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 50/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00050: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0898 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1100 - val_acc: 0.9667 - val_f1score: 0.9653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|         | 30/1296 [1:58:11<161:29:41, 459.23s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 6.6077 - acc: 0.3683 - f1score: 0.2309\n",
      "Epoch 00001: val_acc improved from -inf to 0.48927, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-3.83.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 6.5770 - acc: 0.3704 - f1score: 0.2232 - val_loss: 3.8290 - val_acc: 0.4893 - val_f1score: 0.0429\n",
      "Epoch 2/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.2646 - acc: 0.6654 - f1score: 0.4869\n",
      "Epoch 00002: val_acc improved from 0.48927 to 0.90612, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.35.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.2295 - acc: 0.6690 - f1score: 0.4997 - val_loss: 0.3507 - val_acc: 0.9061 - val_f1score: 0.9072\n",
      "Epoch 3/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2782 - acc: 0.9302 - f1score: 0.9303\n",
      "Epoch 00003: val_acc did not improve from 0.90612\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.2789 - acc: 0.9299 - f1score: 0.9297 - val_loss: 0.3413 - val_acc: 0.8337 - val_f1score: 0.8371\n",
      "Epoch 4/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2229 - acc: 0.9378 - f1score: 0.9378\n",
      "Epoch 00004: val_acc improved from 0.90612 to 0.93348, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.23.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.2217 - acc: 0.9384 - f1score: 0.9389 - val_loss: 0.2335 - val_acc: 0.9335 - val_f1score: 0.9345\n",
      "Epoch 5/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1930 - acc: 0.9464 - f1score: 0.9464\n",
      "Epoch 00005: val_acc did not improve from 0.93348\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1919 - acc: 0.9468 - f1score: 0.9472 - val_loss: 0.2186 - val_acc: 0.9335 - val_f1score: 0.9345\n",
      "Epoch 6/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1798 - acc: 0.9429 - f1score: 0.9429\n",
      "Epoch 00006: val_acc improved from 0.93348 to 0.93455, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.21.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1791 - acc: 0.9429 - f1score: 0.9429 - val_loss: 0.2073 - val_acc: 0.9345 - val_f1score: 0.9315\n",
      "Epoch 7/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9499 - f1score: 0.9499\n",
      "Epoch 00007: val_acc improved from 0.93455 to 0.93562, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.19.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1649 - acc: 0.9497 - f1score: 0.9496 - val_loss: 0.1856 - val_acc: 0.9356 - val_f1score: 0.9325\n",
      "Epoch 8/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1537 - acc: 0.9542 - f1score: 0.9542\n",
      "Epoch 00008: val_acc improved from 0.93562 to 0.94796, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.17.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1527 - acc: 0.9545 - f1score: 0.9548 - val_loss: 0.1690 - val_acc: 0.9480 - val_f1score: 0.9470\n",
      "Epoch 9/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1434 - acc: 0.9591 - f1score: 0.9590\n",
      "Epoch 00009: val_acc did not improve from 0.94796\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1435 - acc: 0.9593 - f1score: 0.9594 - val_loss: 0.1632 - val_acc: 0.9480 - val_f1score: 0.9473\n",
      "Epoch 10/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9569 - f1score: 0.9568\n",
      "Epoch 00010: val_acc improved from 0.94796 to 0.95440, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.15.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1367 - acc: 0.9577 - f1score: 0.9583 - val_loss: 0.1545 - val_acc: 0.9544 - val_f1score: 0.9536\n",
      "Epoch 11/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9607 - f1score: 0.9606\n",
      "Epoch 00011: val_acc improved from 0.95440 to 0.95815, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.11-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1308 - acc: 0.9603 - f1score: 0.9600 - val_loss: 0.1367 - val_acc: 0.9582 - val_f1score: 0.9594\n",
      "Epoch 12/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9688 - f1score: 0.9688\n",
      "Epoch 00012: val_acc improved from 0.95815 to 0.96245, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.12-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1205 - acc: 0.9688 - f1score: 0.9688 - val_loss: 0.1323 - val_acc: 0.9624 - val_f1score: 0.9637\n",
      "Epoch 13/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00013: val_acc improved from 0.96245 to 0.96620, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.13.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1151 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1331 - val_acc: 0.9662 - val_f1score: 0.9672\n",
      "Epoch 14/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00014: val_acc did not improve from 0.96620\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1151 - acc: 0.9693 - f1score: 0.9694 - val_loss: 0.1262 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 15/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9696 - f1score: 0.9696\n",
      "Epoch 00015: val_acc did not improve from 0.96620\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1108 - acc: 0.9690 - f1score: 0.9686 - val_loss: 0.1271 - val_acc: 0.9587 - val_f1score: 0.9592\n",
      "Epoch 16/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9679 - f1score: 0.9679\n",
      "Epoch 00016: val_acc did not improve from 0.96620\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1090 - acc: 0.9680 - f1score: 0.9680 - val_loss: 0.1194 - val_acc: 0.9657 - val_f1score: 0.9651\n",
      "Epoch 17/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9723 - f1score: 0.9722\n",
      "Epoch 00017: val_acc did not improve from 0.96620\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1056 - acc: 0.9701 - f1score: 0.9683 - val_loss: 0.1306 - val_acc: 0.9544 - val_f1score: 0.9543\n",
      "Epoch 18/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00018: val_acc did not improve from 0.96620\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1052 - acc: 0.9688 - f1score: 0.9679 - val_loss: 0.1176 - val_acc: 0.9662 - val_f1score: 0.9656\n",
      "Epoch 19/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00019: val_acc did not improve from 0.96620\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1040 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1172 - val_acc: 0.9641 - val_f1score: 0.9646\n",
      "Epoch 20/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00020: val_acc did not improve from 0.96620\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1009 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1194 - val_acc: 0.9662 - val_f1score: 0.9672\n",
      "Epoch 21/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00021: val_acc did not improve from 0.96620\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1007 - acc: 0.9698 - f1score: 0.9703 - val_loss: 0.1175 - val_acc: 0.9657 - val_f1score: 0.9642\n",
      "Epoch 22/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9723 - f1score: 0.9723\n",
      "Epoch 00022: val_acc improved from 0.96620 to 0.96674, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.22-0.12.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1003 - acc: 0.9717 - f1score: 0.9712 - val_loss: 0.1174 - val_acc: 0.9667 - val_f1score: 0.9667\n",
      "Epoch 23/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00023: val_acc improved from 0.96674 to 0.96727, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.23-0.12.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0986 - acc: 0.9709 - f1score: 0.9714 - val_loss: 0.1165 - val_acc: 0.9673 - val_f1score: 0.9682\n",
      "Epoch 24/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9723 - f1score: 0.9722\n",
      "Epoch 00024: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0987 - acc: 0.9728 - f1score: 0.9731 - val_loss: 0.1139 - val_acc: 0.9651 - val_f1score: 0.9654\n",
      "Epoch 25/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9723 - f1score: 0.9722\n",
      "Epoch 00025: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0984 - acc: 0.9725 - f1score: 0.9727 - val_loss: 0.1174 - val_acc: 0.9667 - val_f1score: 0.9668\n",
      "Epoch 26/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00026: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0974 - acc: 0.9714 - f1score: 0.9719 - val_loss: 0.1140 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 27/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9712 - f1score: 0.9712\n",
      "Epoch 00027: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0957 - acc: 0.9717 - f1score: 0.9721 - val_loss: 0.1236 - val_acc: 0.9651 - val_f1score: 0.9653\n",
      "Epoch 28/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9696 - f1score: 0.9696\n",
      "Epoch 00028: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0979 - acc: 0.9701 - f1score: 0.9706 - val_loss: 0.1111 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 29/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9728 - f1score: 0.9728\n",
      "Epoch 00029: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0966 - acc: 0.9722 - f1score: 0.9717 - val_loss: 0.1100 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 30/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9706 - f1score: 0.9706\n",
      "Epoch 00030: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0967 - acc: 0.9712 - f1score: 0.9716 - val_loss: 0.1110 - val_acc: 0.9667 - val_f1score: 0.9660\n",
      "Epoch 31/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9733 - f1score: 0.9733\n",
      "Epoch 00031: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0952 - acc: 0.9733 - f1score: 0.9732 - val_loss: 0.1155 - val_acc: 0.9673 - val_f1score: 0.9673\n",
      "Epoch 32/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00032: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0969 - acc: 0.9730 - f1score: 0.9725 - val_loss: 0.1109 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 33/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00033: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0954 - acc: 0.9735 - f1score: 0.9730 - val_loss: 0.1109 - val_acc: 0.9641 - val_f1score: 0.9642\n",
      "Epoch 34/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9723 - f1score: 0.9723\n",
      "Epoch 00034: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0931 - acc: 0.9722 - f1score: 0.9722 - val_loss: 0.1126 - val_acc: 0.9673 - val_f1score: 0.9682\n",
      "Epoch 35/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9712 - f1score: 0.9712\n",
      "Epoch 00035: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0940 - acc: 0.9712 - f1score: 0.9712 - val_loss: 0.1158 - val_acc: 0.9657 - val_f1score: 0.9642\n",
      "Epoch 36/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9733 - f1score: 0.9734\n",
      "Epoch 00036: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0949 - acc: 0.9733 - f1score: 0.9733 - val_loss: 0.1106 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 37/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9744 - f1score: 0.9744\n",
      "Epoch 00037: val_acc improved from 0.96727 to 0.96835, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.37-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0940 - acc: 0.9743 - f1score: 0.9743 - val_loss: 0.1106 - val_acc: 0.9683 - val_f1score: 0.9680\n",
      "Epoch 38/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00038: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0938 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1143 - val_acc: 0.9673 - val_f1score: 0.9682\n",
      "Epoch 39/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9717 - f1score: 0.9717\n",
      "Epoch 00039: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0944 - acc: 0.9722 - f1score: 0.9727 - val_loss: 0.1090 - val_acc: 0.9667 - val_f1score: 0.9645\n",
      "Epoch 40/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00040: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0935 - acc: 0.9714 - f1score: 0.9710 - val_loss: 0.1103 - val_acc: 0.9673 - val_f1score: 0.9682\n",
      "Epoch 41/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9728 - f1score: 0.9728\n",
      "Epoch 00041: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0931 - acc: 0.9722 - f1score: 0.9717 - val_loss: 0.1123 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 42/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00042: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0921 - acc: 0.9735 - f1score: 0.9740 - val_loss: 0.1111 - val_acc: 0.9673 - val_f1score: 0.9661\n",
      "Epoch 43/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00043: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0920 - acc: 0.9714 - f1score: 0.9709 - val_loss: 0.1094 - val_acc: 0.9673 - val_f1score: 0.9658\n",
      "Epoch 44/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9728 - f1score: 0.9728\n",
      "Epoch 00044: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0907 - acc: 0.9728 - f1score: 0.9727 - val_loss: 0.1110 - val_acc: 0.9678 - val_f1score: 0.9663\n",
      "Epoch 45/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9714 - f1score: 0.9715\n",
      "Epoch 00045: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0914 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1103 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 46/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9728 - f1score: 0.9728\n",
      "Epoch 00046: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0898 - acc: 0.9733 - f1score: 0.9737 - val_loss: 0.1078 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 47/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9723 - f1score: 0.9722\n",
      "Epoch 00047: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0901 - acc: 0.9717 - f1score: 0.9712 - val_loss: 0.1088 - val_acc: 0.9673 - val_f1score: 0.9674\n",
      "Epoch 48/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9714 - f1score: 0.9715\n",
      "Epoch 00048: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0896 - acc: 0.9714 - f1score: 0.9715 - val_loss: 0.1073 - val_acc: 0.9662 - val_f1score: 0.9664\n",
      "Epoch 49/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00049: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0900 - acc: 0.9741 - f1score: 0.9745 - val_loss: 0.1097 - val_acc: 0.9673 - val_f1score: 0.9658\n",
      "Epoch 50/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00050: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0892 - acc: 0.9735 - f1score: 0.9740 - val_loss: 0.1100 - val_acc: 0.9673 - val_f1score: 0.9657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|         | 31/1296 [2:04:45<154:30:00, 439.68s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.3196 - acc: 0.7198 - f1score: 0.7139\n",
      "Epoch 00001: val_acc improved from -inf to 0.69474, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.64.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.3087 - acc: 0.7214 - f1score: 0.7170 - val_loss: 0.6365 - val_acc: 0.6947 - val_f1score: 0.6773\n",
      "Epoch 2/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4714 - acc: 0.8103 - f1score: 0.8062\n",
      "Epoch 00002: val_acc improved from 0.69474 to 0.87071, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.38.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.4692 - acc: 0.8116 - f1score: 0.8087 - val_loss: 0.3849 - val_acc: 0.8707 - val_f1score: 0.8710\n",
      "Epoch 3/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3040 - acc: 0.9127 - f1score: 0.9123\n",
      "Epoch 00003: val_acc improved from 0.87071 to 0.89753, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.29.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.3007 - acc: 0.9143 - f1score: 0.9152 - val_loss: 0.2854 - val_acc: 0.8975 - val_f1score: 0.8998\n",
      "Epoch 4/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2300 - acc: 0.9205 - f1score: 0.9206\n",
      "Epoch 00004: val_acc improved from 0.89753 to 0.91685, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.23.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2303 - acc: 0.9198 - f1score: 0.9193 - val_loss: 0.2346 - val_acc: 0.9168 - val_f1score: 0.9176\n",
      "Epoch 5/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1950 - acc: 0.9372 - f1score: 0.9373\n",
      "Epoch 00005: val_acc improved from 0.91685 to 0.94742, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.19.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1949 - acc: 0.9373 - f1score: 0.9374 - val_loss: 0.1920 - val_acc: 0.9474 - val_f1score: 0.9480\n",
      "Epoch 6/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1665 - acc: 0.9507 - f1score: 0.9507\n",
      "Epoch 00006: val_acc improved from 0.94742 to 0.94850, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.18.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1659 - acc: 0.9511 - f1score: 0.9514 - val_loss: 0.1793 - val_acc: 0.9485 - val_f1score: 0.9493\n",
      "Epoch 7/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9518 - f1score: 0.9517\n",
      "Epoch 00007: val_acc did not improve from 0.94850\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1535 - acc: 0.9516 - f1score: 0.9514 - val_loss: 0.1868 - val_acc: 0.9388 - val_f1score: 0.9381\n",
      "Epoch 8/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1536 - acc: 0.9529 - f1score: 0.9529\n",
      "Epoch 00008: val_acc did not improve from 0.94850\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1521 - acc: 0.9532 - f1score: 0.9535 - val_loss: 0.1750 - val_acc: 0.9394 - val_f1score: 0.9406\n",
      "Epoch 9/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1471 - acc: 0.9566 - f1score: 0.9567\n",
      "Epoch 00009: val_acc did not improve from 0.94850\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1464 - acc: 0.9569 - f1score: 0.9572 - val_loss: 0.1636 - val_acc: 0.9469 - val_f1score: 0.9465\n",
      "Epoch 10/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9607 - f1score: 0.9607\n",
      "Epoch 00010: val_acc did not improve from 0.94850\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1366 - acc: 0.9603 - f1score: 0.9600 - val_loss: 0.1510 - val_acc: 0.9485 - val_f1score: 0.9467\n",
      "Epoch 11/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9580 - f1score: 0.9580\n",
      "Epoch 00011: val_acc did not improve from 0.94850\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1333 - acc: 0.9571 - f1score: 0.9565 - val_loss: 0.1521 - val_acc: 0.9474 - val_f1score: 0.9471\n",
      "Epoch 12/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9561 - f1score: 0.9561\n",
      "Epoch 00012: val_acc did not improve from 0.94850\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1291 - acc: 0.9563 - f1score: 0.9566 - val_loss: 0.1453 - val_acc: 0.9474 - val_f1score: 0.9480\n",
      "Epoch 13/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00013: val_acc improved from 0.94850 to 0.95440, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.14.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1256 - acc: 0.9635 - f1score: 0.9632 - val_loss: 0.1385 - val_acc: 0.9544 - val_f1score: 0.9548\n",
      "Epoch 14/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00014: val_acc improved from 0.95440 to 0.96513, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.14-0.13.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1209 - acc: 0.9635 - f1score: 0.9631 - val_loss: 0.1317 - val_acc: 0.9651 - val_f1score: 0.9653\n",
      "Epoch 15/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9690 - f1score: 0.9691\n",
      "Epoch 00015: val_acc improved from 0.96513 to 0.96835, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.15-0.13.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1137 - acc: 0.9688 - f1score: 0.9686 - val_loss: 0.1255 - val_acc: 0.9683 - val_f1score: 0.9693\n",
      "Epoch 16/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9679 - f1score: 0.9679\n",
      "Epoch 00016: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1116 - acc: 0.9675 - f1score: 0.9670 - val_loss: 0.1287 - val_acc: 0.9662 - val_f1score: 0.9656\n",
      "Epoch 17/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9706 - f1score: 0.9706\n",
      "Epoch 00017: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1095 - acc: 0.9706 - f1score: 0.9706 - val_loss: 0.1209 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 18/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9679 - f1score: 0.9679\n",
      "Epoch 00018: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1064 - acc: 0.9680 - f1score: 0.9680 - val_loss: 0.1209 - val_acc: 0.9683 - val_f1score: 0.9677\n",
      "Epoch 19/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9728 - f1score: 0.9728\n",
      "Epoch 00019: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1042 - acc: 0.9722 - f1score: 0.9717 - val_loss: 0.1183 - val_acc: 0.9641 - val_f1score: 0.9643\n",
      "Epoch 20/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9696 - f1score: 0.9695\n",
      "Epoch 00020: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1026 - acc: 0.9690 - f1score: 0.9686 - val_loss: 0.1152 - val_acc: 0.9673 - val_f1score: 0.9682\n",
      "Epoch 21/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9712 - f1score: 0.9712\n",
      "Epoch 00021: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1013 - acc: 0.9717 - f1score: 0.9722 - val_loss: 0.1168 - val_acc: 0.9673 - val_f1score: 0.9682\n",
      "Epoch 22/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0983 - acc: 0.9728 - f1score: 0.9728\n",
      "Epoch 00022: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0984 - acc: 0.9725 - f1score: 0.9723 - val_loss: 0.1169 - val_acc: 0.9683 - val_f1score: 0.9669\n",
      "Epoch 23/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0983 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00023: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0976 - acc: 0.9741 - f1score: 0.9745 - val_loss: 0.1128 - val_acc: 0.9662 - val_f1score: 0.9663\n",
      "Epoch 24/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9725 - f1score: 0.9726\n",
      "Epoch 00024: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0982 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1268 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 25/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00025: val_acc improved from 0.96835 to 0.96942, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.25-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1009 - acc: 0.9730 - f1score: 0.9730 - val_loss: 0.1129 - val_acc: 0.9694 - val_f1score: 0.9695\n",
      "Epoch 26/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9749 - f1score: 0.9749\n",
      "Epoch 00026: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0962 - acc: 0.9749 - f1score: 0.9748 - val_loss: 0.1132 - val_acc: 0.9694 - val_f1score: 0.9687\n",
      "Epoch 27/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9752 - f1score: 0.9752\n",
      "Epoch 00027: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0970 - acc: 0.9751 - f1score: 0.9751 - val_loss: 0.1119 - val_acc: 0.9667 - val_f1score: 0.9668\n",
      "Epoch 28/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9755 - f1score: 0.9755\n",
      "Epoch 00028: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0963 - acc: 0.9757 - f1score: 0.9758 - val_loss: 0.1120 - val_acc: 0.9678 - val_f1score: 0.9665\n",
      "Epoch 29/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9752 - f1score: 0.9752\n",
      "Epoch 00029: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0951 - acc: 0.9751 - f1score: 0.9751 - val_loss: 0.1106 - val_acc: 0.9646 - val_f1score: 0.9640\n",
      "Epoch 30/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9733 - f1score: 0.9733\n",
      "Epoch 00030: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0923 - acc: 0.9733 - f1score: 0.9732 - val_loss: 0.1090 - val_acc: 0.9694 - val_f1score: 0.9703\n",
      "Epoch 31/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9744 - f1score: 0.9744\n",
      "Epoch 00031: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0927 - acc: 0.9743 - f1score: 0.9743 - val_loss: 0.1092 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 32/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9749 - f1score: 0.9750\n",
      "Epoch 00032: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0920 - acc: 0.9749 - f1score: 0.9748 - val_loss: 0.1096 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 33/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9758 - f1score: 0.9758\n",
      "Epoch 00033: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0907 - acc: 0.9751 - f1score: 0.9746 - val_loss: 0.1099 - val_acc: 0.9651 - val_f1score: 0.9661\n",
      "Epoch 34/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9752 - f1score: 0.9752\n",
      "Epoch 00034: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0940 - acc: 0.9746 - f1score: 0.9741 - val_loss: 0.1119 - val_acc: 0.9630 - val_f1score: 0.9630\n",
      "Epoch 35/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9760 - f1score: 0.9760\n",
      "Epoch 00035: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0915 - acc: 0.9759 - f1score: 0.9758 - val_loss: 0.1093 - val_acc: 0.9657 - val_f1score: 0.9653\n",
      "Epoch 36/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9760 - f1score: 0.9760\n",
      "Epoch 00036: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0918 - acc: 0.9754 - f1score: 0.9748 - val_loss: 0.1101 - val_acc: 0.9651 - val_f1score: 0.9653\n",
      "Epoch 37/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9728 - f1score: 0.9728\n",
      "Epoch 00037: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0936 - acc: 0.9722 - f1score: 0.9717 - val_loss: 0.1087 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 38/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00038: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0930 - acc: 0.9730 - f1score: 0.9734 - val_loss: 0.1261 - val_acc: 0.9683 - val_f1score: 0.9685\n",
      "Epoch 39/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9733 - f1score: 0.9733\n",
      "Epoch 00039: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0923 - acc: 0.9735 - f1score: 0.9737 - val_loss: 0.1098 - val_acc: 0.9694 - val_f1score: 0.9687\n",
      "Epoch 40/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00040: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0912 - acc: 0.9730 - f1score: 0.9725 - val_loss: 0.1097 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 41/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9747 - f1score: 0.9746\n",
      "Epoch 00041: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0909 - acc: 0.9746 - f1score: 0.9745 - val_loss: 0.1094 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 42/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9747 - f1score: 0.9747\n",
      "Epoch 00042: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0914 - acc: 0.9746 - f1score: 0.9745 - val_loss: 0.1070 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 43/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9755 - f1score: 0.9755\n",
      "Epoch 00043: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0903 - acc: 0.9749 - f1score: 0.9744 - val_loss: 0.1085 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 44/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9731 - f1score: 0.9730\n",
      "Epoch 00044: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0894 - acc: 0.9735 - f1score: 0.9739 - val_loss: 0.1101 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 45/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9739 - f1score: 0.9739\n",
      "Epoch 00045: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0927 - acc: 0.9733 - f1score: 0.9728 - val_loss: 0.1084 - val_acc: 0.9678 - val_f1score: 0.9670\n",
      "Epoch 46/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9733 - f1score: 0.9733\n",
      "Epoch 00046: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0911 - acc: 0.9738 - f1score: 0.9742 - val_loss: 0.1139 - val_acc: 0.9683 - val_f1score: 0.9685\n",
      "Epoch 47/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9733 - f1score: 0.9733\n",
      "Epoch 00047: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0936 - acc: 0.9733 - f1score: 0.9732 - val_loss: 0.1203 - val_acc: 0.9678 - val_f1score: 0.9680\n",
      "Epoch 48/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9739 - f1score: 0.9739\n",
      "Epoch 00048: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0914 - acc: 0.9738 - f1score: 0.9737 - val_loss: 0.1141 - val_acc: 0.9683 - val_f1score: 0.9661\n",
      "Epoch 49/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9755 - f1score: 0.9755\n",
      "Epoch 00049: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0915 - acc: 0.9754 - f1score: 0.9753 - val_loss: 0.1077 - val_acc: 0.9657 - val_f1score: 0.9653\n",
      "Epoch 50/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9741 - f1score: 0.9742\n",
      "Epoch 00050: val_acc improved from 0.96942 to 0.97049, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.50-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0898 - acc: 0.9746 - f1score: 0.9750 - val_loss: 0.1129 - val_acc: 0.9705 - val_f1score: 0.9705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|         | 32/1296 [2:11:20<149:41:37, 426.34s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.4766 - acc: 0.3478 - f1score: 0.3542\n",
      "Epoch 00001: val_acc improved from -inf to 0.68401, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.58.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 2.4498 - acc: 0.3524 - f1score: 0.3627 - val_loss: 0.5780 - val_acc: 0.6840 - val_f1score: 0.7004\n",
      "Epoch 2/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3931 - acc: 0.8591 - f1score: 0.8638\n",
      "Epoch 00002: val_acc improved from 0.68401 to 0.90129, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.31.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.3887 - acc: 0.8614 - f1score: 0.8679 - val_loss: 0.3063 - val_acc: 0.9013 - val_f1score: 0.8998\n",
      "Epoch 3/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2394 - acc: 0.9332 - f1score: 0.9335\n",
      "Epoch 00003: val_acc improved from 0.90129 to 0.92704, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.25.h5\n",
      "1890/1890 [==============================] - 15s 8ms/sample - loss: 0.2391 - acc: 0.9331 - f1score: 0.9333 - val_loss: 0.2510 - val_acc: 0.9270 - val_f1score: 0.9280\n",
      "Epoch 4/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9442 - f1score: 0.9444\n",
      "Epoch 00004: val_acc improved from 0.92704 to 0.92972, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.23.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1997 - acc: 0.9452 - f1score: 0.9462 - val_loss: 0.2311 - val_acc: 0.9297 - val_f1score: 0.9287\n",
      "Epoch 5/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9507 - f1score: 0.9509\n",
      "Epoch 00005: val_acc improved from 0.92972 to 0.94635, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.18.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1714 - acc: 0.9503 - f1score: 0.9501 - val_loss: 0.1843 - val_acc: 0.9464 - val_f1score: 0.9467\n",
      "Epoch 6/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1567 - acc: 0.9555 - f1score: 0.9556\n",
      "Epoch 00006: val_acc improved from 0.94635 to 0.95386, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.17.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1568 - acc: 0.9553 - f1score: 0.9551 - val_loss: 0.1740 - val_acc: 0.9539 - val_f1score: 0.9545\n",
      "Epoch 7/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1470 - acc: 0.9550 - f1score: 0.9551\n",
      "Epoch 00007: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1462 - acc: 0.9548 - f1score: 0.9546 - val_loss: 0.1603 - val_acc: 0.9517 - val_f1score: 0.9511\n",
      "Epoch 8/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1411 - acc: 0.9555 - f1score: 0.9556\n",
      "Epoch 00008: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1395 - acc: 0.9563 - f1score: 0.9571 - val_loss: 0.1532 - val_acc: 0.9464 - val_f1score: 0.9463\n",
      "Epoch 9/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9534 - f1score: 0.9535\n",
      "Epoch 00009: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1357 - acc: 0.9542 - f1score: 0.9550 - val_loss: 0.1508 - val_acc: 0.9490 - val_f1score: 0.9499\n",
      "Epoch 10/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00010: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1311 - acc: 0.9569 - f1score: 0.9552 - val_loss: 0.1514 - val_acc: 0.9447 - val_f1score: 0.9450\n",
      "Epoch 11/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9564 - f1score: 0.9565\n",
      "Epoch 00011: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1290 - acc: 0.9561 - f1score: 0.9560 - val_loss: 0.1467 - val_acc: 0.9453 - val_f1score: 0.9446\n",
      "Epoch 12/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9588 - f1score: 0.9589\n",
      "Epoch 00012: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1281 - acc: 0.9590 - f1score: 0.9593 - val_loss: 0.1402 - val_acc: 0.9506 - val_f1score: 0.9511\n",
      "Epoch 13/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9572 - f1score: 0.9572\n",
      "Epoch 00013: val_acc improved from 0.95386 to 0.95655, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.15.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1258 - acc: 0.9579 - f1score: 0.9586 - val_loss: 0.1529 - val_acc: 0.9565 - val_f1score: 0.9554\n",
      "Epoch 14/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9588 - f1score: 0.9590\n",
      "Epoch 00014: val_acc improved from 0.95655 to 0.95815, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.14-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1265 - acc: 0.9590 - f1score: 0.9594 - val_loss: 0.1405 - val_acc: 0.9582 - val_f1score: 0.9579\n",
      "Epoch 15/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00015: val_acc improved from 0.95815 to 0.96030, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.15-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1247 - acc: 0.9585 - f1score: 0.9581 - val_loss: 0.1391 - val_acc: 0.9603 - val_f1score: 0.9615\n",
      "Epoch 16/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9596 - f1score: 0.9597\n",
      "Epoch 00016: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1239 - acc: 0.9595 - f1score: 0.9596 - val_loss: 0.1394 - val_acc: 0.9560 - val_f1score: 0.9559\n",
      "Epoch 17/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9588 - f1score: 0.9588\n",
      "Epoch 00017: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1228 - acc: 0.9590 - f1score: 0.9592 - val_loss: 0.1394 - val_acc: 0.9565 - val_f1score: 0.9572\n",
      "Epoch 18/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9607 - f1score: 0.9607\n",
      "Epoch 00018: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1210 - acc: 0.9603 - f1score: 0.9601 - val_loss: 0.1365 - val_acc: 0.9549 - val_f1score: 0.9551\n",
      "Epoch 19/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9609 - f1score: 0.9610\n",
      "Epoch 00019: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1198 - acc: 0.9590 - f1score: 0.9574 - val_loss: 0.1388 - val_acc: 0.9555 - val_f1score: 0.9536\n",
      "Epoch 20/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00020: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1201 - acc: 0.9598 - f1score: 0.9600 - val_loss: 0.1378 - val_acc: 0.9501 - val_f1score: 0.9492\n",
      "Epoch 21/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00021: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1187 - acc: 0.9598 - f1score: 0.9604 - val_loss: 0.1380 - val_acc: 0.9576 - val_f1score: 0.9573\n",
      "Epoch 22/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9574 - f1score: 0.9575\n",
      "Epoch 00022: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1179 - acc: 0.9577 - f1score: 0.9579 - val_loss: 0.1328 - val_acc: 0.9555 - val_f1score: 0.9568\n",
      "Epoch 23/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9599 - f1score: 0.9599\n",
      "Epoch 00023: val_acc improved from 0.96030 to 0.96137, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.23-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1175 - acc: 0.9601 - f1score: 0.9603 - val_loss: 0.1386 - val_acc: 0.9614 - val_f1score: 0.9610\n",
      "Epoch 24/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9607 - f1score: 0.9607\n",
      "Epoch 00024: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1177 - acc: 0.9608 - f1score: 0.9611 - val_loss: 0.1325 - val_acc: 0.9582 - val_f1score: 0.9578\n",
      "Epoch 25/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00025: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1165 - acc: 0.9587 - f1score: 0.9589 - val_loss: 0.1333 - val_acc: 0.9592 - val_f1score: 0.9597\n",
      "Epoch 26/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9623 - f1score: 0.9623\n",
      "Epoch 00026: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1159 - acc: 0.9619 - f1score: 0.9616 - val_loss: 0.1335 - val_acc: 0.9576 - val_f1score: 0.9577\n",
      "Epoch 27/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9615 - f1score: 0.9615\n",
      "Epoch 00027: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1147 - acc: 0.9622 - f1score: 0.9628 - val_loss: 0.1338 - val_acc: 0.9539 - val_f1score: 0.9528\n",
      "Epoch 28/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9615 - f1score: 0.9616\n",
      "Epoch 00028: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1131 - acc: 0.9608 - f1score: 0.9604 - val_loss: 0.1320 - val_acc: 0.9560 - val_f1score: 0.9549\n",
      "Epoch 29/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9644 - f1score: 0.9645\n",
      "Epoch 00029: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1118 - acc: 0.9640 - f1score: 0.9637 - val_loss: 0.1364 - val_acc: 0.9598 - val_f1score: 0.9609\n",
      "Epoch 30/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9639 - f1score: 0.9640\n",
      "Epoch 00030: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1133 - acc: 0.9640 - f1score: 0.9642 - val_loss: 0.1330 - val_acc: 0.9506 - val_f1score: 0.9521\n",
      "Epoch 31/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9623 - f1score: 0.9623\n",
      "Epoch 00031: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1135 - acc: 0.9630 - f1score: 0.9636 - val_loss: 0.1304 - val_acc: 0.9549 - val_f1score: 0.9554\n",
      "Epoch 32/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9626 - f1score: 0.9626\n",
      "Epoch 00032: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1119 - acc: 0.9627 - f1score: 0.9629 - val_loss: 0.1327 - val_acc: 0.9485 - val_f1score: 0.9467\n",
      "Epoch 33/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9620 - f1score: 0.9621\n",
      "Epoch 00033: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1124 - acc: 0.9619 - f1score: 0.9619 - val_loss: 0.1326 - val_acc: 0.9598 - val_f1score: 0.9603\n",
      "Epoch 34/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9636 - f1score: 0.9637\n",
      "Epoch 00034: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1106 - acc: 0.9643 - f1score: 0.9649 - val_loss: 0.1313 - val_acc: 0.9544 - val_f1score: 0.9541\n",
      "Epoch 35/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9647 - f1score: 0.9647\n",
      "Epoch 00035: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1113 - acc: 0.9643 - f1score: 0.9639 - val_loss: 0.1306 - val_acc: 0.9549 - val_f1score: 0.9562\n",
      "Epoch 36/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9628 - f1score: 0.9629\n",
      "Epoch 00036: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1113 - acc: 0.9619 - f1score: 0.9612 - val_loss: 0.1292 - val_acc: 0.9544 - val_f1score: 0.9525\n",
      "Epoch 37/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9620 - f1score: 0.9621\n",
      "Epoch 00037: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1100 - acc: 0.9627 - f1score: 0.9633 - val_loss: 0.1392 - val_acc: 0.9614 - val_f1score: 0.9593\n",
      "Epoch 38/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9644 - f1score: 0.9645\n",
      "Epoch 00038: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1103 - acc: 0.9646 - f1score: 0.9647 - val_loss: 0.1318 - val_acc: 0.9603 - val_f1score: 0.9615\n",
      "Epoch 39/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9626 - f1score: 0.9626\n",
      "Epoch 00039: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1102 - acc: 0.9627 - f1score: 0.9628 - val_loss: 0.1305 - val_acc: 0.9549 - val_f1score: 0.9557\n",
      "Epoch 40/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9615 - f1score: 0.9615\n",
      "Epoch 00040: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1097 - acc: 0.9622 - f1score: 0.9628 - val_loss: 0.1319 - val_acc: 0.9576 - val_f1score: 0.9578\n",
      "Epoch 41/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9669 - f1score: 0.9668\n",
      "Epoch 00041: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1094 - acc: 0.9669 - f1score: 0.9670 - val_loss: 0.1300 - val_acc: 0.9587 - val_f1score: 0.9584\n",
      "Epoch 42/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00042: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1085 - acc: 0.9630 - f1score: 0.9631 - val_loss: 0.1295 - val_acc: 0.9528 - val_f1score: 0.9527\n",
      "Epoch 43/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9626 - f1score: 0.9626\n",
      "Epoch 00043: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1085 - acc: 0.9632 - f1score: 0.9638 - val_loss: 0.1293 - val_acc: 0.9565 - val_f1score: 0.9564\n",
      "Epoch 44/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9626 - f1score: 0.9626\n",
      "Epoch 00044: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1083 - acc: 0.9627 - f1score: 0.9629 - val_loss: 0.1307 - val_acc: 0.9608 - val_f1score: 0.9598\n",
      "Epoch 45/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00045: val_acc improved from 0.96137 to 0.96245, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.45-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1075 - acc: 0.9640 - f1score: 0.9647 - val_loss: 0.1352 - val_acc: 0.9624 - val_f1score: 0.9621\n",
      "Epoch 46/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9663 - f1score: 0.9663\n",
      "Epoch 00046: val_acc did not improve from 0.96245\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1077 - acc: 0.9653 - f1score: 0.9645 - val_loss: 0.1270 - val_acc: 0.9560 - val_f1score: 0.9565\n",
      "Epoch 47/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00047: val_acc did not improve from 0.96245\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1073 - acc: 0.9630 - f1score: 0.9631 - val_loss: 0.1270 - val_acc: 0.9592 - val_f1score: 0.9601\n",
      "Epoch 48/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00048: val_acc did not improve from 0.96245\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1059 - acc: 0.9672 - f1score: 0.9672 - val_loss: 0.1315 - val_acc: 0.9464 - val_f1score: 0.9470\n",
      "Epoch 49/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00049: val_acc did not improve from 0.96245\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1071 - acc: 0.9635 - f1score: 0.9641 - val_loss: 0.1295 - val_acc: 0.9614 - val_f1score: 0.9620\n",
      "Epoch 50/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9636 - f1score: 0.9637\n",
      "Epoch 00050: val_acc did not improve from 0.96245\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1066 - acc: 0.9638 - f1score: 0.9639 - val_loss: 0.1262 - val_acc: 0.9598 - val_f1score: 0.9577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|         | 33/1296 [2:18:28<149:46:45, 426.92s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.0473 - acc: 0.5321 - f1score: 0.5091\n",
      "Epoch 00001: val_acc improved from -inf to 0.73498, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.53.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 2.0196 - acc: 0.5360 - f1score: 0.5147 - val_loss: 0.5267 - val_acc: 0.7350 - val_f1score: 0.6875\n",
      "Epoch 2/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3344 - acc: 0.8693 - f1score: 0.8584\n",
      "Epoch 00002: val_acc improved from 0.73498 to 0.92275, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.25.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.3326 - acc: 0.8701 - f1score: 0.8602 - val_loss: 0.2538 - val_acc: 0.9227 - val_f1score: 0.9206\n",
      "Epoch 3/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2013 - acc: 0.9313 - f1score: 0.9311\n",
      "Epoch 00003: val_acc improved from 0.92275 to 0.93240, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.20.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2041 - acc: 0.9299 - f1score: 0.9285 - val_loss: 0.1973 - val_acc: 0.9324 - val_f1score: 0.9319\n",
      "Epoch 4/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9491 - f1score: 0.9489\n",
      "Epoch 00004: val_acc improved from 0.93240 to 0.94635, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1629 - acc: 0.9484 - f1score: 0.9477 - val_loss: 0.1666 - val_acc: 0.9464 - val_f1score: 0.9454\n",
      "Epoch 5/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9564 - f1score: 0.9563\n",
      "Epoch 00005: val_acc improved from 0.94635 to 0.95601, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.15.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1411 - acc: 0.9566 - f1score: 0.9568 - val_loss: 0.1529 - val_acc: 0.9560 - val_f1score: 0.9548\n",
      "Epoch 6/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1356 - acc: 0.9626 - f1score: 0.9627\n",
      "Epoch 00006: val_acc did not improve from 0.95601\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1337 - acc: 0.9632 - f1score: 0.9639 - val_loss: 0.1471 - val_acc: 0.9544 - val_f1score: 0.9540\n",
      "Epoch 7/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9615 - f1score: 0.9615\n",
      "Epoch 00007: val_acc improved from 0.95601 to 0.96137, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1250 - acc: 0.9622 - f1score: 0.9628 - val_loss: 0.1347 - val_acc: 0.9614 - val_f1score: 0.9613\n",
      "Epoch 8/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9642 - f1score: 0.9642\n",
      "Epoch 00008: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1199 - acc: 0.9640 - f1score: 0.9639 - val_loss: 0.1330 - val_acc: 0.9614 - val_f1score: 0.9622\n",
      "Epoch 9/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9701 - f1score: 0.9701\n",
      "Epoch 00009: val_acc improved from 0.96137 to 0.96674, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.13.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1161 - acc: 0.9706 - f1score: 0.9711 - val_loss: 0.1332 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 10/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9696 - f1score: 0.9696\n",
      "Epoch 00010: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1090 - acc: 0.9693 - f1score: 0.9691 - val_loss: 0.1228 - val_acc: 0.9565 - val_f1score: 0.9576\n",
      "Epoch 11/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9679 - f1score: 0.9680\n",
      "Epoch 00011: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1107 - acc: 0.9680 - f1score: 0.9681 - val_loss: 0.1179 - val_acc: 0.9630 - val_f1score: 0.9630\n",
      "Epoch 12/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9690 - f1score: 0.9691\n",
      "Epoch 00012: val_acc improved from 0.96674 to 0.96727, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.12-0.12.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1078 - acc: 0.9696 - f1score: 0.9701 - val_loss: 0.1161 - val_acc: 0.9673 - val_f1score: 0.9682\n",
      "Epoch 13/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9706 - f1score: 0.9706\n",
      "Epoch 00013: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1038 - acc: 0.9706 - f1score: 0.9706 - val_loss: 0.1136 - val_acc: 0.9667 - val_f1score: 0.9673\n",
      "Epoch 14/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00014: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1011 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1163 - val_acc: 0.9673 - val_f1score: 0.9674\n",
      "Epoch 15/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00015: val_acc improved from 0.96727 to 0.96835, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.15-0.11.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1026 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1096 - val_acc: 0.9683 - val_f1score: 0.9692\n",
      "Epoch 16/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00016: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0990 - acc: 0.9720 - f1score: 0.9714 - val_loss: 0.1151 - val_acc: 0.9630 - val_f1score: 0.9624\n",
      "Epoch 17/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00017: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0998 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1091 - val_acc: 0.9667 - val_f1score: 0.9656\n",
      "Epoch 18/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9712 - f1score: 0.9712\n",
      "Epoch 00018: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0999 - acc: 0.9701 - f1score: 0.9692 - val_loss: 0.1126 - val_acc: 0.9667 - val_f1score: 0.9673\n",
      "Epoch 19/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00019: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1032 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1098 - val_acc: 0.9651 - val_f1score: 0.9652\n",
      "Epoch 20/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9717 - f1score: 0.9717\n",
      "Epoch 00020: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0995 - acc: 0.9712 - f1score: 0.9707 - val_loss: 0.1163 - val_acc: 0.9683 - val_f1score: 0.9685\n",
      "Epoch 21/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9712 - f1score: 0.9711\n",
      "Epoch 00021: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0975 - acc: 0.9712 - f1score: 0.9711 - val_loss: 0.1172 - val_acc: 0.9673 - val_f1score: 0.9682\n",
      "Epoch 22/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00022: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1027 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1113 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 23/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9723 - f1score: 0.9722\n",
      "Epoch 00023: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1011 - acc: 0.9728 - f1score: 0.9732 - val_loss: 0.1112 - val_acc: 0.9651 - val_f1score: 0.9661\n",
      "Epoch 24/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9696 - f1score: 0.9696\n",
      "Epoch 00024: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0962 - acc: 0.9698 - f1score: 0.9701 - val_loss: 0.1129 - val_acc: 0.9673 - val_f1score: 0.9673\n",
      "Epoch 25/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00025: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0966 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1110 - val_acc: 0.9683 - val_f1score: 0.9675\n",
      "Epoch 26/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9733 - f1score: 0.9733\n",
      "Epoch 00026: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0930 - acc: 0.9728 - f1score: 0.9722 - val_loss: 0.1098 - val_acc: 0.9646 - val_f1score: 0.9647\n",
      "Epoch 27/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9706 - f1score: 0.9706\n",
      "Epoch 00027: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0970 - acc: 0.9701 - f1score: 0.9696 - val_loss: 0.1125 - val_acc: 0.9641 - val_f1score: 0.9643\n",
      "Epoch 28/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00028: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0929 - acc: 0.9741 - f1score: 0.9745 - val_loss: 0.1198 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 29/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9723 - f1score: 0.9722\n",
      "Epoch 00029: val_acc improved from 0.96835 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.29-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0971 - acc: 0.9728 - f1score: 0.9732 - val_loss: 0.1099 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 30/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00030: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0963 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1105 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 31/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00031: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0959 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1119 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 32/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00032: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0913 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1112 - val_acc: 0.9678 - val_f1score: 0.9672\n",
      "Epoch 33/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00033: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0914 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1080 - val_acc: 0.9667 - val_f1score: 0.9660\n",
      "Epoch 34/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00034: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0913 - acc: 0.9735 - f1score: 0.9740 - val_loss: 0.1095 - val_acc: 0.9689 - val_f1score: 0.9689\n",
      "Epoch 35/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9723 - f1score: 0.9722\n",
      "Epoch 00035: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0897 - acc: 0.9717 - f1score: 0.9712 - val_loss: 0.1080 - val_acc: 0.9667 - val_f1score: 0.9678\n",
      "Epoch 36/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9739 - f1score: 0.9738\n",
      "Epoch 00036: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0890 - acc: 0.9733 - f1score: 0.9728 - val_loss: 0.1091 - val_acc: 0.9678 - val_f1score: 0.9672\n",
      "Epoch 37/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9706 - f1score: 0.9706\n",
      "Epoch 00037: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0915 - acc: 0.9704 - f1score: 0.9702 - val_loss: 0.1109 - val_acc: 0.9635 - val_f1score: 0.9638\n",
      "Epoch 38/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9704 - f1score: 0.9703\n",
      "Epoch 00038: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0879 - acc: 0.9709 - f1score: 0.9713 - val_loss: 0.1186 - val_acc: 0.9683 - val_f1score: 0.9684\n",
      "Epoch 39/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00039: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0921 - acc: 0.9730 - f1score: 0.9730 - val_loss: 0.1085 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 40/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00040: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0878 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1072 - val_acc: 0.9646 - val_f1score: 0.9640\n",
      "Epoch 41/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00041: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0930 - acc: 0.9720 - f1score: 0.9724 - val_loss: 0.1078 - val_acc: 0.9662 - val_f1score: 0.9673\n",
      "Epoch 42/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9739 - f1score: 0.9738\n",
      "Epoch 00042: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0903 - acc: 0.9743 - f1score: 0.9747 - val_loss: 0.1060 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 43/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9733 - f1score: 0.9733\n",
      "Epoch 00043: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0888 - acc: 0.9733 - f1score: 0.9733 - val_loss: 0.1050 - val_acc: 0.9683 - val_f1score: 0.9684\n",
      "Epoch 44/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9755 - f1score: 0.9754\n",
      "Epoch 00044: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0903 - acc: 0.9757 - f1score: 0.9758 - val_loss: 0.1061 - val_acc: 0.9683 - val_f1score: 0.9684\n",
      "Epoch 45/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0903 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00045: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0889 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1055 - val_acc: 0.9662 - val_f1score: 0.9664\n",
      "Epoch 46/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9717 - f1score: 0.9717\n",
      "Epoch 00046: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0882 - acc: 0.9722 - f1score: 0.9726 - val_loss: 0.1086 - val_acc: 0.9678 - val_f1score: 0.9676\n",
      "Epoch 47/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9752 - f1score: 0.9752\n",
      "Epoch 00047: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0894 - acc: 0.9746 - f1score: 0.9741 - val_loss: 0.1042 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 48/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00048: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0873 - acc: 0.9735 - f1score: 0.9735 - val_loss: 0.1061 - val_acc: 0.9673 - val_f1score: 0.9674\n",
      "Epoch 49/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9706 - f1score: 0.9706\n",
      "Epoch 00049: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0883 - acc: 0.9706 - f1score: 0.9706 - val_loss: 0.1065 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 50/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9741 - f1score: 0.9742\n",
      "Epoch 00050: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0911 - acc: 0.9741 - f1score: 0.9740 - val_loss: 0.1044 - val_acc: 0.9678 - val_f1score: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|         | 34/1296 [2:25:35<149:38:41, 426.88s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.2506 - acc: 0.7775 - f1score: 0.7859\n",
      "Epoch 00001: val_acc improved from -inf to 0.86481, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.64.h5\n",
      "1890/1890 [==============================] - 14s 7ms/sample - loss: 1.2334 - acc: 0.7804 - f1score: 0.7911 - val_loss: 0.6414 - val_acc: 0.8648 - val_f1score: 0.8615\n",
      "Epoch 2/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3041 - acc: 0.9081 - f1score: 0.9042\n",
      "Epoch 00002: val_acc improved from 0.86481 to 0.93401, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.21.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.3010 - acc: 0.9087 - f1score: 0.9055 - val_loss: 0.2050 - val_acc: 0.9340 - val_f1score: 0.9332\n",
      "Epoch 3/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1783 - acc: 0.9429 - f1score: 0.9427\n",
      "Epoch 00003: val_acc improved from 0.93401 to 0.93670, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.18.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1791 - acc: 0.9423 - f1score: 0.9416 - val_loss: 0.1819 - val_acc: 0.9367 - val_f1score: 0.9378\n",
      "Epoch 4/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9496 - f1score: 0.9495\n",
      "Epoch 00004: val_acc improved from 0.93670 to 0.94474, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.18.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1535 - acc: 0.9495 - f1score: 0.9492 - val_loss: 0.1803 - val_acc: 0.9447 - val_f1score: 0.9448\n",
      "Epoch 5/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9507 - f1score: 0.9507\n",
      "Epoch 00005: val_acc improved from 0.94474 to 0.94903, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.18.h5\n",
      "1890/1890 [==============================] - 12s 7ms/sample - loss: 0.1504 - acc: 0.9516 - f1score: 0.9523 - val_loss: 0.1762 - val_acc: 0.9490 - val_f1score: 0.9488\n",
      "Epoch 6/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1436 - acc: 0.9545 - f1score: 0.9545\n",
      "Epoch 00006: val_acc improved from 0.94903 to 0.95601, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.16.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1420 - acc: 0.9553 - f1score: 0.9560 - val_loss: 0.1595 - val_acc: 0.9560 - val_f1score: 0.9566\n",
      "Epoch 7/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9609 - f1score: 0.9610\n",
      "Epoch 00007: val_acc did not improve from 0.95601\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1355 - acc: 0.9616 - f1score: 0.9623 - val_loss: 0.1632 - val_acc: 0.9517 - val_f1score: 0.9483\n",
      "Epoch 8/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9620 - f1score: 0.9620\n",
      "Epoch 00008: val_acc did not improve from 0.95601\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1341 - acc: 0.9627 - f1score: 0.9633 - val_loss: 0.1448 - val_acc: 0.9512 - val_f1score: 0.9525\n",
      "Epoch 9/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9569 - f1score: 0.9569\n",
      "Epoch 00009: val_acc did not improve from 0.95601\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1295 - acc: 0.9561 - f1score: 0.9554 - val_loss: 0.1425 - val_acc: 0.9501 - val_f1score: 0.9508\n",
      "Epoch 10/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9607 - f1score: 0.9606\n",
      "Epoch 00010: val_acc improved from 0.95601 to 0.95655, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1255 - acc: 0.9614 - f1score: 0.9620 - val_loss: 0.1720 - val_acc: 0.9565 - val_f1score: 0.9570\n",
      "Epoch 11/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9615 - f1score: 0.9615\n",
      "Epoch 00011: val_acc did not improve from 0.95655\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1291 - acc: 0.9616 - f1score: 0.9618 - val_loss: 0.1439 - val_acc: 0.9469 - val_f1score: 0.9460\n",
      "Epoch 12/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00012: val_acc did not improve from 0.95655\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1252 - acc: 0.9614 - f1score: 0.9615 - val_loss: 0.1365 - val_acc: 0.9501 - val_f1score: 0.9508\n",
      "Epoch 13/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1185 - acc: 0.9636 - f1score: 0.9637\n",
      "Epoch 00013: val_acc did not improve from 0.95655\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1217 - acc: 0.9632 - f1score: 0.9629 - val_loss: 0.1418 - val_acc: 0.9453 - val_f1score: 0.9436\n",
      "Epoch 14/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00014: val_acc did not improve from 0.95655\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1166 - acc: 0.9640 - f1score: 0.9646 - val_loss: 0.1806 - val_acc: 0.9490 - val_f1score: 0.9505\n",
      "Epoch 15/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00015: val_acc did not improve from 0.95655\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1171 - acc: 0.9635 - f1score: 0.9631 - val_loss: 0.1536 - val_acc: 0.9453 - val_f1score: 0.9461\n",
      "Epoch 16/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9634 - f1score: 0.9633\n",
      "Epoch 00016: val_acc improved from 0.95655 to 0.96352, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.16-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1170 - acc: 0.9640 - f1score: 0.9645 - val_loss: 0.1315 - val_acc: 0.9635 - val_f1score: 0.9629\n",
      "Epoch 17/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1143 - acc: 0.9685 - f1score: 0.9684\n",
      "Epoch 00017: val_acc did not improve from 0.96352\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1148 - acc: 0.9680 - f1score: 0.9675 - val_loss: 0.1371 - val_acc: 0.9608 - val_f1score: 0.9609\n",
      "Epoch 18/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00018: val_acc did not improve from 0.96352\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1095 - acc: 0.9683 - f1score: 0.9687 - val_loss: 0.1301 - val_acc: 0.9603 - val_f1score: 0.9612\n",
      "Epoch 19/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9679 - f1score: 0.9680\n",
      "Epoch 00019: val_acc improved from 0.96352 to 0.96459, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.19-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1045 - acc: 0.9685 - f1score: 0.9691 - val_loss: 0.1216 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 20/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9728 - f1score: 0.9728\n",
      "Epoch 00020: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0992 - acc: 0.9728 - f1score: 0.9727 - val_loss: 0.1482 - val_acc: 0.9528 - val_f1score: 0.9533\n",
      "Epoch 21/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9685 - f1score: 0.9685\n",
      "Epoch 00021: val_acc improved from 0.96459 to 0.96835, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.21-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.0990 - acc: 0.9690 - f1score: 0.9695 - val_loss: 0.1178 - val_acc: 0.9683 - val_f1score: 0.9685\n",
      "Epoch 22/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00022: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1005 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1103 - val_acc: 0.9678 - val_f1score: 0.9663\n",
      "Epoch 23/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9744 - f1score: 0.9744\n",
      "Epoch 00023: val_acc improved from 0.96835 to 0.97103, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.23-0.11.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1000 - acc: 0.9741 - f1score: 0.9738 - val_loss: 0.1085 - val_acc: 0.9710 - val_f1score: 0.9719\n",
      "Epoch 24/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00024: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0977 - acc: 0.9693 - f1score: 0.9693 - val_loss: 0.1456 - val_acc: 0.9565 - val_f1score: 0.9562\n",
      "Epoch 25/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9717 - f1score: 0.9717\n",
      "Epoch 00025: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0954 - acc: 0.9717 - f1score: 0.9717 - val_loss: 0.1094 - val_acc: 0.9683 - val_f1score: 0.9685\n",
      "Epoch 26/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9717 - f1score: 0.9717\n",
      "Epoch 00026: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0967 - acc: 0.9717 - f1score: 0.9717 - val_loss: 0.1091 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 27/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9712 - f1score: 0.9712\n",
      "Epoch 00027: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0963 - acc: 0.9706 - f1score: 0.9702 - val_loss: 0.1169 - val_acc: 0.9635 - val_f1score: 0.9640\n",
      "Epoch 28/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9755 - f1score: 0.9755\n",
      "Epoch 00028: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0976 - acc: 0.9759 - f1score: 0.9763 - val_loss: 0.1090 - val_acc: 0.9694 - val_f1score: 0.9694\n",
      "Epoch 29/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00029: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0942 - acc: 0.9714 - f1score: 0.9719 - val_loss: 0.1114 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 30/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00030: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0972 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1068 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 31/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00031: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0937 - acc: 0.9730 - f1score: 0.9721 - val_loss: 0.1069 - val_acc: 0.9673 - val_f1score: 0.9677\n",
      "Epoch 32/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9744 - f1score: 0.9744\n",
      "Epoch 00032: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0922 - acc: 0.9743 - f1score: 0.9743 - val_loss: 0.1067 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 33/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00033: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0961 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1067 - val_acc: 0.9700 - val_f1score: 0.9684\n",
      "Epoch 34/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00034: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0946 - acc: 0.9735 - f1score: 0.9735 - val_loss: 0.1096 - val_acc: 0.9635 - val_f1score: 0.9622\n",
      "Epoch 35/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9733 - f1score: 0.9733\n",
      "Epoch 00035: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0945 - acc: 0.9733 - f1score: 0.9732 - val_loss: 0.1053 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 36/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00036: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0947 - acc: 0.9741 - f1score: 0.9740 - val_loss: 0.1156 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 37/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9747 - f1score: 0.9747\n",
      "Epoch 00037: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0927 - acc: 0.9746 - f1score: 0.9745 - val_loss: 0.1063 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 38/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9723 - f1score: 0.9723\n",
      "Epoch 00038: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0946 - acc: 0.9728 - f1score: 0.9732 - val_loss: 0.1111 - val_acc: 0.9683 - val_f1score: 0.9684\n",
      "Epoch 39/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9744 - f1score: 0.9744\n",
      "Epoch 00039: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0923 - acc: 0.9743 - f1score: 0.9743 - val_loss: 0.1056 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 40/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00040: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0918 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1208 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 41/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00041: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0943 - acc: 0.9722 - f1score: 0.9725 - val_loss: 0.1161 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 42/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00042: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0915 - acc: 0.9746 - f1score: 0.9750 - val_loss: 0.1080 - val_acc: 0.9689 - val_f1score: 0.9673\n",
      "Epoch 43/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00043: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0898 - acc: 0.9741 - f1score: 0.9745 - val_loss: 0.1058 - val_acc: 0.9689 - val_f1score: 0.9674\n",
      "Epoch 44/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9744 - f1score: 0.9744\n",
      "Epoch 00044: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0902 - acc: 0.9743 - f1score: 0.9743 - val_loss: 0.1113 - val_acc: 0.9700 - val_f1score: 0.9692\n",
      "Epoch 45/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9741 - f1score: 0.9742\n",
      "Epoch 00045: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0920 - acc: 0.9746 - f1score: 0.9750 - val_loss: 0.1329 - val_acc: 0.9641 - val_f1score: 0.9635\n",
      "Epoch 46/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9728 - f1score: 0.9728\n",
      "Epoch 00046: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0940 - acc: 0.9733 - f1score: 0.9737 - val_loss: 0.1070 - val_acc: 0.9673 - val_f1score: 0.9682\n",
      "Epoch 47/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9744 - f1score: 0.9744\n",
      "Epoch 00047: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.0923 - acc: 0.9728 - f1score: 0.9713 - val_loss: 0.1067 - val_acc: 0.9673 - val_f1score: 0.9673\n",
      "Epoch 48/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9739 - f1score: 0.9739\n",
      "Epoch 00048: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0900 - acc: 0.9743 - f1score: 0.9747 - val_loss: 0.1084 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 49/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9744 - f1score: 0.9744\n",
      "Epoch 00049: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0899 - acc: 0.9733 - f1score: 0.9723 - val_loss: 0.1324 - val_acc: 0.9603 - val_f1score: 0.9589\n",
      "Epoch 50/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00050: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0932 - acc: 0.9735 - f1score: 0.9730 - val_loss: 0.1133 - val_acc: 0.9683 - val_f1score: 0.9684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|         | 35/1296 [2:34:37<161:38:31, 461.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.4495 - acc: 0.6923 - f1score: 0.7238\n",
      "Epoch 00001: val_acc improved from -inf to 0.88144, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.43.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 1.4306 - acc: 0.6963 - f1score: 0.7299 - val_loss: 0.4286 - val_acc: 0.8814 - val_f1score: 0.8727\n",
      "Epoch 2/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2463 - acc: 0.9213 - f1score: 0.9214\n",
      "Epoch 00002: val_acc improved from 0.88144 to 0.92597, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.21.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.2486 - acc: 0.9196 - f1score: 0.9181 - val_loss: 0.2122 - val_acc: 0.9260 - val_f1score: 0.9265\n",
      "Epoch 3/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1779 - acc: 0.9421 - f1score: 0.9425\n",
      "Epoch 00003: val_acc improved from 0.92597 to 0.94474, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.18.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1774 - acc: 0.9421 - f1score: 0.9425 - val_loss: 0.1821 - val_acc: 0.9447 - val_f1score: 0.9434\n",
      "Epoch 4/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1526 - acc: 0.9539 - f1score: 0.9541\n",
      "Epoch 00004: val_acc improved from 0.94474 to 0.95547, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1518 - acc: 0.9537 - f1score: 0.9537 - val_loss: 0.1661 - val_acc: 0.9555 - val_f1score: 0.9558\n",
      "Epoch 5/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9582 - f1score: 0.9584\n",
      "Epoch 00005: val_acc did not improve from 0.95547\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1399 - acc: 0.9579 - f1score: 0.9579 - val_loss: 0.1502 - val_acc: 0.9485 - val_f1score: 0.9501\n",
      "Epoch 6/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9585 - f1score: 0.9587\n",
      "Epoch 00006: val_acc did not improve from 0.95547\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1373 - acc: 0.9577 - f1score: 0.9571 - val_loss: 0.1506 - val_acc: 0.9442 - val_f1score: 0.9446\n",
      "Epoch 7/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9628 - f1score: 0.9630\n",
      "Epoch 00007: val_acc improved from 0.95547 to 0.95923, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.16.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1298 - acc: 0.9624 - f1score: 0.9623 - val_loss: 0.1627 - val_acc: 0.9592 - val_f1score: 0.9562\n",
      "Epoch 8/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9593 - f1score: 0.9594\n",
      "Epoch 00008: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1362 - acc: 0.9595 - f1score: 0.9598 - val_loss: 0.1410 - val_acc: 0.9501 - val_f1score: 0.9496\n",
      "Epoch 9/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9612 - f1score: 0.9613\n",
      "Epoch 00009: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1292 - acc: 0.9606 - f1score: 0.9602 - val_loss: 0.1384 - val_acc: 0.9544 - val_f1score: 0.9542\n",
      "Epoch 10/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9612 - f1score: 0.9613\n",
      "Epoch 00010: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1392 - acc: 0.9614 - f1score: 0.9616 - val_loss: 0.1446 - val_acc: 0.9533 - val_f1score: 0.9551\n",
      "Epoch 11/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9623 - f1score: 0.9624\n",
      "Epoch 00011: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1264 - acc: 0.9624 - f1score: 0.9627 - val_loss: 0.1351 - val_acc: 0.9506 - val_f1score: 0.9508\n",
      "Epoch 12/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9631 - f1score: 0.9631\n",
      "Epoch 00012: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1198 - acc: 0.9622 - f1score: 0.9614 - val_loss: 0.1378 - val_acc: 0.9485 - val_f1score: 0.9481\n",
      "Epoch 13/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9593 - f1score: 0.9593\n",
      "Epoch 00013: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1179 - acc: 0.9595 - f1score: 0.9597 - val_loss: 0.1341 - val_acc: 0.9485 - val_f1score: 0.9486\n",
      "Epoch 14/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00014: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1211 - acc: 0.9598 - f1score: 0.9600 - val_loss: 0.1387 - val_acc: 0.9565 - val_f1score: 0.9570\n",
      "Epoch 15/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00015: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1257 - acc: 0.9635 - f1score: 0.9627 - val_loss: 0.1585 - val_acc: 0.9539 - val_f1score: 0.9550\n",
      "Epoch 16/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9628 - f1score: 0.9629\n",
      "Epoch 00016: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1157 - acc: 0.9616 - f1score: 0.9606 - val_loss: 0.1436 - val_acc: 0.9506 - val_f1score: 0.9504\n",
      "Epoch 17/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9669 - f1score: 0.9669\n",
      "Epoch 00017: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1176 - acc: 0.9664 - f1score: 0.9660 - val_loss: 0.1718 - val_acc: 0.9447 - val_f1score: 0.9439\n",
      "Epoch 18/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00018: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1276 - acc: 0.9638 - f1score: 0.9641 - val_loss: 0.1547 - val_acc: 0.9517 - val_f1score: 0.9522\n",
      "Epoch 19/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00019: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1144 - acc: 0.9630 - f1score: 0.9631 - val_loss: 0.1284 - val_acc: 0.9576 - val_f1score: 0.9562\n",
      "Epoch 20/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00020: val_acc improved from 0.95923 to 0.96298, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.20-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1108 - acc: 0.9640 - f1score: 0.9641 - val_loss: 0.1295 - val_acc: 0.9630 - val_f1score: 0.9640\n",
      "Epoch 21/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9626 - f1score: 0.9624\n",
      "Epoch 00021: val_acc did not improve from 0.96298\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1106 - acc: 0.9632 - f1score: 0.9637 - val_loss: 0.1734 - val_acc: 0.9496 - val_f1score: 0.9510\n",
      "Epoch 22/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00022: val_acc did not improve from 0.96298\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1065 - acc: 0.9661 - f1score: 0.9667 - val_loss: 0.1304 - val_acc: 0.9490 - val_f1score: 0.9505\n",
      "Epoch 23/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9620 - f1score: 0.9621\n",
      "Epoch 00023: val_acc did not improve from 0.96298\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1148 - acc: 0.9622 - f1score: 0.9624 - val_loss: 0.1733 - val_acc: 0.9496 - val_f1score: 0.9500\n",
      "Epoch 24/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9658 - f1score: 0.9656\n",
      "Epoch 00024: val_acc did not improve from 0.96298\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1116 - acc: 0.9643 - f1score: 0.9629 - val_loss: 0.1367 - val_acc: 0.9624 - val_f1score: 0.9618\n",
      "Epoch 25/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9658 - f1score: 0.9658\n",
      "Epoch 00025: val_acc did not improve from 0.96298\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1146 - acc: 0.9648 - f1score: 0.9640 - val_loss: 0.1379 - val_acc: 0.9447 - val_f1score: 0.9455\n",
      "Epoch 26/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9663 - f1score: 0.9664\n",
      "Epoch 00026: val_acc did not improve from 0.96298\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1211 - acc: 0.9664 - f1score: 0.9666 - val_loss: 0.1654 - val_acc: 0.9512 - val_f1score: 0.9496\n",
      "Epoch 27/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9663 - f1score: 0.9663\n",
      "Epoch 00027: val_acc did not improve from 0.96298\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1110 - acc: 0.9653 - f1score: 0.9645 - val_loss: 0.1209 - val_acc: 0.9582 - val_f1score: 0.9561\n",
      "Epoch 28/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9658 - f1score: 0.9658\n",
      "Epoch 00028: val_acc did not improve from 0.96298\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1064 - acc: 0.9653 - f1score: 0.9650 - val_loss: 0.1227 - val_acc: 0.9549 - val_f1score: 0.9541\n",
      "Epoch 29/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9669 - f1score: 0.9668\n",
      "Epoch 00029: val_acc did not improve from 0.96298\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1070 - acc: 0.9669 - f1score: 0.9670 - val_loss: 0.1297 - val_acc: 0.9624 - val_f1score: 0.9620\n",
      "Epoch 30/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00030: val_acc did not improve from 0.96298\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1034 - acc: 0.9667 - f1score: 0.9662 - val_loss: 0.1447 - val_acc: 0.9598 - val_f1score: 0.9599\n",
      "Epoch 31/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00031: val_acc did not improve from 0.96298\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1120 - acc: 0.9635 - f1score: 0.9636 - val_loss: 0.1246 - val_acc: 0.9501 - val_f1score: 0.9501\n",
      "Epoch 32/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9636 - f1score: 0.9637\n",
      "Epoch 00032: val_acc did not improve from 0.96298\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1098 - acc: 0.9638 - f1score: 0.9639 - val_loss: 0.1226 - val_acc: 0.9603 - val_f1score: 0.9609\n",
      "Epoch 33/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9677 - f1score: 0.9676\n",
      "Epoch 00033: val_acc improved from 0.96298 to 0.96513, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.33-0.12.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1052 - acc: 0.9675 - f1score: 0.9672 - val_loss: 0.1203 - val_acc: 0.9651 - val_f1score: 0.9643\n",
      "Epoch 34/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9693 - f1score: 0.9694\n",
      "Epoch 00034: val_acc did not improve from 0.96513\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1036 - acc: 0.9698 - f1score: 0.9704 - val_loss: 0.1655 - val_acc: 0.9523 - val_f1score: 0.9537\n",
      "Epoch 35/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9658 - f1score: 0.9657\n",
      "Epoch 00035: val_acc did not improve from 0.96513\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1180 - acc: 0.9653 - f1score: 0.9648 - val_loss: 0.1402 - val_acc: 0.9523 - val_f1score: 0.9524\n",
      "Epoch 36/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9650 - f1score: 0.9650\n",
      "Epoch 00036: val_acc did not improve from 0.96513\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1138 - acc: 0.9656 - f1score: 0.9662 - val_loss: 0.1279 - val_acc: 0.9635 - val_f1score: 0.9629\n",
      "Epoch 37/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00037: val_acc did not improve from 0.96513\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1033 - acc: 0.9714 - f1score: 0.9705 - val_loss: 0.1238 - val_acc: 0.9480 - val_f1score: 0.9475\n",
      "Epoch 38/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9669 - f1score: 0.9669\n",
      "Epoch 00038: val_acc did not improve from 0.96513\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1044 - acc: 0.9675 - f1score: 0.9680 - val_loss: 0.1228 - val_acc: 0.9646 - val_f1score: 0.9658\n",
      "Epoch 39/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00039: val_acc did not improve from 0.96513\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1074 - acc: 0.9704 - f1score: 0.9699 - val_loss: 0.1483 - val_acc: 0.9587 - val_f1score: 0.9584\n",
      "Epoch 40/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00040: val_acc did not improve from 0.96513\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1054 - acc: 0.9672 - f1score: 0.9663 - val_loss: 0.1248 - val_acc: 0.9646 - val_f1score: 0.9639\n",
      "Epoch 41/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9679 - f1score: 0.9680\n",
      "Epoch 00041: val_acc did not improve from 0.96513\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1126 - acc: 0.9680 - f1score: 0.9680 - val_loss: 0.1409 - val_acc: 0.9587 - val_f1score: 0.9605\n",
      "Epoch 42/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9696 - f1score: 0.9695\n",
      "Epoch 00042: val_acc did not improve from 0.96513\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1083 - acc: 0.9696 - f1score: 0.9695 - val_loss: 0.1273 - val_acc: 0.9624 - val_f1score: 0.9624\n",
      "Epoch 43/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9688 - f1score: 0.9687\n",
      "Epoch 00043: val_acc improved from 0.96513 to 0.96567, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.43-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1002 - acc: 0.9690 - f1score: 0.9693 - val_loss: 0.1162 - val_acc: 0.9657 - val_f1score: 0.9644\n",
      "Epoch 44/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9690 - f1score: 0.9691\n",
      "Epoch 00044: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0992 - acc: 0.9690 - f1score: 0.9692 - val_loss: 0.1149 - val_acc: 0.9587 - val_f1score: 0.9599\n",
      "Epoch 45/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9701 - f1score: 0.9702\n",
      "Epoch 00045: val_acc improved from 0.96567 to 0.96835, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.45-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1041 - acc: 0.9701 - f1score: 0.9702 - val_loss: 0.1180 - val_acc: 0.9683 - val_f1score: 0.9693\n",
      "Epoch 46/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9671 - f1score: 0.9672\n",
      "Epoch 00046: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1014 - acc: 0.9677 - f1score: 0.9683 - val_loss: 0.1142 - val_acc: 0.9603 - val_f1score: 0.9621\n",
      "Epoch 47/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00047: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0989 - acc: 0.9725 - f1score: 0.9716 - val_loss: 0.1146 - val_acc: 0.9624 - val_f1score: 0.9630\n",
      "Epoch 48/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9688 - f1score: 0.9688\n",
      "Epoch 00048: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0963 - acc: 0.9693 - f1score: 0.9698 - val_loss: 0.1179 - val_acc: 0.9549 - val_f1score: 0.9545\n",
      "Epoch 49/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00049: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0958 - acc: 0.9720 - f1score: 0.9720 - val_loss: 0.1154 - val_acc: 0.9587 - val_f1score: 0.9579\n",
      "Epoch 50/50\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9747 - f1score: 0.9748\n",
      "Epoch 00050: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0944 - acc: 0.9738 - f1score: 0.9732 - val_loss: 0.1111 - val_acc: 0.9673 - val_f1score: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|         | 36/1296 [2:43:30<169:01:49, 482.94s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 8.4832 - acc: 0.4203 - f1score: 0.4203\n",
      "Epoch 00001: val_acc improved from -inf to 0.45172, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-8.09.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 8.4458 - acc: 0.4233 - f1score: 0.4259 - val_loss: 8.0944 - val_acc: 0.4517 - val_f1score: 0.4556\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 7.0768 - acc: 0.4811 - f1score: 0.4811\n",
      "Epoch 00002: val_acc improved from 0.45172 to 0.84013, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.58.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 7.0050 - acc: 0.4847 - f1score: 0.4877 - val_loss: 0.5763 - val_acc: 0.8401 - val_f1score: 0.8407\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.7241 - acc: 0.8082 - f1score: 0.8082\n",
      "Epoch 00003: val_acc improved from 0.84013 to 0.89378, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.36.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.7140 - acc: 0.8090 - f1score: 0.8097 - val_loss: 0.3563 - val_acc: 0.8938 - val_f1score: 0.8944\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.7301 - acc: 0.8260 - f1score: 0.8260\n",
      "Epoch 00004: val_acc improved from 0.89378 to 0.91202, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.41.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.7187 - acc: 0.8270 - f1score: 0.8278 - val_loss: 0.4118 - val_acc: 0.9120 - val_f1score: 0.9138\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.3884 - acc: 0.8529 - f1score: 0.8529\n",
      "Epoch 00005: val_acc improved from 0.91202 to 0.91524, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.37.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3743 - acc: 0.8534 - f1score: 0.8539 - val_loss: 0.3700 - val_acc: 0.9152 - val_f1score: 0.9161\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.1603 - acc: 0.8712 - f1score: 0.8712\n",
      "Epoch 00006: val_acc improved from 0.91524 to 0.93026, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.44.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1485 - acc: 0.8725 - f1score: 0.8736 - val_loss: 0.4363 - val_acc: 0.9303 - val_f1score: 0.9299\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.0631 - acc: 0.8798 - f1score: 0.8798\n",
      "Epoch 00007: val_acc did not improve from 0.93026\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0651 - acc: 0.8788 - f1score: 0.8780 - val_loss: 0.4377 - val_acc: 0.9067 - val_f1score: 0.9045\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8491 - acc: 0.8966 - f1score: 0.8966\n",
      "Epoch 00008: val_acc improved from 0.93026 to 0.93240, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.43.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.8345 - acc: 0.8979 - f1score: 0.8990 - val_loss: 0.4312 - val_acc: 0.9324 - val_f1score: 0.9336\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5668 - acc: 0.9197 - f1score: 0.9197\n",
      "Epoch 00009: val_acc did not improve from 0.93240\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5666 - acc: 0.9196 - f1score: 0.9195 - val_loss: 0.4101 - val_acc: 0.9281 - val_f1score: 0.9294\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4706 - acc: 0.9348 - f1score: 0.9348\n",
      "Epoch 00010: val_acc improved from 0.93240 to 0.95708, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.35.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4649 - acc: 0.9349 - f1score: 0.9350 - val_loss: 0.3534 - val_acc: 0.9571 - val_f1score: 0.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|         | 37/1296 [2:44:57<127:17:39, 363.99s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 5.3639 - acc: 0.4165 - f1score: 0.4165\n",
      "Epoch 00001: val_acc improved from -inf to 0.54828, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-1.08.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 5.3069 - acc: 0.4175 - f1score: 0.4183 - val_loss: 1.0811 - val_acc: 0.5483 - val_f1score: 0.5485\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.0980 - acc: 0.7430 - f1score: 0.7430\n",
      "Epoch 00002: val_acc improved from 0.54828 to 0.91524, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.28.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.0988 - acc: 0.7429 - f1score: 0.7427 - val_loss: 0.2779 - val_acc: 0.9152 - val_f1score: 0.9128\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.6634 - acc: 0.8631 - f1score: 0.8631\n",
      "Epoch 00003: val_acc improved from 0.91524 to 0.92918, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.22.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.6684 - acc: 0.8630 - f1score: 0.8628 - val_loss: 0.2213 - val_acc: 0.9292 - val_f1score: 0.9296\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5436 - acc: 0.8879 - f1score: 0.8879\n",
      "Epoch 00004: val_acc improved from 0.92918 to 0.93026, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.25.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5614 - acc: 0.8873 - f1score: 0.8868 - val_loss: 0.2500 - val_acc: 0.9303 - val_f1score: 0.9291\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4283 - acc: 0.9111 - f1score: 0.9111\n",
      "Epoch 00005: val_acc improved from 0.93026 to 0.94635, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.26.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4430 - acc: 0.9090 - f1score: 0.9072 - val_loss: 0.2563 - val_acc: 0.9464 - val_f1score: 0.9463\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3299 - acc: 0.9267 - f1score: 0.9267\n",
      "Epoch 00006: val_acc did not improve from 0.94635\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.3292 - acc: 0.9270 - f1score: 0.9272 - val_loss: 0.2045 - val_acc: 0.9442 - val_f1score: 0.9434\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2647 - acc: 0.9391 - f1score: 0.9391\n",
      "Epoch 00007: val_acc did not improve from 0.94635\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2656 - acc: 0.9381 - f1score: 0.9372 - val_loss: 0.2186 - val_acc: 0.9453 - val_f1score: 0.9469\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2275 - acc: 0.9397 - f1score: 0.9397\n",
      "Epoch 00008: val_acc improved from 0.94635 to 0.94742, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.16.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.2265 - acc: 0.9402 - f1score: 0.9407 - val_loss: 0.1634 - val_acc: 0.9474 - val_f1score: 0.9490\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2097 - acc: 0.9440 - f1score: 0.9440\n",
      "Epoch 00009: val_acc improved from 0.94742 to 0.95601, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.17.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.2084 - acc: 0.9434 - f1score: 0.9429 - val_loss: 0.1658 - val_acc: 0.9560 - val_f1score: 0.9573\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1900 - acc: 0.9526 - f1score: 0.9526\n",
      "Epoch 00010: val_acc did not improve from 0.95601\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1893 - acc: 0.9524 - f1score: 0.9522 - val_loss: 0.1416 - val_acc: 0.9517 - val_f1score: 0.9507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|         | 38/1296 [2:46:29<98:42:14, 282.46s/it] \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.8528 - acc: 0.5787 - f1score: 0.5787\n",
      "Epoch 00001: val_acc improved from -inf to 0.89914, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.30.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 1.8353 - acc: 0.5831 - f1score: 0.5868 - val_loss: 0.3038 - val_acc: 0.8991 - val_f1score: 0.8988\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8657 - acc: 0.8696 - f1score: 0.8696\n",
      "Epoch 00002: val_acc improved from 0.89914 to 0.93026, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.22.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.8672 - acc: 0.8688 - f1score: 0.8681 - val_loss: 0.2232 - val_acc: 0.9303 - val_f1score: 0.9299\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7443 - acc: 0.8906 - f1score: 0.8906\n",
      "Epoch 00003: val_acc improved from 0.93026 to 0.95172, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.30.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7542 - acc: 0.8899 - f1score: 0.8894 - val_loss: 0.3022 - val_acc: 0.9517 - val_f1score: 0.9523\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5360 - acc: 0.9181 - f1score: 0.9181\n",
      "Epoch 00004: val_acc did not improve from 0.95172\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5349 - acc: 0.9190 - f1score: 0.9199 - val_loss: 0.3697 - val_acc: 0.9474 - val_f1score: 0.9449\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4315 - acc: 0.9321 - f1score: 0.9321\n",
      "Epoch 00005: val_acc improved from 0.95172 to 0.95279, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.34.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4247 - acc: 0.9328 - f1score: 0.9334 - val_loss: 0.3381 - val_acc: 0.9528 - val_f1score: 0.9501\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3255 - acc: 0.9483 - f1score: 0.9483\n",
      "Epoch 00006: val_acc did not improve from 0.95279\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.3200 - acc: 0.9492 - f1score: 0.9500 - val_loss: 0.2796 - val_acc: 0.9453 - val_f1score: 0.9461\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2391 - acc: 0.9537 - f1score: 0.9537\n",
      "Epoch 00007: val_acc improved from 0.95279 to 0.95708, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.21.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2368 - acc: 0.9540 - f1score: 0.9542 - val_loss: 0.2099 - val_acc: 0.9571 - val_f1score: 0.9559\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1878 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00008: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1923 - acc: 0.9603 - f1score: 0.9591 - val_loss: 0.1584 - val_acc: 0.9431 - val_f1score: 0.9432\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9569 - f1score: 0.9569\n",
      "Epoch 00009: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1726 - acc: 0.9571 - f1score: 0.9574 - val_loss: 0.1452 - val_acc: 0.9506 - val_f1score: 0.9513\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1350 - acc: 0.9569 - f1score: 0.9569\n",
      "Epoch 00010: val_acc did not improve from 0.95708\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1333 - acc: 0.9577 - f1score: 0.9583 - val_loss: 0.1381 - val_acc: 0.9549 - val_f1score: 0.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|         | 39/1296 [2:48:01<78:42:02, 225.40s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 6.2560 - acc: 0.4181 - f1score: 0.4181\n",
      "Epoch 00001: val_acc improved from -inf to 0.72747, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.82.h5\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 6.1600 - acc: 0.4243 - f1score: 0.4297 - val_loss: 0.8181 - val_acc: 0.7275 - val_f1score: 0.7281\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.0489 - acc: 0.7575 - f1score: 0.7575\n",
      "Epoch 00002: val_acc improved from 0.72747 to 0.90129, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.44.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 2.0353 - acc: 0.7598 - f1score: 0.7617 - val_loss: 0.4435 - val_acc: 0.9013 - val_f1score: 0.9017\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.3677 - acc: 0.8448 - f1score: 0.8448\n",
      "Epoch 00003: val_acc did not improve from 0.90129\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3580 - acc: 0.8450 - f1score: 0.8451 - val_loss: 0.4559 - val_acc: 0.8981 - val_f1score: 0.8954\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.2441 - acc: 0.8540 - f1score: 0.8540\n",
      "Epoch 00004: val_acc did not improve from 0.90129\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.2457 - acc: 0.8545 - f1score: 0.8549 - val_loss: 0.4709 - val_acc: 0.8981 - val_f1score: 0.8986\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8007 - acc: 0.8928 - f1score: 0.8928\n",
      "Epoch 00005: val_acc improved from 0.90129 to 0.91631, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.45.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7917 - acc: 0.8926 - f1score: 0.8924 - val_loss: 0.4460 - val_acc: 0.9163 - val_f1score: 0.9123\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7452 - acc: 0.8976 - f1score: 0.8976\n",
      "Epoch 00006: val_acc did not improve from 0.91631\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7437 - acc: 0.8984 - f1score: 0.8991 - val_loss: 0.4656 - val_acc: 0.9163 - val_f1score: 0.9163\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7487 - acc: 0.9084 - f1score: 0.9084\n",
      "Epoch 00007: val_acc did not improve from 0.91631\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7385 - acc: 0.9085 - f1score: 0.9085 - val_loss: 0.4429 - val_acc: 0.9077 - val_f1score: 0.9072\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.6790 - acc: 0.9106 - f1score: 0.9106\n",
      "Epoch 00008: val_acc improved from 0.91631 to 0.92489, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.46.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6671 - acc: 0.9122 - f1score: 0.9135 - val_loss: 0.4627 - val_acc: 0.9249 - val_f1score: 0.9263\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5514 - acc: 0.9278 - f1score: 0.9278\n",
      "Epoch 00009: val_acc improved from 0.92489 to 0.92918, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.44.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5604 - acc: 0.9270 - f1score: 0.9263 - val_loss: 0.4406 - val_acc: 0.9292 - val_f1score: 0.9304\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5485 - acc: 0.9397 - f1score: 0.9397\n",
      "Epoch 00010: val_acc improved from 0.92918 to 0.93884, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.41.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5388 - acc: 0.9407 - f1score: 0.9417 - val_loss: 0.4058 - val_acc: 0.9388 - val_f1score: 0.9382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|         | 40/1296 [2:49:30<64:23:24, 184.56s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.0558 - acc: 0.7915 - f1score: 0.7915\n",
      "Epoch 00001: val_acc improved from -inf to 0.93133, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.26.h5\n",
      "1890/1890 [==============================] - 16s 8ms/sample - loss: 1.0439 - acc: 0.7937 - f1score: 0.7955 - val_loss: 0.2627 - val_acc: 0.9313 - val_f1score: 0.9301\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3349 - acc: 0.9224 - f1score: 0.9224\n",
      "Epoch 00002: val_acc improved from 0.93133 to 0.94957, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.27.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.3296 - acc: 0.9238 - f1score: 0.9250 - val_loss: 0.2661 - val_acc: 0.9496 - val_f1score: 0.9502\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2262 - acc: 0.9467 - f1score: 0.9467\n",
      "Epoch 00003: val_acc did not improve from 0.94957\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2238 - acc: 0.9466 - f1score: 0.9465 - val_loss: 0.2368 - val_acc: 0.9464 - val_f1score: 0.9471\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1971 - acc: 0.9526 - f1score: 0.9526\n",
      "Epoch 00004: val_acc improved from 0.94957 to 0.95708, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1942 - acc: 0.9534 - f1score: 0.9542 - val_loss: 0.1702 - val_acc: 0.9571 - val_f1score: 0.9567\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9520 - f1score: 0.9520\n",
      "Epoch 00005: val_acc improved from 0.95708 to 0.96459, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.15.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1620 - acc: 0.9519 - f1score: 0.9517 - val_loss: 0.1478 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9580 - f1score: 0.9580\n",
      "Epoch 00006: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1449 - acc: 0.9582 - f1score: 0.9584 - val_loss: 0.1558 - val_acc: 0.9560 - val_f1score: 0.9557\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00007: val_acc improved from 0.96459 to 0.96674, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.15.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1333 - acc: 0.9593 - f1score: 0.9599 - val_loss: 0.1530 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00008: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1252 - acc: 0.9635 - f1score: 0.9627 - val_loss: 0.1385 - val_acc: 0.9582 - val_f1score: 0.9594\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00009: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1299 - acc: 0.9598 - f1score: 0.9600 - val_loss: 0.1347 - val_acc: 0.9646 - val_f1score: 0.9640\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00010: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1238 - acc: 0.9635 - f1score: 0.9641 - val_loss: 0.1453 - val_acc: 0.9474 - val_f1score: 0.9490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|         | 41/1296 [2:51:32<57:46:44, 165.74s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.9446 - acc: 0.7667 - f1score: 0.7667\n",
      "Epoch 00001: val_acc improved from -inf to 0.90665, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.34.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.9320 - acc: 0.7693 - f1score: 0.7715 - val_loss: 0.3369 - val_acc: 0.9067 - val_f1score: 0.9069\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2790 - acc: 0.9133 - f1score: 0.9133\n",
      "Epoch 00002: val_acc improved from 0.90665 to 0.94850, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.20.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.2832 - acc: 0.9127 - f1score: 0.9122 - val_loss: 0.2008 - val_acc: 0.9485 - val_f1score: 0.9492\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2000 - acc: 0.9364 - f1score: 0.9364\n",
      "Epoch 00003: val_acc did not improve from 0.94850\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1978 - acc: 0.9370 - f1score: 0.9376 - val_loss: 0.1773 - val_acc: 0.9399 - val_f1score: 0.9400\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1640 - acc: 0.9515 - f1score: 0.9515\n",
      "Epoch 00004: val_acc improved from 0.94850 to 0.95172, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.16.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1639 - acc: 0.9519 - f1score: 0.9521 - val_loss: 0.1568 - val_acc: 0.9517 - val_f1score: 0.9531\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9574 - f1score: 0.9574\n",
      "Epoch 00005: val_acc did not improve from 0.95172\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1376 - acc: 0.9571 - f1score: 0.9569 - val_loss: 0.1561 - val_acc: 0.9496 - val_f1score: 0.9470\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00006: val_acc did not improve from 0.95172\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1411 - acc: 0.9593 - f1score: 0.9585 - val_loss: 0.1674 - val_acc: 0.9442 - val_f1score: 0.9442\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9569 - f1score: 0.9569\n",
      "Epoch 00007: val_acc did not improve from 0.95172\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1364 - acc: 0.9571 - f1score: 0.9574 - val_loss: 0.1473 - val_acc: 0.9496 - val_f1score: 0.9486\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9574 - f1score: 0.9574\n",
      "Epoch 00008: val_acc improved from 0.95172 to 0.96137, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.15.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1256 - acc: 0.9577 - f1score: 0.9579 - val_loss: 0.1526 - val_acc: 0.9614 - val_f1score: 0.9617\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00009: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1266 - acc: 0.9603 - f1score: 0.9605 - val_loss: 0.1554 - val_acc: 0.9517 - val_f1score: 0.9515\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00010: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1281 - acc: 0.9651 - f1score: 0.9638 - val_loss: 0.1675 - val_acc: 0.9453 - val_f1score: 0.9461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|         | 42/1296 [2:53:32<52:52:41, 151.80s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.8472 - acc: 0.6719 - f1score: 0.6617\n",
      "Epoch 00001: val_acc improved from -inf to 0.82994, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.86.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 1.8264 - acc: 0.6738 - f1score: 0.6658 - val_loss: 0.8586 - val_acc: 0.8299 - val_f1score: 0.8274\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.1001 - acc: 0.8284 - f1score: 0.8320\n",
      "Epoch 00002: val_acc improved from 0.82994 to 0.90504, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.28.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0998 - acc: 0.8294 - f1score: 0.8339 - val_loss: 0.2819 - val_acc: 0.9050 - val_f1score: 0.9046\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.0744 - acc: 0.8634 - f1score: 0.8631\n",
      "Epoch 00003: val_acc improved from 0.90504 to 0.91631, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.24.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0701 - acc: 0.8638 - f1score: 0.8637 - val_loss: 0.2443 - val_acc: 0.9163 - val_f1score: 0.9173\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8200 - acc: 0.8877 - f1score: 0.8873\n",
      "Epoch 00004: val_acc improved from 0.91631 to 0.92060, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.23.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.8165 - acc: 0.8881 - f1score: 0.8881 - val_loss: 0.2334 - val_acc: 0.9206 - val_f1score: 0.9213\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8240 - acc: 0.8793 - f1score: 0.8789\n",
      "Epoch 00005: val_acc improved from 0.92060 to 0.93562, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.22.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.8204 - acc: 0.8794 - f1score: 0.8790 - val_loss: 0.2158 - val_acc: 0.9356 - val_f1score: 0.9333\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5324 - acc: 0.8976 - f1score: 0.8973\n",
      "Epoch 00006: val_acc did not improve from 0.93562\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5304 - acc: 0.8976 - f1score: 0.8975 - val_loss: 0.1936 - val_acc: 0.9356 - val_f1score: 0.9352\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3687 - acc: 0.9251 - f1score: 0.9243\n",
      "Epoch 00007: val_acc improved from 0.93562 to 0.94903, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.19.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.3669 - acc: 0.9254 - f1score: 0.9249 - val_loss: 0.1909 - val_acc: 0.9490 - val_f1score: 0.9494\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2923 - acc: 0.9329 - f1score: 0.9318\n",
      "Epoch 00008: val_acc improved from 0.94903 to 0.96352, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.20.h5\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.2893 - acc: 0.9328 - f1score: 0.9316 - val_loss: 0.1957 - val_acc: 0.9635 - val_f1score: 0.9631\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2076 - acc: 0.9502 - f1score: 0.9497\n",
      "Epoch 00009: val_acc did not improve from 0.96352\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.2104 - acc: 0.9492 - f1score: 0.9479 - val_loss: 0.1744 - val_acc: 0.9517 - val_f1score: 0.9521\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1845 - acc: 0.9475 - f1score: 0.9471\n",
      "Epoch 00010: val_acc did not improve from 0.96352\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1897 - acc: 0.9460 - f1score: 0.9444 - val_loss: 0.1577 - val_acc: 0.9587 - val_f1score: 0.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|         | 43/1296 [2:55:05<46:46:23, 134.38s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.1336 - acc: 0.7064 - f1score: 0.7341\n",
      "Epoch 00001: val_acc improved from -inf to 0.78648, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-1.02.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 2.1248 - acc: 0.7077 - f1score: 0.7357 - val_loss: 1.0190 - val_acc: 0.7865 - val_f1score: 0.8020\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.4839 - acc: 0.7629 - f1score: 0.7641\n",
      "Epoch 00002: val_acc improved from 0.78648 to 0.86695, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.39.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.4861 - acc: 0.7630 - f1score: 0.7642 - val_loss: 0.3877 - val_acc: 0.8670 - val_f1score: 0.8733\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.1328 - acc: 0.8537 - f1score: 0.8540\n",
      "Epoch 00003: val_acc improved from 0.86695 to 0.91202, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.27.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.1230 - acc: 0.8553 - f1score: 0.8569 - val_loss: 0.2652 - val_acc: 0.9120 - val_f1score: 0.9117\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.1155 - acc: 0.8747 - f1score: 0.8740\n",
      "Epoch 00004: val_acc improved from 0.91202 to 0.93240, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.21.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0982 - acc: 0.8765 - f1score: 0.8772 - val_loss: 0.2129 - val_acc: 0.9324 - val_f1score: 0.9314\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.1996 - acc: 0.8793 - f1score: 0.8791\n",
      "Epoch 00005: val_acc improved from 0.93240 to 0.94045, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.18.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.2040 - acc: 0.8794 - f1score: 0.8792 - val_loss: 0.1778 - val_acc: 0.9405 - val_f1score: 0.9396\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.1646 - acc: 0.8836 - f1score: 0.8835\n",
      "Epoch 00006: val_acc improved from 0.94045 to 0.94313, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.17.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.1626 - acc: 0.8836 - f1score: 0.8834 - val_loss: 0.1672 - val_acc: 0.9431 - val_f1score: 0.9424\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.9630 - acc: 0.8990 - f1score: 0.8991\n",
      "Epoch 00007: val_acc did not improve from 0.94313\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.9750 - acc: 0.8981 - f1score: 0.8975 - val_loss: 0.3236 - val_acc: 0.8546 - val_f1score: 0.8545\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.0392 - acc: 0.8949 - f1score: 0.8949\n",
      "Epoch 00008: val_acc improved from 0.94313 to 0.96030, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.16.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.0534 - acc: 0.8947 - f1score: 0.8945 - val_loss: 0.1576 - val_acc: 0.9603 - val_f1score: 0.9605\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8615 - acc: 0.9146 - f1score: 0.9146\n",
      "Epoch 00009: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.8565 - acc: 0.9151 - f1score: 0.9155 - val_loss: 0.1502 - val_acc: 0.9528 - val_f1score: 0.9527\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.9248 - acc: 0.9100 - f1score: 0.9102\n",
      "Epoch 00010: val_acc improved from 0.96030 to 0.96567, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.14.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.9254 - acc: 0.9106 - f1score: 0.9112 - val_loss: 0.1394 - val_acc: 0.9657 - val_f1score: 0.9650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|         | 44/1296 [2:56:39<42:27:39, 122.09s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.2251 - acc: 0.6153 - f1score: 0.5521\n",
      "Epoch 00001: val_acc improved from -inf to 0.80687, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.78.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 2.2066 - acc: 0.6180 - f1score: 0.5592 - val_loss: 0.7823 - val_acc: 0.8069 - val_f1score: 0.8124\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.6959 - acc: 0.8502 - f1score: 0.8497\n",
      "Epoch 00002: val_acc improved from 0.80687 to 0.90451, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.29.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6910 - acc: 0.8503 - f1score: 0.8500 - val_loss: 0.2917 - val_acc: 0.9045 - val_f1score: 0.9034\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4264 - acc: 0.8982 - f1score: 0.8980\n",
      "Epoch 00003: val_acc improved from 0.90451 to 0.92328, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.25.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4294 - acc: 0.8974 - f1score: 0.8965 - val_loss: 0.2521 - val_acc: 0.9233 - val_f1score: 0.9229\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3663 - acc: 0.9141 - f1score: 0.9141\n",
      "Epoch 00004: val_acc improved from 0.92328 to 0.93187, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.24.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.3629 - acc: 0.9146 - f1score: 0.9150 - val_loss: 0.2438 - val_acc: 0.9319 - val_f1score: 0.9291\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2806 - acc: 0.9294 - f1score: 0.9291\n",
      "Epoch 00005: val_acc improved from 0.93187 to 0.93616, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.22.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.2834 - acc: 0.9291 - f1score: 0.9285 - val_loss: 0.2188 - val_acc: 0.9362 - val_f1score: 0.9342\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2481 - acc: 0.9383 - f1score: 0.9382\n",
      "Epoch 00006: val_acc improved from 0.93616 to 0.94528, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.20.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2451 - acc: 0.9386 - f1score: 0.9388 - val_loss: 0.1998 - val_acc: 0.9453 - val_f1score: 0.9450\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2274 - acc: 0.9434 - f1score: 0.9428\n",
      "Epoch 00007: val_acc did not improve from 0.94528\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2367 - acc: 0.9421 - f1score: 0.9404 - val_loss: 0.5910 - val_acc: 0.8455 - val_f1score: 0.8447\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2114 - acc: 0.9453 - f1score: 0.9451\n",
      "Epoch 00008: val_acc improved from 0.94528 to 0.95547, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.14.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2127 - acc: 0.9450 - f1score: 0.9444 - val_loss: 0.1448 - val_acc: 0.9555 - val_f1score: 0.9538\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1896 - acc: 0.9564 - f1score: 0.9562\n",
      "Epoch 00009: val_acc improved from 0.95547 to 0.95869, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.14.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1872 - acc: 0.9566 - f1score: 0.9567 - val_loss: 0.1389 - val_acc: 0.9587 - val_f1score: 0.9576\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9580 - f1score: 0.9579\n",
      "Epoch 00010: val_acc improved from 0.95869 to 0.96030, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.14.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1652 - acc: 0.9577 - f1score: 0.9573 - val_loss: 0.1384 - val_acc: 0.9603 - val_f1score: 0.9612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|         | 45/1296 [2:58:24<40:39:03, 116.98s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 3.7170 - acc: 0.5207 - f1score: 0.3133\n",
      "Epoch 00001: val_acc improved from -inf to 0.75536, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.82.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 3.6762 - acc: 0.5243 - f1score: 0.3270 - val_loss: 0.8229 - val_acc: 0.7554 - val_f1score: 0.7886\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.4048 - acc: 0.8033 - f1score: 0.8146\n",
      "Epoch 00002: val_acc improved from 0.75536 to 0.87661, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.68.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.3939 - acc: 0.8048 - f1score: 0.8170 - val_loss: 0.6764 - val_acc: 0.8766 - val_f1score: 0.8878\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.0411 - acc: 0.8545 - f1score: 0.8571\n",
      "Epoch 00003: val_acc improved from 0.87661 to 0.91470, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.38.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0366 - acc: 0.8553 - f1score: 0.8585 - val_loss: 0.3819 - val_acc: 0.9147 - val_f1score: 0.9191\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8795 - acc: 0.8804 - f1score: 0.8828\n",
      "Epoch 00004: val_acc improved from 0.91470 to 0.92167, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.34.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.8788 - acc: 0.8807 - f1score: 0.8833 - val_loss: 0.3369 - val_acc: 0.9217 - val_f1score: 0.9239\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.6993 - acc: 0.9052 - f1score: 0.9069\n",
      "Epoch 00005: val_acc improved from 0.92167 to 0.93509, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.31.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6959 - acc: 0.9050 - f1score: 0.9067 - val_loss: 0.3081 - val_acc: 0.9351 - val_f1score: 0.9373\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.6559 - acc: 0.9122 - f1score: 0.9145\n",
      "Epoch 00006: val_acc improved from 0.93509 to 0.94260, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.27.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6516 - acc: 0.9124 - f1score: 0.9149 - val_loss: 0.2673 - val_acc: 0.9426 - val_f1score: 0.9431\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5312 - acc: 0.9246 - f1score: 0.9260\n",
      "Epoch 00007: val_acc improved from 0.94260 to 0.95976, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.30.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5476 - acc: 0.9238 - f1score: 0.9248 - val_loss: 0.2951 - val_acc: 0.9598 - val_f1score: 0.9595\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4001 - acc: 0.9364 - f1score: 0.9371\n",
      "Epoch 00008: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4046 - acc: 0.9357 - f1score: 0.9357 - val_loss: 0.3080 - val_acc: 0.9544 - val_f1score: 0.9533\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3581 - acc: 0.9415 - f1score: 0.9413\n",
      "Epoch 00009: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.3518 - acc: 0.9426 - f1score: 0.9432 - val_loss: 0.2470 - val_acc: 0.9598 - val_f1score: 0.9595\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2951 - acc: 0.9453 - f1score: 0.9456\n",
      "Epoch 00010: val_acc did not improve from 0.95976\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2925 - acc: 0.9458 - f1score: 0.9464 - val_loss: 0.2814 - val_acc: 0.9582 - val_f1score: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|         | 46/1296 [2:59:56<37:59:38, 109.42s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.3911 - acc: 0.7209 - f1score: 0.6777\n",
      "Epoch 00001: val_acc improved from -inf to 0.88144, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.68.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 1.3735 - acc: 0.7235 - f1score: 0.6843 - val_loss: 0.6825 - val_acc: 0.8814 - val_f1score: 0.8814\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.6560 - acc: 0.8777 - f1score: 0.8772\n",
      "Epoch 00002: val_acc improved from 0.88144 to 0.90290, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.40.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.6559 - acc: 0.8783 - f1score: 0.8782 - val_loss: 0.3968 - val_acc: 0.9029 - val_f1score: 0.9026\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4912 - acc: 0.9089 - f1score: 0.9081\n",
      "Epoch 00003: val_acc improved from 0.90290 to 0.92006, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.38.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4972 - acc: 0.9079 - f1score: 0.9063 - val_loss: 0.3759 - val_acc: 0.9201 - val_f1score: 0.9209\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4167 - acc: 0.9216 - f1score: 0.9212\n",
      "Epoch 00004: val_acc improved from 0.92006 to 0.93991, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.28.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4150 - acc: 0.9214 - f1score: 0.9208 - val_loss: 0.2845 - val_acc: 0.9399 - val_f1score: 0.9393\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2965 - acc: 0.9397 - f1score: 0.9392\n",
      "Epoch 00005: val_acc improved from 0.93991 to 0.95547, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.26.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.2940 - acc: 0.9402 - f1score: 0.9402 - val_loss: 0.2618 - val_acc: 0.9555 - val_f1score: 0.9558\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2667 - acc: 0.9429 - f1score: 0.9424\n",
      "Epoch 00006: val_acc improved from 0.95547 to 0.95869, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.22.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.2632 - acc: 0.9431 - f1score: 0.9429 - val_loss: 0.2175 - val_acc: 0.9587 - val_f1score: 0.9592\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9502 - f1score: 0.9501\n",
      "Epoch 00007: val_acc did not improve from 0.95869\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2251 - acc: 0.9503 - f1score: 0.9502 - val_loss: 0.2207 - val_acc: 0.9571 - val_f1score: 0.9576\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2000 - acc: 0.9537 - f1score: 0.9535\n",
      "Epoch 00008: val_acc did not improve from 0.95869\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1983 - acc: 0.9537 - f1score: 0.9536 - val_loss: 0.2174 - val_acc: 0.9464 - val_f1score: 0.9455\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1738 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00009: val_acc did not improve from 0.95869\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1719 - acc: 0.9585 - f1score: 0.9584 - val_loss: 0.1680 - val_acc: 0.9587 - val_f1score: 0.9583\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1729 - acc: 0.9596 - f1score: 0.9595\n",
      "Epoch 00010: val_acc did not improve from 0.95869\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1707 - acc: 0.9598 - f1score: 0.9599 - val_loss: 0.1666 - val_acc: 0.9464 - val_f1score: 0.9452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|         | 47/1296 [3:01:56<39:04:02, 112.60s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7571 - acc: 0.6888 - f1score: 0.6908\n",
      "Epoch 00001: val_acc improved from -inf to 0.86212, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.34.h5\n",
      "1890/1890 [==============================] - 15s 8ms/sample - loss: 0.7505 - acc: 0.6915 - f1score: 0.6955 - val_loss: 0.3395 - val_acc: 0.8621 - val_f1score: 0.8569\n",
      "Epoch 2/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2353 - acc: 0.9192 - f1score: 0.9191\n",
      "Epoch 00002: val_acc improved from 0.86212 to 0.93348, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.21.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.2353 - acc: 0.9196 - f1score: 0.9198 - val_loss: 0.2146 - val_acc: 0.9335 - val_f1score: 0.9340\n",
      "Epoch 3/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9383 - f1score: 0.9384\n",
      "Epoch 00003: val_acc improved from 0.93348 to 0.93830, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.18.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1714 - acc: 0.9384 - f1score: 0.9385 - val_loss: 0.1784 - val_acc: 0.9383 - val_f1score: 0.9395\n",
      "Epoch 4/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1541 - acc: 0.9531 - f1score: 0.9533\n",
      "Epoch 00004: val_acc improved from 0.93830 to 0.94313, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.16.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1545 - acc: 0.9529 - f1score: 0.9529 - val_loss: 0.1596 - val_acc: 0.9431 - val_f1score: 0.9432\n",
      "Epoch 5/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9593 - f1score: 0.9594\n",
      "Epoch 00005: val_acc improved from 0.94313 to 0.95655, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.15.h5\n",
      "1890/1890 [==============================] - 14s 7ms/sample - loss: 0.1361 - acc: 0.9590 - f1score: 0.9588 - val_loss: 0.1450 - val_acc: 0.9565 - val_f1score: 0.9571\n",
      "Epoch 6/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9572 - f1score: 0.9573\n",
      "Epoch 00006: val_acc did not improve from 0.95655\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1333 - acc: 0.9569 - f1score: 0.9567 - val_loss: 0.1410 - val_acc: 0.9560 - val_f1score: 0.9553\n",
      "Epoch 7/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00007: val_acc improved from 0.95655 to 0.95762, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.14.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1210 - acc: 0.9587 - f1score: 0.9585 - val_loss: 0.1380 - val_acc: 0.9576 - val_f1score: 0.9580\n",
      "Epoch 8/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9591 - f1score: 0.9592\n",
      "Epoch 00008: val_acc did not improve from 0.95762\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1249 - acc: 0.9593 - f1score: 0.9595 - val_loss: 0.1331 - val_acc: 0.9555 - val_f1score: 0.9552\n",
      "Epoch 9/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9631 - f1score: 0.9631\n",
      "Epoch 00009: val_acc improved from 0.95762 to 0.96191, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.13.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1175 - acc: 0.9632 - f1score: 0.9633 - val_loss: 0.1330 - val_acc: 0.9619 - val_f1score: 0.9629\n",
      "Epoch 10/10\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9599 - f1score: 0.9598\n",
      "Epoch 00010: val_acc improved from 0.96191 to 0.96620, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1181 - acc: 0.9606 - f1score: 0.9611 - val_loss: 0.1309 - val_acc: 0.9662 - val_f1score: 0.9672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|         | 48/1296 [3:04:06<40:50:06, 117.79s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.7884 - acc: 0.4644 - f1score: 0.4644\n",
      "Epoch 00001: val_acc improved from -inf to 0.75536, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.50.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.7781 - acc: 0.4688 - f1score: 0.4725 - val_loss: 0.5013 - val_acc: 0.7554 - val_f1score: 0.7544\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7252 - acc: 0.8324 - f1score: 0.8324\n",
      "Epoch 00002: val_acc improved from 0.75536 to 0.89807, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.28.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.7192 - acc: 0.8333 - f1score: 0.8341 - val_loss: 0.2760 - val_acc: 0.8981 - val_f1score: 0.9002\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5053 - acc: 0.8825 - f1score: 0.8825\n",
      "Epoch 00003: val_acc improved from 0.89807 to 0.92382, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.24.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.5035 - acc: 0.8825 - f1score: 0.8825 - val_loss: 0.2426 - val_acc: 0.9238 - val_f1score: 0.9244\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3428 - acc: 0.9143 - f1score: 0.9143\n",
      "Epoch 00004: val_acc improved from 0.92382 to 0.93562, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.20.h5\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.3418 - acc: 0.9148 - f1score: 0.9152 - val_loss: 0.2037 - val_acc: 0.9356 - val_f1score: 0.9351\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2561 - acc: 0.9305 - f1score: 0.9305\n",
      "Epoch 00005: val_acc improved from 0.93562 to 0.94635, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.22.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2587 - acc: 0.9291 - f1score: 0.9279 - val_loss: 0.2238 - val_acc: 0.9464 - val_f1score: 0.9471\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2459 - acc: 0.9407 - f1score: 0.9407\n",
      "Epoch 00006: val_acc did not improve from 0.94635\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2456 - acc: 0.9407 - f1score: 0.9407 - val_loss: 0.1933 - val_acc: 0.9421 - val_f1score: 0.9397\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9553 - f1score: 0.9553\n",
      "Epoch 00007: val_acc improved from 0.94635 to 0.95708, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.17.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1722 - acc: 0.9550 - f1score: 0.9548 - val_loss: 0.1695 - val_acc: 0.9571 - val_f1score: 0.9567\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1423 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00008: val_acc improved from 0.95708 to 0.96030, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.15.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1418 - acc: 0.9630 - f1score: 0.9626 - val_loss: 0.1473 - val_acc: 0.9603 - val_f1score: 0.9598\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00009: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1379 - acc: 0.9614 - f1score: 0.9611 - val_loss: 0.1415 - val_acc: 0.9485 - val_f1score: 0.9468\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00010: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1363 - acc: 0.9593 - f1score: 0.9594 - val_loss: 0.1352 - val_acc: 0.9603 - val_f1score: 0.9606\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00011: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1222 - acc: 0.9630 - f1score: 0.9622 - val_loss: 0.1422 - val_acc: 0.9517 - val_f1score: 0.9523\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00012: val_acc improved from 0.96030 to 0.96245, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.12-0.13.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1243 - acc: 0.9667 - f1score: 0.9667 - val_loss: 0.1277 - val_acc: 0.9624 - val_f1score: 0.9611\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00013: val_acc improved from 0.96245 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.12.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1200 - acc: 0.9630 - f1score: 0.9626 - val_loss: 0.1215 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00014: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1126 - acc: 0.9672 - f1score: 0.9668 - val_loss: 0.1223 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00015: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1139 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1202 - val_acc: 0.9528 - val_f1score: 0.9534\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9650 - f1score: 0.9650\n",
      "Epoch 00016: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1112 - acc: 0.9646 - f1score: 0.9642 - val_loss: 0.1167 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00017: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1097 - acc: 0.9693 - f1score: 0.9689 - val_loss: 0.1223 - val_acc: 0.9506 - val_f1score: 0.9513\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00018: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1086 - acc: 0.9688 - f1score: 0.9693 - val_loss: 0.1182 - val_acc: 0.9689 - val_f1score: 0.9682\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00019: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1069 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1155 - val_acc: 0.9624 - val_f1score: 0.9611\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00020: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1069 - acc: 0.9672 - f1score: 0.9672 - val_loss: 0.1148 - val_acc: 0.9635 - val_f1score: 0.9638\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00021: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1048 - acc: 0.9661 - f1score: 0.9667 - val_loss: 0.1228 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00022: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1045 - acc: 0.9683 - f1score: 0.9683 - val_loss: 0.1161 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00023: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1049 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1154 - val_acc: 0.9635 - val_f1score: 0.9622\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00024: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1038 - acc: 0.9698 - f1score: 0.9703 - val_loss: 0.1147 - val_acc: 0.9560 - val_f1score: 0.9549\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00025: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1037 - acc: 0.9677 - f1score: 0.9673 - val_loss: 0.1165 - val_acc: 0.9549 - val_f1score: 0.9546\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00026: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1025 - acc: 0.9714 - f1score: 0.9700 - val_loss: 0.1119 - val_acc: 0.9657 - val_f1score: 0.9667\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00027: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1033 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1130 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00028: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1015 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1127 - val_acc: 0.9657 - val_f1score: 0.9659\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00029: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1010 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1091 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00030: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1020 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1100 - val_acc: 0.9689 - val_f1score: 0.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|         | 49/1296 [3:08:20<54:58:04, 158.69s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.8466 - acc: 0.7241 - f1score: 0.7241\n",
      "Epoch 00001: val_acc improved from -inf to 0.83155, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.44.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 1.8219 - acc: 0.7270 - f1score: 0.7294 - val_loss: 0.4447 - val_acc: 0.8315 - val_f1score: 0.8324\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.2936 - acc: 0.8109 - f1score: 0.8109\n",
      "Epoch 00002: val_acc improved from 0.83155 to 0.91845, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.27.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.3125 - acc: 0.8106 - f1score: 0.8103 - val_loss: 0.2725 - val_acc: 0.9185 - val_f1score: 0.9192\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.1825 - acc: 0.8567 - f1score: 0.8567\n",
      "Epoch 00003: val_acc improved from 0.91845 to 0.92167, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.23.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.1809 - acc: 0.8556 - f1score: 0.8546 - val_loss: 0.2295 - val_acc: 0.9217 - val_f1score: 0.9223\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.0971 - acc: 0.8750 - f1score: 0.8750\n",
      "Epoch 00004: val_acc improved from 0.92167 to 0.93348, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.18.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.0905 - acc: 0.8751 - f1score: 0.8752 - val_loss: 0.1843 - val_acc: 0.9335 - val_f1score: 0.9338\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.9587 - acc: 0.8917 - f1score: 0.8917\n",
      "Epoch 00005: val_acc improved from 0.93348 to 0.94528, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.19.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.9683 - acc: 0.8910 - f1score: 0.8904 - val_loss: 0.1897 - val_acc: 0.9453 - val_f1score: 0.9453\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.0382 - acc: 0.8939 - f1score: 0.8939\n",
      "Epoch 00006: val_acc improved from 0.94528 to 0.95172, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.17.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.0395 - acc: 0.8937 - f1score: 0.8935 - val_loss: 0.1679 - val_acc: 0.9517 - val_f1score: 0.9499\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.9691 - acc: 0.8998 - f1score: 0.8998\n",
      "Epoch 00007: val_acc improved from 0.95172 to 0.95279, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.17.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.9618 - acc: 0.9000 - f1score: 0.9002 - val_loss: 0.1671 - val_acc: 0.9528 - val_f1score: 0.9534\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.9808 - acc: 0.9062 - f1score: 0.9062\n",
      "Epoch 00008: val_acc did not improve from 0.95279\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.9941 - acc: 0.9053 - f1score: 0.9045 - val_loss: 0.1564 - val_acc: 0.9528 - val_f1score: 0.9517\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8799 - acc: 0.9084 - f1score: 0.9084\n",
      "Epoch 00009: val_acc improved from 0.95279 to 0.96674, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.16.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.8756 - acc: 0.9079 - f1score: 0.9075 - val_loss: 0.1601 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8561 - acc: 0.9095 - f1score: 0.9095\n",
      "Epoch 00010: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.8495 - acc: 0.9101 - f1score: 0.9105 - val_loss: 0.1511 - val_acc: 0.9464 - val_f1score: 0.9471\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.9356 - acc: 0.9079 - f1score: 0.9079\n",
      "Epoch 00011: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.9248 - acc: 0.9090 - f1score: 0.9100 - val_loss: 0.1743 - val_acc: 0.9549 - val_f1score: 0.9554\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.6840 - acc: 0.9095 - f1score: 0.9095\n",
      "Epoch 00012: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.6805 - acc: 0.9101 - f1score: 0.9105 - val_loss: 0.2914 - val_acc: 0.9592 - val_f1score: 0.9580\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3685 - acc: 0.9445 - f1score: 0.9445\n",
      "Epoch 00013: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.3654 - acc: 0.9450 - f1score: 0.9454 - val_loss: 0.3361 - val_acc: 0.9549 - val_f1score: 0.9538\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.9494 - f1score: 0.9494\n",
      "Epoch 00014: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.3115 - acc: 0.9497 - f1score: 0.9501 - val_loss: 0.3112 - val_acc: 0.9560 - val_f1score: 0.9565\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2295 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00015: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.2260 - acc: 0.9593 - f1score: 0.9594 - val_loss: 0.1721 - val_acc: 0.9614 - val_f1score: 0.9609\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1673 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00016: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1669 - acc: 0.9593 - f1score: 0.9594 - val_loss: 0.1394 - val_acc: 0.9657 - val_f1score: 0.9659\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00017: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1319 - acc: 0.9614 - f1score: 0.9611 - val_loss: 0.1240 - val_acc: 0.9624 - val_f1score: 0.9619\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00018: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1299 - acc: 0.9693 - f1score: 0.9689 - val_loss: 0.1241 - val_acc: 0.9442 - val_f1score: 0.9450\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00019: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1119 - acc: 0.9672 - f1score: 0.9663 - val_loss: 0.1166 - val_acc: 0.9474 - val_f1score: 0.9490\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00020: val_acc improved from 0.96674 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.20-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1089 - acc: 0.9651 - f1score: 0.9656 - val_loss: 0.1138 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00021: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1062 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1110 - val_acc: 0.9657 - val_f1score: 0.9667\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9688 - f1score: 0.9688\n",
      "Epoch 00022: val_acc improved from 0.96781 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.22-0.11.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1054 - acc: 0.9683 - f1score: 0.9678 - val_loss: 0.1085 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00023: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1056 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1196 - val_acc: 0.9485 - val_f1score: 0.9492\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00024: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1103 - acc: 0.9646 - f1score: 0.9646 - val_loss: 0.1076 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00025: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1044 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1127 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0998 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00026: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0990 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1083 - val_acc: 0.9678 - val_f1score: 0.9688\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00027: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1063 - acc: 0.9661 - f1score: 0.9667 - val_loss: 0.1213 - val_acc: 0.9678 - val_f1score: 0.9688\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00028: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1003 - acc: 0.9704 - f1score: 0.9704 - val_loss: 0.1106 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00029: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0995 - acc: 0.9709 - f1score: 0.9714 - val_loss: 0.1082 - val_acc: 0.9678 - val_f1score: 0.9655\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9741 - f1score: 0.9741\n",
      "Epoch 00030: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.0975 - acc: 0.9735 - f1score: 0.9730 - val_loss: 0.1066 - val_acc: 0.9678 - val_f1score: 0.9687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|         | 50/1296 [3:12:28<64:16:05, 185.69s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.9964 - acc: 0.7107 - f1score: 0.7107\n",
      "Epoch 00001: val_acc improved from -inf to 0.86695, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.38.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.9855 - acc: 0.7143 - f1score: 0.7174 - val_loss: 0.3752 - val_acc: 0.8670 - val_f1score: 0.8676\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2943 - acc: 0.9122 - f1score: 0.9122\n",
      "Epoch 00002: val_acc improved from 0.86695 to 0.93670, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.20.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2918 - acc: 0.9122 - f1score: 0.9122 - val_loss: 0.2016 - val_acc: 0.9367 - val_f1score: 0.9377\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2060 - acc: 0.9418 - f1score: 0.9418\n",
      "Epoch 00003: val_acc improved from 0.93670 to 0.94099, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.17.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2038 - acc: 0.9423 - f1score: 0.9428 - val_loss: 0.1736 - val_acc: 0.9410 - val_f1score: 0.9427\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9434 - f1score: 0.9434\n",
      "Epoch 00004: val_acc improved from 0.94099 to 0.95815, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.18.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1742 - acc: 0.9439 - f1score: 0.9443 - val_loss: 0.1789 - val_acc: 0.9582 - val_f1score: 0.9586\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1519 - acc: 0.9526 - f1score: 0.9526\n",
      "Epoch 00005: val_acc did not improve from 0.95815\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1534 - acc: 0.9519 - f1score: 0.9512 - val_loss: 0.1604 - val_acc: 0.9539 - val_f1score: 0.9544\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9558 - f1score: 0.9558\n",
      "Epoch 00006: val_acc did not improve from 0.95815\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1455 - acc: 0.9561 - f1score: 0.9563 - val_loss: 0.1733 - val_acc: 0.9399 - val_f1score: 0.9400\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00007: val_acc did not improve from 0.95815\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1497 - acc: 0.9587 - f1score: 0.9585 - val_loss: 0.1510 - val_acc: 0.9431 - val_f1score: 0.9432\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00008: val_acc did not improve from 0.95815\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1295 - acc: 0.9635 - f1score: 0.9636 - val_loss: 0.1520 - val_acc: 0.9421 - val_f1score: 0.9421\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9564 - f1score: 0.9564\n",
      "Epoch 00009: val_acc did not improve from 0.95815\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1413 - acc: 0.9566 - f1score: 0.9568 - val_loss: 0.1424 - val_acc: 0.9539 - val_f1score: 0.9544\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9526 - f1score: 0.9526\n",
      "Epoch 00010: val_acc improved from 0.95815 to 0.96030, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.15.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1391 - acc: 0.9534 - f1score: 0.9542 - val_loss: 0.1536 - val_acc: 0.9603 - val_f1score: 0.9606\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00011: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1327 - acc: 0.9593 - f1score: 0.9599 - val_loss: 0.1485 - val_acc: 0.9571 - val_f1score: 0.9575\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00012: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1321 - acc: 0.9593 - f1score: 0.9599 - val_loss: 0.1462 - val_acc: 0.9528 - val_f1score: 0.9509\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00013: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1277 - acc: 0.9640 - f1score: 0.9646 - val_loss: 0.1496 - val_acc: 0.9571 - val_f1score: 0.9583\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00014: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1270 - acc: 0.9614 - f1score: 0.9611 - val_loss: 0.1437 - val_acc: 0.9496 - val_f1score: 0.9502\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00015: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1280 - acc: 0.9587 - f1score: 0.9589 - val_loss: 0.1396 - val_acc: 0.9549 - val_f1score: 0.9498\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9574 - f1score: 0.9574\n",
      "Epoch 00016: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1264 - acc: 0.9571 - f1score: 0.9569 - val_loss: 0.1419 - val_acc: 0.9571 - val_f1score: 0.9575\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00017: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1219 - acc: 0.9624 - f1score: 0.9621 - val_loss: 0.1420 - val_acc: 0.9474 - val_f1score: 0.9473\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00018: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1232 - acc: 0.9608 - f1score: 0.9601 - val_loss: 0.1391 - val_acc: 0.9464 - val_f1score: 0.9455\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9623 - f1score: 0.9623\n",
      "Epoch 00019: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1190 - acc: 0.9624 - f1score: 0.9626 - val_loss: 0.1361 - val_acc: 0.9496 - val_f1score: 0.9502\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9569 - f1score: 0.9569\n",
      "Epoch 00020: val_acc improved from 0.96030 to 0.96137, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.20-0.14.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1187 - acc: 0.9577 - f1score: 0.9583 - val_loss: 0.1425 - val_acc: 0.9614 - val_f1score: 0.9609\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00021: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1200 - acc: 0.9640 - f1score: 0.9641 - val_loss: 0.1417 - val_acc: 0.9614 - val_f1score: 0.9617\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9580 - f1score: 0.9580\n",
      "Epoch 00022: val_acc improved from 0.96137 to 0.96459, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.22-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1197 - acc: 0.9582 - f1score: 0.9584 - val_loss: 0.1400 - val_acc: 0.9646 - val_f1score: 0.9656\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00023: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1173 - acc: 0.9640 - f1score: 0.9646 - val_loss: 0.1412 - val_acc: 0.9592 - val_f1score: 0.9596\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00024: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1226 - acc: 0.9598 - f1score: 0.9595 - val_loss: 0.1378 - val_acc: 0.9474 - val_f1score: 0.9465\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9623 - f1score: 0.9623\n",
      "Epoch 00025: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1174 - acc: 0.9624 - f1score: 0.9626 - val_loss: 0.1332 - val_acc: 0.9549 - val_f1score: 0.9554\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00026: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1173 - acc: 0.9614 - f1score: 0.9611 - val_loss: 0.1339 - val_acc: 0.9528 - val_f1score: 0.9534\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00027: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1115 - acc: 0.9614 - f1score: 0.9615 - val_loss: 0.1361 - val_acc: 0.9592 - val_f1score: 0.9556\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00028: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1149 - acc: 0.9630 - f1score: 0.9631 - val_loss: 0.1338 - val_acc: 0.9539 - val_f1score: 0.9544\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00029: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1175 - acc: 0.9640 - f1score: 0.9641 - val_loss: 0.1306 - val_acc: 0.9539 - val_f1score: 0.9544\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00030: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1122 - acc: 0.9656 - f1score: 0.9657 - val_loss: 0.1352 - val_acc: 0.9603 - val_f1score: 0.9615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|         | 51/1296 [3:16:51<72:14:52, 208.91s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 7.0522 - acc: 0.4542 - f1score: 0.4542\n",
      "Epoch 00001: val_acc improved from -inf to 0.45386, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-4.47.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 7.0435 - acc: 0.4534 - f1score: 0.4528 - val_loss: 4.4744 - val_acc: 0.4539 - val_f1score: 0.4512\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.8289 - acc: 0.7150 - f1score: 0.7150\n",
      "Epoch 00002: val_acc improved from 0.45386 to 0.88841, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.37.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.8089 - acc: 0.7185 - f1score: 0.7215 - val_loss: 0.3711 - val_acc: 0.8884 - val_f1score: 0.8884\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.9678 - acc: 0.8642 - f1score: 0.8642\n",
      "Epoch 00003: val_acc improved from 0.88841 to 0.90236, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.29.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.9736 - acc: 0.8646 - f1score: 0.8648 - val_loss: 0.2862 - val_acc: 0.9024 - val_f1score: 0.9028\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.0130 - acc: 0.8761 - f1score: 0.8761\n",
      "Epoch 00004: val_acc improved from 0.90236 to 0.92275, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.29.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 1.0150 - acc: 0.8767 - f1score: 0.8773 - val_loss: 0.2913 - val_acc: 0.9227 - val_f1score: 0.9234\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.1107 - acc: 0.8766 - f1score: 0.8766\n",
      "Epoch 00005: val_acc improved from 0.92275 to 0.93026, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.27.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 1.1044 - acc: 0.8767 - f1score: 0.8768 - val_loss: 0.2699 - val_acc: 0.9303 - val_f1score: 0.9299\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8928 - acc: 0.8917 - f1score: 0.8917\n",
      "Epoch 00006: val_acc improved from 0.93026 to 0.93991, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.26.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.8946 - acc: 0.8915 - f1score: 0.8914 - val_loss: 0.2616 - val_acc: 0.9399 - val_f1score: 0.9392\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8625 - acc: 0.8966 - f1score: 0.8966\n",
      "Epoch 00007: val_acc did not improve from 0.93991\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.8580 - acc: 0.8968 - f1score: 0.8971 - val_loss: 0.3098 - val_acc: 0.9217 - val_f1score: 0.9231\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7780 - acc: 0.9046 - f1score: 0.9046\n",
      "Epoch 00008: val_acc improved from 0.93991 to 0.94742, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.29.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.7709 - acc: 0.9058 - f1score: 0.9068 - val_loss: 0.2917 - val_acc: 0.9474 - val_f1score: 0.9473\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.6887 - acc: 0.9046 - f1score: 0.9046\n",
      "Epoch 00009: val_acc did not improve from 0.94742\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.6807 - acc: 0.9053 - f1score: 0.9059 - val_loss: 0.3275 - val_acc: 0.9399 - val_f1score: 0.9368\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5166 - acc: 0.9251 - f1score: 0.9251\n",
      "Epoch 00010: val_acc did not improve from 0.94742\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5097 - acc: 0.9254 - f1score: 0.9256 - val_loss: 0.3690 - val_acc: 0.9442 - val_f1score: 0.9434\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.9294 - f1score: 0.9294\n",
      "Epoch 00011: val_acc did not improve from 0.94742\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4503 - acc: 0.9291 - f1score: 0.9288 - val_loss: 0.3725 - val_acc: 0.9442 - val_f1score: 0.9434\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4083 - acc: 0.9370 - f1score: 0.9370\n",
      "Epoch 00012: val_acc did not improve from 0.94742\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.4121 - acc: 0.9365 - f1score: 0.9361 - val_loss: 0.2979 - val_acc: 0.9474 - val_f1score: 0.9481\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3111 - acc: 0.9477 - f1score: 0.9477\n",
      "Epoch 00013: val_acc improved from 0.94742 to 0.95279, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.24.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.3174 - acc: 0.9466 - f1score: 0.9456 - val_loss: 0.2444 - val_acc: 0.9528 - val_f1score: 0.9517\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2419 - acc: 0.9515 - f1score: 0.9515\n",
      "Epoch 00014: val_acc improved from 0.95279 to 0.96030, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.14-0.16.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2420 - acc: 0.9513 - f1score: 0.9512 - val_loss: 0.1585 - val_acc: 0.9603 - val_f1score: 0.9598\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2462 - acc: 0.9504 - f1score: 0.9504\n",
      "Epoch 00015: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2421 - acc: 0.9513 - f1score: 0.9521 - val_loss: 0.1840 - val_acc: 0.9549 - val_f1score: 0.9562\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1874 - acc: 0.9537 - f1score: 0.9537\n",
      "Epoch 00016: val_acc improved from 0.96030 to 0.96137, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.16-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1848 - acc: 0.9540 - f1score: 0.9542 - val_loss: 0.1404 - val_acc: 0.9614 - val_f1score: 0.9609\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00017: val_acc improved from 0.96137 to 0.96459, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.17-0.14.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1388 - acc: 0.9614 - f1score: 0.9615 - val_loss: 0.1352 - val_acc: 0.9646 - val_f1score: 0.9640\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9607 - f1score: 0.9607\n",
      "Epoch 00018: val_acc improved from 0.96459 to 0.96674, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.18-0.14.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1318 - acc: 0.9608 - f1score: 0.9610 - val_loss: 0.1373 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00019: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1122 - acc: 0.9635 - f1score: 0.9636 - val_loss: 0.1216 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00020: val_acc improved from 0.96674 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.20-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1141 - acc: 0.9640 - f1score: 0.9646 - val_loss: 0.1219 - val_acc: 0.9678 - val_f1score: 0.9663\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00021: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1085 - acc: 0.9683 - f1score: 0.9683 - val_loss: 0.1148 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00022: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1057 - acc: 0.9672 - f1score: 0.9668 - val_loss: 0.1170 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00023: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1086 - acc: 0.9630 - f1score: 0.9626 - val_loss: 0.1191 - val_acc: 0.9528 - val_f1score: 0.9542\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00024: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1066 - acc: 0.9683 - f1score: 0.9683 - val_loss: 0.1146 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00025: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1078 - acc: 0.9667 - f1score: 0.9663 - val_loss: 0.1158 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00026: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1023 - acc: 0.9683 - f1score: 0.9683 - val_loss: 0.1142 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00027: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1040 - acc: 0.9683 - f1score: 0.9687 - val_loss: 0.1112 - val_acc: 0.9678 - val_f1score: 0.9655\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00028: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1040 - acc: 0.9672 - f1score: 0.9668 - val_loss: 0.1130 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00029: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1035 - acc: 0.9667 - f1score: 0.9667 - val_loss: 0.1111 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00030: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1077 - acc: 0.9688 - f1score: 0.9693 - val_loss: 0.1107 - val_acc: 0.9678 - val_f1score: 0.9679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|         | 52/1296 [3:21:15<77:50:29, 225.26s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 4.7080 - acc: 0.5485 - f1score: 0.5485\n",
      "Epoch 00001: val_acc improved from -inf to 0.91202, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.46.h5\n",
      "1890/1890 [==============================] - 14s 8ms/sample - loss: 4.6322 - acc: 0.5550 - f1score: 0.5606 - val_loss: 0.4564 - val_acc: 0.9120 - val_f1score: 0.9146\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5318 - acc: 0.8890 - f1score: 0.8890\n",
      "Epoch 00002: val_acc improved from 0.91202 to 0.92704, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.32.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5292 - acc: 0.8899 - f1score: 0.8907 - val_loss: 0.3185 - val_acc: 0.9270 - val_f1score: 0.9251\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4386 - acc: 0.9149 - f1score: 0.9149\n",
      "Epoch 00003: val_acc improved from 0.92704 to 0.92918, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.37.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4451 - acc: 0.9138 - f1score: 0.9128 - val_loss: 0.3658 - val_acc: 0.9292 - val_f1score: 0.9272\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3063 - acc: 0.9327 - f1score: 0.9327\n",
      "Epoch 00004: val_acc improved from 0.92918 to 0.93991, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.23.h5\n",
      "1890/1890 [==============================] - 12s 7ms/sample - loss: 0.3034 - acc: 0.9333 - f1score: 0.9339 - val_loss: 0.2263 - val_acc: 0.9399 - val_f1score: 0.9409\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2393 - acc: 0.9332 - f1score: 0.9332\n",
      "Epoch 00005: val_acc improved from 0.93991 to 0.95064, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.19.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.2363 - acc: 0.9339 - f1score: 0.9344 - val_loss: 0.1857 - val_acc: 0.9506 - val_f1score: 0.9521\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9450 - f1score: 0.9450\n",
      "Epoch 00006: val_acc improved from 0.95064 to 0.95601, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.18.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.2071 - acc: 0.9450 - f1score: 0.9449 - val_loss: 0.1826 - val_acc: 0.9560 - val_f1score: 0.9557\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9558 - f1score: 0.9558\n",
      "Epoch 00007: val_acc improved from 0.95601 to 0.96245, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.16.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1470 - acc: 0.9556 - f1score: 0.9553 - val_loss: 0.1640 - val_acc: 0.9624 - val_f1score: 0.9619\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9601 - f1score: 0.9601\n",
      "Epoch 00008: val_acc did not improve from 0.96245\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1508 - acc: 0.9587 - f1score: 0.9575 - val_loss: 0.1474 - val_acc: 0.9431 - val_f1score: 0.9440\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00009: val_acc did not improve from 0.96245\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1463 - acc: 0.9582 - f1score: 0.9579 - val_loss: 0.1440 - val_acc: 0.9506 - val_f1score: 0.9497\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00010: val_acc did not improve from 0.96245\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1252 - acc: 0.9582 - f1score: 0.9579 - val_loss: 0.1434 - val_acc: 0.9549 - val_f1score: 0.9546\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9607 - f1score: 0.9607\n",
      "Epoch 00011: val_acc did not improve from 0.96245\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1322 - acc: 0.9593 - f1score: 0.9581 - val_loss: 0.1747 - val_acc: 0.9474 - val_f1score: 0.9465\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1356 - acc: 0.9574 - f1score: 0.9574\n",
      "Epoch 00012: val_acc improved from 0.96245 to 0.96352, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.12-0.14.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1357 - acc: 0.9566 - f1score: 0.9559 - val_loss: 0.1350 - val_acc: 0.9635 - val_f1score: 0.9630\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1268 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00013: val_acc improved from 0.96352 to 0.96459, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.14.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1272 - acc: 0.9614 - f1score: 0.9611 - val_loss: 0.1420 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00014: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1245 - acc: 0.9608 - f1score: 0.9605 - val_loss: 0.1339 - val_acc: 0.9485 - val_f1score: 0.9492\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9612 - f1score: 0.9612\n",
      "Epoch 00015: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1206 - acc: 0.9614 - f1score: 0.9615 - val_loss: 0.1263 - val_acc: 0.9582 - val_f1score: 0.9586\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1198 - acc: 0.9591 - f1score: 0.9591\n",
      "Epoch 00016: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1194 - acc: 0.9593 - f1score: 0.9594 - val_loss: 0.1303 - val_acc: 0.9571 - val_f1score: 0.9575\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00017: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1162 - acc: 0.9646 - f1score: 0.9646 - val_loss: 0.1417 - val_acc: 0.9614 - val_f1score: 0.9609\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00018: val_acc improved from 0.96459 to 0.96674, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.18-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1161 - acc: 0.9635 - f1score: 0.9641 - val_loss: 0.1342 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00019: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1144 - acc: 0.9635 - f1score: 0.9636 - val_loss: 0.1235 - val_acc: 0.9560 - val_f1score: 0.9565\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1143 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00020: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1129 - acc: 0.9603 - f1score: 0.9609 - val_loss: 0.1429 - val_acc: 0.9624 - val_f1score: 0.9635\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00021: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1085 - acc: 0.9677 - f1score: 0.9682 - val_loss: 0.1216 - val_acc: 0.9624 - val_f1score: 0.9619\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9639 - f1score: 0.9639\n",
      "Epoch 00022: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1097 - acc: 0.9640 - f1score: 0.9641 - val_loss: 0.1239 - val_acc: 0.9614 - val_f1score: 0.9625\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00023: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1115 - acc: 0.9656 - f1score: 0.9652 - val_loss: 0.1212 - val_acc: 0.9539 - val_f1score: 0.9552\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00024: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1079 - acc: 0.9683 - f1score: 0.9674 - val_loss: 0.1204 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9688 - f1score: 0.9687\n",
      "Epoch 00025: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1060 - acc: 0.9693 - f1score: 0.9698 - val_loss: 0.1151 - val_acc: 0.9657 - val_f1score: 0.9634\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00026: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1095 - acc: 0.9651 - f1score: 0.9647 - val_loss: 0.1279 - val_acc: 0.9635 - val_f1score: 0.9646\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00027: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1063 - acc: 0.9661 - f1score: 0.9662 - val_loss: 0.1295 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00028: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1087 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1164 - val_acc: 0.9549 - val_f1score: 0.9538\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00029: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1046 - acc: 0.9661 - f1score: 0.9667 - val_loss: 0.1151 - val_acc: 0.9635 - val_f1score: 0.9630\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9688 - f1score: 0.9688\n",
      "Epoch 00030: val_acc improved from 0.96674 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.30-0.11.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1047 - acc: 0.9693 - f1score: 0.9698 - val_loss: 0.1145 - val_acc: 0.9678 - val_f1score: 0.9687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|         | 53/1296 [3:26:55<89:42:43, 259.83s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 2.8314 - acc: 0.5539 - f1score: 0.5539\n",
      "Epoch 00001: val_acc improved from -inf to 0.84013, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.54.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 2.8130 - acc: 0.5577 - f1score: 0.5609 - val_loss: 0.5399 - val_acc: 0.8401 - val_f1score: 0.8424\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8737 - acc: 0.8481 - f1score: 0.8481\n",
      "Epoch 00002: val_acc improved from 0.84013 to 0.90987, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.35.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.8625 - acc: 0.8492 - f1score: 0.8502 - val_loss: 0.3540 - val_acc: 0.9099 - val_f1score: 0.9101\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7272 - acc: 0.8869 - f1score: 0.8869\n",
      "Epoch 00003: val_acc improved from 0.90987 to 0.93133, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.37.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.7171 - acc: 0.8884 - f1score: 0.8896 - val_loss: 0.3732 - val_acc: 0.9313 - val_f1score: 0.9317\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5601 - acc: 0.9192 - f1score: 0.9192\n",
      "Epoch 00004: val_acc did not improve from 0.93133\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.5566 - acc: 0.9185 - f1score: 0.9180 - val_loss: 0.3777 - val_acc: 0.9313 - val_f1score: 0.9317\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4091 - acc: 0.9332 - f1score: 0.9332\n",
      "Epoch 00005: val_acc improved from 0.93133 to 0.94742, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.36.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.4076 - acc: 0.9323 - f1score: 0.9315 - val_loss: 0.3619 - val_acc: 0.9474 - val_f1score: 0.9481\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3705 - acc: 0.9494 - f1score: 0.9494\n",
      "Epoch 00006: val_acc improved from 0.94742 to 0.95386, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.33.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.3695 - acc: 0.9497 - f1score: 0.9501 - val_loss: 0.3266 - val_acc: 0.9539 - val_f1score: 0.9520\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2828 - acc: 0.9537 - f1score: 0.9537\n",
      "Epoch 00007: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.2869 - acc: 0.9534 - f1score: 0.9532 - val_loss: 0.3116 - val_acc: 0.9539 - val_f1score: 0.9536\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2922 - acc: 0.9504 - f1score: 0.9504\n",
      "Epoch 00008: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.2874 - acc: 0.9513 - f1score: 0.9521 - val_loss: 0.2632 - val_acc: 0.9539 - val_f1score: 0.9536\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2552 - acc: 0.9515 - f1score: 0.9515\n",
      "Epoch 00009: val_acc improved from 0.95386 to 0.95494, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.28.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2540 - acc: 0.9497 - f1score: 0.9482 - val_loss: 0.2777 - val_acc: 0.9549 - val_f1score: 0.9562\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2121 - acc: 0.9585 - f1score: 0.9585\n",
      "Epoch 00010: val_acc did not improve from 0.95494\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.2087 - acc: 0.9593 - f1score: 0.9599 - val_loss: 0.1860 - val_acc: 0.9549 - val_f1score: 0.9554\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2002 - acc: 0.9477 - f1score: 0.9477\n",
      "Epoch 00011: val_acc did not improve from 0.95494\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1978 - acc: 0.9481 - f1score: 0.9485 - val_loss: 0.1719 - val_acc: 0.9528 - val_f1score: 0.9525\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1697 - acc: 0.9617 - f1score: 0.9617\n",
      "Epoch 00012: val_acc did not improve from 0.95494\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1688 - acc: 0.9608 - f1score: 0.9601 - val_loss: 0.1419 - val_acc: 0.9474 - val_f1score: 0.9473\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1443 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00013: val_acc improved from 0.95494 to 0.96030, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.13.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1458 - acc: 0.9577 - f1score: 0.9560 - val_loss: 0.1338 - val_acc: 0.9603 - val_f1score: 0.9615\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9574 - f1score: 0.9574\n",
      "Epoch 00014: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1331 - acc: 0.9577 - f1score: 0.9579 - val_loss: 0.1313 - val_acc: 0.9560 - val_f1score: 0.9565\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00015: val_acc improved from 0.96030 to 0.96674, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.15-0.13.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1182 - acc: 0.9651 - f1score: 0.9647 - val_loss: 0.1273 - val_acc: 0.9667 - val_f1score: 0.9669\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00016: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1141 - acc: 0.9672 - f1score: 0.9668 - val_loss: 0.1218 - val_acc: 0.9517 - val_f1score: 0.9523\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00017: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1101 - acc: 0.9635 - f1score: 0.9627 - val_loss: 0.1203 - val_acc: 0.9485 - val_f1score: 0.9476\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00018: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1118 - acc: 0.9661 - f1score: 0.9667 - val_loss: 0.1171 - val_acc: 0.9539 - val_f1score: 0.9544\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00019: val_acc improved from 0.96674 to 0.96996, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.19-0.11.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1054 - acc: 0.9698 - f1score: 0.9703 - val_loss: 0.1122 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00020: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1021 - acc: 0.9698 - f1score: 0.9699 - val_loss: 0.1126 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00021: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1007 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1092 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9688 - f1score: 0.9688\n",
      "Epoch 00022: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1011 - acc: 0.9693 - f1score: 0.9698 - val_loss: 0.1176 - val_acc: 0.9689 - val_f1score: 0.9674\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00023: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0980 - acc: 0.9667 - f1score: 0.9667 - val_loss: 0.1086 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00024: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0960 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1101 - val_acc: 0.9689 - val_f1score: 0.9698\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00025: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0950 - acc: 0.9698 - f1score: 0.9699 - val_loss: 0.1120 - val_acc: 0.9700 - val_f1score: 0.9692\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00026: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0911 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1099 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00027: val_acc improved from 0.96996 to 0.97103, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.27-0.11.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.0981 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1105 - val_acc: 0.9710 - val_f1score: 0.9711\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00028: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0977 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1142 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9688 - f1score: 0.9688\n",
      "Epoch 00029: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.0995 - acc: 0.9693 - f1score: 0.9698 - val_loss: 0.1152 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9688 - f1score: 0.9687\n",
      "Epoch 00030: val_acc did not improve from 0.97103\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0981 - acc: 0.9688 - f1score: 0.9688 - val_loss: 0.1070 - val_acc: 0.9710 - val_f1score: 0.9703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|         | 54/1296 [3:32:25<96:53:43, 280.86s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.3865 - acc: 0.4688 - f1score: 0.3334\n",
      "Epoch 00001: val_acc improved from -inf to 0.59067, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.65.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 1.3738 - acc: 0.4722 - f1score: 0.3442 - val_loss: 0.6491 - val_acc: 0.5907 - val_f1score: 0.5850\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5498 - acc: 0.7880 - f1score: 0.7839\n",
      "Epoch 00002: val_acc improved from 0.59067 to 0.91577, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.33.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.5452 - acc: 0.7905 - f1score: 0.7887 - val_loss: 0.3281 - val_acc: 0.9158 - val_f1score: 0.9164\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3177 - acc: 0.9162 - f1score: 0.9160\n",
      "Epoch 00003: val_acc improved from 0.91577 to 0.93670, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.26.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.3151 - acc: 0.9169 - f1score: 0.9174 - val_loss: 0.2600 - val_acc: 0.9367 - val_f1score: 0.9361\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2369 - acc: 0.9362 - f1score: 0.9362\n",
      "Epoch 00004: val_acc did not improve from 0.93670\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.2356 - acc: 0.9365 - f1score: 0.9369 - val_loss: 0.2350 - val_acc: 0.9356 - val_f1score: 0.9375\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1944 - acc: 0.9485 - f1score: 0.9485\n",
      "Epoch 00005: val_acc did not improve from 0.93670\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1951 - acc: 0.9484 - f1score: 0.9482 - val_loss: 0.2238 - val_acc: 0.9351 - val_f1score: 0.9370\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1870 - acc: 0.9453 - f1score: 0.9454\n",
      "Epoch 00006: val_acc improved from 0.93670 to 0.93884, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.21.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1854 - acc: 0.9458 - f1score: 0.9462 - val_loss: 0.2065 - val_acc: 0.9388 - val_f1score: 0.9374\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9488 - f1score: 0.9488\n",
      "Epoch 00007: val_acc did not improve from 0.93884\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1688 - acc: 0.9487 - f1score: 0.9485 - val_loss: 0.1928 - val_acc: 0.9388 - val_f1score: 0.9382\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1573 - acc: 0.9504 - f1score: 0.9504\n",
      "Epoch 00008: val_acc improved from 0.93884 to 0.93991, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.17.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1573 - acc: 0.9508 - f1score: 0.9511 - val_loss: 0.1743 - val_acc: 0.9399 - val_f1score: 0.9376\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.9502 - f1score: 0.9500\n",
      "Epoch 00009: val_acc improved from 0.93991 to 0.94474, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.15.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1422 - acc: 0.9505 - f1score: 0.9507 - val_loss: 0.1543 - val_acc: 0.9447 - val_f1score: 0.9436\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9566 - f1score: 0.9566\n",
      "Epoch 00010: val_acc improved from 0.94474 to 0.96084, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.14.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1290 - acc: 0.9569 - f1score: 0.9570 - val_loss: 0.1387 - val_acc: 0.9608 - val_f1score: 0.9608\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9652 - f1score: 0.9652\n",
      "Epoch 00011: val_acc improved from 0.96084 to 0.96191, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.11-0.13.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1205 - acc: 0.9648 - f1score: 0.9644 - val_loss: 0.1304 - val_acc: 0.9619 - val_f1score: 0.9619\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9663 - f1score: 0.9661\n",
      "Epoch 00012: val_acc did not improve from 0.96191\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1175 - acc: 0.9651 - f1score: 0.9639 - val_loss: 0.1292 - val_acc: 0.9603 - val_f1score: 0.9606\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9658 - f1score: 0.9657\n",
      "Epoch 00013: val_acc improved from 0.96191 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.12.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1165 - acc: 0.9659 - f1score: 0.9659 - val_loss: 0.1233 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9661 - f1score: 0.9660\n",
      "Epoch 00014: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1149 - acc: 0.9661 - f1score: 0.9661 - val_loss: 0.1214 - val_acc: 0.9641 - val_f1score: 0.9633\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9644 - f1score: 0.9643\n",
      "Epoch 00015: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1120 - acc: 0.9646 - f1score: 0.9645 - val_loss: 0.1176 - val_acc: 0.9646 - val_f1score: 0.9647\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9669 - f1score: 0.9667\n",
      "Epoch 00016: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1116 - acc: 0.9669 - f1score: 0.9668 - val_loss: 0.1160 - val_acc: 0.9662 - val_f1score: 0.9655\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9696 - f1score: 0.9695\n",
      "Epoch 00017: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1109 - acc: 0.9690 - f1score: 0.9686 - val_loss: 0.1181 - val_acc: 0.9630 - val_f1score: 0.9618\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9677 - f1score: 0.9676\n",
      "Epoch 00018: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1075 - acc: 0.9683 - f1score: 0.9687 - val_loss: 0.1170 - val_acc: 0.9673 - val_f1score: 0.9666\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9698 - f1score: 0.9697\n",
      "Epoch 00019: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1077 - acc: 0.9677 - f1score: 0.9658 - val_loss: 0.1131 - val_acc: 0.9662 - val_f1score: 0.9671\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9704 - f1score: 0.9703\n",
      "Epoch 00020: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1058 - acc: 0.9696 - f1score: 0.9688 - val_loss: 0.1123 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00021: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1046 - acc: 0.9714 - f1score: 0.9714 - val_loss: 0.1146 - val_acc: 0.9678 - val_f1score: 0.9688\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9682 - f1score: 0.9682\n",
      "Epoch 00022: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1029 - acc: 0.9683 - f1score: 0.9682 - val_loss: 0.1139 - val_acc: 0.9678 - val_f1score: 0.9663\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9693 - f1score: 0.9692\n",
      "Epoch 00023: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1013 - acc: 0.9696 - f1score: 0.9698 - val_loss: 0.1123 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9696 - f1score: 0.9696\n",
      "Epoch 00024: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1024 - acc: 0.9701 - f1score: 0.9706 - val_loss: 0.1134 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9696 - f1score: 0.9696\n",
      "Epoch 00025: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1011 - acc: 0.9701 - f1score: 0.9706 - val_loss: 0.1138 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00026: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1012 - acc: 0.9693 - f1score: 0.9688 - val_loss: 0.1117 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00027: val_acc improved from 0.96781 to 0.96835, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.27-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1010 - acc: 0.9709 - f1score: 0.9700 - val_loss: 0.1094 - val_acc: 0.9683 - val_f1score: 0.9676\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9701 - f1score: 0.9701\n",
      "Epoch 00028: val_acc improved from 0.96835 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.28-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0992 - acc: 0.9706 - f1score: 0.9711 - val_loss: 0.1093 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9690 - f1score: 0.9690\n",
      "Epoch 00029: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0994 - acc: 0.9690 - f1score: 0.9690 - val_loss: 0.1102 - val_acc: 0.9673 - val_f1score: 0.9674\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9712 - f1score: 0.9711\n",
      "Epoch 00030: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0991 - acc: 0.9712 - f1score: 0.9711 - val_loss: 0.1088 - val_acc: 0.9683 - val_f1score: 0.9684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|         | 55/1296 [3:36:33<93:24:17, 270.96s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           42624       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           42624       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 84)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            170         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,647,788\n",
      "Trainable params: 85,688\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.4044 - acc: 0.6721 - f1score: 0.6890\n",
      "Epoch 00001: val_acc improved from -inf to 0.82511, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.81.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 1.4036 - acc: 0.6738 - f1score: 0.6922 - val_loss: 0.8141 - val_acc: 0.8251 - val_f1score: 0.8307\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.8037 - acc: 0.7920 - f1score: 0.7886\n",
      "Epoch 00002: val_acc improved from 0.82511 to 0.86964, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.39.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.8037 - acc: 0.7915 - f1score: 0.7880 - val_loss: 0.3868 - val_acc: 0.8696 - val_f1score: 0.8652\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4719 - acc: 0.8478 - f1score: 0.8468\n",
      "Epoch 00003: val_acc improved from 0.86964 to 0.89807, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.29.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.4812 - acc: 0.8474 - f1score: 0.8460 - val_loss: 0.2900 - val_acc: 0.8981 - val_f1score: 0.8976\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3236 - acc: 0.8979 - f1score: 0.8981\n",
      "Epoch 00004: val_acc improved from 0.89807 to 0.92221, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.25.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.3210 - acc: 0.8984 - f1score: 0.8990 - val_loss: 0.2460 - val_acc: 0.9222 - val_f1score: 0.9206\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2844 - acc: 0.9227 - f1score: 0.9225\n",
      "Epoch 00005: val_acc improved from 0.92221 to 0.92704, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.22.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.2861 - acc: 0.9222 - f1score: 0.9217 - val_loss: 0.2246 - val_acc: 0.9270 - val_f1score: 0.9277\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2372 - acc: 0.9278 - f1score: 0.9282\n",
      "Epoch 00006: val_acc improved from 0.92704 to 0.93884, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.20.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.2340 - acc: 0.9291 - f1score: 0.9306 - val_loss: 0.2030 - val_acc: 0.9388 - val_f1score: 0.9390\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1864 - acc: 0.9413 - f1score: 0.9414\n",
      "Epoch 00007: val_acc improved from 0.93884 to 0.95655, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.17.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1888 - acc: 0.9410 - f1score: 0.9409 - val_loss: 0.1737 - val_acc: 0.9565 - val_f1score: 0.9559\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1718 - acc: 0.9518 - f1score: 0.9519\n",
      "Epoch 00008: val_acc improved from 0.95655 to 0.95869, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.16.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1701 - acc: 0.9524 - f1score: 0.9530 - val_loss: 0.1593 - val_acc: 0.9587 - val_f1score: 0.9600\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1676 - acc: 0.9539 - f1score: 0.9540\n",
      "Epoch 00009: val_acc did not improve from 0.95869\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1666 - acc: 0.9540 - f1score: 0.9541 - val_loss: 0.1544 - val_acc: 0.9539 - val_f1score: 0.9553\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1434 - acc: 0.9582 - f1score: 0.9584\n",
      "Epoch 00010: val_acc improved from 0.95869 to 0.95923, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.15.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1421 - acc: 0.9579 - f1score: 0.9579 - val_loss: 0.1540 - val_acc: 0.9592 - val_f1score: 0.9581\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9661 - f1score: 0.9662\n",
      "Epoch 00011: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1344 - acc: 0.9667 - f1score: 0.9673 - val_loss: 0.1396 - val_acc: 0.9555 - val_f1score: 0.9544\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9636 - f1score: 0.9637\n",
      "Epoch 00012: val_acc did not improve from 0.95923\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1315 - acc: 0.9635 - f1score: 0.9634 - val_loss: 0.1315 - val_acc: 0.9582 - val_f1score: 0.9578\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9628 - f1score: 0.9629\n",
      "Epoch 00013: val_acc improved from 0.95923 to 0.96674, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.14.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1349 - acc: 0.9627 - f1score: 0.9626 - val_loss: 0.1368 - val_acc: 0.9667 - val_f1score: 0.9670\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9623 - f1score: 0.9624\n",
      "Epoch 00014: val_acc did not improve from 0.96674\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1267 - acc: 0.9619 - f1score: 0.9617 - val_loss: 0.1301 - val_acc: 0.9624 - val_f1score: 0.9625\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9647 - f1score: 0.9647\n",
      "Epoch 00015: val_acc improved from 0.96674 to 0.96835, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.15-0.13.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1152 - acc: 0.9653 - f1score: 0.9659 - val_loss: 0.1288 - val_acc: 0.9683 - val_f1score: 0.9669\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00016: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1145 - acc: 0.9667 - f1score: 0.9672 - val_loss: 0.1266 - val_acc: 0.9630 - val_f1score: 0.9634\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9669 - f1score: 0.9669\n",
      "Epoch 00017: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1110 - acc: 0.9667 - f1score: 0.9665 - val_loss: 0.1217 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9714 - f1score: 0.9714\n",
      "Epoch 00018: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1105 - acc: 0.9717 - f1score: 0.9719 - val_loss: 0.1225 - val_acc: 0.9624 - val_f1score: 0.9636\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9658 - f1score: 0.9658\n",
      "Epoch 00019: val_acc improved from 0.96835 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.19-0.13.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1165 - acc: 0.9664 - f1score: 0.9669 - val_loss: 0.1250 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9674 - f1score: 0.9673\n",
      "Epoch 00020: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1142 - acc: 0.9669 - f1score: 0.9665 - val_loss: 0.1191 - val_acc: 0.9651 - val_f1score: 0.9650\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9685 - f1score: 0.9686\n",
      "Epoch 00021: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1138 - acc: 0.9685 - f1score: 0.9686 - val_loss: 0.1178 - val_acc: 0.9689 - val_f1score: 0.9666\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9690 - f1score: 0.9691\n",
      "Epoch 00022: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1093 - acc: 0.9693 - f1score: 0.9696 - val_loss: 0.1163 - val_acc: 0.9683 - val_f1score: 0.9685\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9696 - f1score: 0.9696\n",
      "Epoch 00023: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1084 - acc: 0.9690 - f1score: 0.9686 - val_loss: 0.1172 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9736 - f1score: 0.9736\n",
      "Epoch 00024: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1046 - acc: 0.9728 - f1score: 0.9721 - val_loss: 0.1148 - val_acc: 0.9651 - val_f1score: 0.9654\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9690 - f1score: 0.9690\n",
      "Epoch 00025: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1092 - acc: 0.9680 - f1score: 0.9671 - val_loss: 0.1144 - val_acc: 0.9683 - val_f1score: 0.9685\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9674 - f1score: 0.9674\n",
      "Epoch 00026: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1024 - acc: 0.9675 - f1score: 0.9675 - val_loss: 0.1138 - val_acc: 0.9683 - val_f1score: 0.9685\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9698 - f1score: 0.9699\n",
      "Epoch 00027: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1020 - acc: 0.9704 - f1score: 0.9709 - val_loss: 0.1107 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9677 - f1score: 0.9677\n",
      "Epoch 00028: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1049 - acc: 0.9677 - f1score: 0.9678 - val_loss: 0.1131 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9739 - f1score: 0.9738\n",
      "Epoch 00029: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1009 - acc: 0.9738 - f1score: 0.9737 - val_loss: 0.1120 - val_acc: 0.9630 - val_f1score: 0.9616\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9679 - f1score: 0.9680\n",
      "Epoch 00030: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 7s 4ms/sample - loss: 0.1006 - acc: 0.9685 - f1score: 0.9690 - val_loss: 0.1110 - val_acc: 0.9689 - val_f1score: 0.9682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|         | 56/1296 [3:40:43<91:09:56, 264.67s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.0827 - acc: 0.7406 - f1score: 0.7352\n",
      "Epoch 00001: val_acc improved from -inf to 0.88090, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.43.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 1.0810 - acc: 0.7418 - f1score: 0.7378 - val_loss: 0.4274 - val_acc: 0.8809 - val_f1score: 0.8803\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5193 - acc: 0.8688 - f1score: 0.8695\n",
      "Epoch 00002: val_acc improved from 0.88090 to 0.92167, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.26.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5161 - acc: 0.8685 - f1score: 0.8691 - val_loss: 0.2588 - val_acc: 0.9217 - val_f1score: 0.9194\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3805 - acc: 0.8990 - f1score: 0.8992\n",
      "Epoch 00003: val_acc improved from 0.92167 to 0.94796, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.20.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.3805 - acc: 0.8992 - f1score: 0.8996 - val_loss: 0.2024 - val_acc: 0.9480 - val_f1score: 0.9468\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2828 - acc: 0.9310 - f1score: 0.9310\n",
      "Epoch 00004: val_acc improved from 0.94796 to 0.95064, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.18.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.2837 - acc: 0.9310 - f1score: 0.9308 - val_loss: 0.1846 - val_acc: 0.9506 - val_f1score: 0.9521\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2410 - acc: 0.9391 - f1score: 0.9393\n",
      "Epoch 00005: val_acc improved from 0.95064 to 0.95225, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.19.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2400 - acc: 0.9389 - f1score: 0.9389 - val_loss: 0.1899 - val_acc: 0.9523 - val_f1score: 0.9495\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2128 - acc: 0.9477 - f1score: 0.9476\n",
      "Epoch 00006: val_acc improved from 0.95225 to 0.95440, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.18.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.2105 - acc: 0.9481 - f1score: 0.9484 - val_loss: 0.1808 - val_acc: 0.9544 - val_f1score: 0.9547\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1718 - acc: 0.9537 - f1score: 0.9537\n",
      "Epoch 00007: val_acc improved from 0.95440 to 0.96084, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.16.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1718 - acc: 0.9534 - f1score: 0.9533 - val_loss: 0.1589 - val_acc: 0.9608 - val_f1score: 0.9620\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9545 - f1score: 0.9545\n",
      "Epoch 00008: val_acc did not improve from 0.96084\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1650 - acc: 0.9545 - f1score: 0.9546 - val_loss: 0.1620 - val_acc: 0.9571 - val_f1score: 0.9583\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9609 - f1score: 0.9609\n",
      "Epoch 00009: val_acc did not improve from 0.96084\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1409 - acc: 0.9606 - f1score: 0.9603 - val_loss: 0.3627 - val_acc: 0.8487 - val_f1score: 0.8521\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9569 - f1score: 0.9570\n",
      "Epoch 00010: val_acc improved from 0.96084 to 0.96191, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.15.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1462 - acc: 0.9574 - f1score: 0.9579 - val_loss: 0.1482 - val_acc: 0.9619 - val_f1score: 0.9623\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9636 - f1score: 0.9636\n",
      "Epoch 00011: val_acc improved from 0.96191 to 0.96459, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.11-0.13.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1280 - acc: 0.9632 - f1score: 0.9628 - val_loss: 0.1270 - val_acc: 0.9646 - val_f1score: 0.9648\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9652 - f1score: 0.9653\n",
      "Epoch 00012: val_acc did not improve from 0.96459\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1241 - acc: 0.9653 - f1score: 0.9654 - val_loss: 0.1240 - val_acc: 0.9528 - val_f1score: 0.9527\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9674 - f1score: 0.9675\n",
      "Epoch 00013: val_acc improved from 0.96459 to 0.96727, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.13-0.12.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1131 - acc: 0.9675 - f1score: 0.9676 - val_loss: 0.1208 - val_acc: 0.9673 - val_f1score: 0.9666\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9661 - f1score: 0.9661\n",
      "Epoch 00014: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1184 - acc: 0.9659 - f1score: 0.9658 - val_loss: 0.1203 - val_acc: 0.9587 - val_f1score: 0.9585\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9701 - f1score: 0.9701\n",
      "Epoch 00015: val_acc improved from 0.96727 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.15-0.12.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1143 - acc: 0.9701 - f1score: 0.9701 - val_loss: 0.1215 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00016: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1158 - acc: 0.9672 - f1score: 0.9672 - val_loss: 0.1150 - val_acc: 0.9673 - val_f1score: 0.9666\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00017: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1099 - acc: 0.9677 - f1score: 0.9682 - val_loss: 0.1188 - val_acc: 0.9651 - val_f1score: 0.9654\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1094 - acc: 0.9658 - f1score: 0.9658\n",
      "Epoch 00018: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1083 - acc: 0.9659 - f1score: 0.9659 - val_loss: 0.1151 - val_acc: 0.9673 - val_f1score: 0.9666\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9717 - f1score: 0.9717\n",
      "Epoch 00019: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1012 - acc: 0.9717 - f1score: 0.9716 - val_loss: 0.1160 - val_acc: 0.9614 - val_f1score: 0.9618\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9679 - f1score: 0.9680\n",
      "Epoch 00020: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1055 - acc: 0.9680 - f1score: 0.9681 - val_loss: 0.1242 - val_acc: 0.9673 - val_f1score: 0.9683\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00021: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0992 - acc: 0.9704 - f1score: 0.9699 - val_loss: 0.1163 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9690 - f1score: 0.9690\n",
      "Epoch 00022: val_acc improved from 0.96781 to 0.96835, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.22-0.11.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.1037 - acc: 0.9690 - f1score: 0.9691 - val_loss: 0.1118 - val_acc: 0.9683 - val_f1score: 0.9685\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9706 - f1score: 0.9706\n",
      "Epoch 00023: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0992 - acc: 0.9706 - f1score: 0.9706 - val_loss: 0.1121 - val_acc: 0.9683 - val_f1score: 0.9669\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9712 - f1score: 0.9712\n",
      "Epoch 00024: val_acc improved from 0.96835 to 0.96942, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.24-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1002 - acc: 0.9706 - f1score: 0.9702 - val_loss: 0.1137 - val_acc: 0.9694 - val_f1score: 0.9695\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00025: val_acc did not improve from 0.96942\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0987 - acc: 0.9709 - f1score: 0.9708 - val_loss: 0.1126 - val_acc: 0.9673 - val_f1score: 0.9666\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00026: val_acc improved from 0.96942 to 0.96996, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.26-0.11.h5\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0980 - acc: 0.9704 - f1score: 0.9708 - val_loss: 0.1115 - val_acc: 0.9700 - val_f1score: 0.9708\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9723 - f1score: 0.9723\n",
      "Epoch 00027: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0959 - acc: 0.9722 - f1score: 0.9722 - val_loss: 0.1126 - val_acc: 0.9694 - val_f1score: 0.9679\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9701 - f1score: 0.9701\n",
      "Epoch 00028: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0963 - acc: 0.9701 - f1score: 0.9701 - val_loss: 0.1090 - val_acc: 0.9694 - val_f1score: 0.9695\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00029: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0946 - acc: 0.9725 - f1score: 0.9729 - val_loss: 0.1161 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9720 - f1score: 0.9720\n",
      "Epoch 00030: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0953 - acc: 0.9720 - f1score: 0.9719 - val_loss: 0.1074 - val_acc: 0.9689 - val_f1score: 0.9682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|         | 57/1296 [3:45:16<91:56:56, 267.16s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           93440       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           93440       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 148)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            298         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,749,548\n",
      "Trainable params: 187,448\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.9224 - acc: 0.6339 - f1score: 0.5845\n",
      "Epoch 00001: val_acc improved from -inf to 0.84496, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.43.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.9113 - acc: 0.6389 - f1score: 0.5956 - val_loss: 0.4292 - val_acc: 0.8450 - val_f1score: 0.8475\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2733 - acc: 0.9071 - f1score: 0.9078\n",
      "Epoch 00002: val_acc improved from 0.84496 to 0.92704, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.23.h5\n",
      "1890/1890 [==============================] - 9s 5ms/sample - loss: 0.2709 - acc: 0.9077 - f1score: 0.9090 - val_loss: 0.2339 - val_acc: 0.9270 - val_f1score: 0.9288\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1864 - acc: 0.9386 - f1score: 0.9387\n",
      "Epoch 00003: val_acc improved from 0.92704 to 0.93938, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.18.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1844 - acc: 0.9397 - f1score: 0.9408 - val_loss: 0.1818 - val_acc: 0.9394 - val_f1score: 0.9382\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9512 - f1score: 0.9512\n",
      "Epoch 00004: val_acc improved from 0.93938 to 0.94635, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.16.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1533 - acc: 0.9519 - f1score: 0.9523 - val_loss: 0.1578 - val_acc: 0.9464 - val_f1score: 0.9459\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9585 - f1score: 0.9586\n",
      "Epoch 00005: val_acc improved from 0.94635 to 0.95333, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.05-0.15.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1441 - acc: 0.9569 - f1score: 0.9555 - val_loss: 0.1519 - val_acc: 0.9533 - val_f1score: 0.9508\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9607 - f1score: 0.9606\n",
      "Epoch 00006: val_acc improved from 0.95333 to 0.96030, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.15.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1323 - acc: 0.9603 - f1score: 0.9600 - val_loss: 0.1476 - val_acc: 0.9603 - val_f1score: 0.9595\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9634 - f1score: 0.9633\n",
      "Epoch 00007: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1223 - acc: 0.9632 - f1score: 0.9630 - val_loss: 0.1406 - val_acc: 0.9603 - val_f1score: 0.9609\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9628 - f1score: 0.9627\n",
      "Epoch 00008: val_acc did not improve from 0.96030\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1177 - acc: 0.9635 - f1score: 0.9640 - val_loss: 0.1346 - val_acc: 0.9544 - val_f1score: 0.9550\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9652 - f1score: 0.9652\n",
      "Epoch 00009: val_acc improved from 0.96030 to 0.96352, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.09-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1176 - acc: 0.9653 - f1score: 0.9654 - val_loss: 0.1233 - val_acc: 0.9635 - val_f1score: 0.9615\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9666 - f1score: 0.9665\n",
      "Epoch 00010: val_acc improved from 0.96352 to 0.96567, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.10-0.13.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1112 - acc: 0.9672 - f1score: 0.9676 - val_loss: 0.1257 - val_acc: 0.9657 - val_f1score: 0.9649\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9682 - f1score: 0.9681\n",
      "Epoch 00011: val_acc did not improve from 0.96567\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1092 - acc: 0.9688 - f1score: 0.9692 - val_loss: 0.1254 - val_acc: 0.9641 - val_f1score: 0.9643\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9690 - f1score: 0.9690\n",
      "Epoch 00012: val_acc improved from 0.96567 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.12-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1107 - acc: 0.9696 - f1score: 0.9701 - val_loss: 0.1201 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00013: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1077 - acc: 0.9677 - f1score: 0.9682 - val_loss: 0.1179 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00014: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1081 - acc: 0.9688 - f1score: 0.9683 - val_loss: 0.1137 - val_acc: 0.9662 - val_f1score: 0.9651\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9698 - f1score: 0.9698\n",
      "Epoch 00015: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1060 - acc: 0.9698 - f1score: 0.9698 - val_loss: 0.1152 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9693 - f1score: 0.9691\n",
      "Epoch 00016: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1022 - acc: 0.9693 - f1score: 0.9692 - val_loss: 0.1212 - val_acc: 0.9673 - val_f1score: 0.9666\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9712 - f1score: 0.9711\n",
      "Epoch 00017: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1023 - acc: 0.9712 - f1score: 0.9711 - val_loss: 0.1124 - val_acc: 0.9641 - val_f1score: 0.9651\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9685 - f1score: 0.9684\n",
      "Epoch 00018: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1043 - acc: 0.9680 - f1score: 0.9675 - val_loss: 0.1118 - val_acc: 0.9667 - val_f1score: 0.9677\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9709 - f1score: 0.9709\n",
      "Epoch 00019: val_acc improved from 0.96781 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.19-0.11.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.0987 - acc: 0.9709 - f1score: 0.9709 - val_loss: 0.1108 - val_acc: 0.9689 - val_f1score: 0.9690\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9717 - f1score: 0.9717\n",
      "Epoch 00020: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1024 - acc: 0.9712 - f1score: 0.9707 - val_loss: 0.1137 - val_acc: 0.9635 - val_f1score: 0.9646\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9679 - f1score: 0.9679\n",
      "Epoch 00021: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1025 - acc: 0.9685 - f1score: 0.9690 - val_loss: 0.1151 - val_acc: 0.9678 - val_f1score: 0.9679\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9712 - f1score: 0.9711\n",
      "Epoch 00022: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0996 - acc: 0.9717 - f1score: 0.9721 - val_loss: 0.1126 - val_acc: 0.9678 - val_f1score: 0.9671\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9704 - f1score: 0.9704\n",
      "Epoch 00023: val_acc improved from 0.96888 to 0.96996, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.23-0.11.h5\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.0990 - acc: 0.9709 - f1score: 0.9714 - val_loss: 0.1091 - val_acc: 0.9700 - val_f1score: 0.9692\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9696 - f1score: 0.9695\n",
      "Epoch 00024: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.1007 - acc: 0.9696 - f1score: 0.9696 - val_loss: 0.1095 - val_acc: 0.9700 - val_f1score: 0.9700\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00025: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0957 - acc: 0.9720 - f1score: 0.9715 - val_loss: 0.1133 - val_acc: 0.9683 - val_f1score: 0.9685\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9706 - f1score: 0.9706\n",
      "Epoch 00026: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0936 - acc: 0.9706 - f1score: 0.9706 - val_loss: 0.1081 - val_acc: 0.9694 - val_f1score: 0.9695\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9717 - f1score: 0.9717\n",
      "Epoch 00027: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0970 - acc: 0.9722 - f1score: 0.9726 - val_loss: 0.1083 - val_acc: 0.9694 - val_f1score: 0.9695\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9731 - f1score: 0.9731\n",
      "Epoch 00028: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0933 - acc: 0.9725 - f1score: 0.9720 - val_loss: 0.1093 - val_acc: 0.9673 - val_f1score: 0.9683\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9717 - f1score: 0.9717\n",
      "Epoch 00029: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0936 - acc: 0.9712 - f1score: 0.9707 - val_loss: 0.1079 - val_acc: 0.9700 - val_f1score: 0.9692\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9725 - f1score: 0.9725\n",
      "Epoch 00030: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 8s 4ms/sample - loss: 0.0935 - acc: 0.9725 - f1score: 0.9725 - val_loss: 0.1080 - val_acc: 0.9700 - val_f1score: 0.9692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|         | 58/1296 [3:49:52<92:48:08, 269.86s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 4.1775 - acc: 0.4976 - f1score: 0.4842\n",
      "Epoch 00001: val_acc improved from -inf to 0.88734, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.41.h5\n",
      "1890/1890 [==============================] - 14s 8ms/sample - loss: 4.1153 - acc: 0.5037 - f1score: 0.4959 - val_loss: 0.4099 - val_acc: 0.8873 - val_f1score: 0.8871\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.7477 - acc: 0.8895 - f1score: 0.8911\n",
      "Epoch 00002: val_acc improved from 0.88734 to 0.93187, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.32.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.7477 - acc: 0.8902 - f1score: 0.8922 - val_loss: 0.3236 - val_acc: 0.9319 - val_f1score: 0.9316\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5779 - acc: 0.9062 - f1score: 0.9074\n",
      "Epoch 00003: val_acc improved from 0.93187 to 0.93509, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.30.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.5796 - acc: 0.9058 - f1score: 0.9067 - val_loss: 0.3006 - val_acc: 0.9351 - val_f1score: 0.9355\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.5468 - acc: 0.9044 - f1score: 0.9051\n",
      "Epoch 00004: val_acc did not improve from 0.93509\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.5377 - acc: 0.9058 - f1score: 0.9078 - val_loss: 0.2952 - val_acc: 0.9345 - val_f1score: 0.9332\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.4528 - acc: 0.9189 - f1score: 0.9189\n",
      "Epoch 00005: val_acc did not improve from 0.93509\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.4469 - acc: 0.9193 - f1score: 0.9196 - val_loss: 0.2943 - val_acc: 0.9313 - val_f1score: 0.9317\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3705 - acc: 0.9291 - f1score: 0.9291\n",
      "Epoch 00006: val_acc improved from 0.93509 to 0.94474, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.06-0.27.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.3749 - acc: 0.9286 - f1score: 0.9281 - val_loss: 0.2714 - val_acc: 0.9447 - val_f1score: 0.9455\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3017 - acc: 0.9394 - f1score: 0.9393\n",
      "Epoch 00007: val_acc improved from 0.94474 to 0.95064, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.07-0.22.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.3020 - acc: 0.9392 - f1score: 0.9390 - val_loss: 0.2247 - val_acc: 0.9506 - val_f1score: 0.9501\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2451 - acc: 0.9475 - f1score: 0.9475\n",
      "Epoch 00008: val_acc improved from 0.95064 to 0.95815, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.20.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.2506 - acc: 0.9463 - f1score: 0.9453 - val_loss: 0.1954 - val_acc: 0.9582 - val_f1score: 0.9569\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2100 - acc: 0.9477 - f1score: 0.9478\n",
      "Epoch 00009: val_acc did not improve from 0.95815\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.2107 - acc: 0.9471 - f1score: 0.9466 - val_loss: 0.1718 - val_acc: 0.9442 - val_f1score: 0.9435\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1808 - acc: 0.9515 - f1score: 0.9517\n",
      "Epoch 00010: val_acc did not improve from 0.95815\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1791 - acc: 0.9519 - f1score: 0.9523 - val_loss: 0.1694 - val_acc: 0.9464 - val_f1score: 0.9462\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1643 - acc: 0.9526 - f1score: 0.9527\n",
      "Epoch 00011: val_acc improved from 0.95815 to 0.96137, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.11-0.15.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1624 - acc: 0.9532 - f1score: 0.9538 - val_loss: 0.1468 - val_acc: 0.9614 - val_f1score: 0.9625\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9545 - f1score: 0.9546\n",
      "Epoch 00012: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1526 - acc: 0.9537 - f1score: 0.9531 - val_loss: 0.1372 - val_acc: 0.9512 - val_f1score: 0.9491\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9591 - f1score: 0.9590\n",
      "Epoch 00013: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1338 - acc: 0.9593 - f1score: 0.9594 - val_loss: 0.1317 - val_acc: 0.9549 - val_f1score: 0.9536\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9604 - f1score: 0.9603\n",
      "Epoch 00014: val_acc improved from 0.96137 to 0.96191, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.14-0.13.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1252 - acc: 0.9606 - f1score: 0.9606 - val_loss: 0.1326 - val_acc: 0.9619 - val_f1score: 0.9628\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9599 - f1score: 0.9598\n",
      "Epoch 00015: val_acc did not improve from 0.96191\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1300 - acc: 0.9606 - f1score: 0.9612 - val_loss: 0.1362 - val_acc: 0.9619 - val_f1score: 0.9628\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9596 - f1score: 0.9596\n",
      "Epoch 00016: val_acc did not improve from 0.96191\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1182 - acc: 0.9603 - f1score: 0.9609 - val_loss: 0.1238 - val_acc: 0.9608 - val_f1score: 0.9615\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00017: val_acc improved from 0.96191 to 0.96406, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.17-0.12.h5\n",
      "1890/1890 [==============================] - 14s 7ms/sample - loss: 0.1166 - acc: 0.9646 - f1score: 0.9637 - val_loss: 0.1245 - val_acc: 0.9641 - val_f1score: 0.9641\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9671 - f1score: 0.9670\n",
      "Epoch 00018: val_acc improved from 0.96406 to 0.96781, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.18-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1086 - acc: 0.9672 - f1score: 0.9671 - val_loss: 0.1195 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9655 - f1score: 0.9655\n",
      "Epoch 00019: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1078 - acc: 0.9656 - f1score: 0.9657 - val_loss: 0.1224 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9696 - f1score: 0.9696\n",
      "Epoch 00020: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1089 - acc: 0.9696 - f1score: 0.9696 - val_loss: 0.1212 - val_acc: 0.9549 - val_f1score: 0.9538\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9663 - f1score: 0.9663\n",
      "Epoch 00021: val_acc did not improve from 0.96781\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1073 - acc: 0.9659 - f1score: 0.9655 - val_loss: 0.1151 - val_acc: 0.9576 - val_f1score: 0.9549\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9644 - f1score: 0.9644\n",
      "Epoch 00022: val_acc improved from 0.96781 to 0.96835, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.22-0.11.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1113 - acc: 0.9646 - f1score: 0.9646 - val_loss: 0.1139 - val_acc: 0.9683 - val_f1score: 0.9684\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9679 - f1score: 0.9679\n",
      "Epoch 00023: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1057 - acc: 0.9685 - f1score: 0.9690 - val_loss: 0.1267 - val_acc: 0.9667 - val_f1score: 0.9661\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9647 - f1score: 0.9647\n",
      "Epoch 00024: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1081 - acc: 0.9648 - f1score: 0.9649 - val_loss: 0.1174 - val_acc: 0.9683 - val_f1score: 0.9693\n",
      "Epoch 25/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9650 - f1score: 0.9650\n",
      "Epoch 00025: val_acc did not improve from 0.96835\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1044 - acc: 0.9656 - f1score: 0.9662 - val_loss: 0.1154 - val_acc: 0.9678 - val_f1score: 0.9687\n",
      "Epoch 26/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9671 - f1score: 0.9671\n",
      "Epoch 00026: val_acc improved from 0.96835 to 0.96888, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.26-0.11.h5\n",
      "1890/1890 [==============================] - 14s 7ms/sample - loss: 0.1036 - acc: 0.9667 - f1score: 0.9662 - val_loss: 0.1103 - val_acc: 0.9689 - val_f1score: 0.9694\n",
      "Epoch 27/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9658 - f1score: 0.9657\n",
      "Epoch 00027: val_acc did not improve from 0.96888\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1018 - acc: 0.9664 - f1score: 0.9669 - val_loss: 0.1147 - val_acc: 0.9683 - val_f1score: 0.9693\n",
      "Epoch 28/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9677 - f1score: 0.9676\n",
      "Epoch 00028: val_acc improved from 0.96888 to 0.96996, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.28-0.11.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1016 - acc: 0.9672 - f1score: 0.9668 - val_loss: 0.1117 - val_acc: 0.9700 - val_f1score: 0.9687\n",
      "Epoch 29/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9647 - f1score: 0.9647\n",
      "Epoch 00029: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1038 - acc: 0.9653 - f1score: 0.9658 - val_loss: 0.1200 - val_acc: 0.9683 - val_f1score: 0.9684\n",
      "Epoch 30/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9688 - f1score: 0.9687\n",
      "Epoch 00030: val_acc did not improve from 0.96996\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1021 - acc: 0.9688 - f1score: 0.9688 - val_loss: 0.1113 - val_acc: 0.9683 - val_f1score: 0.9677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  5%|         | 59/1296 [3:55:42<100:58:23, 293.86s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function standard_lstm at 0x7f3df567d1e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function standard_lstm at 0x7f3df567d1e0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function cudnn_lstm at 0x7f3df567d268> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function cudnn_lstm at 0x7f3df567d268>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1500)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           20          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1500, 300)    7503300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 5, 300)       58800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          219648      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 276)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            554         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 8,002,220\n",
      "Trainable params: 440,120\n",
      "Non-trainable params: 7,562,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1890 samples, validate on 932 samples\n",
      "Epoch 1/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 1.1374 - acc: 0.6530 - f1score: 0.6376\n",
      "Epoch 00001: val_acc improved from -inf to 0.85032, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.01-0.41.h5\n",
      "1890/1890 [==============================] - 14s 7ms/sample - loss: 1.1315 - acc: 0.6548 - f1score: 0.6420 - val_loss: 0.4133 - val_acc: 0.8503 - val_f1score: 0.8634\n",
      "Epoch 2/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.3222 - acc: 0.9038 - f1score: 0.9047\n",
      "Epoch 00002: val_acc improved from 0.85032 to 0.92543, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.02-0.24.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.3216 - acc: 0.9037 - f1score: 0.9043 - val_loss: 0.2358 - val_acc: 0.9254 - val_f1score: 0.9253\n",
      "Epoch 3/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.2280 - acc: 0.9294 - f1score: 0.9295\n",
      "Epoch 00003: val_acc improved from 0.92543 to 0.92918, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.03-0.20.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.2264 - acc: 0.9296 - f1score: 0.9299 - val_loss: 0.1973 - val_acc: 0.9292 - val_f1score: 0.9302\n",
      "Epoch 4/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1669 - acc: 0.9477 - f1score: 0.9477\n",
      "Epoch 00004: val_acc improved from 0.92918 to 0.95064, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.04-0.17.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1679 - acc: 0.9471 - f1score: 0.9465 - val_loss: 0.1664 - val_acc: 0.9506 - val_f1score: 0.9514\n",
      "Epoch 5/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9555 - f1score: 0.9555\n",
      "Epoch 00005: val_acc did not improve from 0.95064\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1487 - acc: 0.9550 - f1score: 0.9546 - val_loss: 0.1812 - val_acc: 0.9426 - val_f1score: 0.9407\n",
      "Epoch 6/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9582 - f1score: 0.9581\n",
      "Epoch 00006: val_acc did not improve from 0.95064\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1480 - acc: 0.9579 - f1score: 0.9575 - val_loss: 0.1531 - val_acc: 0.9501 - val_f1score: 0.9497\n",
      "Epoch 7/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9572 - f1score: 0.9571\n",
      "Epoch 00007: val_acc did not improve from 0.95064\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1446 - acc: 0.9569 - f1score: 0.9566 - val_loss: 0.1581 - val_acc: 0.9431 - val_f1score: 0.9433\n",
      "Epoch 8/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1327 - acc: 0.9631 - f1score: 0.9630\n",
      "Epoch 00008: val_acc improved from 0.95064 to 0.95386, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.08-0.14.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1314 - acc: 0.9635 - f1score: 0.9638 - val_loss: 0.1414 - val_acc: 0.9539 - val_f1score: 0.9554\n",
      "Epoch 9/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9631 - f1score: 0.9631\n",
      "Epoch 00009: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1325 - acc: 0.9624 - f1score: 0.9618 - val_loss: 0.1427 - val_acc: 0.9523 - val_f1score: 0.9529\n",
      "Epoch 10/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9591 - f1score: 0.9590\n",
      "Epoch 00010: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1273 - acc: 0.9593 - f1score: 0.9594 - val_loss: 0.1429 - val_acc: 0.9501 - val_f1score: 0.9500\n",
      "Epoch 11/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9582 - f1score: 0.9582\n",
      "Epoch 00011: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1300 - acc: 0.9585 - f1score: 0.9586 - val_loss: 0.1439 - val_acc: 0.9523 - val_f1score: 0.9527\n",
      "Epoch 12/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9626 - f1score: 0.9625\n",
      "Epoch 00012: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1263 - acc: 0.9606 - f1score: 0.9589 - val_loss: 0.1445 - val_acc: 0.9442 - val_f1score: 0.9450\n",
      "Epoch 13/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9617 - f1score: 0.9618\n",
      "Epoch 00013: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1211 - acc: 0.9614 - f1score: 0.9611 - val_loss: 0.1358 - val_acc: 0.9480 - val_f1score: 0.9496\n",
      "Epoch 14/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9604 - f1score: 0.9605\n",
      "Epoch 00014: val_acc did not improve from 0.95386\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1197 - acc: 0.9601 - f1score: 0.9598 - val_loss: 0.1374 - val_acc: 0.9469 - val_f1score: 0.9465\n",
      "Epoch 15/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9612 - f1score: 0.9613\n",
      "Epoch 00015: val_acc improved from 0.95386 to 0.95923, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.15-0.14.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1170 - acc: 0.9601 - f1score: 0.9591 - val_loss: 0.1424 - val_acc: 0.9592 - val_f1score: 0.9606\n",
      "Epoch 16/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9607 - f1score: 0.9606\n",
      "Epoch 00016: val_acc improved from 0.95923 to 0.96137, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.16-0.13.h5\n",
      "1890/1890 [==============================] - 12s 6ms/sample - loss: 0.1156 - acc: 0.9614 - f1score: 0.9619 - val_loss: 0.1327 - val_acc: 0.9614 - val_f1score: 0.9613\n",
      "Epoch 17/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9628 - f1score: 0.9628\n",
      "Epoch 00017: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1148 - acc: 0.9635 - f1score: 0.9641 - val_loss: 0.1315 - val_acc: 0.9565 - val_f1score: 0.9571\n",
      "Epoch 18/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9636 - f1score: 0.9637\n",
      "Epoch 00018: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 10s 6ms/sample - loss: 0.1117 - acc: 0.9638 - f1score: 0.9639 - val_loss: 0.1254 - val_acc: 0.9587 - val_f1score: 0.9600\n",
      "Epoch 19/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9634 - f1score: 0.9634\n",
      "Epoch 00019: val_acc did not improve from 0.96137\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1100 - acc: 0.9635 - f1score: 0.9636 - val_loss: 0.1230 - val_acc: 0.9501 - val_f1score: 0.9483\n",
      "Epoch 20/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9642 - f1score: 0.9642\n",
      "Epoch 00020: val_acc improved from 0.96137 to 0.96245, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.20-0.12.h5\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1108 - acc: 0.9643 - f1score: 0.9644 - val_loss: 0.1217 - val_acc: 0.9624 - val_f1score: 0.9627\n",
      "Epoch 21/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9696 - f1score: 0.9696\n",
      "Epoch 00021: val_acc did not improve from 0.96245\n",
      "1890/1890 [==============================] - 10s 5ms/sample - loss: 0.1046 - acc: 0.9690 - f1score: 0.9686 - val_loss: 0.1185 - val_acc: 0.9619 - val_f1score: 0.9621\n",
      "Epoch 22/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9666 - f1score: 0.9666\n",
      "Epoch 00022: val_acc improved from 0.96245 to 0.96298, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.22-0.14.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1012 - acc: 0.9661 - f1score: 0.9658 - val_loss: 0.1354 - val_acc: 0.9630 - val_f1score: 0.9641\n",
      "Epoch 23/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9690 - f1score: 0.9690\n",
      "Epoch 00023: val_acc improved from 0.96298 to 0.96727, saving model to /content/drive/My Drive/LSTM_model_spatio_temporal/model.23-0.12.h5\n",
      "1890/1890 [==============================] - 13s 7ms/sample - loss: 0.1027 - acc: 0.9685 - f1score: 0.9680 - val_loss: 0.1206 - val_acc: 0.9673 - val_f1score: 0.9666\n",
      "Epoch 24/30\n",
      "1856/1890 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9693 - f1score: 0.9693\n",
      "Epoch 00024: val_acc did not improve from 0.96727\n",
      "1890/1890 [==============================] - 11s 6ms/sample - loss: 0.1021 - acc: 0.9693 - f1score: 0.9693 - val_loss: 0.1163 - val_acc: 0.9646 - val_f1score: 0.9632\n",
      "Epoch 25/30\n",
      "1344/1890 [====================>.........] - ETA: 2s - loss: 0.1027 - acc: 0.9695 - f1score: 0.9694"
     ]
    }
   ],
   "source": [
    "scan_object = talos.Scan(x=[X1_train, X2_train, X3_train, X4_train],\n",
    "                         y=y_train,\n",
    "                         x_val=[X1_val, X2_val, X3_val, X4_val],\n",
    "                         y_val=y_val,\n",
    "                         params=p,\n",
    "                         model=lstm_model,\n",
    "                         experiment_name=\"LSTM Model with spatial data\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Country_Date.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
